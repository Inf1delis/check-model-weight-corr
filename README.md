# check-model-weight-corr

> Проверил на
> [mistralai/Mistral-Nemo-Instruct-2407/](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407/)
> и
> [Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24](https://huggingface.co/Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24),
>там корреляции в районе единицы, что говорит о прямом наследовании модели (об этом авторы `Vikhr-Nemo-12B` пишут прямо в карточке на HuggingFace). Корреляции в файле [check_corr_nemo_12b.csv](./check_corr_nemo_12b.csv)

Небольшой инструмент для **покомпонентного сравнения весов двух LLM-чекпоинтов**. Считает набор метрик похожести для каждого тензора (по ключам), с агрегацией по слоям и отдельным анализом LayerNorm/bias.

Основной сценарий: быстро проверить, *насколько и где именно* два чекпоинта похожи/разошлись, не сваливая всё в одно усреднение по модели.  
Отдельно добавлен **спектральный (SVD) анализ**, который устойчив к допустимым перестановкам нейронов/голов и смене базиса.

---

## Возможности

* **Стриминговая загрузка**: веса читаются по слоям и по файлам `.safetensors`, без полного загрузочного пика по памяти.
* **Сопоставление по ключам**: сравниваются только тензоры с совпавшими именами.
* **Пропуск MoE-экспертов** по умолчанию (см. `DEFAULT_SKIP_REGEXES`).
* **Набор метрик похожести** на уровне каждого тензора.
* **Спектральные метрики (SVD)** для permutation-invariant сравнения.
* **Отдельный буфер для LayerNorm и bias** и отдельная статистика по ним.
* **CSV-выгрузка** и агрегации per-layer.

---

## Установка

Минимальные зависимости:

```bash
pip install torch pandas numpy safetensors
````

(Используется только чтение safetensors через `safe_open`, никаких HF-зависимостей не нужно.)

---

## Как это работает

1. **Индексация**: строим лёгкий индекс `layer -> {key: filepath}` для каждого из двух чекпоинтов (`build_layer_index`).

   * Ключи, попадающие под `DEFAULT_SKIP_REGEXES` (например, `\.experts\.`), игнорируются ещё на этапе индексации/загрузки.
2. **Сравнение по слоям** (`compare_models_streaming`):

   * Идём по `layer_id` от `0` до `NUM_LAYERS-1`.
   * Находим пересечение ключей.
   * Подгружаем нужные тензоры `safe_open`-ом по требованию.
   * Считаем метрики и складываем строки в DataFrame.
3. **Сводка** (`summarize_results`):

   * Отбрасываем несовпавшие по форме тензоры.
   * Отдельно считаем статистику для LayerNorm/bias и для остальных весов.
   * Делаем per-layer mean по метрикам.

---

## Метрики

### Базовые метрики (по элементам тензора)

Для каждого совпавшего тензора считаются:

* **cos_sim** — cosine similarity между флеттен-векторами. Показывает совпадение *направления* в пространстве весов. Не чувствителен к общему масштабу.
* **pearson** — линейная корреляция по элементам (после вычитания среднего).
* **spearman** (опционально, с сэмплингом) — ранговая корреляция.
* **rel_l2_err** — относительная L2-ошибка `||a - b|| / ||a||`.
* **mean_rel_diff / max_rel_diff** — средняя/максимальная относительная |diff| по элементам.
* **mean_abs_diff / max_abs_diff** — средняя/максимальная абсолютная |diff|.
* **norm_ratio / mean_ratio / std_ratio** — отношение норм/средних/стандартных отклонений.
* **q01/q05/q50/q95/q99_abs_diff** — квантили абсолютной разницы (с optional сэмплингом для скорости).
* **zero_frac_a / zero_frac_b** — доля нулей.

Почему так много метрик:

* одна метрика часто скрывает важные эффекты;
* например, `cos_sim ≈ 1` может сочетаться с высокой `rel_l2_err`, если совпало лишь доминирующее подпространство;
* а высокая корреляция (Pearson/Spearman) может быть при отличающемся масштабе.

### Спектральные метрики (SVD)

> см. ноутбук [check_corr-spectrum.ipynb](./check_corr-spectrum.ipynb) и файл с результатами [check_corr_spectrum.csv](./check_corr_spectrum.csv)

Спектральный блок сравнивает тензоры как линейные операторы, устойчиво к:

* перестановкам скрытых размерностей/голов,
* флипам знаков сингулярных векторов,
* смене базиса внутри топ-k подпространства.

Как считается:

1. Тензор приводится к 2D-матрице (если ndim>2 — склеиваются все оси кроме первой).
2. Делается SVD:
   `A = Ua diag(Sa) Vha`, `B = Ub diag(Sb) Vhb`.

Метрики:

* **spec_rel_l2_err** — относительная L2-ошибка между спектрами `Sa` и `Sb`.
  Маленькая → спектры совпадают.

* **spec_a_max/min**, **spec_b_max/min** — крайние сингулярные значения (масштаб/конд. матрицы).

* **spec_topk_u_cos_mean/min** — средняя/минимальная |cos| между соответствующими левыми сингулярными векторами `Ua_k` и `Ub_k`.

* **spec_topk_v_cos_mean/min** — то же для правых сингулярных векторов `V_k`.
  Высокие значения → совпадают главные направления.

* **spec_subspace_overlap_u/v** — перекрытие топ-k подпространств:
  `||Ua_k^T Ub_k||_F / k` (аналогично для V).
  Это основной permutation-invariant сигнал:
  overlap ~1 → «та же математика» (в т.ч. после пермутаций),
  overlap ~0 → независимые веса.

Практика: если высокая похожесть наблюдается только на LN/bias, а для остальных тензоров overlap и top-k cos около нуля — это обычно означает независимое обучение.

---

## Почему LayerNorm и bias анализируются отдельно

В `summarize_results` мы делим тензоры на:

* **LayerNorm/bias** (`is_layernorm_key`) — ключи, оканчивающиеся на `*.layernorm.weight`, `*.ln.weight`, и т.п., плюс некоторые bias-ключи.
* **Остальные веса** (attention/MLP/embeddings и т.д.).

Причины:

1. **Другие статистические свойства.**
   LN-параметры и bias обычно маленькие по размеру, с другим распределением и динамикой, поэтому искажают общие агрегаты.

2. **Их роль — калибровка, а не «знание».**
   Основное содержание модели сидит в матрицах проекций attention/MLP.

3. **Есть инвариантности.**
   Нормализации компенсируют часть сдвигов/масштабов, поэтому LN/bias часто сходятся к похожим решениям даже при независимом обучении.

---

## Пропуск MoE-экспертов

По умолчанию включён `DEFAULT_SKIP_REGEXES = (r"\.experts\.",)`.

Зачем:

* эксперты MoE — самый большой по объёму блок, который легко утопит отчёт;
* их похожесть/непохожесть обычно рассматривается отдельно;
* если нужно — отключите пропуск, передав `skip_regexes=()`.

---

## Использование

Основной запуск (как в ноутбуке):

```python
GIGACHAT_DIR = "..."
DEEPSEEK_DIR = "..."
DEVICE = "cuda:0"
NUM_LAYERS = 61
RESULT_CSV_PATH = "check_corr.csv"

df = compare_models_streaming(
    gigachat_dir=GIGACHAT_DIR,
    deepseek_dir=DEEPSEEK_DIR,
    n_layers=NUM_LAYERS,
    device=DEVICE,
    # --- spectral включён по умолчанию ---
    do_spectral=True,
    spectral_topk=128,
    spectral_max_numel=None,     # без гарда по умолчанию
    spectral_force_cpu=False,
    spectral_dtype=torch.float32,
)

summary = summarize_results(df)
print_summary(summary)

df.to_csv(RESULT_CSV_PATH, index=False)
```

Полезные параметры:

* `skip_regexes` — что игнорировать на этапе индексации/загрузки.
* `cast_to=torch.float32` — в каком dtype сравнивать.
* `quantile_max_samples` — ограничение сэмплов для квантилей.
* `spearman_max_samples` — ограничение сэмплов для Spearman.
* `max_tensors` — ранний стоп для отладки.
* `do_spectral` — включить/выключить SVD-метрики.
* `spectral_topk` — размер топ-k для векторов/overlap.
* `spectral_max_numel` — гард по размеру матриц (если хотите пропускать гигантские тензоры).
* `spectral_force_cpu` — SVD на CPU (если GPU падает/не хватает памяти).
* `spectral_dtype` — dtype для SVD.

---

## Формат результата

`df` содержит по строке на тензор. Важные поля:

* `layer` — номер слоя;
* `key` — имя тензора;
* `shape`, `numel` — форма/размер;
* базовые метрики: `cos_sim`, `pearson`, `spearman`, `rel_l2_err`, `mean/max_rel_diff`, `mean/max_abs_diff`, `norm_ratio`, `std_ratio`, `mean_ratio`, `q01..q99_abs_diff`;
* спектральные метрики: `spec_*` из списка выше;
* `note="shape_mismatch"` — если формы не совпали.

`summarize_results` возвращает:

* `coverage` — сколько тензоров сравнилось/не сравнилось;
* `closeness` — доли тензоров с очень высоким cos sim;
* `other_summary` / `layernorm_summary` — describe по метрикам;
* `other_layer_mean` / `layernorm_layer_mean` — средние метрики по слоям.

---

## Интерпретация отчёта (коротко)

* Сначала смотрите **не-LN веса** (`other_summary`, `other_layer_mean`).
* Высокие `spec_subspace_overlap_*` и `spec_topk_*_cos_*` по многим матрицам/слоям — сильный сигнал родства.
* Высокая похожесть только у LN/bias — ожидаемо и не говорит о заимствовании.

---

## Ограничения

* Скрипт сравнивает **только совпадающие ключи**. Если тензоры переименованы/разложены иначе, нужно предварительное маппирование ключей.
* По умолчанию MoE-эксперты пропускаются.
* Для очень больших тензоров можно включить гард `spectral_max_numel` или `spectral_force_cpu`.
