# check-model-weight-corr

> Проверил на
> [mistralai/Mistral-Nemo-Instruct-2407/](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407/)
> и
> [Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24](https://huggingface.co/Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24),
>там корреляции в районе единицы, что говорит о прямом наследовании модели (об этом авторы `Vikhr-Nemo-12B` пишут прямо в карточке на HuggingFace). Корреляции в файле [check_corr_nemo_12b.csv](./check_corr_nemo_12b.csv)

Небольшой инструмент для **покомпонентного сравнения весов двух LLM‑чекпоинтов**. Считает набор метрик похожести для каждого тензора (по ключам), с агрегацией по слоям и отдельным анализом LayerNorm/bias.

Основной сценарий: быстро проверить, *насколько и где именно* два чекпоинта похожи/разошлись, не сваливая всё в одно усреднение по модели.

---

## Возможности

* **Стриминговая загрузка**: веса читаются по слоям и по файлам `.safetensors`, без полного загрузочного пика по памяти.
* **Сопоставление по ключам**: сравниваются только тензоры с совпавшими именами.
* **Пропуск MoE‑экспертов** по умолчанию (см. `DEFAULT_SKIP_REGEXES`).
* **Набор метрик похожести** на уровне каждого тензора.
* **Отдельный буфер для LayerNorm и bias** и отдельная статистика по ним.
* **CSV‑выгрузка** и агрегации per‑layer.

---

## Установка

Минимальные зависимости:

```bash
pip install torch pandas numpy safetensors
```

(Используется только чтение safetensors через `safe_open`, никаких HF‑зависимостей не нужно.)

---

## Как это работает

1. **Индексация**: строим лёгкий индекс `layer -> {key: filepath}` для каждого из двух чекпоинтов (`build_layer_index`).

   * Ключи, попадающие под `DEFAULT_SKIP_REGEXES` (например, `\.experts\.`), игнорируются ещё на этапе индексации/загрузки.
2. **Сравнение по слоям** (`compare_models_streaming`):

   * Идём по `layer_id` от `0` до `NUM_LAYERS-1`.
   * Находим пересечение ключей.
   * Подгружаем нужные тензоры `safe_open`‑ом по требованию.
   * Считаем метрики и складываем строки в DataFrame.
3. **Сводка** (`summarize_results`):

   * Отбрасываем несовпавшие по форме тензоры.
   * Отдельно считаем статистику для LayerNorm/bias и для остальных весов.
   * Делаем per‑layer mean по метрикам.

---

## Метрики

Для каждого совпавшего тензора считаются:

* **cos_sim** — cosine similarity между флеттен‑векторами. Показывает совпадение *направления* в пространстве весов. Не чувствителен к общему масштабу.
* **pearson** — линейная корреляция по элементам (после вычитания среднего). Ловит случаи, когда веса совпадают с точностью до линейного преобразования.
* **spearman** (опционально, с сэмплингом) — ранговая корреляция. Устойчива к нелинейным монотонным преобразованиям.
* **rel_l2_err** — относительная L2‑ошибка `||a - b|| / ||a||`. Чувствительна к абсолютным расхождениям.
* **mean_rel_diff / max_rel_diff** — средняя/максимальная относительная |diff| по элементам.
* **mean_abs_diff / max_abs_diff** — средняя/максимальная абсолютная |diff|.
* **norm_ratio / mean_ratio / std_ratio** — отношение норм/средних/стандартных отклонений. Помогают понять, различается ли масштаб/калибровка.
* **q01/q05/q50/q95/q99_abs_diff** — квантили абсолютной разницы (с optional сэмплингом для скорости).
* **zero_frac_a / zero_frac_b** — доля нулей (полезно для разреженных/квантизованных весов).

Почему так много метрик:

* одна метрика часто скрывает важные эффекты;
* например, `cos_sim ≈ 1` может сочетаться с высокой `rel_l2_err`, если совпало лишь доминирующее подпространство;
* а высокая корреляция (Pearson/Spearman) может быть при отличающемся масштабе.

---

## Почему LayerNorm и bias анализируются отдельно

В `summarize_results` мы делим тензоры на:

* **LayerNorm/bias** (`is_layernorm_key`) — ключи, оканчивающиеся на `*.layernorm.weight`, `*.ln.weight`, и т.п., плюс некоторые bias‑ключи.
* **Остальные веса** (attention/MLP/embeddings и т.д.).

Причины:

1. **Другие статистические свойства.**
   LN‑параметры и bias обычно маленькие по размеру, с другим распределением и динамикой. Если смешивать их с остальными, они искажают агрегаты (в среднем всегда выглядят «слишком похожими»).

2. **Их роль — калибровка, а не «знание».**
   Основное содержание модели сидит в матрицах проекций attention/MLP. LN и bias в основном стабилизируют активации и задают сдвиги.

3. **Есть инвариантности.**
   Во многих архитектурах часть трансформаций масштабов/сдвигов компенсируется нормализациями. Поэтому LN/bias часто сходятся к похожим решениям даже при независимом обучении.

---

## Почему высокая корреляция LayerNorm/bias — это нормально

Если в отчёте видно, что **LayerNorm/bias имеют `cos_sim/pearson ~ 1`**, а остальные веса — низкую похожесть, это *не повод паниковать*.

* LN/bias низкоразмерные и решают похожую задачу (держать активации в рабочем диапазоне), поэтому часто сойдутся к почти одинаковым значениям.
* Эта похожесть **не означает “копирование знаний”**, а лишь одинаковую калибровку.
* Реальные признаки сильной зависимости обычно проявляются в **крупных контентных матрицах** (QKV/O, up/down/gate в MLP и т.п.).

Практическое правило:

> Смотрите на метрики **вне Ln/bias‑подмножества** и на per‑layer mean по этим весам.

---

## Пропуск MoE‑экспертов

По умолчанию включён `DEFAULT_SKIP_REGEXES = (r"\.experts\.",)`.

Зачем:

* эксперты MoE — самый большой по объёму блок, который легко утопит отчёт;
* их похожесть/непохожесть обычно рассматривается отдельно;
* если нужно — отключите пропуск, передав `skip_regexes=()`.

---

## Использование

Основной запуск (как в ноутбуке):

```python
GIGACHAT_DIR = "..."
DEEPSEEK_DIR = "..."
DEVICE = "cuda:0"
NUM_LAYERS = 61

df = compare_models_streaming(
    gigachat_dir=GIGACHAT_DIR,
    deepseek_dir=DEEPSEEK_DIR,
    n_layers=NUM_LAYERS,
    device=DEVICE,
)

summary = summarize_results(df)
print_summary(summary)

# сохранить таблицу
df.to_csv(RESULT_CSV_PATH, index=False)
```

Полезные параметры:

* `skip_regexes` — что игнорировать на этапе индексации/загрузки.
* `cast_to=torch.float32` — в каком dtype сравнивать.
* `quantile_max_samples` — ограничение сэмплов для квантилей.
* `spearman_max_samples` — ограничение сэмплов для Spearman.
* `max_tensors` — ранний стоп для отладки.

---

## Формат результата

`df` содержит по строке на тензор. Важные поля:

* `layer` — номер слоя;
* `key` — имя тензора;
* `shape`, `numel` — форма/размер;
* `cos_sim`, `pearson`, `spearman`;
* `rel_l2_err`, `mean_rel_diff`, `max_rel_diff`;
* `mean_abs_diff`, `max_abs_diff`;
* `norm_ratio`, `mean_ratio`, `std_ratio`;
* `q01_abs_diff ... q99_abs_diff`.

`summarize_results` возвращает:

* `coverage` — сколько тензоров сравнилось/не сравнилось;
* `closeness` — доли тензоров с очень высоким cos sim;
* `other_summary` / `layernorm_summary` — describe по метрикам;
* `other_layer_mean` / `layernorm_layer_mean` — средние метрики по слоям.

---

## Интерпретация отчёта (коротко)

* **Сначала смотрите `other_summary` и `other_layer_mean`** — это “содержательные” веса.
* Высокие метрики только у LN/bias — ожидаемо.
* Если видите высокую похожесть в QKV/MLP матрицах *по многим слоям*, это уже существенный сигнал.

---

## Ограничения

* Скрипт сравнивает **только совпадающие ключи**. Если в одном чекпоинте тензоры переименованы/разложены иначе, нужно предварительное маппирование ключей.
* По умолчанию MoE‑эксперты пропускаются.
* Для очень больших тензоров Spearman/квантили лучше включать с `*_max_samples`.

---
