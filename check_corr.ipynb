{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bc8a6f0-7083-46cf-b860-987c1a9b94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GIGACHAT_DIR = \"...\"\n",
    "DEEPSEEK_DIR = \"...\"\n",
    "DEVICE = \"cuda:0\"\n",
    "NUM_LAYERS = 61\n",
    "\n",
    "RESULT_CSV_PATH = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee1f3e7-b21a-4c71-afe3-12d0704cd352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:51] layer 0 (12 common tensors)\n",
      "[12:06:51] processed 1 tensors (158.6/s, layer 0 1/12 in 0.0s)\n",
      "[12:06:58] processed 5 tensors (0.6/s, layer 0 5/12 in 7.7s)\n",
      "[12:06:58] processed 10 tensors (1.3/s, layer 0 10/12 in 7.8s)\n",
      "[12:06:58] layer 1 (12 common tensors)\n",
      "[12:07:03] processed 15 tensors (1.2/s, layer 1 3/12 in 4.8s)\n",
      "[12:07:06] layer 2 (12 common tensors)\n",
      "[12:07:06] processed 25 tensors (1.6/s, layer 2 1/12 in 0.0s)\n",
      "[12:07:13] processed 30 tensors (1.3/s, layer 2 6/12 in 7.1s)\n",
      "[12:07:13] processed 35 tensors (1.6/s, layer 2 11/12 in 7.2s)\n",
      "[12:07:13] layer 3 (14 common tensors)\n",
      "[12:07:13] processed 40 tensors (1.8/s, layer 3 4/14 in 0.0s)\n",
      "[12:07:13] processed 45 tensors (2.0/s, layer 3 9/14 in 0.1s)\n",
      "[12:07:13] layer 4 (14 common tensors)\n",
      "[12:07:13] processed 55 tensors (2.4/s, layer 4 5/14 in 0.1s)\n",
      "[12:07:14] layer 5 (14 common tensors)\n",
      "[12:07:14] processed 65 tensors (2.8/s, layer 5 1/14 in 0.0s)\n",
      "[12:07:14] processed 70 tensors (3.0/s, layer 5 6/14 in 0.1s)\n",
      "[12:07:14] layer 6 (14 common tensors)\n",
      "[12:07:14] processed 80 tensors (3.5/s, layer 6 2/14 in 0.0s)\n",
      "[12:07:14] processed 85 tensors (3.7/s, layer 6 7/14 in 0.1s)\n",
      "[12:07:14] processed 90 tensors (3.9/s, layer 6 12/14 in 0.1s)\n",
      "[12:07:14] layer 7 (14 common tensors)\n",
      "[12:07:14] processed 95 tensors (4.1/s, layer 7 3/14 in 0.0s)\n",
      "[12:07:14] processed 100 tensors (4.3/s, layer 7 8/14 in 0.1s)\n",
      "[12:07:14] processed 105 tensors (4.5/s, layer 7 13/14 in 0.1s)\n",
      "[12:07:14] layer 8 (14 common tensors)\n",
      "[12:07:14] processed 110 tensors (4.7/s, layer 8 4/14 in 0.0s)\n",
      "[12:07:14] processed 115 tensors (4.9/s, layer 8 9/14 in 0.1s)\n",
      "[12:07:14] layer 9 (14 common tensors)\n",
      "[12:07:14] processed 125 tensors (5.3/s, layer 9 5/14 in 0.1s)\n",
      "[12:07:14] layer 10 (14 common tensors)\n",
      "[12:07:14] processed 135 tensors (5.7/s, layer 10 1/14 in 0.0s)\n",
      "[12:07:14] processed 140 tensors (5.9/s, layer 10 6/14 in 0.1s)\n",
      "[12:07:15] layer 11 (14 common tensors)\n",
      "[12:07:15] processed 150 tensors (6.3/s, layer 11 2/14 in 0.0s)\n",
      "[12:07:15] processed 155 tensors (6.4/s, layer 11 7/14 in 0.1s)\n",
      "[12:07:15] processed 160 tensors (6.6/s, layer 11 12/14 in 0.1s)\n",
      "[12:07:15] layer 12 (14 common tensors)\n",
      "[12:07:15] processed 165 tensors (6.8/s, layer 12 3/14 in 0.0s)\n",
      "[12:07:15] processed 170 tensors (7.0/s, layer 12 8/14 in 0.1s)\n",
      "[12:07:15] processed 175 tensors (7.2/s, layer 12 13/14 in 0.1s)\n",
      "[12:07:15] layer 13 (14 common tensors)\n",
      "[12:07:15] processed 180 tensors (7.4/s, layer 13 4/14 in 0.0s)\n",
      "[12:07:15] processed 185 tensors (7.6/s, layer 13 9/14 in 0.1s)\n",
      "[12:07:15] layer 14 (14 common tensors)\n",
      "[12:07:15] processed 195 tensors (8.0/s, layer 14 5/14 in 0.0s)\n",
      "[12:07:15] layer 15 (14 common tensors)\n",
      "[12:07:15] processed 205 tensors (8.3/s, layer 15 1/14 in 0.0s)\n",
      "[12:07:15] processed 210 tensors (8.5/s, layer 15 6/14 in 0.1s)\n",
      "[12:07:15] layer 16 (14 common tensors)\n",
      "[12:07:15] processed 220 tensors (8.9/s, layer 16 2/14 in 0.0s)\n",
      "[12:07:15] processed 225 tensors (9.1/s, layer 16 7/14 in 0.1s)\n",
      "[12:07:16] processed 230 tensors (9.2/s, layer 16 12/14 in 0.1s)\n",
      "[12:07:16] layer 17 (14 common tensors)\n",
      "[12:07:16] processed 235 tensors (9.4/s, layer 17 3/14 in 0.0s)\n",
      "[12:07:16] processed 240 tensors (9.6/s, layer 17 8/14 in 0.1s)\n",
      "[12:07:16] processed 245 tensors (9.8/s, layer 17 13/14 in 0.1s)\n",
      "[12:07:16] layer 18 (14 common tensors)\n",
      "[12:07:16] processed 250 tensors (9.9/s, layer 18 4/14 in 0.0s)\n",
      "[12:07:16] processed 255 tensors (10.1/s, layer 18 9/14 in 0.1s)\n",
      "[12:07:16] layer 19 (14 common tensors)\n",
      "[12:07:16] processed 265 tensors (10.5/s, layer 19 5/14 in 0.1s)\n",
      "[12:07:16] layer 20 (14 common tensors)\n",
      "[12:07:16] processed 275 tensors (10.8/s, layer 20 1/14 in 0.0s)\n",
      "[12:07:16] processed 280 tensors (11.0/s, layer 20 6/14 in 0.1s)\n",
      "[12:07:16] layer 21 (14 common tensors)\n",
      "[12:07:16] processed 290 tensors (11.3/s, layer 21 2/14 in 0.0s)\n",
      "[12:07:16] processed 295 tensors (11.5/s, layer 21 7/14 in 0.1s)\n",
      "[12:07:16] processed 300 tensors (11.7/s, layer 21 12/14 in 0.1s)\n",
      "[12:07:16] layer 22 (14 common tensors)\n",
      "[12:07:16] processed 305 tensors (11.8/s, layer 22 3/14 in 0.0s)\n",
      "[12:07:16] processed 310 tensors (12.0/s, layer 22 8/14 in 0.1s)\n",
      "[12:07:17] processed 315 tensors (12.2/s, layer 22 13/14 in 0.1s)\n",
      "[12:07:17] layer 23 (14 common tensors)\n",
      "[12:07:17] processed 320 tensors (12.3/s, layer 23 4/14 in 0.0s)\n",
      "[12:07:17] processed 325 tensors (12.5/s, layer 23 9/14 in 0.1s)\n",
      "[12:07:17] layer 24 (14 common tensors)\n",
      "[12:07:17] processed 335 tensors (12.8/s, layer 24 5/14 in 0.0s)\n",
      "[12:07:17] layer 25 (14 common tensors)\n",
      "[12:07:17] processed 345 tensors (13.1/s, layer 25 1/14 in 0.0s)\n",
      "[12:07:17] processed 350 tensors (13.3/s, layer 25 6/14 in 0.1s)\n",
      "[12:07:17] layer 26 (14 common tensors)\n",
      "[12:07:17] processed 360 tensors (13.6/s, layer 26 2/14 in 0.0s)\n",
      "[12:07:17] processed 365 tensors (13.8/s, layer 26 7/14 in 0.1s)\n",
      "[12:07:17] processed 370 tensors (13.9/s, layer 26 12/14 in 0.1s)\n",
      "[12:07:17] layer 27 (14 common tensors)\n",
      "[12:07:17] processed 375 tensors (14.0/s, layer 27 3/14 in 0.0s)\n",
      "[12:07:17] processed 380 tensors (14.2/s, layer 27 8/14 in 0.1s)\n",
      "[12:07:17] processed 385 tensors (14.3/s, layer 27 13/14 in 0.2s)\n",
      "[12:07:17] layer 28 (14 common tensors)\n",
      "[12:07:17] processed 390 tensors (14.5/s, layer 28 4/14 in 0.0s)\n",
      "[12:07:18] processed 395 tensors (14.7/s, layer 28 9/14 in 0.1s)\n",
      "[12:07:18] layer 29 (14 common tensors)\n",
      "[12:07:18] processed 405 tensors (15.0/s, layer 29 5/14 in 0.1s)\n",
      "[12:07:18] layer 30 (14 common tensors)\n",
      "[12:07:18] processed 415 tensors (15.3/s, layer 30 1/14 in 0.0s)\n",
      "[12:07:18] processed 420 tensors (15.4/s, layer 30 6/14 in 0.1s)\n",
      "[12:07:18] layer 31 (14 common tensors)\n",
      "[12:07:18] processed 430 tensors (15.7/s, layer 31 2/14 in 0.0s)\n",
      "[12:07:18] processed 435 tensors (15.9/s, layer 31 7/14 in 0.1s)\n",
      "[12:07:18] processed 440 tensors (16.0/s, layer 31 12/14 in 0.1s)\n",
      "[12:07:18] layer 32 (14 common tensors)\n",
      "[12:07:18] processed 445 tensors (16.2/s, layer 32 3/14 in 0.0s)\n",
      "[12:07:18] processed 450 tensors (16.3/s, layer 32 8/14 in 0.1s)\n",
      "[12:07:18] processed 455 tensors (16.5/s, layer 32 13/14 in 0.1s)\n",
      "[12:07:18] layer 33 (14 common tensors)\n",
      "[12:07:18] processed 460 tensors (16.6/s, layer 33 4/14 in 0.0s)\n",
      "[12:07:18] processed 465 tensors (16.7/s, layer 33 9/14 in 0.1s)\n",
      "[12:07:18] layer 34 (14 common tensors)\n",
      "[12:07:18] processed 475 tensors (17.0/s, layer 34 5/14 in 0.1s)\n",
      "[12:07:19] layer 35 (14 common tensors)\n",
      "[12:07:19] processed 485 tensors (17.3/s, layer 35 1/14 in 0.0s)\n",
      "[12:07:19] processed 490 tensors (17.4/s, layer 35 6/14 in 0.1s)\n",
      "[12:07:19] layer 36 (14 common tensors)\n",
      "[12:07:19] processed 500 tensors (17.7/s, layer 36 2/14 in 0.0s)\n",
      "[12:07:19] processed 505 tensors (17.9/s, layer 36 7/14 in 0.1s)\n",
      "[12:07:19] processed 510 tensors (18.0/s, layer 36 12/14 in 0.1s)\n",
      "[12:07:19] layer 37 (14 common tensors)\n",
      "[12:07:19] processed 515 tensors (18.2/s, layer 37 3/14 in 0.0s)\n",
      "[12:07:19] processed 520 tensors (18.3/s, layer 37 8/14 in 0.1s)\n",
      "[12:07:19] processed 525 tensors (18.4/s, layer 37 13/14 in 0.1s)\n",
      "[12:07:19] layer 38 (14 common tensors)\n",
      "[12:07:19] processed 530 tensors (18.6/s, layer 38 4/14 in 0.0s)\n",
      "[12:07:19] processed 535 tensors (18.7/s, layer 38 9/14 in 0.1s)\n",
      "[12:07:19] layer 39 (14 common tensors)\n",
      "[12:07:19] processed 545 tensors (19.0/s, layer 39 5/14 in 0.1s)\n",
      "[12:07:19] layer 40 (14 common tensors)\n",
      "[12:07:19] processed 555 tensors (19.2/s, layer 40 1/14 in 0.0s)\n",
      "[12:07:19] processed 560 tensors (19.4/s, layer 40 6/14 in 0.1s)\n",
      "[12:07:20] layer 41 (14 common tensors)\n",
      "[12:07:20] processed 570 tensors (19.7/s, layer 41 2/14 in 0.0s)\n",
      "[12:07:20] processed 575 tensors (19.8/s, layer 41 7/14 in 0.1s)\n",
      "[12:07:20] processed 580 tensors (19.9/s, layer 41 12/14 in 0.1s)\n",
      "[12:07:20] layer 42 (14 common tensors)\n",
      "[12:07:20] processed 585 tensors (20.1/s, layer 42 3/14 in 0.0s)\n",
      "[12:07:20] processed 590 tensors (20.2/s, layer 42 8/14 in 0.1s)\n",
      "[12:07:20] processed 595 tensors (20.3/s, layer 42 13/14 in 0.1s)\n",
      "[12:07:20] layer 43 (14 common tensors)\n",
      "[12:07:20] processed 600 tensors (20.5/s, layer 43 4/14 in 0.0s)\n",
      "[12:07:20] processed 605 tensors (20.6/s, layer 43 9/14 in 0.1s)\n",
      "[12:07:20] layer 44 (14 common tensors)\n",
      "[12:07:20] processed 615 tensors (20.8/s, layer 44 5/14 in 0.0s)\n",
      "[12:07:20] layer 45 (14 common tensors)\n",
      "[12:07:20] processed 625 tensors (21.1/s, layer 45 1/14 in 0.0s)\n",
      "[12:07:20] processed 630 tensors (21.2/s, layer 45 6/14 in 0.1s)\n",
      "[12:07:20] layer 46 (14 common tensors)\n",
      "[12:07:20] processed 640 tensors (21.5/s, layer 46 2/14 in 0.0s)\n",
      "[12:07:20] processed 645 tensors (21.6/s, layer 46 7/14 in 0.1s)\n",
      "[12:07:20] processed 650 tensors (21.7/s, layer 46 12/14 in 0.1s)\n",
      "[12:07:21] layer 47 (14 common tensors)\n",
      "[12:07:21] processed 655 tensors (21.9/s, layer 47 3/14 in 0.0s)\n",
      "[12:07:21] processed 660 tensors (22.0/s, layer 47 8/14 in 0.1s)\n",
      "[12:07:21] processed 665 tensors (22.1/s, layer 47 13/14 in 0.1s)\n",
      "[12:07:21] layer 48 (14 common tensors)\n",
      "[12:07:21] processed 670 tensors (22.2/s, layer 48 4/14 in 0.0s)\n",
      "[12:07:21] processed 675 tensors (22.4/s, layer 48 9/14 in 0.1s)\n",
      "[12:07:21] layer 49 (14 common tensors)\n",
      "[12:07:21] processed 685 tensors (22.6/s, layer 49 5/14 in 0.1s)\n",
      "[12:07:21] layer 50 (14 common tensors)\n",
      "[12:07:21] processed 695 tensors (22.8/s, layer 50 1/14 in 0.0s)\n",
      "[12:07:21] processed 700 tensors (23.0/s, layer 50 6/14 in 0.1s)\n",
      "[12:07:21] layer 51 (14 common tensors)\n",
      "[12:07:21] processed 710 tensors (23.2/s, layer 51 2/14 in 0.0s)\n",
      "[12:07:21] processed 715 tensors (23.3/s, layer 51 7/14 in 0.1s)\n",
      "[12:07:21] processed 720 tensors (23.4/s, layer 51 12/14 in 0.1s)\n",
      "[12:07:21] layer 52 (14 common tensors)\n",
      "[12:07:21] processed 725 tensors (23.5/s, layer 52 3/14 in 0.0s)\n",
      "[12:07:21] processed 730 tensors (23.7/s, layer 52 8/14 in 0.1s)\n",
      "[12:07:22] processed 735 tensors (23.8/s, layer 52 13/14 in 0.1s)\n",
      "[12:07:22] layer 53 (14 common tensors)\n",
      "[12:07:22] processed 740 tensors (23.9/s, layer 53 4/14 in 0.0s)\n",
      "[12:07:22] processed 745 tensors (24.0/s, layer 53 9/14 in 0.1s)\n",
      "[12:07:22] layer 54 (14 common tensors)\n",
      "[12:07:22] processed 755 tensors (24.2/s, layer 54 5/14 in 0.0s)\n",
      "[12:07:22] layer 55 (14 common tensors)\n",
      "[12:07:22] processed 765 tensors (24.5/s, layer 55 1/14 in 0.0s)\n",
      "[12:07:22] processed 770 tensors (24.6/s, layer 55 6/14 in 0.1s)\n",
      "[12:07:22] layer 56 (14 common tensors)\n",
      "[12:07:22] processed 780 tensors (24.8/s, layer 56 2/14 in 0.0s)\n",
      "[12:07:22] processed 785 tensors (24.9/s, layer 56 7/14 in 0.1s)\n",
      "[12:07:22] processed 790 tensors (25.0/s, layer 56 12/14 in 0.2s)\n",
      "[12:07:22] layer 57 (14 common tensors)\n",
      "[12:07:22] processed 795 tensors (25.1/s, layer 57 3/14 in 0.0s)\n",
      "[12:07:22] processed 800 tensors (25.2/s, layer 57 8/14 in 0.1s)\n",
      "[12:07:22] processed 805 tensors (25.4/s, layer 57 13/14 in 0.1s)\n",
      "[12:07:22] layer 58 (14 common tensors)\n",
      "[12:07:22] processed 810 tensors (25.5/s, layer 58 4/14 in 0.0s)\n",
      "[12:07:22] processed 815 tensors (25.6/s, layer 58 9/14 in 0.1s)\n",
      "[12:07:23] layer 59 (14 common tensors)\n",
      "[12:07:23] processed 825 tensors (25.8/s, layer 59 5/14 in 0.1s)\n",
      "[12:07:23] layer 60 (14 common tensors)\n",
      "[12:07:23] processed 835 tensors (26.0/s, layer 60 1/14 in 0.0s)\n",
      "[12:07:23] processed 840 tensors (26.1/s, layer 60 6/14 in 0.1s)\n",
      "[12:07:23] finished: 848 tensors in 32.3s (26.3/s)\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from contextlib import ExitStack\n",
    "from typing import Optional, Sequence\n",
    "from safetensors import safe_open\n",
    "\n",
    "# ---------- regex setup ----------\n",
    "DEFAULT_PREFIXES = (\n",
    "    r\"model\\.layers\\.(\\d+)\\.\",       # llama/qwen/deepseek-style\n",
    ")\n",
    "\n",
    "# --- skip patterns (ignore at indexing/load stage) ---\n",
    "DEFAULT_SKIP_REGEXES = (\n",
    "    r\"\\.experts\\.\",   # ignore MoE experts tensors\n",
    ")\n",
    "\n",
    "def iter_safetensors_files(model_dir):\n",
    "    files = sorted(glob.glob(os.path.join(model_dir, \"*.safetensors\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .safetensors files in {model_dir}\")\n",
    "    return files\n",
    "\n",
    "def compile_regexes(patterns):\n",
    "    if not patterns:\n",
    "        return []\n",
    "    return [re.compile(p) for p in patterns]\n",
    "\n",
    "def compile_prefixes(prefixes):\n",
    "    return compile_regexes(prefixes)\n",
    "\n",
    "def _should_skip_key(key, regs):\n",
    "    for rgx in regs:\n",
    "        if rgx.search(key):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_layer_id(key, regs):\n",
    "    for rgx in regs:\n",
    "        m = rgx.search(key)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "# ---------- 1) lightweight index: layer -> {key: filepath} ----------\n",
    "def build_layer_index(\n",
    "    model_dir,\n",
    "    n_layers=3,\n",
    "    prefixes=DEFAULT_PREFIXES,\n",
    "    skip_regexes=DEFAULT_SKIP_REGEXES,   # <-- default ignore here\n",
    "):\n",
    "    files = iter_safetensors_files(model_dir)\n",
    "    regs = compile_prefixes(prefixes)\n",
    "    skip_regs = compile_regexes(skip_regexes)\n",
    "\n",
    "    layer_to_keys = {i: {} for i in range(n_layers)}\n",
    "    for path in files:\n",
    "        with safe_open(path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for k in f.keys():\n",
    "                if skip_regs and _should_skip_key(k, skip_regs):\n",
    "                    continue\n",
    "                lid = extract_layer_id(k, regs)\n",
    "                if lid is None or lid >= n_layers:\n",
    "                    continue\n",
    "                layer_to_keys[lid][k] = path\n",
    "    return layer_to_keys\n",
    "\n",
    "# ---------- 2) metrics ----------\n",
    "def _cos_sim(fa, fb, eps=1e-12):\n",
    "    denom = (fa.norm() * fb.norm()).clamp_min(eps)\n",
    "    return (fa @ fb / denom).item()\n",
    "\n",
    "def _pearson(fa, fb, eps=1e-12):\n",
    "    fa_c = fa - fa.mean()\n",
    "    fb_c = fb - fb.mean()\n",
    "    denom = (fa_c.norm() * fb_c.norm()).clamp_min(eps)\n",
    "    return (fa_c @ fb_c / denom).item()\n",
    "\n",
    "def _spearman(fa, fb, eps=1e-12):\n",
    "    ra = torch.argsort(torch.argsort(fa))\n",
    "    rb = torch.argsort(torch.argsort(fb))\n",
    "    ra = ra.float() - ra.float().mean()\n",
    "    rb = rb.float() - rb.float().mean()\n",
    "    denom = (ra.norm() * rb.norm()).clamp_min(eps)\n",
    "    return (ra @ rb / denom).item()\n",
    "\n",
    "def _quantiles(abs_diff, qs=(0.01, 0.05, 0.5, 0.95, 0.99), max_samples=None):\n",
    "    if abs_diff.numel() == 0:\n",
    "        return {}\n",
    "\n",
    "    vals = abs_diff.flatten()\n",
    "\n",
    "    if max_samples is not None and vals.numel() > max_samples:\n",
    "        idx = torch.randperm(vals.numel(), device=vals.device)[:max_samples]\n",
    "        vals = vals[idx]\n",
    "\n",
    "    qv = torch.tensor(qs, device=vals.device, dtype=vals.dtype)\n",
    "    try:\n",
    "        out = torch.quantile(vals, qv)\n",
    "    except RuntimeError:\n",
    "        vals_cpu = vals.float().cpu().numpy()\n",
    "        qv_np = qv.float().cpu().numpy()\n",
    "        out_np = np.quantile(vals_cpu, qv_np)\n",
    "        out = torch.from_numpy(out_np).to(vals)\n",
    "\n",
    "    return {f\"q{int(q*100):02d}_abs_diff\": out[i].item() for i, q in enumerate(qs)}\n",
    "\n",
    "def _sample_pair(fa, fb, max_samples=None):\n",
    "    if max_samples is None or fa.numel() <= max_samples:\n",
    "        return fa, fb\n",
    "    idx = torch.randint(0, fa.numel(), (max_samples,), device=fa.device)\n",
    "    return fa[idx], fb[idx]\n",
    "\n",
    "def _rel_l2_err(fa, fb, eps=1e-12):\n",
    "    return (fa - fb).norm().div(fa.norm().clamp_min(eps)).item()\n",
    "\n",
    "def _rel_max_abs_diff(fa, fb, eps=1e-12):\n",
    "    denom = fa.abs().clamp_min(eps)\n",
    "    return ((fa - fb).abs() / denom).max().item()\n",
    "\n",
    "def _rel_mean_abs_diff(fa, fb, eps=1e-12):\n",
    "    denom = fa.abs().clamp_min(eps)\n",
    "    return ((fa - fb).abs() / denom).mean().item()\n",
    "\n",
    "\n",
    "# ---------- 3) streaming compare per layer ----------\n",
    "def compare_models_streaming(\n",
    "    gigachat_dir,\n",
    "    deepseek_dir,\n",
    "    n_layers=3,\n",
    "    prefixes=DEFAULT_PREFIXES,\n",
    "    cast_to=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    do_spearman=True,\n",
    "    quantile_max_samples: Optional[int] = None,\n",
    "    spearman_max_samples: Optional[int] = None,\n",
    "    log_every=5,\n",
    "    max_tensors=None,\n",
    "    verbose=True,\n",
    "    skip_regexes=DEFAULT_SKIP_REGEXES,  # <-- default ignore here too\n",
    "):\n",
    "    # lightweight indexes\n",
    "    gc_index = build_layer_index(\n",
    "        gigachat_dir,\n",
    "        n_layers=n_layers,\n",
    "        prefixes=prefixes,\n",
    "        skip_regexes=skip_regexes,\n",
    "    )\n",
    "    ds_index = build_layer_index(\n",
    "        deepseek_dir,\n",
    "        n_layers=n_layers,\n",
    "        prefixes=prefixes,\n",
    "        skip_regexes=skip_regexes,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    processed = 0\n",
    "    interrupted = False\n",
    "    start_time = time.time()\n",
    "\n",
    "    stop_requested = False\n",
    "\n",
    "    try:\n",
    "        for lid in range(n_layers):\n",
    "            gc_keys = gc_index[lid]\n",
    "            ds_keys = ds_index[lid]\n",
    "            common_keys = sorted(set(gc_keys) & set(ds_keys))\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"[{time.strftime('%H:%M:%S')}] layer {lid} \"\n",
    "                    f\"({len(common_keys)} common tensors)\"\n",
    "                )\n",
    "\n",
    "            if not common_keys:\n",
    "                continue\n",
    "\n",
    "            layer_start = time.time()\n",
    "\n",
    "            with ExitStack() as stack:\n",
    "                gc_handles = {}\n",
    "                ds_handles = {}\n",
    "\n",
    "                def get_tensor(handles, path, key):\n",
    "                    if path not in handles:\n",
    "                        handles[path] = stack.enter_context(\n",
    "                            safe_open(path, framework=\"pt\", device=str(device))\n",
    "                        )\n",
    "                    return handles[path].get_tensor(key)\n",
    "\n",
    "                for idx, k in enumerate(common_keys, 1):\n",
    "                    a = get_tensor(gc_handles, gc_keys[k], k).to(dtype=cast_to)\n",
    "                    b = get_tensor(ds_handles, ds_keys[k], k).to(dtype=cast_to)\n",
    "\n",
    "                    if a.shape != b.shape:\n",
    "                        rows.append(dict(\n",
    "                            layer=lid, key=k,\n",
    "                            shape_a=tuple(a.shape), shape_b=tuple(b.shape),\n",
    "                            note=\"shape_mismatch\",\n",
    "                        ))\n",
    "                        processed += 1\n",
    "                        continue\n",
    "\n",
    "                    fa = a.reshape(-1)\n",
    "                    fb = b.reshape(-1)\n",
    "                    abs_diff = (fa - fb).abs()\n",
    "\n",
    "                    row = dict(\n",
    "                        layer=lid,\n",
    "                        key=k,\n",
    "                        shape=tuple(a.shape),\n",
    "                        numel=int(fa.numel()),\n",
    "                        norm_a=fa.norm().item(),\n",
    "                        norm_b=fb.norm().item(),\n",
    "                        norm_ratio=(fa.norm() / fb.norm().clamp_min(1e-12)).item(),\n",
    "                        mean_a=fa.mean().item(),\n",
    "                        mean_b=fb.mean().item(),\n",
    "                        mean_ratio=(fa.mean() / fb.mean().clamp_min(1e-12)).item(),\n",
    "                        std_a=fa.std(unbiased=False).item(),\n",
    "                        std_b=fb.std(unbiased=False).item(),\n",
    "                        std_ratio=(fa.std(unbiased=False) / fb.std(unbiased=False).clamp_min(1e-12)).item(),\n",
    "                        zero_frac_a=(fa == 0).float().mean().item(),\n",
    "                        zero_frac_b=(fb == 0).float().mean().item(),\n",
    "                        cos_sim=_cos_sim(fa, fb),\n",
    "                        rel_l2_err=_rel_l2_err(fa, fb),\n",
    "                        mean_rel_diff=_rel_mean_abs_diff(fa, fb),\n",
    "                        max_rel_diff=_rel_max_abs_diff(fa, fb),\n",
    "                        pearson=_pearson(fa, fb),\n",
    "                        max_abs_diff=abs_diff.max().item(),\n",
    "                        mean_abs_diff=abs_diff.mean().item(),\n",
    "                    )\n",
    "\n",
    "                    if do_spearman:\n",
    "                        fa_sp, fb_sp = _sample_pair(fa, fb, spearman_max_samples)\n",
    "                        row[\"spearman\"] = _spearman(fa_sp, fb_sp)\n",
    "\n",
    "                    row.update(_quantiles(abs_diff, max_samples=quantile_max_samples))\n",
    "\n",
    "                    rows.append(row)\n",
    "                    processed += 1\n",
    "\n",
    "                    if verbose and (processed == 1 or processed % max(1, log_every) == 0):\n",
    "                        elapsed = time.time() - start_time\n",
    "                        rate = processed / max(elapsed, 1e-6)\n",
    "                        layer_elapsed = time.time() - layer_start\n",
    "                        print(\n",
    "                            f\"[{time.strftime('%H:%M:%S')}] processed \"\n",
    "                            f\"{processed} tensors ({rate:.1f}/s, \"\n",
    "                            f\"layer {lid} {idx}/{len(common_keys)} in {layer_elapsed:.1f}s)\"\n",
    "                        )\n",
    "\n",
    "                    if max_tensors is not None and processed >= max_tensors:\n",
    "                        stop_requested = True\n",
    "                        break\n",
    "\n",
    "                if stop_requested:\n",
    "                    break\n",
    "    except KeyboardInterrupt:\n",
    "        interrupted = True\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{time.strftime('%H:%M:%S')}] KeyboardInterrupt received, \"\n",
    "                \"returning partial results.\"\n",
    "            )\n",
    "\n",
    "    total_elapsed = time.time() - start_time\n",
    "    if verbose:\n",
    "        status = \"interrupted\" if interrupted else \"finished\"\n",
    "        print(\n",
    "            f\"[{time.strftime('%H:%M:%S')}] {status}: {processed} tensors \"\n",
    "            f\"in {total_elapsed:.1f}s ({processed / max(total_elapsed, 1e-6):.1f}/s)\"\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.attrs[\"interrupted\"] = interrupted\n",
    "    df.attrs[\"processed_tensors\"] = processed\n",
    "    df.attrs[\"elapsed_seconds\"] = total_elapsed\n",
    "    df.attrs[\"stop_requested\"] = stop_requested\n",
    "    return df\n",
    "\n",
    "# ---------- 4) usage ----------\n",
    "df = compare_models_streaming(\n",
    "    gigachat_dir=GIGACHAT_DIR,\n",
    "    deepseek_dir=DEEPSEEK_DIR,\n",
    "    n_layers=NUM_LAYERS,\n",
    "    device=\"cuda:0\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe2fd765-addf-4703-a991-541928d763f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== non-layernorm stats (describe) ===\n",
      "          cos_sim     pearson    spearman    rel_l2_err  mean_rel_diff  \\\n",
      "count  363.000000  363.000000  363.000000    363.000000     363.000000   \n",
      "mean    -0.000037   -0.000040   -0.000002   4294.096856   57084.277631   \n",
      "std      0.001984    0.001982    0.001965   2463.475244   43614.327872   \n",
      "min     -0.009123   -0.009121   -0.008588      1.144950       4.780324   \n",
      "1%      -0.006066   -0.006074   -0.006189      1.159569       5.800548   \n",
      "5%      -0.003547   -0.003558   -0.003408      1.181075       6.962997   \n",
      "50%      0.000011    0.000011    0.000010   4663.833496   53996.414062   \n",
      "95%      0.003594    0.003576    0.003543   7572.696387  123171.325000   \n",
      "99%      0.006864    0.006845    0.006718  11331.787813  209752.977500   \n",
      "max      0.007981    0.007958    0.008460  16530.933594  326736.812500   \n",
      "\n",
      "       max_rel_diff  mean_abs_diff  max_abs_diff  norm_ratio   std_ratio  \\\n",
      "count  3.630000e+02     363.000000    363.000000  363.000000  363.000000   \n",
      "mean   1.356075e+11      45.850916    376.558432    0.231714    0.231715   \n",
      "std    3.392392e+11      24.643936    164.208483    0.539690    0.539693   \n",
      "min    1.075075e+05       0.021599      0.277832    0.000060    0.000060   \n",
      "1%     2.869566e+05       0.023559      0.371387    0.000088    0.000088   \n",
      "5%     8.936970e+05       0.031007      0.458531    0.000132    0.000132   \n",
      "50%    4.133502e+10      48.836674    448.050781    0.000214    0.000214   \n",
      "95%    5.063086e+11      82.750228    448.128711    1.590086    1.590120   \n",
      "99%    1.602375e+12      84.169096    448.200000    1.691253    1.691307   \n",
      "max    3.728145e+12      85.509880    448.259766    1.777323    1.777332   \n",
      "\n",
      "         mean_ratio  \n",
      "count  3.630000e+02  \n",
      "mean  -9.349179e+06  \n",
      "std    4.061707e+07  \n",
      "min   -2.069384e+08  \n",
      "1%    -1.824003e+08  \n",
      "5%    -1.146533e+08  \n",
      "50%   -8.076385e-06  \n",
      "95%    9.265593e+06  \n",
      "99%    2.442668e+07  \n",
      "max    1.989925e+08  \n",
      "\n",
      "=== per-layer mean metrics (non-layernorm) ===\n",
      "        cos_sim   pearson  spearman   rel_l2_err  mean_rel_diff  max_rel_diff  \\\n",
      "layer                                                                           \n",
      "0     -0.000135 -0.000130 -0.000623  7026.511914   91911.600781  5.577121e+11   \n",
      "1     -0.000602 -0.000606 -0.000942  9311.209961  103031.828125  2.816871e+11   \n",
      "2     -0.000346 -0.000347 -0.000753  6882.745264   97897.479688  6.337466e+11   \n",
      "3      0.000632  0.000627 -0.001283  6614.248081   87685.230215  8.916687e+10   \n",
      "4     -0.001191 -0.001195 -0.001825  6200.696583   83600.781367  1.347536e+11   \n",
      "5      0.001811  0.001806  0.001117  5337.763031   61829.800468  8.698469e+10   \n",
      "6      0.001424  0.001424  0.000871  5419.931874   61739.098724  8.558960e+10   \n",
      "7      0.000279  0.000279 -0.000411  4849.219060   52643.242496  7.655435e+10   \n",
      "8      0.000103  0.000092 -0.000208  4303.811008   87571.120382  4.744828e+11   \n",
      "9      0.000308  0.000295  0.000141  4417.576350   59645.623364  1.318525e+11   \n",
      "10    -0.000660 -0.000667 -0.000329  4181.631169   54274.677305  4.898702e+10   \n",
      "11    -0.000479 -0.000488 -0.000203  3951.850684   51376.466808  6.820438e+10   \n",
      "12    -0.000487 -0.000496 -0.000256  4017.827218   47979.758995  2.100822e+10   \n",
      "13    -0.000814 -0.000822 -0.000454  3889.521894   58801.965441  9.503264e+10   \n",
      "14    -0.000936 -0.000951 -0.000565  3636.478184   58667.353584  1.872031e+11   \n",
      "15    -0.000686 -0.000693 -0.000472  3570.938780   47676.521263  6.216946e+10   \n",
      "16    -0.001210 -0.001212 -0.001112  3670.140803   57776.752816  9.130974e+10   \n",
      "17    -0.000840 -0.000842 -0.000558  3761.970839   49010.932669  3.313251e+10   \n",
      "18    -0.000771 -0.000771 -0.000476  3921.191300   72819.044997  2.480720e+11   \n",
      "19    -0.001115 -0.001115 -0.001042  3533.985649   52428.366760  1.005843e+11   \n",
      "20    -0.001140 -0.001139 -0.000866  3942.705001   59123.267792  1.190118e+11   \n",
      "21    -0.001001 -0.001001 -0.000806  3983.494529   57156.300433  1.475448e+11   \n",
      "22    -0.000873 -0.000873 -0.000706  3739.336923   61823.552769  3.081871e+11   \n",
      "23    -0.000885 -0.000884 -0.000680  3816.099226   50512.566020  9.672341e+10   \n",
      "24    -0.001406 -0.001406 -0.001314  3719.275757   43976.915225  4.755554e+10   \n",
      "25    -0.001123 -0.001124 -0.000949  3860.239021   46191.630724  8.211684e+10   \n",
      "26    -0.000883 -0.000882 -0.000718  3912.268674   48277.338083  9.245679e+10   \n",
      "27    -0.001646 -0.001645 -0.001503  4333.685103   46601.670398  4.366977e+10   \n",
      "28    -0.001321 -0.001322 -0.001225  3911.369726   45450.073346  3.641720e+10   \n",
      "29    -0.001070 -0.001069 -0.000816  3933.355396   47289.569196  6.684731e+10   \n",
      "30    -0.000685 -0.000686 -0.000698  4058.771872   45771.137511  4.218073e+10   \n",
      "31    -0.000732 -0.000733 -0.000569  3923.669108   43011.521439  5.682617e+10   \n",
      "32    -0.000289 -0.000289 -0.000190  3825.969224   58276.759696  1.655002e+11   \n",
      "33    -0.000599 -0.000598 -0.000607  3842.479649   49370.380105  1.884936e+11   \n",
      "34    -0.000106 -0.000107 -0.000035  3758.958718   54281.940386  1.450933e+11   \n",
      "35    -0.000183 -0.000182 -0.000192  3693.310013   40152.212649  3.401919e+10   \n",
      "36     0.000229  0.000226  0.000316  4122.610588   44082.176437  3.210474e+10   \n",
      "37     0.000350  0.000347  0.000435  3945.891608   46788.268109  6.579517e+10   \n",
      "38     0.000290  0.000287  0.000429  3801.323583   41392.615699  4.452161e+10   \n",
      "39     0.000251  0.000249  0.000309  4089.731600   64214.326960  1.625791e+11   \n",
      "40     0.000767  0.000763  0.000969  3833.658317   91813.798357  6.976923e+11   \n",
      "41     0.001136  0.001129  0.001352  3926.065169   42978.645225  6.692783e+10   \n",
      "42     0.000927  0.000922  0.001083  3959.288880   44596.229273  4.034060e+10   \n",
      "43     0.000846  0.000840  0.001023  3777.743049   35844.374952  1.632306e+10   \n",
      "44     0.000959  0.000954  0.001165  3871.786476   61948.501360  9.523794e+10   \n",
      "45     0.001222  0.001219  0.001310  3881.738720   39021.885669  3.057472e+10   \n",
      "46     0.001109  0.001104  0.001187  3897.186598   41322.190609  3.373693e+10   \n",
      "47     0.000607  0.000603  0.000707  4220.556733   46598.678812  5.540907e+10   \n",
      "48     0.001331  0.001326  0.001544  4576.280139   51694.369589  8.586971e+10   \n",
      "49     0.001030  0.001027  0.001250  4532.365096   71329.527170  2.545884e+11   \n",
      "50     0.001037  0.001030  0.001186  4096.003124   53466.502738  1.724499e+11   \n",
      "51     0.000911  0.000903  0.001077  4271.564467   54452.429306  9.593829e+10   \n",
      "52     0.001219  0.001211  0.001393  4332.804286   51560.960813  7.001991e+10   \n",
      "53     0.000510  0.000504  0.000831  4184.673489   49669.152920  8.111408e+10   \n",
      "54     0.000777  0.000772  0.001084  4632.718320   80594.917183  3.032219e+11   \n",
      "55     0.000670  0.000668  0.000782  4659.282773   59719.724455  8.824719e+10   \n",
      "56     0.000932  0.000931  0.001037  4441.013091   58924.626417  1.275267e+11   \n",
      "57     0.000505  0.000503  0.000634  4283.544529   56881.284219  6.783192e+10   \n",
      "58    -0.000140 -0.000136 -0.000015  4257.464816   88592.957123  4.421627e+11   \n",
      "59     0.000246  0.000253  0.000199  3774.962268   45120.024937  6.437445e+10   \n",
      "60    -0.000489 -0.000481 -0.000566  3538.442367   44162.964427  7.431137e+10   \n",
      "\n",
      "       mean_abs_diff  max_abs_diff  norm_ratio  std_ratio    mean_ratio  \n",
      "layer                                                                    \n",
      "0          36.095914    448.039722    0.000176   0.000176  2.022600e+06  \n",
      "1          23.279104    448.039648    0.000134   0.000134  6.717640e+04  \n",
      "2          20.811070    448.076025    0.000174   0.000174 -1.070413e+06  \n",
      "3          42.545957    373.418823    0.146903   0.146904 -3.957470e+05  \n",
      "4          45.634215    373.459147    0.174559   0.174559  1.635415e+05  \n",
      "5          42.294876    373.472270    0.169059   0.169060 -3.113163e+04  \n",
      "6          45.047117    373.493652    0.169408   0.169409  5.302880e+06  \n",
      "7          44.509487    373.485738    0.182962   0.182960  3.320241e+07  \n",
      "8          41.832731    373.493856    0.201253   0.201246  3.075810e+05  \n",
      "9          44.867018    373.484985    0.191212   0.191206 -1.690569e+05  \n",
      "10         44.791637    373.481110    0.177095   0.177088 -1.651539e+06  \n",
      "11         45.094709    373.468343    0.178119   0.178112  3.380822e+05  \n",
      "12         44.663183    373.490763    0.183944   0.183938  2.688658e+07  \n",
      "13         44.325340    373.507462    0.193578   0.193577  2.119224e-01  \n",
      "14         43.773825    373.504272    0.202696   0.202701  1.758884e+05  \n",
      "15         43.650303    373.479858    0.213633   0.213640  4.347012e+05  \n",
      "16         43.957077    373.489156    0.202052   0.202064  2.079754e+06  \n",
      "17         44.236493    373.487956    0.212088   0.212093  1.132580e+06  \n",
      "18         45.237489    373.482422    0.219458   0.219458  2.307796e+06  \n",
      "19         45.480223    373.502724    0.229976   0.229977 -5.266936e+05  \n",
      "20         47.668445    373.538371    0.223859   0.223859  4.111479e+06  \n",
      "21         48.306880    373.503204    0.233131   0.233132 -1.983102e+06  \n",
      "22         46.940085    373.495773    0.246239   0.246238  1.937957e+06  \n",
      "23         47.705673    373.504801    0.262922   0.262919  8.457962e+04  \n",
      "24         46.845186    373.523229    0.267828   0.267825  8.758429e+04  \n",
      "25         46.103125    373.508158    0.263827   0.263824 -3.538511e+07  \n",
      "26         47.454010    373.478058    0.261123   0.261117  1.175494e+06  \n",
      "27         47.593796    373.479696    0.264381   0.264379  4.586115e+06  \n",
      "28         48.874617    373.481527    0.269012   0.269009 -3.414088e+07  \n",
      "29         49.483899    373.486287    0.267872   0.267868 -2.064774e+06  \n",
      "30         49.320511    373.475057    0.263836   0.263834 -2.816930e+07  \n",
      "31         46.905888    373.475179    0.266316   0.266315 -2.900786e+07  \n",
      "32         47.747174    373.469604    0.268888   0.268887 -1.617503e+07  \n",
      "33         48.830886    373.491364    0.254523   0.254521  2.197639e+06  \n",
      "34         46.921373    373.479268    0.261392   0.261391 -2.025165e+07  \n",
      "35         46.300569    373.492472    0.263062   0.263059  5.104522e+06  \n",
      "36         50.155621    373.484843    0.256716   0.256717 -2.817037e+07  \n",
      "37         48.253192    373.456472    0.265274   0.265280 -2.032090e+07  \n",
      "38         46.772023    373.479513    0.262685   0.262687 -1.755644e+07  \n",
      "39         46.559349    373.483538    0.275903   0.275901 -3.027038e+07  \n",
      "40         47.360487    373.457540    0.268529   0.268531 -2.336229e+07  \n",
      "41         46.845509    373.452647    0.264500   0.264505 -3.009107e+07  \n",
      "42         48.445379    373.459432    0.252501   0.252510 -1.767003e+07  \n",
      "43         45.399606    373.482890    0.258154   0.258157 -2.805347e+07  \n",
      "44         47.051765    373.462097    0.261030   0.261032 -2.496118e+07  \n",
      "45         45.690856    373.474955    0.264485   0.264487 -1.693497e+07  \n",
      "46         44.954813    373.458171    0.261305   0.261306 -2.793436e+07  \n",
      "47         46.198360    373.459025    0.262705   0.262716 -1.228775e+07  \n",
      "48         49.735172    373.448771    0.267742   0.267751 -1.932760e+07  \n",
      "49         49.053340    373.464668    0.278844   0.278848 -1.629451e+07  \n",
      "50         47.331959    373.476186    0.273476   0.273475 -3.448145e+07  \n",
      "51         48.859772    373.454590    0.277335   0.277342 -2.491777e+07  \n",
      "52         49.056022    373.453735    0.270328   0.270335 -2.332959e+07  \n",
      "53         47.857891    373.469035    0.287251   0.287268 -1.530711e+07  \n",
      "54         49.280820    373.443729    0.275656   0.275658 -2.823010e+07  \n",
      "55         49.119225    373.438899    0.295842   0.295849 -1.346278e+07  \n",
      "56         51.014257    373.442312    0.296383   0.296384 -8.374003e+06  \n",
      "57         49.309720    373.468562    0.288442   0.288439 -2.614121e+07  \n",
      "58         48.638377    373.440592    0.271862   0.271865 -1.326911e-01  \n",
      "59         46.544265    373.483276    0.229642   0.229645 -5.312970e+05  \n",
      "60         42.727091    373.475545    0.165511   0.165520 -1.294610e+05  \n",
      "\n",
      "=== layernorm stats (describe) ===\n",
      "          cos_sim     pearson    spearman  rel_l2_err  mean_rel_diff  \\\n",
      "count  302.000000  302.000000  302.000000  302.000000     302.000000   \n",
      "mean     0.963563    0.001364    0.003930    0.903966       1.404837   \n",
      "std      0.072419    0.037280    0.037178    1.081123       2.742865   \n",
      "min      0.498078   -0.144866   -0.141759    0.016897       0.012783   \n",
      "1%       0.557142   -0.090683   -0.082903    0.024140       0.023490   \n",
      "5%       0.855185   -0.054296   -0.057509    0.098984       0.090186   \n",
      "50%      0.993157    0.002341    0.002388    0.474432       0.504654   \n",
      "95%      0.999965    0.067485    0.072153    3.192692       4.561763   \n",
      "99%      0.999997    0.117415    0.112628    4.945868      16.161101   \n",
      "max      0.999999    0.183239    0.137209    7.319476      24.702936   \n",
      "\n",
      "       max_rel_diff  mean_abs_diff  max_abs_diff  norm_ratio   std_ratio  \\\n",
      "count    302.000000     302.000000    302.000000  302.000000  302.000000   \n",
      "mean     156.681234       0.443565      0.824930    0.888084    2.000243   \n",
      "std      797.474330       0.533522      0.676851    0.508395    2.553445   \n",
      "min        0.070988       0.006171      0.031281    0.120433    0.080051   \n",
      "1%         0.088940       0.008520      0.041569    0.169147    0.178505   \n",
      "5%         0.138170       0.017868      0.138205    0.239501    0.267284   \n",
      "50%       12.716930       0.242872      0.596283    0.778921    0.891027   \n",
      "95%      287.434053       1.448285      2.005762    1.802262    8.077391   \n",
      "99%     4393.195371       2.333940      2.572470    2.451044   10.240369   \n",
      "max    10239.000000       3.316026      3.513270    3.051423   12.237870   \n",
      "\n",
      "       mean_ratio  \n",
      "count  302.000000  \n",
      "mean     0.887491  \n",
      "std      0.510084  \n",
      "min      0.119603  \n",
      "1%       0.165605  \n",
      "5%       0.238993  \n",
      "50%      0.771332  \n",
      "95%      1.788723  \n",
      "99%      2.453490  \n",
      "max      3.063137  \n"
     ]
    }
   ],
   "source": [
    "SUMMARY_METRICS = [\n",
    "    \"cos_sim\",\n",
    "    \"pearson\",\n",
    "    \"spearman\",\n",
    "    \"rel_l2_err\",\n",
    "    \"mean_rel_diff\",\n",
    "    \"max_rel_diff\",\n",
    "    \"mean_abs_diff\",\n",
    "    \"max_abs_diff\",\n",
    "    \"norm_ratio\",\n",
    "    \"std_ratio\",\n",
    "    \"mean_ratio\",\n",
    "]\n",
    "\n",
    "def _safe_filter_columns(df, cols: Sequence[str]):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "# --- LayerNorm detection ---\n",
    "LAYERNORM_SUFFIXES = (\n",
    "    \".layernorm.weight\",\n",
    "    \".layer_norm.weight\",\n",
    "    \".ln.weight\",\n",
    "    \".ln_f.weight\",\n",
    "    \"layernorm.weight\",\n",
    "    \"layer_norm.weight\",\n",
    "    # bias here too\n",
    "    \"e_score_correction_bias\",\n",
    ")\n",
    "def is_layernorm_key(key: str, suffixes=LAYERNORM_SUFFIXES) -> bool:\n",
    "    return any(key.endswith(suf) for suf in suffixes)\n",
    "\n",
    "def _describe(df_part: pd.DataFrame, metrics: Sequence[str]):\n",
    "    if df_part is None or len(df_part) == 0:\n",
    "        return pd.DataFrame()\n",
    "    return df_part[list(metrics)].describe(\n",
    "        percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]\n",
    "    )\n",
    "\n",
    "def _closeness_stats(df_part: pd.DataFrame, prefix=\"\"):\n",
    "    out = {}\n",
    "    if df_part is None or len(df_part) == 0:\n",
    "        return out\n",
    "    if \"cos_sim\" in df_part:\n",
    "        out[f\"{prefix}cos_gt_0.99_frac\"] = (df_part[\"cos_sim\"] > 0.99).mean()\n",
    "        out[f\"{prefix}cos_gt_0.999_frac\"] = (df_part[\"cos_sim\"] > 0.999).mean()\n",
    "    return out\n",
    "    \n",
    "def summarize_results(df: pd.DataFrame):\n",
    "    # drop shape mismatches and other non-comparable rows\n",
    "    comparable = df[df.get(\"note\").isna()]\n",
    "    shape_mismatches = df[\"note\"].eq(\"shape_mismatch\").sum() if \"note\" in df else 0\n",
    "\n",
    "    metrics = _safe_filter_columns(comparable, SUMMARY_METRICS)\n",
    "\n",
    "    # split layernorm vs others\n",
    "    if \"key\" in comparable:\n",
    "        ln_mask = comparable[\"key\"].apply(is_layernorm_key)\n",
    "    else:\n",
    "        ln_mask = pd.Series(False, index=comparable.index)\n",
    "\n",
    "    ln_part = comparable[ln_mask]\n",
    "    other_part = comparable[~ln_mask]\n",
    "\n",
    "    ln_summary = _describe(ln_part, metrics)\n",
    "    other_summary = _describe(other_part, metrics)\n",
    "\n",
    "    layer_summary = {}\n",
    "    layer_summary_ln = {}\n",
    "    layer_summary_other = {}\n",
    "    if \"layer\" in comparable:\n",
    "        if len(comparable) > 0:\n",
    "            layer_summary = comparable.groupby(\"layer\")[metrics].mean()\n",
    "        if len(ln_part) > 0:\n",
    "            layer_summary_ln = ln_part.groupby(\"layer\")[metrics].mean()\n",
    "        if len(other_part) > 0:\n",
    "            layer_summary_other = other_part.groupby(\"layer\")[metrics].mean()\n",
    "\n",
    "    closeness = {}\n",
    "    closeness.update(_closeness_stats(comparable, prefix=\"all_\"))\n",
    "    closeness.update(_closeness_stats(ln_part, prefix=\"ln_\"))\n",
    "    closeness.update(_closeness_stats(other_part, prefix=\"other_\"))\n",
    "\n",
    "    coverage = {\n",
    "        \"total_rows\": len(df),\n",
    "        \"comparable_rows\": len(comparable),\n",
    "        \"shape_mismatches\": int(shape_mismatches),\n",
    "        \"layernorm_rows\": int(len(ln_part)),\n",
    "        \"other_rows\": int(len(other_part)),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"coverage\": coverage,\n",
    "        \"closeness\": closeness,\n",
    "        \"layer_mean\": layer_summary,\n",
    "        \"layernorm_summary\": ln_summary,\n",
    "        \"other_summary\": other_summary,\n",
    "        \"layernorm_layer_mean\": layer_summary_ln,\n",
    "        \"other_layer_mean\": layer_summary_other,\n",
    "    }\n",
    "\n",
    "def print_summary(summary):\n",
    "    if isinstance(summary.get(\"other_summary\"), pd.DataFrame) and not summary[\"other_summary\"].empty:\n",
    "        print(\"\\n=== non-layernorm stats (describe) ===\")\n",
    "        print(summary[\"other_summary\"])\n",
    "\n",
    "    if isinstance(summary.get(\"other_layer_mean\"), pd.DataFrame) and not summary[\"other_layer_mean\"].empty:\n",
    "        print(\"\\n=== per-layer mean metrics (non-layernorm) ===\")\n",
    "        print(summary[\"other_layer_mean\"])\n",
    "\n",
    "    if isinstance(summary.get(\"layernorm_summary\"), pd.DataFrame) and not summary[\"layernorm_summary\"].empty:\n",
    "        print(\"\\n=== layernorm stats (describe) ===\")\n",
    "        print(summary[\"layernorm_summary\"])\n",
    "\n",
    "summary = summarize_results(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09d9029b-9199-4442-87ae-c55f05f04f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>key</th>\n",
       "      <th>shape</th>\n",
       "      <th>numel</th>\n",
       "      <th>norm_a</th>\n",
       "      <th>norm_b</th>\n",
       "      <th>norm_ratio</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_a</th>\n",
       "      <th>std_b</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>zero_frac_a</th>\n",
       "      <th>zero_frac_b</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rel_l2_err</th>\n",
       "      <th>mean_rel_diff</th>\n",
       "      <th>max_rel_diff</th>\n",
       "      <th>pearson</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "      <th>spearman</th>\n",
       "      <th>q01_abs_diff</th>\n",
       "      <th>q05_abs_diff</th>\n",
       "      <th>q50_abs_diff</th>\n",
       "      <th>q95_abs_diff</th>\n",
       "      <th>q99_abs_diff</th>\n",
       "      <th>shape_a</th>\n",
       "      <th>shape_b</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>59.667873</td>\n",
       "      <td>428978.468750</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>1.938400e-07</td>\n",
       "      <td>-5.042707e-03</td>\n",
       "      <td>1.938400e+05</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>37.320744</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>7189.438477</td>\n",
       "      <td>83933.062500</td>\n",
       "      <td>6.245747e+11</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>23.491154</td>\n",
       "      <td>-6.912752e-06</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>1.003906</td>\n",
       "      <td>13.997543</td>\n",
       "      <td>80.000687</td>\n",
       "      <td>143.996338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>56.593945</td>\n",
       "      <td>233500.296875</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-1.141391e-05</td>\n",
       "      <td>2.023005e-01</td>\n",
       "      <td>-5.642058e-05</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>20.313309</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>4125.888672</td>\n",
       "      <td>94711.351562</td>\n",
       "      <td>1.379779e+12</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>448.040039</td>\n",
       "      <td>6.796145</td>\n",
       "      <td>-2.233854e-03</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.186165</td>\n",
       "      <td>2.499613</td>\n",
       "      <td>23.998825</td>\n",
       "      <td>79.999825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>51.375027</td>\n",
       "      <td>589028.500000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>4.222969e-07</td>\n",
       "      <td>-3.271475e-03</td>\n",
       "      <td>4.222969e+05</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>51.244949</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>11465.268555</td>\n",
       "      <td>144081.312500</td>\n",
       "      <td>6.944284e+11</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>448.027222</td>\n",
       "      <td>35.005745</td>\n",
       "      <td>1.957554e-05</td>\n",
       "      <td>0.376633</td>\n",
       "      <td>1.876915</td>\n",
       "      <td>23.983521</td>\n",
       "      <td>111.997208</td>\n",
       "      <td>176.000168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.883209</td>\n",
       "      <td>143063.109375</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>8.415574e-06</td>\n",
       "      <td>-5.285055e-02</td>\n",
       "      <td>8.415574e+06</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>70.407242</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>3336.111328</td>\n",
       "      <td>27890.207031</td>\n",
       "      <td>5.200393e+09</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>448.052734</td>\n",
       "      <td>47.079998</td>\n",
       "      <td>-8.733455e-04</td>\n",
       "      <td>0.450989</td>\n",
       "      <td>2.255432</td>\n",
       "      <td>27.993683</td>\n",
       "      <td>160.000259</td>\n",
       "      <td>239.989075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>32.806965</td>\n",
       "      <td>295782.718750</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.081290e-06</td>\n",
       "      <td>-1.848673e-02</td>\n",
       "      <td>1.081290e+06</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>89.141144</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>9015.852539</td>\n",
       "      <td>108942.070312</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>448.038086</td>\n",
       "      <td>68.106529</td>\n",
       "      <td>-2.073852e-05</td>\n",
       "      <td>0.940406</td>\n",
       "      <td>4.515320</td>\n",
       "      <td>52.008484</td>\n",
       "      <td>176.012634</td>\n",
       "      <td>255.995758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>31.056589</td>\n",
       "      <td>311506.968750</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.974590e-08</td>\n",
       "      <td>-6.014036e-03</td>\n",
       "      <td>1.974590e+04</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>27.100826</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>10030.302734</td>\n",
       "      <td>92496.351562</td>\n",
       "      <td>2.210074e+11</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>448.031982</td>\n",
       "      <td>15.785647</td>\n",
       "      <td>-8.367174e-05</td>\n",
       "      <td>0.142975</td>\n",
       "      <td>0.748177</td>\n",
       "      <td>9.001137</td>\n",
       "      <td>52.000927</td>\n",
       "      <td>104.000656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>46.198711</td>\n",
       "      <td>275344.031250</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>7.893201e-06</td>\n",
       "      <td>2.129500e-01</td>\n",
       "      <td>3.706598e-05</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>23.953739</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-0.002543</td>\n",
       "      <td>5959.996582</td>\n",
       "      <td>80385.343750</td>\n",
       "      <td>1.901858e+11</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>448.058594</td>\n",
       "      <td>5.853664</td>\n",
       "      <td>-4.157898e-03</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.102169</td>\n",
       "      <td>1.375315</td>\n",
       "      <td>17.999088</td>\n",
       "      <td>111.999542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>24.128511</td>\n",
       "      <td>398866.781250</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-7.624888e-08</td>\n",
       "      <td>7.651516e-03</td>\n",
       "      <td>-9.965200e-06</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>34.701054</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>16530.933594</td>\n",
       "      <td>175742.328125</td>\n",
       "      <td>9.296684e+11</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>448.016846</td>\n",
       "      <td>19.753969</td>\n",
       "      <td>8.872247e-05</td>\n",
       "      <td>0.171158</td>\n",
       "      <td>0.872360</td>\n",
       "      <td>10.002838</td>\n",
       "      <td>72.000519</td>\n",
       "      <td>143.999527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>28.544937</td>\n",
       "      <td>119154.664062</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-4.458476e-08</td>\n",
       "      <td>-2.386205e-02</td>\n",
       "      <td>-4.458476e+04</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>58.640915</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>4174.283691</td>\n",
       "      <td>40850.437500</td>\n",
       "      <td>1.004120e+10</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>448.053955</td>\n",
       "      <td>38.335239</td>\n",
       "      <td>3.593929e-05</td>\n",
       "      <td>0.347580</td>\n",
       "      <td>1.748683</td>\n",
       "      <td>23.976929</td>\n",
       "      <td>127.997711</td>\n",
       "      <td>208.010315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>17.876047</td>\n",
       "      <td>176267.359375</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>3.607209e-07</td>\n",
       "      <td>-9.147654e-03</td>\n",
       "      <td>3.607209e+05</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>53.122345</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>9860.533203</td>\n",
       "      <td>125684.679688</td>\n",
       "      <td>5.753258e+10</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>-5.945576e-04</td>\n",
       "      <td>0.406069</td>\n",
       "      <td>1.999565</td>\n",
       "      <td>24.006989</td>\n",
       "      <td>111.999786</td>\n",
       "      <td>176.004730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>35.113667</td>\n",
       "      <td>253710.390625</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>2.642451e-07</td>\n",
       "      <td>-2.943784e-04</td>\n",
       "      <td>2.642451e+05</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>22.072577</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>7225.403320</td>\n",
       "      <td>84006.882812</td>\n",
       "      <td>5.088649e+11</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>12.308104</td>\n",
       "      <td>3.585698e-05</td>\n",
       "      <td>0.115158</td>\n",
       "      <td>0.563599</td>\n",
       "      <td>7.004242</td>\n",
       "      <td>39.999340</td>\n",
       "      <td>87.996933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>47.933502</td>\n",
       "      <td>201596.265625</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>3.276502e-06</td>\n",
       "      <td>9.338737e-02</td>\n",
       "      <td>3.508507e-05</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>17.538445</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>4205.749023</td>\n",
       "      <td>78158.953125</td>\n",
       "      <td>1.039538e+12</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>448.207031</td>\n",
       "      <td>4.621072</td>\n",
       "      <td>-2.001503e-03</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.093677</td>\n",
       "      <td>1.249559</td>\n",
       "      <td>15.999390</td>\n",
       "      <td>71.999466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>28.609304</td>\n",
       "      <td>325057.093750</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2.105856e-07</td>\n",
       "      <td>9.443110e-04</td>\n",
       "      <td>2.230045e-04</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>28.279673</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>11361.936523</td>\n",
       "      <td>136232.515625</td>\n",
       "      <td>9.815383e+11</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>448.032227</td>\n",
       "      <td>15.789912</td>\n",
       "      <td>-6.906464e-05</td>\n",
       "      <td>0.155973</td>\n",
       "      <td>0.752869</td>\n",
       "      <td>9.000614</td>\n",
       "      <td>52.000919</td>\n",
       "      <td>112.000687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>27.854443</td>\n",
       "      <td>98536.000000</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-3.046824e-06</td>\n",
       "      <td>-1.653090e-02</td>\n",
       "      <td>-3.046824e+06</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>48.493622</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>3537.533447</td>\n",
       "      <td>48838.906250</td>\n",
       "      <td>6.926057e+10</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>-1.181142e-03</td>\n",
       "      <td>0.276855</td>\n",
       "      <td>1.376617</td>\n",
       "      <td>17.991028</td>\n",
       "      <td>104.005463</td>\n",
       "      <td>191.986572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>23.909323</td>\n",
       "      <td>193261.531250</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-2.569489e-06</td>\n",
       "      <td>-1.133139e-02</td>\n",
       "      <td>-2.569488e+06</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>58.243946</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>8083.104004</td>\n",
       "      <td>142250.140625</td>\n",
       "      <td>5.695312e+11</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>448.025635</td>\n",
       "      <td>41.066807</td>\n",
       "      <td>-5.489405e-04</td>\n",
       "      <td>0.488159</td>\n",
       "      <td>2.496185</td>\n",
       "      <td>28.007050</td>\n",
       "      <td>120.005280</td>\n",
       "      <td>192.003342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>29.393806</td>\n",
       "      <td>33.376320</td>\n",
       "      <td>0.880678</td>\n",
       "      <td>7.770116e-05</td>\n",
       "      <td>1.165834e-04</td>\n",
       "      <td>6.664856e-01</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>0.024639</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>1.515584</td>\n",
       "      <td>13.248475</td>\n",
       "      <td>1.562718e+06</td>\n",
       "      <td>-0.003391</td>\n",
       "      <td>0.277832</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>-3.804966e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>28.635567</td>\n",
       "      <td>241520.312500</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-2.374483e-06</td>\n",
       "      <td>-6.645652e-03</td>\n",
       "      <td>-2.374483e+06</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>63.036152</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>8434.277344</td>\n",
       "      <td>111086.609375</td>\n",
       "      <td>1.099512e+11</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.027954</td>\n",
       "      <td>45.915237</td>\n",
       "      <td>2.101869e-04</td>\n",
       "      <td>0.570087</td>\n",
       "      <td>2.995636</td>\n",
       "      <td>32.006226</td>\n",
       "      <td>128.003174</td>\n",
       "      <td>192.008850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>31.387489</td>\n",
       "      <td>230882.187500</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>3.296047e-05</td>\n",
       "      <td>2.247492e-01</td>\n",
       "      <td>1.466545e-04</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>60.259205</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>7355.858887</td>\n",
       "      <td>106107.656250</td>\n",
       "      <td>4.311810e+10</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>448.034912</td>\n",
       "      <td>40.476818</td>\n",
       "      <td>-3.379034e-03</td>\n",
       "      <td>0.409973</td>\n",
       "      <td>2.003235</td>\n",
       "      <td>26.005737</td>\n",
       "      <td>127.991394</td>\n",
       "      <td>223.995483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>25.626366</td>\n",
       "      <td>355590.343750</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>6.067139e-07</td>\n",
       "      <td>1.293623e-03</td>\n",
       "      <td>4.690038e-04</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>92.808113</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>13875.956055</td>\n",
       "      <td>188024.328125</td>\n",
       "      <td>2.638828e+11</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>448.029175</td>\n",
       "      <td>72.166595</td>\n",
       "      <td>3.838496e-04</td>\n",
       "      <td>1.007935</td>\n",
       "      <td>5.490479</td>\n",
       "      <td>59.993073</td>\n",
       "      <td>191.994324</td>\n",
       "      <td>255.998505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>34.273003</td>\n",
       "      <td>139565.296875</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>5.541524e-06</td>\n",
       "      <td>3.586704e-02</td>\n",
       "      <td>1.545019e-04</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>68.685829</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>4072.165283</td>\n",
       "      <td>44838.820312</td>\n",
       "      <td>1.610613e+10</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>448.102539</td>\n",
       "      <td>47.355137</td>\n",
       "      <td>-9.473588e-04</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>2.491821</td>\n",
       "      <td>30.020508</td>\n",
       "      <td>144.023438</td>\n",
       "      <td>224.016846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>37.585987</td>\n",
       "      <td>223475.562500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-1.298052e-06</td>\n",
       "      <td>1.999416e-02</td>\n",
       "      <td>-6.492158e-05</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>67.349655</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>5945.715332</td>\n",
       "      <td>76040.718750</td>\n",
       "      <td>1.019415e+11</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>49.336349</td>\n",
       "      <td>-1.592607e-04</td>\n",
       "      <td>0.629211</td>\n",
       "      <td>3.240967</td>\n",
       "      <td>36.002991</td>\n",
       "      <td>143.994354</td>\n",
       "      <td>208.007111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.083839</td>\n",
       "      <td>38.301109</td>\n",
       "      <td>1.046545</td>\n",
       "      <td>9.968146e-05</td>\n",
       "      <td>1.027509e-04</td>\n",
       "      <td>9.701275e-01</td>\n",
       "      <td>0.029590</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>1.046546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005643</td>\n",
       "      <td>1.387016</td>\n",
       "      <td>10.403044</td>\n",
       "      <td>2.972342e+06</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>0.514404</td>\n",
       "      <td>0.032241</td>\n",
       "      <td>-4.600448e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.081299</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>31.385395</td>\n",
       "      <td>252685.328125</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>9.522834e-07</td>\n",
       "      <td>-7.535151e-03</td>\n",
       "      <td>9.522834e+05</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>65.950188</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>8051.048340</td>\n",
       "      <td>104473.632812</td>\n",
       "      <td>2.286984e+11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>448.034668</td>\n",
       "      <td>48.497044</td>\n",
       "      <td>3.059335e-04</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>3.016235</td>\n",
       "      <td>35.999348</td>\n",
       "      <td>143.989685</td>\n",
       "      <td>207.994507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.515797</td>\n",
       "      <td>200585.921875</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>3.550852e-05</td>\n",
       "      <td>2.336629e-01</td>\n",
       "      <td>1.519648e-04</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>52.351864</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>3748.165527</td>\n",
       "      <td>41904.957031</td>\n",
       "      <td>1.778622e+10</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>448.047607</td>\n",
       "      <td>35.467117</td>\n",
       "      <td>-7.591132e-03</td>\n",
       "      <td>0.379333</td>\n",
       "      <td>1.878891</td>\n",
       "      <td>23.997864</td>\n",
       "      <td>104.023315</td>\n",
       "      <td>176.067383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>30.086203</td>\n",
       "      <td>340374.531250</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2.896452e-08</td>\n",
       "      <td>-2.909102e-02</td>\n",
       "      <td>2.896452e+04</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>88.836830</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>11313.309570</td>\n",
       "      <td>123050.289062</td>\n",
       "      <td>9.657872e+10</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>448.027832</td>\n",
       "      <td>68.796997</td>\n",
       "      <td>-9.841732e-05</td>\n",
       "      <td>0.998769</td>\n",
       "      <td>5.001511</td>\n",
       "      <td>55.997406</td>\n",
       "      <td>176.004272</td>\n",
       "      <td>255.986877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>34.652184</td>\n",
       "      <td>153807.328125</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-4.588853e-06</td>\n",
       "      <td>4.405908e-02</td>\n",
       "      <td>-1.041523e-04</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>75.694916</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>4438.604004</td>\n",
       "      <td>103584.546875</td>\n",
       "      <td>2.521173e+11</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>54.851147</td>\n",
       "      <td>2.915825e-04</td>\n",
       "      <td>0.569122</td>\n",
       "      <td>2.974731</td>\n",
       "      <td>39.991089</td>\n",
       "      <td>160.002487</td>\n",
       "      <td>239.970703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>29.676378</td>\n",
       "      <td>286426.500000</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>8.800778e-07</td>\n",
       "      <td>3.902343e-03</td>\n",
       "      <td>2.255255e-04</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>86.321419</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>9651.665039</td>\n",
       "      <td>128580.859375</td>\n",
       "      <td>2.133381e+11</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>448.054688</td>\n",
       "      <td>66.160744</td>\n",
       "      <td>7.446480e-04</td>\n",
       "      <td>0.933838</td>\n",
       "      <td>4.505768</td>\n",
       "      <td>52.001846</td>\n",
       "      <td>175.999649</td>\n",
       "      <td>240.010193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>47.636959</td>\n",
       "      <td>47.007324</td>\n",
       "      <td>1.013394</td>\n",
       "      <td>6.166619e-05</td>\n",
       "      <td>1.320220e-04</td>\n",
       "      <td>4.670901e-01</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>0.034701</td>\n",
       "      <td>1.013400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>1.402891</td>\n",
       "      <td>10.279372</td>\n",
       "      <td>1.655645e+06</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>3.035732e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>32.378353</td>\n",
       "      <td>258382.609375</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>3.037285e-06</td>\n",
       "      <td>4.000738e-03</td>\n",
       "      <td>7.591810e-04</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>67.437164</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7980.104004</td>\n",
       "      <td>83325.734375</td>\n",
       "      <td>9.926146e+10</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>448.026367</td>\n",
       "      <td>49.998989</td>\n",
       "      <td>1.949253e-04</td>\n",
       "      <td>0.635193</td>\n",
       "      <td>3.250435</td>\n",
       "      <td>36.008972</td>\n",
       "      <td>143.994904</td>\n",
       "      <td>207.996582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.461613</td>\n",
       "      <td>204030.687500</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>3.864144e-05</td>\n",
       "      <td>4.771323e-01</td>\n",
       "      <td>8.098686e-05</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>53.249321</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>3489.986328</td>\n",
       "      <td>59396.566406</td>\n",
       "      <td>1.157381e+11</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>35.807480</td>\n",
       "      <td>3.278170e-03</td>\n",
       "      <td>0.373726</td>\n",
       "      <td>1.872040</td>\n",
       "      <td>23.996719</td>\n",
       "      <td>111.992462</td>\n",
       "      <td>191.994537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>32.674606</td>\n",
       "      <td>322552.281250</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-1.867902e-07</td>\n",
       "      <td>-7.872188e-03</td>\n",
       "      <td>-1.867902e+05</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>84.185272</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>9871.651367</td>\n",
       "      <td>122963.664062</td>\n",
       "      <td>2.057566e+11</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>448.029419</td>\n",
       "      <td>64.861771</td>\n",
       "      <td>-6.318197e-04</td>\n",
       "      <td>0.935623</td>\n",
       "      <td>4.508240</td>\n",
       "      <td>51.999256</td>\n",
       "      <td>175.991150</td>\n",
       "      <td>239.998718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>39.866913</td>\n",
       "      <td>127441.625000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-3.083006e-06</td>\n",
       "      <td>2.253130e-02</td>\n",
       "      <td>-1.368322e-04</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>62.719273</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>3196.676270</td>\n",
       "      <td>26617.050781</td>\n",
       "      <td>6.568774e+09</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>448.097168</td>\n",
       "      <td>42.111485</td>\n",
       "      <td>7.890060e-04</td>\n",
       "      <td>0.415527</td>\n",
       "      <td>2.018799</td>\n",
       "      <td>26.019531</td>\n",
       "      <td>143.984955</td>\n",
       "      <td>223.992340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>35.922665</td>\n",
       "      <td>268944.281250</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-6.152970e-06</td>\n",
       "      <td>6.052906e-03</td>\n",
       "      <td>-1.016532e-03</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>81.052742</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>7486.757324</td>\n",
       "      <td>78665.507812</td>\n",
       "      <td>9.458165e+10</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>60.950573</td>\n",
       "      <td>3.757286e-05</td>\n",
       "      <td>0.811775</td>\n",
       "      <td>4.000033</td>\n",
       "      <td>47.989502</td>\n",
       "      <td>160.019287</td>\n",
       "      <td>240.001343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>52.055973</td>\n",
       "      <td>51.258682</td>\n",
       "      <td>1.015554</td>\n",
       "      <td>3.220308e-05</td>\n",
       "      <td>-1.018610e-04</td>\n",
       "      <td>3.220308e+07</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>1.015558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>1.402278</td>\n",
       "      <td>11.150939</td>\n",
       "      <td>1.377131e+06</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.675049</td>\n",
       "      <td>0.042596</td>\n",
       "      <td>1.835468e-03</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.143066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>35.252045</td>\n",
       "      <td>265794.281250</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.716296e-06</td>\n",
       "      <td>-2.312120e-02</td>\n",
       "      <td>1.716296e+06</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>69.371590</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>7539.826172</td>\n",
       "      <td>68780.289062</td>\n",
       "      <td>1.816374e+10</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>448.034180</td>\n",
       "      <td>51.997993</td>\n",
       "      <td>-1.342449e-05</td>\n",
       "      <td>0.686539</td>\n",
       "      <td>3.494934</td>\n",
       "      <td>39.998970</td>\n",
       "      <td>143.998383</td>\n",
       "      <td>207.999298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>65.565948</td>\n",
       "      <td>208179.843750</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-7.949048e-06</td>\n",
       "      <td>2.292349e-01</td>\n",
       "      <td>-3.467642e-05</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>54.333893</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>3175.114746</td>\n",
       "      <td>42008.457031</td>\n",
       "      <td>7.996448e+10</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>34.640247</td>\n",
       "      <td>3.572013e-03</td>\n",
       "      <td>0.338318</td>\n",
       "      <td>1.726318</td>\n",
       "      <td>21.988647</td>\n",
       "      <td>112.004150</td>\n",
       "      <td>208.000977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>35.650501</td>\n",
       "      <td>316225.750000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>4.467801e-07</td>\n",
       "      <td>-1.222656e-02</td>\n",
       "      <td>4.467801e+05</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>82.534065</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>8870.164062</td>\n",
       "      <td>96643.554688</td>\n",
       "      <td>1.178048e+11</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>63.304726</td>\n",
       "      <td>-5.896445e-04</td>\n",
       "      <td>0.918457</td>\n",
       "      <td>4.501740</td>\n",
       "      <td>51.987183</td>\n",
       "      <td>160.014648</td>\n",
       "      <td>239.997330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>35.578690</td>\n",
       "      <td>165172.265625</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>7.151962e-07</td>\n",
       "      <td>5.476070e-02</td>\n",
       "      <td>1.306039e-05</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>81.288063</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>4642.449219</td>\n",
       "      <td>56666.421875</td>\n",
       "      <td>6.972513e+10</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>58.334003</td>\n",
       "      <td>2.724180e-05</td>\n",
       "      <td>0.632538</td>\n",
       "      <td>3.237610</td>\n",
       "      <td>40.003754</td>\n",
       "      <td>176.001343</td>\n",
       "      <td>255.988953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>32.842499</td>\n",
       "      <td>272285.156250</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-2.548874e-06</td>\n",
       "      <td>-2.222098e-02</td>\n",
       "      <td>-2.548874e+06</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>82.059593</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>8290.634766</td>\n",
       "      <td>106324.718750</td>\n",
       "      <td>2.278781e+11</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>448.031982</td>\n",
       "      <td>61.963135</td>\n",
       "      <td>3.921397e-04</td>\n",
       "      <td>0.833496</td>\n",
       "      <td>4.010559</td>\n",
       "      <td>47.998489</td>\n",
       "      <td>175.985352</td>\n",
       "      <td>240.002960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.166615</td>\n",
       "      <td>56.682781</td>\n",
       "      <td>1.096746</td>\n",
       "      <td>1.989925e-04</td>\n",
       "      <td>-5.538079e-05</td>\n",
       "      <td>1.989925e+08</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>1.096737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>1.353423</td>\n",
       "      <td>8.175681</td>\n",
       "      <td>5.932172e+05</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.621704</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>-3.559407e-04</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.040955</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.165039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>34.187748</td>\n",
       "      <td>274685.562500</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>6.911815e-07</td>\n",
       "      <td>-3.381542e-03</td>\n",
       "      <td>6.911815e+05</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>71.692192</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>8034.620117</td>\n",
       "      <td>86767.773438</td>\n",
       "      <td>1.824075e+11</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>448.025879</td>\n",
       "      <td>53.748817</td>\n",
       "      <td>5.208848e-04</td>\n",
       "      <td>0.704590</td>\n",
       "      <td>3.508240</td>\n",
       "      <td>40.007050</td>\n",
       "      <td>144.005157</td>\n",
       "      <td>208.012329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>73.995186</td>\n",
       "      <td>214966.609375</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>5.357097e-05</td>\n",
       "      <td>1.608118e-01</td>\n",
       "      <td>3.331284e-04</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>56.105476</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>2905.140869</td>\n",
       "      <td>33285.167969</td>\n",
       "      <td>2.114446e+10</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>34.820297</td>\n",
       "      <td>-1.786743e-03</td>\n",
       "      <td>0.329346</td>\n",
       "      <td>1.632996</td>\n",
       "      <td>20.013794</td>\n",
       "      <td>119.993774</td>\n",
       "      <td>223.989624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>36.493416</td>\n",
       "      <td>296291.062500</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-3.694102e-06</td>\n",
       "      <td>2.692454e-02</td>\n",
       "      <td>-1.372020e-04</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>77.331161</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>8119.027832</td>\n",
       "      <td>90334.429688</td>\n",
       "      <td>1.449906e+11</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>448.033447</td>\n",
       "      <td>58.566914</td>\n",
       "      <td>1.396643e-04</td>\n",
       "      <td>0.806244</td>\n",
       "      <td>3.994720</td>\n",
       "      <td>44.012390</td>\n",
       "      <td>159.997574</td>\n",
       "      <td>224.006592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.163628</td>\n",
       "      <td>158275.140625</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-3.632149e-06</td>\n",
       "      <td>-5.050855e-02</td>\n",
       "      <td>-3.632149e+06</td>\n",
       "      <td>0.021735</td>\n",
       "      <td>77.893707</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>3583.836182</td>\n",
       "      <td>28647.994141</td>\n",
       "      <td>2.987803e+09</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>448.128906</td>\n",
       "      <td>54.644348</td>\n",
       "      <td>-8.211295e-04</td>\n",
       "      <td>0.527466</td>\n",
       "      <td>2.732056</td>\n",
       "      <td>36.001358</td>\n",
       "      <td>175.983154</td>\n",
       "      <td>240.047607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>44.411427</td>\n",
       "      <td>286513.031250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>3.162919e-06</td>\n",
       "      <td>-2.790407e-02</td>\n",
       "      <td>3.162919e+06</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>86.347496</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>6451.335938</td>\n",
       "      <td>76815.914062</td>\n",
       "      <td>1.077953e+11</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>448.043213</td>\n",
       "      <td>65.227463</td>\n",
       "      <td>-1.600708e-04</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>4.491943</td>\n",
       "      <td>51.966553</td>\n",
       "      <td>176.005432</td>\n",
       "      <td>255.989624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.920872</td>\n",
       "      <td>52.985229</td>\n",
       "      <td>1.206390</td>\n",
       "      <td>4.126995e-04</td>\n",
       "      <td>7.247948e-05</td>\n",
       "      <td>5.694018e+00</td>\n",
       "      <td>0.047185</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>1.206346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>1.300376</td>\n",
       "      <td>7.747681</td>\n",
       "      <td>6.337558e+05</td>\n",
       "      <td>-0.002351</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>-1.099915e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.040474</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>37.425797</td>\n",
       "      <td>232908.671875</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.845480e-06</td>\n",
       "      <td>-2.657622e-03</td>\n",
       "      <td>1.845480e+06</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>60.788536</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>6223.212402</td>\n",
       "      <td>72496.890625</td>\n",
       "      <td>1.360221e+11</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>448.045654</td>\n",
       "      <td>43.508984</td>\n",
       "      <td>1.693380e-04</td>\n",
       "      <td>0.490967</td>\n",
       "      <td>2.497208</td>\n",
       "      <td>31.980713</td>\n",
       "      <td>127.994049</td>\n",
       "      <td>192.008850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>83.790474</td>\n",
       "      <td>224043.687500</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>2.012922e-04</td>\n",
       "      <td>3.143978e-01</td>\n",
       "      <td>6.402470e-04</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>58.473953</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>2673.854492</td>\n",
       "      <td>33780.730469</td>\n",
       "      <td>2.987803e+10</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>35.894470</td>\n",
       "      <td>-1.253507e-03</td>\n",
       "      <td>0.335999</td>\n",
       "      <td>1.660400</td>\n",
       "      <td>20.009705</td>\n",
       "      <td>127.996002</td>\n",
       "      <td>224.015503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>39.538883</td>\n",
       "      <td>287792.812500</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>6.882189e-07</td>\n",
       "      <td>3.672514e-02</td>\n",
       "      <td>1.873972e-05</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>75.113144</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>7278.729492</td>\n",
       "      <td>326736.812500</td>\n",
       "      <td>2.645441e+12</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>448.039551</td>\n",
       "      <td>56.034348</td>\n",
       "      <td>-5.232000e-04</td>\n",
       "      <td>0.746902</td>\n",
       "      <td>3.745941</td>\n",
       "      <td>43.991028</td>\n",
       "      <td>159.990540</td>\n",
       "      <td>224.013000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.211086</td>\n",
       "      <td>148725.421875</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-2.210979e-07</td>\n",
       "      <td>2.284615e-02</td>\n",
       "      <td>-9.677687e-06</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>73.193909</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3363.983643</td>\n",
       "      <td>31014.486328</td>\n",
       "      <td>6.921386e+09</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>53.058487</td>\n",
       "      <td>1.029713e-03</td>\n",
       "      <td>0.623327</td>\n",
       "      <td>3.216797</td>\n",
       "      <td>36.137207</td>\n",
       "      <td>159.985657</td>\n",
       "      <td>224.022705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>43.829700</td>\n",
       "      <td>275328.781250</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.262830e-05</td>\n",
       "      <td>2.441130e-03</td>\n",
       "      <td>5.173140e-03</td>\n",
       "      <td>0.013209</td>\n",
       "      <td>82.976860</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>6281.785645</td>\n",
       "      <td>61390.054688</td>\n",
       "      <td>2.863311e+10</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>62.451614</td>\n",
       "      <td>4.300878e-04</td>\n",
       "      <td>0.850277</td>\n",
       "      <td>4.020264</td>\n",
       "      <td>47.998512</td>\n",
       "      <td>175.991638</td>\n",
       "      <td>240.016113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.512337</td>\n",
       "      <td>53.668427</td>\n",
       "      <td>1.146155</td>\n",
       "      <td>3.828389e-04</td>\n",
       "      <td>1.262108e-04</td>\n",
       "      <td>3.033328e+00</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.039618</td>\n",
       "      <td>1.146120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>1.327242</td>\n",
       "      <td>9.150343</td>\n",
       "      <td>1.513408e+06</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.047580</td>\n",
       "      <td>8.339830e-04</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.872108</td>\n",
       "      <td>251042.640625</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-7.462968e-07</td>\n",
       "      <td>-5.120226e-05</td>\n",
       "      <td>-7.462969e+05</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>65.521454</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>6142.150391</td>\n",
       "      <td>94325.835938</td>\n",
       "      <td>3.845286e+11</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>448.035645</td>\n",
       "      <td>47.616280</td>\n",
       "      <td>3.318621e-04</td>\n",
       "      <td>0.571205</td>\n",
       "      <td>2.990845</td>\n",
       "      <td>35.993347</td>\n",
       "      <td>128.019531</td>\n",
       "      <td>208.003082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>86.544426</td>\n",
       "      <td>211574.093750</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>2.213672e-04</td>\n",
       "      <td>2.932894e-01</td>\n",
       "      <td>7.547740e-04</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>55.219490</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>2444.686279</td>\n",
       "      <td>36657.710938</td>\n",
       "      <td>3.642960e+10</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>448.090332</td>\n",
       "      <td>33.766823</td>\n",
       "      <td>-3.190789e-04</td>\n",
       "      <td>0.333740</td>\n",
       "      <td>1.635498</td>\n",
       "      <td>19.997711</td>\n",
       "      <td>120.000870</td>\n",
       "      <td>223.992004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.083069</td>\n",
       "      <td>264269.031250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-2.680473e-07</td>\n",
       "      <td>-9.782354e-03</td>\n",
       "      <td>-2.680473e+05</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>68.973503</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>6432.552734</td>\n",
       "      <td>74949.867188</td>\n",
       "      <td>1.022802e+11</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>448.033447</td>\n",
       "      <td>50.510826</td>\n",
       "      <td>2.795917e-04</td>\n",
       "      <td>0.621231</td>\n",
       "      <td>3.011292</td>\n",
       "      <td>36.010742</td>\n",
       "      <td>143.999207</td>\n",
       "      <td>223.983276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.943066</td>\n",
       "      <td>171746.765625</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.195049e-06</td>\n",
       "      <td>5.308273e-02</td>\n",
       "      <td>2.251295e-05</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>84.523651</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>3908.392822</td>\n",
       "      <td>38092.027344</td>\n",
       "      <td>1.365288e+10</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>448.082031</td>\n",
       "      <td>61.989113</td>\n",
       "      <td>3.512416e-04</td>\n",
       "      <td>0.514893</td>\n",
       "      <td>2.721191</td>\n",
       "      <td>44.042236</td>\n",
       "      <td>176.005432</td>\n",
       "      <td>240.064941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>42.547871</td>\n",
       "      <td>322357.468750</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>5.205086e-06</td>\n",
       "      <td>2.235255e-02</td>\n",
       "      <td>2.328632e-04</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>97.150070</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>7576.348633</td>\n",
       "      <td>113839.148438</td>\n",
       "      <td>2.542223e+11</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>75.271484</td>\n",
       "      <td>-6.341565e-04</td>\n",
       "      <td>1.105835</td>\n",
       "      <td>5.493256</td>\n",
       "      <td>60.002914</td>\n",
       "      <td>192.009827</td>\n",
       "      <td>256.013733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>59.963379</td>\n",
       "      <td>56.496185</td>\n",
       "      <td>1.061370</td>\n",
       "      <td>4.075590e-04</td>\n",
       "      <td>1.312464e-04</td>\n",
       "      <td>3.105295e+00</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>1.061331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>1.376859</td>\n",
       "      <td>9.255237</td>\n",
       "      <td>5.682615e+05</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.048087</td>\n",
       "      <td>-2.849257e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.163010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.310238</td>\n",
       "      <td>263960.593750</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-4.547229e-06</td>\n",
       "      <td>-2.533327e-03</td>\n",
       "      <td>-4.547230e+06</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>68.893005</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>5825.627930</td>\n",
       "      <td>75546.671875</td>\n",
       "      <td>1.027581e+11</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>51.127525</td>\n",
       "      <td>2.469720e-04</td>\n",
       "      <td>0.671936</td>\n",
       "      <td>3.255890</td>\n",
       "      <td>39.991577</td>\n",
       "      <td>143.996109</td>\n",
       "      <td>208.006927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>91.581459</td>\n",
       "      <td>205267.031250</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>2.173313e-04</td>\n",
       "      <td>7.173754e-02</td>\n",
       "      <td>3.029533e-03</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>53.574089</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>2241.360596</td>\n",
       "      <td>46266.199219</td>\n",
       "      <td>6.871948e+10</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>448.088867</td>\n",
       "      <td>32.213394</td>\n",
       "      <td>2.221519e-04</td>\n",
       "      <td>0.326538</td>\n",
       "      <td>1.627747</td>\n",
       "      <td>19.988403</td>\n",
       "      <td>112.002502</td>\n",
       "      <td>224.000320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.552773</td>\n",
       "      <td>262363.000000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-6.160434e-06</td>\n",
       "      <td>9.338681e-03</td>\n",
       "      <td>-6.596685e-04</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>68.476036</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>6024.025879</td>\n",
       "      <td>71460.921875</td>\n",
       "      <td>3.248557e+10</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>448.050537</td>\n",
       "      <td>50.749287</td>\n",
       "      <td>-7.098765e-05</td>\n",
       "      <td>0.632996</td>\n",
       "      <td>3.247665</td>\n",
       "      <td>39.987732</td>\n",
       "      <td>143.994507</td>\n",
       "      <td>208.005646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>46.502293</td>\n",
       "      <td>165971.343750</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-3.878666e-06</td>\n",
       "      <td>1.243844e-03</td>\n",
       "      <td>-3.118289e-03</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>81.681343</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>3569.100342</td>\n",
       "      <td>33626.273438</td>\n",
       "      <td>9.111975e+09</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>448.125000</td>\n",
       "      <td>59.024380</td>\n",
       "      <td>1.225635e-04</td>\n",
       "      <td>0.536621</td>\n",
       "      <td>2.743713</td>\n",
       "      <td>43.968994</td>\n",
       "      <td>175.995392</td>\n",
       "      <td>255.968506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>43.622997</td>\n",
       "      <td>324044.500000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-5.362010e-06</td>\n",
       "      <td>-3.328361e-02</td>\n",
       "      <td>-5.362010e+06</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>97.658493</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>7428.295410</td>\n",
       "      <td>98738.742188</td>\n",
       "      <td>8.084645e+10</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>448.048828</td>\n",
       "      <td>75.587151</td>\n",
       "      <td>3.544447e-04</td>\n",
       "      <td>1.106934</td>\n",
       "      <td>5.491821</td>\n",
       "      <td>60.003540</td>\n",
       "      <td>192.013794</td>\n",
       "      <td>256.017578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.361385</td>\n",
       "      <td>57.482117</td>\n",
       "      <td>1.067487</td>\n",
       "      <td>4.563871e-04</td>\n",
       "      <td>2.085474e-04</td>\n",
       "      <td>2.188409e+00</td>\n",
       "      <td>0.045295</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002468</td>\n",
       "      <td>1.371926</td>\n",
       "      <td>11.144596</td>\n",
       "      <td>1.712673e+06</td>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>-1.191945e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.967201</td>\n",
       "      <td>250408.062500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1.679038e-06</td>\n",
       "      <td>1.292949e-02</td>\n",
       "      <td>1.298611e-04</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>65.355827</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>5966.756348</td>\n",
       "      <td>87873.343750</td>\n",
       "      <td>1.917753e+11</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>47.950573</td>\n",
       "      <td>-1.841962e-04</td>\n",
       "      <td>0.612549</td>\n",
       "      <td>3.001550</td>\n",
       "      <td>36.000183</td>\n",
       "      <td>128.007629</td>\n",
       "      <td>208.000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>94.314461</td>\n",
       "      <td>206260.328125</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>2.190171e-04</td>\n",
       "      <td>1.562747e-02</td>\n",
       "      <td>1.401488e-02</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>53.833389</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>2186.943359</td>\n",
       "      <td>36411.246094</td>\n",
       "      <td>2.824088e+10</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>448.088379</td>\n",
       "      <td>32.682415</td>\n",
       "      <td>6.006173e-04</td>\n",
       "      <td>0.340088</td>\n",
       "      <td>1.700195</td>\n",
       "      <td>19.997894</td>\n",
       "      <td>112.004181</td>\n",
       "      <td>224.000977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.831738</td>\n",
       "      <td>254143.609375</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>7.714563e-07</td>\n",
       "      <td>8.034391e-03</td>\n",
       "      <td>9.601926e-05</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>66.330795</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>5933.535156</td>\n",
       "      <td>81376.351562</td>\n",
       "      <td>1.268667e+11</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>48.853081</td>\n",
       "      <td>-9.829581e-06</td>\n",
       "      <td>0.617920</td>\n",
       "      <td>3.005066</td>\n",
       "      <td>36.004578</td>\n",
       "      <td>128.024780</td>\n",
       "      <td>207.999374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.810741</td>\n",
       "      <td>192736.578125</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>2.028491e-06</td>\n",
       "      <td>-3.845371e-02</td>\n",
       "      <td>2.028491e+06</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>94.853600</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>3793.225342</td>\n",
       "      <td>37852.476562</td>\n",
       "      <td>1.453681e+10</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>448.090820</td>\n",
       "      <td>70.807175</td>\n",
       "      <td>-3.470240e-04</td>\n",
       "      <td>0.587402</td>\n",
       "      <td>2.997269</td>\n",
       "      <td>55.970459</td>\n",
       "      <td>192.017090</td>\n",
       "      <td>256.023560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>52.763145</td>\n",
       "      <td>307570.718750</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>8.200746e-07</td>\n",
       "      <td>4.014836e-02</td>\n",
       "      <td>2.042610e-05</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>92.693726</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>5829.271973</td>\n",
       "      <td>64734.238281</td>\n",
       "      <td>4.780485e+10</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>448.048096</td>\n",
       "      <td>70.225998</td>\n",
       "      <td>-8.608949e-05</td>\n",
       "      <td>0.888306</td>\n",
       "      <td>4.499134</td>\n",
       "      <td>52.032227</td>\n",
       "      <td>191.998734</td>\n",
       "      <td>256.008057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.909180</td>\n",
       "      <td>55.247620</td>\n",
       "      <td>1.102476</td>\n",
       "      <td>4.544015e-04</td>\n",
       "      <td>2.422025e-04</td>\n",
       "      <td>1.876122e+00</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.040784</td>\n",
       "      <td>1.102439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001725</td>\n",
       "      <td>1.351247</td>\n",
       "      <td>14.124280</td>\n",
       "      <td>1.053342e+07</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>-1.109093e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.653931</td>\n",
       "      <td>261757.046875</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-2.420139e-06</td>\n",
       "      <td>1.095472e-02</td>\n",
       "      <td>-2.209221e-04</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>68.317879</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>5861.903809</td>\n",
       "      <td>67611.867188</td>\n",
       "      <td>2.224445e+10</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>448.050049</td>\n",
       "      <td>50.335476</td>\n",
       "      <td>1.039982e-05</td>\n",
       "      <td>0.658813</td>\n",
       "      <td>3.253235</td>\n",
       "      <td>39.986267</td>\n",
       "      <td>143.991516</td>\n",
       "      <td>223.994385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>88.550323</td>\n",
       "      <td>213861.343750</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.613195e-04</td>\n",
       "      <td>-4.928809e-02</td>\n",
       "      <td>1.613195e+08</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>55.817215</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>2415.140869</td>\n",
       "      <td>44485.601562</td>\n",
       "      <td>1.963414e+10</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>34.325626</td>\n",
       "      <td>-6.342654e-04</td>\n",
       "      <td>0.359253</td>\n",
       "      <td>1.772827</td>\n",
       "      <td>21.949707</td>\n",
       "      <td>119.996979</td>\n",
       "      <td>224.009094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.156055</td>\n",
       "      <td>254356.968750</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-1.379924e-06</td>\n",
       "      <td>5.655065e-04</td>\n",
       "      <td>-2.440156e-03</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>66.386482</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5760.409668</td>\n",
       "      <td>63613.476562</td>\n",
       "      <td>1.636178e+10</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>448.053955</td>\n",
       "      <td>48.593182</td>\n",
       "      <td>1.552255e-04</td>\n",
       "      <td>0.619751</td>\n",
       "      <td>3.006042</td>\n",
       "      <td>36.002228</td>\n",
       "      <td>128.022827</td>\n",
       "      <td>208.008850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.693699</td>\n",
       "      <td>179631.687500</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-2.288964e-06</td>\n",
       "      <td>9.703936e-02</td>\n",
       "      <td>-2.358800e-05</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>88.404106</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>3689.012695</td>\n",
       "      <td>33560.445312</td>\n",
       "      <td>4.805558e+09</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>448.106934</td>\n",
       "      <td>65.864243</td>\n",
       "      <td>3.001177e-04</td>\n",
       "      <td>0.628906</td>\n",
       "      <td>3.230469</td>\n",
       "      <td>51.960938</td>\n",
       "      <td>176.037842</td>\n",
       "      <td>255.989197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>47.013763</td>\n",
       "      <td>299907.625000</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3.287169e-06</td>\n",
       "      <td>4.231628e-03</td>\n",
       "      <td>7.768095e-04</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>90.384285</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>6379.145020</td>\n",
       "      <td>78593.039062</td>\n",
       "      <td>6.299286e+10</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>448.057373</td>\n",
       "      <td>68.812584</td>\n",
       "      <td>-2.605715e-04</td>\n",
       "      <td>0.936611</td>\n",
       "      <td>4.515076</td>\n",
       "      <td>52.014038</td>\n",
       "      <td>191.983521</td>\n",
       "      <td>256.000092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.685085</td>\n",
       "      <td>54.026512</td>\n",
       "      <td>1.160265</td>\n",
       "      <td>2.984306e-04</td>\n",
       "      <td>2.348996e-04</td>\n",
       "      <td>1.270460e+00</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>0.039882</td>\n",
       "      <td>1.160261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>10.097334</td>\n",
       "      <td>1.601146e+06</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>0.601654</td>\n",
       "      <td>0.048259</td>\n",
       "      <td>-2.003028e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.040192</td>\n",
       "      <td>0.120361</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.977657</td>\n",
       "      <td>255123.500000</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>2.263072e-06</td>\n",
       "      <td>2.233088e-02</td>\n",
       "      <td>1.013427e-04</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>66.586540</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5936.188965</td>\n",
       "      <td>72545.148438</td>\n",
       "      <td>5.429687e+10</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>48.868233</td>\n",
       "      <td>-9.275613e-05</td>\n",
       "      <td>0.624369</td>\n",
       "      <td>3.232300</td>\n",
       "      <td>36.006989</td>\n",
       "      <td>128.011536</td>\n",
       "      <td>223.966553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>80.258064</td>\n",
       "      <td>197298.640625</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>9.398915e-05</td>\n",
       "      <td>9.880558e-02</td>\n",
       "      <td>9.512535e-04</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>51.494320</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.002048</td>\n",
       "      <td>2458.305176</td>\n",
       "      <td>50679.742188</td>\n",
       "      <td>5.961208e+10</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>448.101074</td>\n",
       "      <td>31.786739</td>\n",
       "      <td>-8.464399e-04</td>\n",
       "      <td>0.337982</td>\n",
       "      <td>1.656738</td>\n",
       "      <td>19.997437</td>\n",
       "      <td>104.005585</td>\n",
       "      <td>208.006439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.370766</td>\n",
       "      <td>249163.703125</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.542116e-06</td>\n",
       "      <td>3.286558e-02</td>\n",
       "      <td>4.692192e-05</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>65.031044</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>5744.969238</td>\n",
       "      <td>137100.203125</td>\n",
       "      <td>4.317101e+11</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>47.781593</td>\n",
       "      <td>-6.801366e-05</td>\n",
       "      <td>0.620422</td>\n",
       "      <td>3.008301</td>\n",
       "      <td>36.000195</td>\n",
       "      <td>128.005127</td>\n",
       "      <td>207.999573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.868774</td>\n",
       "      <td>186268.890625</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4.309190e-06</td>\n",
       "      <td>7.512900e-02</td>\n",
       "      <td>5.735721e-05</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>91.670570</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>3661.753174</td>\n",
       "      <td>35885.093750</td>\n",
       "      <td>9.554579e+09</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>448.188477</td>\n",
       "      <td>68.483772</td>\n",
       "      <td>4.107679e-04</td>\n",
       "      <td>0.619507</td>\n",
       "      <td>3.217285</td>\n",
       "      <td>52.008484</td>\n",
       "      <td>191.992615</td>\n",
       "      <td>256.006226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>54.821720</td>\n",
       "      <td>303415.875000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-1.320386e-06</td>\n",
       "      <td>1.594279e-02</td>\n",
       "      <td>-8.282024e-05</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>91.441566</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>5534.592773</td>\n",
       "      <td>56591.507812</td>\n",
       "      <td>1.502065e+10</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>68.983444</td>\n",
       "      <td>-1.252155e-04</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>4.496109</td>\n",
       "      <td>52.004486</td>\n",
       "      <td>191.994751</td>\n",
       "      <td>256.007629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.182152</td>\n",
       "      <td>52.010090</td>\n",
       "      <td>1.214806</td>\n",
       "      <td>3.551023e-04</td>\n",
       "      <td>4.025494e-04</td>\n",
       "      <td>8.821335e-01</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.038392</td>\n",
       "      <td>1.214837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>1.297325</td>\n",
       "      <td>7.492600</td>\n",
       "      <td>5.786942e+05</td>\n",
       "      <td>-0.003380</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>0.047714</td>\n",
       "      <td>-2.543100e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039706</td>\n",
       "      <td>0.118896</td>\n",
       "      <td>0.161591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.694138</td>\n",
       "      <td>253349.312500</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-3.134209e-06</td>\n",
       "      <td>-2.396222e-02</td>\n",
       "      <td>-3.134208e+06</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>66.123482</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>5798.245605</td>\n",
       "      <td>103942.492188</td>\n",
       "      <td>4.773074e+11</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>448.169922</td>\n",
       "      <td>49.261894</td>\n",
       "      <td>-1.668757e-04</td>\n",
       "      <td>0.567585</td>\n",
       "      <td>2.988892</td>\n",
       "      <td>36.024536</td>\n",
       "      <td>128.008850</td>\n",
       "      <td>192.010742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>83.070198</td>\n",
       "      <td>152293.328125</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>8.412390e-05</td>\n",
       "      <td>8.334381e-02</td>\n",
       "      <td>1.009360e-03</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>39.748058</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>1833.311279</td>\n",
       "      <td>60341.679688</td>\n",
       "      <td>2.532906e+11</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>448.087402</td>\n",
       "      <td>25.531776</td>\n",
       "      <td>-1.006113e-03</td>\n",
       "      <td>0.294250</td>\n",
       "      <td>1.496918</td>\n",
       "      <td>17.990234</td>\n",
       "      <td>72.002457</td>\n",
       "      <td>159.990173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.037579</td>\n",
       "      <td>238882.812500</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-2.181807e-06</td>\n",
       "      <td>-1.616513e-02</td>\n",
       "      <td>-2.181807e+06</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>62.347771</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5424.522461</td>\n",
       "      <td>87642.031250</td>\n",
       "      <td>3.227924e+11</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>46.309608</td>\n",
       "      <td>4.099178e-04</td>\n",
       "      <td>0.616943</td>\n",
       "      <td>3.004120</td>\n",
       "      <td>35.994324</td>\n",
       "      <td>127.995575</td>\n",
       "      <td>191.996231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.171547</td>\n",
       "      <td>189226.890625</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-1.168154e-05</td>\n",
       "      <td>3.427737e-02</td>\n",
       "      <td>-3.407946e-04</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>93.126350</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3697.892822</td>\n",
       "      <td>43932.089844</td>\n",
       "      <td>3.435974e+10</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>448.087891</td>\n",
       "      <td>68.981293</td>\n",
       "      <td>1.938382e-04</td>\n",
       "      <td>0.607259</td>\n",
       "      <td>3.019043</td>\n",
       "      <td>51.998413</td>\n",
       "      <td>192.010559</td>\n",
       "      <td>256.025513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>62.171219</td>\n",
       "      <td>314810.125000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>6.371345e-06</td>\n",
       "      <td>-2.448407e-03</td>\n",
       "      <td>6.371344e+06</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>94.875511</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>5063.599609</td>\n",
       "      <td>56138.335938</td>\n",
       "      <td>3.546812e+10</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>448.065430</td>\n",
       "      <td>72.510666</td>\n",
       "      <td>-2.761971e-04</td>\n",
       "      <td>0.952332</td>\n",
       "      <td>4.978561</td>\n",
       "      <td>56.007233</td>\n",
       "      <td>192.006836</td>\n",
       "      <td>256.015137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.850780</td>\n",
       "      <td>49.865566</td>\n",
       "      <td>1.280458</td>\n",
       "      <td>1.851208e-04</td>\n",
       "      <td>3.350106e-04</td>\n",
       "      <td>5.525820e-01</td>\n",
       "      <td>0.047135</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>1.280502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>1.270987</td>\n",
       "      <td>7.658829</td>\n",
       "      <td>1.154136e+06</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>-2.689425e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.159729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.938866</td>\n",
       "      <td>231562.562500</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>2.060468e-06</td>\n",
       "      <td>7.649785e-03</td>\n",
       "      <td>2.693498e-04</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>60.437206</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5392.842773</td>\n",
       "      <td>89205.640625</td>\n",
       "      <td>2.199023e+11</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>44.529606</td>\n",
       "      <td>3.690844e-04</td>\n",
       "      <td>0.560165</td>\n",
       "      <td>2.753052</td>\n",
       "      <td>32.012451</td>\n",
       "      <td>120.006836</td>\n",
       "      <td>191.990845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>76.841179</td>\n",
       "      <td>154447.515625</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>4.140424e-05</td>\n",
       "      <td>7.981002e-02</td>\n",
       "      <td>5.187850e-04</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>40.310303</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>2009.958862</td>\n",
       "      <td>34416.296875</td>\n",
       "      <td>4.678773e+10</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>448.074219</td>\n",
       "      <td>26.249416</td>\n",
       "      <td>-8.827740e-04</td>\n",
       "      <td>0.307098</td>\n",
       "      <td>1.506195</td>\n",
       "      <td>17.998337</td>\n",
       "      <td>72.027344</td>\n",
       "      <td>159.937012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.662048</td>\n",
       "      <td>231356.515625</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>2.608207e-06</td>\n",
       "      <td>-1.491899e-02</td>\n",
       "      <td>2.608207e+06</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>60.383430</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5423.005859</td>\n",
       "      <td>68517.617188</td>\n",
       "      <td>4.006318e+10</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>44.436245</td>\n",
       "      <td>1.883693e-04</td>\n",
       "      <td>0.563178</td>\n",
       "      <td>2.758484</td>\n",
       "      <td>32.004517</td>\n",
       "      <td>127.978271</td>\n",
       "      <td>191.986328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.585777</td>\n",
       "      <td>194538.734375</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>-2.157557e-05</td>\n",
       "      <td>3.859184e-03</td>\n",
       "      <td>-5.590707e-03</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>95.740532</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>3771.169922</td>\n",
       "      <td>36770.828125</td>\n",
       "      <td>6.650272e+09</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>448.105957</td>\n",
       "      <td>71.288094</td>\n",
       "      <td>1.848901e-04</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>3.222778</td>\n",
       "      <td>55.962402</td>\n",
       "      <td>192.034424</td>\n",
       "      <td>256.044678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.028961</td>\n",
       "      <td>323574.531250</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>9.261754e-06</td>\n",
       "      <td>3.194254e-02</td>\n",
       "      <td>2.899505e-04</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>97.516869</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>4827.384277</td>\n",
       "      <td>57141.085938</td>\n",
       "      <td>5.961208e+10</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>448.062256</td>\n",
       "      <td>75.351212</td>\n",
       "      <td>-1.204373e-06</td>\n",
       "      <td>1.020264</td>\n",
       "      <td>5.461426</td>\n",
       "      <td>60.001373</td>\n",
       "      <td>192.020996</td>\n",
       "      <td>256.025513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.051323</td>\n",
       "      <td>51.242741</td>\n",
       "      <td>1.210929</td>\n",
       "      <td>5.022708e-05</td>\n",
       "      <td>4.078590e-04</td>\n",
       "      <td>1.231481e-01</td>\n",
       "      <td>0.045807</td>\n",
       "      <td>0.037826</td>\n",
       "      <td>1.210999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006046</td>\n",
       "      <td>1.300750</td>\n",
       "      <td>7.540335</td>\n",
       "      <td>7.418769e+05</td>\n",
       "      <td>-0.006058</td>\n",
       "      <td>0.579712</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>-5.781804e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>0.158447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.100792</td>\n",
       "      <td>251104.656250</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.771797e-06</td>\n",
       "      <td>-2.997688e-05</td>\n",
       "      <td>-1.771797e+06</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>65.537636</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>5567.632812</td>\n",
       "      <td>65712.617188</td>\n",
       "      <td>8.078044e+10</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>48.383396</td>\n",
       "      <td>2.285991e-04</td>\n",
       "      <td>0.565744</td>\n",
       "      <td>2.978027</td>\n",
       "      <td>36.000435</td>\n",
       "      <td>128.027222</td>\n",
       "      <td>192.014282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>75.130760</td>\n",
       "      <td>130005.640625</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>1.298265e-05</td>\n",
       "      <td>5.368698e-02</td>\n",
       "      <td>2.418213e-04</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>33.931076</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>1730.392944</td>\n",
       "      <td>38455.523438</td>\n",
       "      <td>4.754645e+10</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>448.109863</td>\n",
       "      <td>23.628176</td>\n",
       "      <td>-5.342925e-04</td>\n",
       "      <td>0.292969</td>\n",
       "      <td>1.493958</td>\n",
       "      <td>17.973511</td>\n",
       "      <td>64.004578</td>\n",
       "      <td>104.011292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.422676</td>\n",
       "      <td>231655.156250</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>5.882713e-07</td>\n",
       "      <td>-2.174682e-02</td>\n",
       "      <td>5.882714e+05</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>60.461372</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>5214.794922</td>\n",
       "      <td>68696.265625</td>\n",
       "      <td>1.691556e+11</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>44.068352</td>\n",
       "      <td>2.352858e-04</td>\n",
       "      <td>0.552856</td>\n",
       "      <td>2.747253</td>\n",
       "      <td>31.996460</td>\n",
       "      <td>127.993500</td>\n",
       "      <td>191.994934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.504116</td>\n",
       "      <td>189007.765625</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>1.287167e-05</td>\n",
       "      <td>-2.249974e-02</td>\n",
       "      <td>1.287167e+07</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>93.018517</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>3896.737061</td>\n",
       "      <td>108091.843750</td>\n",
       "      <td>1.809323e+11</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>448.100586</td>\n",
       "      <td>69.130898</td>\n",
       "      <td>-4.219027e-04</td>\n",
       "      <td>0.634135</td>\n",
       "      <td>3.242462</td>\n",
       "      <td>52.002319</td>\n",
       "      <td>192.006134</td>\n",
       "      <td>256.014648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.526833</td>\n",
       "      <td>333944.687500</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>7.903849e-07</td>\n",
       "      <td>-3.563926e-02</td>\n",
       "      <td>7.903849e+05</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>100.642151</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>5609.986328</td>\n",
       "      <td>65696.726562</td>\n",
       "      <td>6.944284e+10</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>448.056396</td>\n",
       "      <td>78.484642</td>\n",
       "      <td>-3.994679e-04</td>\n",
       "      <td>1.128547</td>\n",
       "      <td>5.526367</td>\n",
       "      <td>63.991028</td>\n",
       "      <td>207.982300</td>\n",
       "      <td>287.971436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.750134</td>\n",
       "      <td>49.359756</td>\n",
       "      <td>1.271281</td>\n",
       "      <td>4.912720e-05</td>\n",
       "      <td>2.551288e-04</td>\n",
       "      <td>1.925584e-01</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>1.271312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003551</td>\n",
       "      <td>1.274495</td>\n",
       "      <td>8.138981</td>\n",
       "      <td>2.219794e+06</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>0.552246</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>-3.055236e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.149212</td>\n",
       "      <td>247063.156250</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-1.787721e-06</td>\n",
       "      <td>-1.017821e-02</td>\n",
       "      <td>-1.787721e+06</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>64.482819</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>5861.631836</td>\n",
       "      <td>83600.359375</td>\n",
       "      <td>4.386349e+10</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>448.059570</td>\n",
       "      <td>48.018024</td>\n",
       "      <td>3.088471e-04</td>\n",
       "      <td>0.629456</td>\n",
       "      <td>3.245850</td>\n",
       "      <td>36.007324</td>\n",
       "      <td>127.998901</td>\n",
       "      <td>207.968506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>72.227585</td>\n",
       "      <td>181604.406250</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1.781603e-05</td>\n",
       "      <td>1.264764e-02</td>\n",
       "      <td>1.408644e-03</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>47.398262</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>2514.337891</td>\n",
       "      <td>46348.429688</td>\n",
       "      <td>4.898814e+10</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>448.113281</td>\n",
       "      <td>31.664038</td>\n",
       "      <td>-8.246223e-04</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>1.865723</td>\n",
       "      <td>21.994659</td>\n",
       "      <td>95.987976</td>\n",
       "      <td>175.998718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.069752</td>\n",
       "      <td>252705.421875</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>3.127269e-06</td>\n",
       "      <td>-2.167179e-03</td>\n",
       "      <td>3.127269e+06</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>65.955437</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>6006.819824</td>\n",
       "      <td>78606.656250</td>\n",
       "      <td>8.144531e+10</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>448.051270</td>\n",
       "      <td>48.941292</td>\n",
       "      <td>3.948596e-04</td>\n",
       "      <td>0.630859</td>\n",
       "      <td>3.244995</td>\n",
       "      <td>36.005676</td>\n",
       "      <td>128.016357</td>\n",
       "      <td>207.982422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.250446</td>\n",
       "      <td>170246.734375</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.038563e-05</td>\n",
       "      <td>-2.859824e-02</td>\n",
       "      <td>1.038563e+07</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>83.785439</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>3258.283447</td>\n",
       "      <td>32944.500000</td>\n",
       "      <td>6.170728e+09</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>448.080566</td>\n",
       "      <td>62.261913</td>\n",
       "      <td>-3.090911e-04</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>2.970825</td>\n",
       "      <td>47.990540</td>\n",
       "      <td>175.990295</td>\n",
       "      <td>240.007263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>65.144463</td>\n",
       "      <td>321128.125000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-4.929692e-06</td>\n",
       "      <td>-1.455903e-02</td>\n",
       "      <td>-4.929692e+06</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>96.779587</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>4929.477539</td>\n",
       "      <td>52557.511719</td>\n",
       "      <td>1.832519e+10</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>448.070801</td>\n",
       "      <td>74.487129</td>\n",
       "      <td>1.362136e-04</td>\n",
       "      <td>0.996406</td>\n",
       "      <td>5.004059</td>\n",
       "      <td>59.988464</td>\n",
       "      <td>192.015503</td>\n",
       "      <td>256.021118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.404762</td>\n",
       "      <td>47.435638</td>\n",
       "      <td>1.315567</td>\n",
       "      <td>-1.113991e-06</td>\n",
       "      <td>6.144195e-05</td>\n",
       "      <td>-1.813078e-02</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>0.035017</td>\n",
       "      <td>1.315569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>1.258886</td>\n",
       "      <td>7.086387</td>\n",
       "      <td>4.426945e+05</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>-3.929820e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>0.154053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.535549</td>\n",
       "      <td>240439.250000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.445487e-06</td>\n",
       "      <td>-1.753473e-04</td>\n",
       "      <td>1.445487e+06</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>62.753994</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>5522.825684</td>\n",
       "      <td>59994.035156</td>\n",
       "      <td>1.871509e+10</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>448.047119</td>\n",
       "      <td>46.171185</td>\n",
       "      <td>1.870972e-04</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>2.750587</td>\n",
       "      <td>35.991638</td>\n",
       "      <td>127.995972</td>\n",
       "      <td>192.002701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>68.102524</td>\n",
       "      <td>174105.203125</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-1.824098e-06</td>\n",
       "      <td>-1.665290e-02</td>\n",
       "      <td>-1.824098e+06</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>45.440990</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>2556.518311</td>\n",
       "      <td>41185.980469</td>\n",
       "      <td>3.646339e+10</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>448.090332</td>\n",
       "      <td>30.620880</td>\n",
       "      <td>-6.035906e-04</td>\n",
       "      <td>0.361694</td>\n",
       "      <td>1.772949</td>\n",
       "      <td>21.965332</td>\n",
       "      <td>88.005005</td>\n",
       "      <td>160.004303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.068176</td>\n",
       "      <td>245458.218750</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>4.456436e-06</td>\n",
       "      <td>-2.655647e-02</td>\n",
       "      <td>4.456436e+06</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>64.063927</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>5699.294434</td>\n",
       "      <td>114335.671875</td>\n",
       "      <td>3.021559e+11</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>448.049561</td>\n",
       "      <td>47.354362</td>\n",
       "      <td>3.372317e-04</td>\n",
       "      <td>0.614807</td>\n",
       "      <td>3.001030</td>\n",
       "      <td>35.996933</td>\n",
       "      <td>128.004608</td>\n",
       "      <td>192.005432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.018276</td>\n",
       "      <td>186641.953125</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>9.768949e-06</td>\n",
       "      <td>-3.703205e-02</td>\n",
       "      <td>9.768949e+06</td>\n",
       "      <td>0.024616</td>\n",
       "      <td>91.854195</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>3731.474609</td>\n",
       "      <td>38760.339844</td>\n",
       "      <td>8.191726e+09</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>68.218445</td>\n",
       "      <td>7.925935e-04</td>\n",
       "      <td>0.640869</td>\n",
       "      <td>3.250557</td>\n",
       "      <td>51.990417</td>\n",
       "      <td>191.998032</td>\n",
       "      <td>256.009949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>55.811195</td>\n",
       "      <td>335747.656250</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-1.355623e-06</td>\n",
       "      <td>6.798734e-02</td>\n",
       "      <td>-1.993935e-05</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>101.185501</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>6015.775879</td>\n",
       "      <td>182631.156250</td>\n",
       "      <td>1.122905e+12</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>79.014297</td>\n",
       "      <td>3.621618e-04</td>\n",
       "      <td>1.133606</td>\n",
       "      <td>5.972412</td>\n",
       "      <td>63.995483</td>\n",
       "      <td>207.987122</td>\n",
       "      <td>287.977295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.084209</td>\n",
       "      <td>45.760281</td>\n",
       "      <td>1.378580</td>\n",
       "      <td>-1.221991e-05</td>\n",
       "      <td>1.062308e-04</td>\n",
       "      <td>-1.150317e-01</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.033781</td>\n",
       "      <td>1.378587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004642</td>\n",
       "      <td>1.238110</td>\n",
       "      <td>8.630249</td>\n",
       "      <td>3.332972e+06</td>\n",
       "      <td>-0.004641</td>\n",
       "      <td>0.630844</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>-4.209928e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>0.153564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.389908</td>\n",
       "      <td>230632.750000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>5.718708e-07</td>\n",
       "      <td>-1.643468e-02</td>\n",
       "      <td>5.718708e+05</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>60.194527</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>4971.615234</td>\n",
       "      <td>60915.753906</td>\n",
       "      <td>5.286114e+10</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>44.023239</td>\n",
       "      <td>-1.658506e-04</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>2.743347</td>\n",
       "      <td>32.004303</td>\n",
       "      <td>120.006378</td>\n",
       "      <td>191.998077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>74.325966</td>\n",
       "      <td>183386.718750</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-1.808949e-05</td>\n",
       "      <td>-8.035551e-02</td>\n",
       "      <td>-1.808949e+07</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>47.863373</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>2467.332031</td>\n",
       "      <td>37515.609375</td>\n",
       "      <td>1.784921e+10</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>448.105469</td>\n",
       "      <td>32.712452</td>\n",
       "      <td>-1.095551e-03</td>\n",
       "      <td>0.383545</td>\n",
       "      <td>1.889160</td>\n",
       "      <td>22.010559</td>\n",
       "      <td>95.999458</td>\n",
       "      <td>160.028320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.460163</td>\n",
       "      <td>235976.156250</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>1.905539e-06</td>\n",
       "      <td>-1.813463e-02</td>\n",
       "      <td>1.905539e+06</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>61.589142</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>5079.107910</td>\n",
       "      <td>69824.281250</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>448.075195</td>\n",
       "      <td>45.274456</td>\n",
       "      <td>-4.907714e-04</td>\n",
       "      <td>0.568390</td>\n",
       "      <td>2.983276</td>\n",
       "      <td>32.012329</td>\n",
       "      <td>127.993652</td>\n",
       "      <td>191.998138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.282570</td>\n",
       "      <td>191723.765625</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.245191e-05</td>\n",
       "      <td>-1.889592e-02</td>\n",
       "      <td>1.245192e+07</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>94.355164</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>3598.245117</td>\n",
       "      <td>32920.160156</td>\n",
       "      <td>5.245762e+09</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>70.256126</td>\n",
       "      <td>1.060141e-04</td>\n",
       "      <td>0.630615</td>\n",
       "      <td>3.245422</td>\n",
       "      <td>52.023926</td>\n",
       "      <td>192.017212</td>\n",
       "      <td>256.026123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.073479</td>\n",
       "      <td>341160.906250</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>3.105785e-06</td>\n",
       "      <td>3.046496e-02</td>\n",
       "      <td>1.019461e-04</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>102.816933</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>5086.375488</td>\n",
       "      <td>113385.765625</td>\n",
       "      <td>4.429687e+11</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>80.569618</td>\n",
       "      <td>-3.955459e-04</td>\n",
       "      <td>1.205078</td>\n",
       "      <td>5.996490</td>\n",
       "      <td>64.007874</td>\n",
       "      <td>207.994110</td>\n",
       "      <td>287.981934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.973553</td>\n",
       "      <td>46.179924</td>\n",
       "      <td>1.342002</td>\n",
       "      <td>-5.842796e-06</td>\n",
       "      <td>2.846467e-05</td>\n",
       "      <td>-2.052648e-01</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.342003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>1.249538</td>\n",
       "      <td>8.309877</td>\n",
       "      <td>2.365393e+06</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>-3.411457e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.112061</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.197800</td>\n",
       "      <td>247829.406250</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>9.818995e-06</td>\n",
       "      <td>1.695100e-02</td>\n",
       "      <td>5.792574e-04</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>64.682808</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>5483.218750</td>\n",
       "      <td>65615.882812</td>\n",
       "      <td>5.216661e+10</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>448.055664</td>\n",
       "      <td>47.841057</td>\n",
       "      <td>1.265548e-04</td>\n",
       "      <td>0.578735</td>\n",
       "      <td>2.997284</td>\n",
       "      <td>36.004364</td>\n",
       "      <td>128.001801</td>\n",
       "      <td>207.991699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>70.298676</td>\n",
       "      <td>199909.265625</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>1.465653e-05</td>\n",
       "      <td>-1.079188e-01</td>\n",
       "      <td>1.465653e+07</td>\n",
       "      <td>0.018348</td>\n",
       "      <td>52.175667</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>2843.714844</td>\n",
       "      <td>45011.886719</td>\n",
       "      <td>4.302437e+10</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>35.923420</td>\n",
       "      <td>-8.924748e-04</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>2.035645</td>\n",
       "      <td>24.034180</td>\n",
       "      <td>104.005585</td>\n",
       "      <td>176.023193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.633236</td>\n",
       "      <td>251577.046875</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.387375e-06</td>\n",
       "      <td>-3.892486e-03</td>\n",
       "      <td>2.387375e+06</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>65.660934</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>5636.540527</td>\n",
       "      <td>70258.507812</td>\n",
       "      <td>1.499334e+11</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>448.055664</td>\n",
       "      <td>48.812527</td>\n",
       "      <td>-2.093344e-04</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>3.247543</td>\n",
       "      <td>36.006805</td>\n",
       "      <td>128.010742</td>\n",
       "      <td>207.953613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.084736</td>\n",
       "      <td>189800.718750</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-6.229685e-06</td>\n",
       "      <td>7.405902e-02</td>\n",
       "      <td>-8.411784e-05</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>93.408730</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>3644.076660</td>\n",
       "      <td>55398.613281</td>\n",
       "      <td>5.662721e+10</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>448.102539</td>\n",
       "      <td>69.423103</td>\n",
       "      <td>-5.787857e-04</td>\n",
       "      <td>0.672485</td>\n",
       "      <td>3.324707</td>\n",
       "      <td>52.001808</td>\n",
       "      <td>192.010925</td>\n",
       "      <td>256.019531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>58.247837</td>\n",
       "      <td>352249.687500</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>7.624965e-06</td>\n",
       "      <td>-1.217848e-02</td>\n",
       "      <td>7.624965e+06</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>106.158806</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>6047.429688</td>\n",
       "      <td>118446.406250</td>\n",
       "      <td>4.123169e+11</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>448.054443</td>\n",
       "      <td>83.965500</td>\n",
       "      <td>-2.292487e-04</td>\n",
       "      <td>1.261597</td>\n",
       "      <td>6.494751</td>\n",
       "      <td>71.989197</td>\n",
       "      <td>208.006378</td>\n",
       "      <td>287.992310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.863007</td>\n",
       "      <td>43.545822</td>\n",
       "      <td>1.397677</td>\n",
       "      <td>-4.725270e-05</td>\n",
       "      <td>7.091826e-05</td>\n",
       "      <td>-6.662980e-01</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>0.032146</td>\n",
       "      <td>1.397680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>1.232308</td>\n",
       "      <td>7.579942</td>\n",
       "      <td>1.231282e+06</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>-3.491116e-03</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.108643</td>\n",
       "      <td>0.147583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.931683</td>\n",
       "      <td>258967.203125</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.960684e-06</td>\n",
       "      <td>-1.130648e-02</td>\n",
       "      <td>1.960684e+06</td>\n",
       "      <td>0.012510</td>\n",
       "      <td>67.589737</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>5402.839844</td>\n",
       "      <td>94233.632812</td>\n",
       "      <td>2.393495e+11</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>49.313259</td>\n",
       "      <td>-1.862604e-04</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>3.007172</td>\n",
       "      <td>36.006104</td>\n",
       "      <td>143.991577</td>\n",
       "      <td>223.992554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>68.468765</td>\n",
       "      <td>223264.484375</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-1.311062e-05</td>\n",
       "      <td>-7.179382e-02</td>\n",
       "      <td>-1.311062e+07</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>58.271381</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>3260.823730</td>\n",
       "      <td>42319.062500</td>\n",
       "      <td>3.276690e+10</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>448.080078</td>\n",
       "      <td>40.509304</td>\n",
       "      <td>-9.134573e-04</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>2.256592</td>\n",
       "      <td>27.996506</td>\n",
       "      <td>120.006439</td>\n",
       "      <td>192.013550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.949577</td>\n",
       "      <td>258003.062500</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-1.868062e-06</td>\n",
       "      <td>-6.031224e-04</td>\n",
       "      <td>-1.868062e+06</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>67.338104</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>5495.322266</td>\n",
       "      <td>59840.785156</td>\n",
       "      <td>1.381296e+10</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>49.617111</td>\n",
       "      <td>-1.027135e-04</td>\n",
       "      <td>0.634949</td>\n",
       "      <td>3.249195</td>\n",
       "      <td>36.008301</td>\n",
       "      <td>143.990601</td>\n",
       "      <td>208.004974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.602535</td>\n",
       "      <td>185338.343750</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-1.446391e-05</td>\n",
       "      <td>5.707364e-02</td>\n",
       "      <td>-2.534253e-04</td>\n",
       "      <td>0.024904</td>\n",
       "      <td>91.212624</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>3662.629883</td>\n",
       "      <td>35816.812500</td>\n",
       "      <td>6.343336e+09</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>67.374046</td>\n",
       "      <td>-3.494063e-04</td>\n",
       "      <td>0.582845</td>\n",
       "      <td>2.994274</td>\n",
       "      <td>51.965332</td>\n",
       "      <td>191.995544</td>\n",
       "      <td>256.009705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>57.460434</td>\n",
       "      <td>349251.406250</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>1.119392e-06</td>\n",
       "      <td>-2.197577e-02</td>\n",
       "      <td>1.119392e+06</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>105.255188</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>6078.119141</td>\n",
       "      <td>110719.929688</td>\n",
       "      <td>5.929950e+11</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>82.983955</td>\n",
       "      <td>2.064742e-04</td>\n",
       "      <td>1.252747</td>\n",
       "      <td>6.475098</td>\n",
       "      <td>71.977539</td>\n",
       "      <td>208.003937</td>\n",
       "      <td>287.991150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.605721</td>\n",
       "      <td>41.730858</td>\n",
       "      <td>1.476263</td>\n",
       "      <td>-1.530145e-04</td>\n",
       "      <td>2.700510e-05</td>\n",
       "      <td>-5.666134e+00</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>1.476255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>1.210989</td>\n",
       "      <td>6.799035</td>\n",
       "      <td>1.167164e+06</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.651154</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>-4.214777e-03</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.036011</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.564346</td>\n",
       "      <td>237526.000000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.318720e-06</td>\n",
       "      <td>-1.888927e-03</td>\n",
       "      <td>2.318720e+06</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>61.993645</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>5101.026855</td>\n",
       "      <td>60454.804688</td>\n",
       "      <td>3.214946e+10</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>45.218090</td>\n",
       "      <td>5.208935e-04</td>\n",
       "      <td>0.554871</td>\n",
       "      <td>2.748199</td>\n",
       "      <td>32.011597</td>\n",
       "      <td>127.994049</td>\n",
       "      <td>192.008179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>66.990974</td>\n",
       "      <td>220415.093750</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-4.016560e-06</td>\n",
       "      <td>-1.647688e-01</td>\n",
       "      <td>-4.016560e+06</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>57.527512</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>3290.221191</td>\n",
       "      <td>154464.421875</td>\n",
       "      <td>1.599290e+12</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>448.083496</td>\n",
       "      <td>40.729774</td>\n",
       "      <td>-4.129802e-04</td>\n",
       "      <td>0.482666</td>\n",
       "      <td>2.490784</td>\n",
       "      <td>28.013306</td>\n",
       "      <td>119.999237</td>\n",
       "      <td>191.995178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.014114</td>\n",
       "      <td>243710.812500</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>5.867026e-06</td>\n",
       "      <td>-6.488448e-03</td>\n",
       "      <td>5.867026e+06</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>63.607864</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>5296.436035</td>\n",
       "      <td>54421.101562</td>\n",
       "      <td>1.906668e+10</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>448.040283</td>\n",
       "      <td>46.840004</td>\n",
       "      <td>-1.056472e-04</td>\n",
       "      <td>0.617981</td>\n",
       "      <td>3.005493</td>\n",
       "      <td>35.992767</td>\n",
       "      <td>128.002899</td>\n",
       "      <td>192.010803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.571045</td>\n",
       "      <td>178447.593750</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>1.410764e-05</td>\n",
       "      <td>-7.414980e-02</td>\n",
       "      <td>1.410764e+07</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>87.821396</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3394.408691</td>\n",
       "      <td>28110.822266</td>\n",
       "      <td>3.435974e+09</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>448.089355</td>\n",
       "      <td>65.355232</td>\n",
       "      <td>-9.170552e-05</td>\n",
       "      <td>0.674968</td>\n",
       "      <td>3.474365</td>\n",
       "      <td>48.023193</td>\n",
       "      <td>176.031982</td>\n",
       "      <td>255.986328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>65.445320</td>\n",
       "      <td>350310.343750</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-6.649078e-06</td>\n",
       "      <td>-5.937477e-02</td>\n",
       "      <td>-6.649078e+06</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>105.574318</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>5352.717773</td>\n",
       "      <td>73483.367188</td>\n",
       "      <td>1.951796e+11</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>448.059570</td>\n",
       "      <td>83.454048</td>\n",
       "      <td>7.091999e-05</td>\n",
       "      <td>1.261597</td>\n",
       "      <td>6.491272</td>\n",
       "      <td>71.983521</td>\n",
       "      <td>208.004395</td>\n",
       "      <td>287.989746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.044193</td>\n",
       "      <td>38.723587</td>\n",
       "      <td>1.576409</td>\n",
       "      <td>-2.331353e-04</td>\n",
       "      <td>1.089518e-07</td>\n",
       "      <td>-2.139803e+03</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>1.576388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005457</td>\n",
       "      <td>1.187151</td>\n",
       "      <td>6.806275</td>\n",
       "      <td>9.437174e+05</td>\n",
       "      <td>-0.005457</td>\n",
       "      <td>0.676025</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>-4.461233e-03</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.035095</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.011139</td>\n",
       "      <td>245694.359375</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>5.785107e-07</td>\n",
       "      <td>-1.659142e-02</td>\n",
       "      <td>5.785106e+05</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>64.125565</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>5226.300781</td>\n",
       "      <td>53237.601562</td>\n",
       "      <td>1.812382e+10</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.056885</td>\n",
       "      <td>46.886604</td>\n",
       "      <td>2.620186e-04</td>\n",
       "      <td>0.561195</td>\n",
       "      <td>2.756317</td>\n",
       "      <td>35.993256</td>\n",
       "      <td>128.003708</td>\n",
       "      <td>207.991394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>61.929295</td>\n",
       "      <td>229450.031250</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>1.733290e-06</td>\n",
       "      <td>-2.156630e-01</td>\n",
       "      <td>1.733290e+06</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>59.885452</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3705.032227</td>\n",
       "      <td>51236.792969</td>\n",
       "      <td>1.124501e+11</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>42.024529</td>\n",
       "      <td>3.742337e-06</td>\n",
       "      <td>0.476196</td>\n",
       "      <td>2.484131</td>\n",
       "      <td>28.022461</td>\n",
       "      <td>127.988831</td>\n",
       "      <td>192.015442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.404636</td>\n",
       "      <td>237881.484375</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-1.802183e-06</td>\n",
       "      <td>-1.224682e-02</td>\n",
       "      <td>-1.802183e+06</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>62.086426</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>5126.244629</td>\n",
       "      <td>56260.359375</td>\n",
       "      <td>2.159755e+10</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>448.051270</td>\n",
       "      <td>45.346439</td>\n",
       "      <td>-1.868989e-04</td>\n",
       "      <td>0.569519</td>\n",
       "      <td>2.988403</td>\n",
       "      <td>32.010132</td>\n",
       "      <td>127.996765</td>\n",
       "      <td>192.007874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.397686</td>\n",
       "      <td>185549.109375</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-7.090073e-06</td>\n",
       "      <td>3.424453e-02</td>\n",
       "      <td>-2.070425e-04</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>91.316360</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>3610.067383</td>\n",
       "      <td>40893.218750</td>\n",
       "      <td>1.385939e+10</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>448.090820</td>\n",
       "      <td>67.768341</td>\n",
       "      <td>3.919393e-04</td>\n",
       "      <td>0.680461</td>\n",
       "      <td>3.486267</td>\n",
       "      <td>51.973633</td>\n",
       "      <td>191.995636</td>\n",
       "      <td>256.010437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.362633</td>\n",
       "      <td>352155.875000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-1.075843e-05</td>\n",
       "      <td>1.588381e-02</td>\n",
       "      <td>-6.773203e-04</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>106.130531</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>5227.763184</td>\n",
       "      <td>101440.617188</td>\n",
       "      <td>4.143087e+11</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>84.165985</td>\n",
       "      <td>-8.860804e-05</td>\n",
       "      <td>1.282471</td>\n",
       "      <td>6.501228</td>\n",
       "      <td>71.991333</td>\n",
       "      <td>208.005585</td>\n",
       "      <td>287.988403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.068474</td>\n",
       "      <td>37.407093</td>\n",
       "      <td>1.605804</td>\n",
       "      <td>-2.001737e-04</td>\n",
       "      <td>1.250116e-05</td>\n",
       "      <td>-1.601241e+01</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>1.605788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009123</td>\n",
       "      <td>1.182865</td>\n",
       "      <td>6.967912</td>\n",
       "      <td>2.037659e+06</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>0.783661</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>-8.587734e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.102905</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.927448</td>\n",
       "      <td>254102.531250</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.557896e-06</td>\n",
       "      <td>-5.352998e-03</td>\n",
       "      <td>2.557896e+06</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>66.320076</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>5532.694336</td>\n",
       "      <td>70815.179688</td>\n",
       "      <td>1.963414e+11</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>448.044189</td>\n",
       "      <td>48.983410</td>\n",
       "      <td>1.331191e-04</td>\n",
       "      <td>0.573914</td>\n",
       "      <td>2.993988</td>\n",
       "      <td>36.006317</td>\n",
       "      <td>143.959229</td>\n",
       "      <td>207.990845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>60.150677</td>\n",
       "      <td>223982.171875</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-5.872026e-06</td>\n",
       "      <td>-2.892585e-01</td>\n",
       "      <td>-5.872026e+06</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>58.458031</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>3723.685547</td>\n",
       "      <td>53367.753906</td>\n",
       "      <td>3.515880e+10</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>40.885448</td>\n",
       "      <td>-1.275543e-04</td>\n",
       "      <td>0.458862</td>\n",
       "      <td>2.255890</td>\n",
       "      <td>27.998032</td>\n",
       "      <td>120.027466</td>\n",
       "      <td>192.003601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.011257</td>\n",
       "      <td>229948.515625</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>3.839652e-06</td>\n",
       "      <td>-7.054937e-03</td>\n",
       "      <td>3.839652e+06</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>60.015942</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>5108.688965</td>\n",
       "      <td>57816.910156</td>\n",
       "      <td>2.237378e+10</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>448.062988</td>\n",
       "      <td>43.369343</td>\n",
       "      <td>-7.604867e-05</td>\n",
       "      <td>0.546936</td>\n",
       "      <td>2.742432</td>\n",
       "      <td>31.986145</td>\n",
       "      <td>127.987976</td>\n",
       "      <td>191.999283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.090969</td>\n",
       "      <td>176628.812500</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-9.493078e-06</td>\n",
       "      <td>3.381686e-02</td>\n",
       "      <td>-2.807202e-04</td>\n",
       "      <td>0.026128</td>\n",
       "      <td>86.926315</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>3326.908203</td>\n",
       "      <td>34240.996094</td>\n",
       "      <td>1.275805e+10</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>448.092773</td>\n",
       "      <td>63.937683</td>\n",
       "      <td>5.589550e-04</td>\n",
       "      <td>0.666138</td>\n",
       "      <td>3.280273</td>\n",
       "      <td>47.973511</td>\n",
       "      <td>176.037109</td>\n",
       "      <td>255.991211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>75.970032</td>\n",
       "      <td>351171.062500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-8.975815e-06</td>\n",
       "      <td>9.288421e-02</td>\n",
       "      <td>-9.663446e-05</td>\n",
       "      <td>0.022895</td>\n",
       "      <td>105.833694</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4622.494629</td>\n",
       "      <td>47613.683594</td>\n",
       "      <td>1.869918e+10</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>83.853996</td>\n",
       "      <td>2.126476e-04</td>\n",
       "      <td>1.277466</td>\n",
       "      <td>6.499177</td>\n",
       "      <td>71.986572</td>\n",
       "      <td>208.004944</td>\n",
       "      <td>287.985779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>58.858749</td>\n",
       "      <td>37.209473</td>\n",
       "      <td>1.581822</td>\n",
       "      <td>-2.069383e-04</td>\n",
       "      <td>-1.533429e-05</td>\n",
       "      <td>-2.069384e+08</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>1.581804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>1.186325</td>\n",
       "      <td>6.157388</td>\n",
       "      <td>8.881391e+05</td>\n",
       "      <td>-0.006102</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>-5.414727e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.812443</td>\n",
       "      <td>263204.593750</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>4.622842e-06</td>\n",
       "      <td>1.639827e-02</td>\n",
       "      <td>2.819104e-04</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>68.695694</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>6007.531250</td>\n",
       "      <td>66962.312500</td>\n",
       "      <td>7.186351e+10</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>448.048828</td>\n",
       "      <td>51.221184</td>\n",
       "      <td>1.382830e-05</td>\n",
       "      <td>0.623573</td>\n",
       "      <td>3.222900</td>\n",
       "      <td>39.994354</td>\n",
       "      <td>143.994781</td>\n",
       "      <td>207.997833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.144016</td>\n",
       "      <td>209996.078125</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-5.015406e-06</td>\n",
       "      <td>-3.113505e-01</td>\n",
       "      <td>-5.015406e+06</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>54.807526</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3740.311035</td>\n",
       "      <td>50413.109375</td>\n",
       "      <td>1.537778e+11</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>37.953381</td>\n",
       "      <td>1.617814e-04</td>\n",
       "      <td>0.422852</td>\n",
       "      <td>2.031128</td>\n",
       "      <td>25.992981</td>\n",
       "      <td>119.971191</td>\n",
       "      <td>191.924805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.932861</td>\n",
       "      <td>230937.734375</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-3.569238e-07</td>\n",
       "      <td>-2.094859e-02</td>\n",
       "      <td>-3.569238e+05</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>60.274117</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>5379.043457</td>\n",
       "      <td>59902.082031</td>\n",
       "      <td>2.411210e+10</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>43.627922</td>\n",
       "      <td>1.329182e-04</td>\n",
       "      <td>0.550537</td>\n",
       "      <td>2.745544</td>\n",
       "      <td>31.989929</td>\n",
       "      <td>127.991577</td>\n",
       "      <td>191.999146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.336922</td>\n",
       "      <td>166856.593750</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-3.956973e-06</td>\n",
       "      <td>5.946008e-02</td>\n",
       "      <td>-6.654839e-05</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>82.116997</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>3188.125244</td>\n",
       "      <td>26756.935547</td>\n",
       "      <td>2.177730e+09</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>60.438431</td>\n",
       "      <td>-9.862677e-04</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>3.271606</td>\n",
       "      <td>44.004913</td>\n",
       "      <td>175.987488</td>\n",
       "      <td>240.024902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.086006</td>\n",
       "      <td>349273.781250</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-7.950891e-06</td>\n",
       "      <td>1.419720e-02</td>\n",
       "      <td>-5.600323e-04</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>105.261940</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>4845.236816</td>\n",
       "      <td>73109.187500</td>\n",
       "      <td>2.407690e+11</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>448.098633</td>\n",
       "      <td>83.337296</td>\n",
       "      <td>4.009024e-04</td>\n",
       "      <td>1.265503</td>\n",
       "      <td>6.492493</td>\n",
       "      <td>71.983154</td>\n",
       "      <td>208.001678</td>\n",
       "      <td>287.985107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>58.200573</td>\n",
       "      <td>37.173981</td>\n",
       "      <td>1.565627</td>\n",
       "      <td>-2.780234e-04</td>\n",
       "      <td>4.305819e-05</td>\n",
       "      <td>-6.456923e+00</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>1.565596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>1.189681</td>\n",
       "      <td>28.079277</td>\n",
       "      <td>3.535601e+07</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.514099</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>-4.877809e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.033279</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.137451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.615864</td>\n",
       "      <td>265324.500000</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-2.007923e-06</td>\n",
       "      <td>-1.622766e-02</td>\n",
       "      <td>-2.007923e+06</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>69.248978</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>5816.496094</td>\n",
       "      <td>71131.429688</td>\n",
       "      <td>1.434146e+11</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>448.053711</td>\n",
       "      <td>51.775349</td>\n",
       "      <td>2.043054e-04</td>\n",
       "      <td>0.626462</td>\n",
       "      <td>3.240356</td>\n",
       "      <td>39.998238</td>\n",
       "      <td>143.996628</td>\n",
       "      <td>207.998383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.633945</td>\n",
       "      <td>216835.828125</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-5.254829e-06</td>\n",
       "      <td>-3.287365e-01</td>\n",
       "      <td>-5.254830e+06</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>56.592617</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>3828.726318</td>\n",
       "      <td>46579.980469</td>\n",
       "      <td>6.077703e+10</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>448.072266</td>\n",
       "      <td>39.595421</td>\n",
       "      <td>9.823422e-05</td>\n",
       "      <td>0.442596</td>\n",
       "      <td>2.246964</td>\n",
       "      <td>26.025879</td>\n",
       "      <td>120.000984</td>\n",
       "      <td>191.988953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.797127</td>\n",
       "      <td>242268.687500</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.348566e-06</td>\n",
       "      <td>-2.978748e-03</td>\n",
       "      <td>1.348566e+06</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>63.231472</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>5408.130371</td>\n",
       "      <td>53408.792969</td>\n",
       "      <td>3.133323e+10</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>448.043457</td>\n",
       "      <td>45.956284</td>\n",
       "      <td>-3.414328e-04</td>\n",
       "      <td>0.564034</td>\n",
       "      <td>2.760315</td>\n",
       "      <td>32.007812</td>\n",
       "      <td>128.006714</td>\n",
       "      <td>192.013916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.520401</td>\n",
       "      <td>177910.296875</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>1.296716e-05</td>\n",
       "      <td>-2.945281e-03</td>\n",
       "      <td>1.296716e+07</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>87.556984</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>3453.199951</td>\n",
       "      <td>38679.003906</td>\n",
       "      <td>2.466853e+10</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>448.123047</td>\n",
       "      <td>64.604950</td>\n",
       "      <td>7.026309e-04</td>\n",
       "      <td>0.673584</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>47.991333</td>\n",
       "      <td>176.046631</td>\n",
       "      <td>255.992615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>69.948273</td>\n",
       "      <td>347354.000000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>8.303167e-08</td>\n",
       "      <td>5.813380e-03</td>\n",
       "      <td>1.428286e-05</td>\n",
       "      <td>0.021081</td>\n",
       "      <td>104.683365</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>4965.869629</td>\n",
       "      <td>79836.742188</td>\n",
       "      <td>2.945120e+11</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>82.751930</td>\n",
       "      <td>-9.464523e-05</td>\n",
       "      <td>1.259033</td>\n",
       "      <td>6.485718</td>\n",
       "      <td>71.975708</td>\n",
       "      <td>207.999298</td>\n",
       "      <td>287.983643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>57.779716</td>\n",
       "      <td>36.448174</td>\n",
       "      <td>1.585257</td>\n",
       "      <td>-1.634033e-04</td>\n",
       "      <td>3.412114e-05</td>\n",
       "      <td>-4.788915e+00</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.026906</td>\n",
       "      <td>1.585246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008816</td>\n",
       "      <td>1.187033</td>\n",
       "      <td>7.955982</td>\n",
       "      <td>2.352456e+06</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>0.039701</td>\n",
       "      <td>-8.011762e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.099243</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.154556</td>\n",
       "      <td>284785.656250</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>-2.963604e-06</td>\n",
       "      <td>-3.467131e-03</td>\n",
       "      <td>-2.963604e+06</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>74.328285</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6919.906738</td>\n",
       "      <td>81858.500000</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>448.039062</td>\n",
       "      <td>56.084431</td>\n",
       "      <td>1.824292e-04</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>3.493866</td>\n",
       "      <td>43.997589</td>\n",
       "      <td>144.019775</td>\n",
       "      <td>223.986206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>49.128021</td>\n",
       "      <td>229124.890625</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-2.033020e-06</td>\n",
       "      <td>-3.252713e-01</td>\n",
       "      <td>-2.033020e+06</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>59.800095</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>4663.833496</td>\n",
       "      <td>55310.933594</td>\n",
       "      <td>9.407586e+10</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>448.057617</td>\n",
       "      <td>42.273369</td>\n",
       "      <td>-6.983956e-04</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>2.267334</td>\n",
       "      <td>29.979492</td>\n",
       "      <td>127.993225</td>\n",
       "      <td>192.003677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.624657</td>\n",
       "      <td>256067.140625</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.440451e-06</td>\n",
       "      <td>-8.315486e-03</td>\n",
       "      <td>1.440451e+06</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>66.832832</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>6303.244629</td>\n",
       "      <td>61047.878906</td>\n",
       "      <td>5.590737e+10</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>448.044922</td>\n",
       "      <td>48.959206</td>\n",
       "      <td>1.930326e-06</td>\n",
       "      <td>0.617432</td>\n",
       "      <td>3.005371</td>\n",
       "      <td>35.999245</td>\n",
       "      <td>143.993927</td>\n",
       "      <td>207.998749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.640358</td>\n",
       "      <td>164400.296875</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2.422474e-05</td>\n",
       "      <td>-2.134536e-02</td>\n",
       "      <td>2.422474e+07</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>80.908165</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>3311.828369</td>\n",
       "      <td>30653.859375</td>\n",
       "      <td>2.627510e+09</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>59.762985</td>\n",
       "      <td>-7.713508e-04</td>\n",
       "      <td>0.665161</td>\n",
       "      <td>3.274902</td>\n",
       "      <td>44.002380</td>\n",
       "      <td>175.961182</td>\n",
       "      <td>240.003448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>68.983093</td>\n",
       "      <td>331264.437500</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>6.848127e-06</td>\n",
       "      <td>-1.303290e-02</td>\n",
       "      <td>6.848127e+06</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>99.834404</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>4802.110352</td>\n",
       "      <td>50730.894531</td>\n",
       "      <td>2.482768e+10</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>448.082520</td>\n",
       "      <td>78.443085</td>\n",
       "      <td>2.769766e-04</td>\n",
       "      <td>1.207520</td>\n",
       "      <td>5.993988</td>\n",
       "      <td>63.997574</td>\n",
       "      <td>192.032715</td>\n",
       "      <td>256.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>57.039749</td>\n",
       "      <td>35.363419</td>\n",
       "      <td>1.612959</td>\n",
       "      <td>-1.894469e-04</td>\n",
       "      <td>-1.777002e-05</td>\n",
       "      <td>-1.894469e+08</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.026106</td>\n",
       "      <td>1.612943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006990</td>\n",
       "      <td>1.180271</td>\n",
       "      <td>6.859995</td>\n",
       "      <td>1.125183e+06</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.039013</td>\n",
       "      <td>-6.854678e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.097412</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.880848</td>\n",
       "      <td>282893.593750</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>2.965367e-06</td>\n",
       "      <td>3.939144e-02</td>\n",
       "      <td>7.527947e-05</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>73.834450</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>5908.282715</td>\n",
       "      <td>86174.664062</td>\n",
       "      <td>1.115447e+11</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>55.759281</td>\n",
       "      <td>4.105823e-04</td>\n",
       "      <td>0.684433</td>\n",
       "      <td>3.492798</td>\n",
       "      <td>43.996429</td>\n",
       "      <td>144.014587</td>\n",
       "      <td>223.977173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.813526</td>\n",
       "      <td>212324.312500</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1.570648e-07</td>\n",
       "      <td>-2.391088e-01</td>\n",
       "      <td>1.570648e+05</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>55.415562</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>3737.214844</td>\n",
       "      <td>38064.398438</td>\n",
       "      <td>1.182271e+10</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>448.062500</td>\n",
       "      <td>39.028008</td>\n",
       "      <td>-6.908864e-04</td>\n",
       "      <td>0.451454</td>\n",
       "      <td>2.251640</td>\n",
       "      <td>27.957520</td>\n",
       "      <td>119.983276</td>\n",
       "      <td>176.018311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.198658</td>\n",
       "      <td>254270.328125</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>2.451872e-06</td>\n",
       "      <td>3.403801e-02</td>\n",
       "      <td>7.203335e-05</td>\n",
       "      <td>0.012058</td>\n",
       "      <td>66.363869</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>5503.847168</td>\n",
       "      <td>55380.269531</td>\n",
       "      <td>4.228891e+10</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>48.690922</td>\n",
       "      <td>-1.330027e-04</td>\n",
       "      <td>0.620636</td>\n",
       "      <td>3.010559</td>\n",
       "      <td>35.998871</td>\n",
       "      <td>143.989746</td>\n",
       "      <td>207.995758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.230282</td>\n",
       "      <td>180721.046875</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-1.555544e-05</td>\n",
       "      <td>-4.958065e-02</td>\n",
       "      <td>-1.555544e+07</td>\n",
       "      <td>0.025705</td>\n",
       "      <td>88.940269</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>3460.082031</td>\n",
       "      <td>30954.318359</td>\n",
       "      <td>2.614328e+09</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>448.137695</td>\n",
       "      <td>65.849876</td>\n",
       "      <td>-1.032151e-04</td>\n",
       "      <td>0.685664</td>\n",
       "      <td>3.489563</td>\n",
       "      <td>48.012695</td>\n",
       "      <td>191.972290</td>\n",
       "      <td>255.999542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.279205</td>\n",
       "      <td>351104.250000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>4.962117e-06</td>\n",
       "      <td>1.478509e-02</td>\n",
       "      <td>3.356162e-04</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>105.813599</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>4857.611328</td>\n",
       "      <td>62119.929688</td>\n",
       "      <td>5.023150e+10</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>83.880600</td>\n",
       "      <td>2.170406e-05</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>6.500224</td>\n",
       "      <td>71.988464</td>\n",
       "      <td>208.004089</td>\n",
       "      <td>287.986694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>56.890789</td>\n",
       "      <td>35.420940</td>\n",
       "      <td>1.606134</td>\n",
       "      <td>-2.449994e-04</td>\n",
       "      <td>4.622344e-05</td>\n",
       "      <td>-5.300328e+00</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>1.606110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>1.180957</td>\n",
       "      <td>10.829238</td>\n",
       "      <td>3.797211e+06</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>0.595947</td>\n",
       "      <td>0.038860</td>\n",
       "      <td>-4.465818e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.138607</td>\n",
       "      <td>278421.906250</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>6.203331e-06</td>\n",
       "      <td>7.772340e-03</td>\n",
       "      <td>7.981291e-04</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>72.667374</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>5906.451660</td>\n",
       "      <td>72467.890625</td>\n",
       "      <td>8.078044e+10</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>54.839592</td>\n",
       "      <td>-4.564773e-06</td>\n",
       "      <td>0.682007</td>\n",
       "      <td>3.488647</td>\n",
       "      <td>43.990662</td>\n",
       "      <td>144.007568</td>\n",
       "      <td>208.014832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.204090</td>\n",
       "      <td>229367.781250</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-9.100067e-06</td>\n",
       "      <td>-3.669771e-01</td>\n",
       "      <td>-9.100068e+06</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>59.863251</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>4231.559082</td>\n",
       "      <td>39594.101562</td>\n",
       "      <td>8.371916e+09</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>448.049805</td>\n",
       "      <td>42.527416</td>\n",
       "      <td>-9.614210e-05</td>\n",
       "      <td>0.483643</td>\n",
       "      <td>2.491272</td>\n",
       "      <td>29.993164</td>\n",
       "      <td>127.991882</td>\n",
       "      <td>192.003510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.840836</td>\n",
       "      <td>256352.265625</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.288569e-06</td>\n",
       "      <td>-1.102681e-02</td>\n",
       "      <td>-3.288569e+06</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>66.907257</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>5592.225098</td>\n",
       "      <td>69093.937500</td>\n",
       "      <td>8.365849e+10</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>49.193718</td>\n",
       "      <td>-8.202424e-05</td>\n",
       "      <td>0.624697</td>\n",
       "      <td>3.223511</td>\n",
       "      <td>36.002594</td>\n",
       "      <td>143.991821</td>\n",
       "      <td>207.997772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.593529</td>\n",
       "      <td>186104.609375</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-1.703942e-07</td>\n",
       "      <td>4.032629e-03</td>\n",
       "      <td>-4.225387e-05</td>\n",
       "      <td>0.025883</td>\n",
       "      <td>91.589745</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>3538.546143</td>\n",
       "      <td>32983.320312</td>\n",
       "      <td>7.362801e+09</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>448.108398</td>\n",
       "      <td>68.122375</td>\n",
       "      <td>-1.174289e-04</td>\n",
       "      <td>0.719971</td>\n",
       "      <td>3.526123</td>\n",
       "      <td>51.981445</td>\n",
       "      <td>191.997528</td>\n",
       "      <td>256.011292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>79.557137</td>\n",
       "      <td>344495.843750</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>4.319254e-07</td>\n",
       "      <td>3.405518e-02</td>\n",
       "      <td>1.268310e-05</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>103.821999</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>4330.169434</td>\n",
       "      <td>69587.335938</td>\n",
       "      <td>2.209064e+11</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>448.072266</td>\n",
       "      <td>82.181435</td>\n",
       "      <td>-1.277678e-04</td>\n",
       "      <td>1.263855</td>\n",
       "      <td>6.480957</td>\n",
       "      <td>71.966553</td>\n",
       "      <td>207.990601</td>\n",
       "      <td>287.968018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>56.199585</td>\n",
       "      <td>35.525330</td>\n",
       "      <td>1.581958</td>\n",
       "      <td>-1.777210e-04</td>\n",
       "      <td>-7.934801e-05</td>\n",
       "      <td>-1.777210e+08</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>1.581951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>1.185189</td>\n",
       "      <td>6.934441</td>\n",
       "      <td>7.369352e+05</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.479492</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>-3.889156e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.984955</td>\n",
       "      <td>279280.562500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-2.315411e-06</td>\n",
       "      <td>5.455615e-03</td>\n",
       "      <td>-4.244088e-04</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>72.891472</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>5944.042480</td>\n",
       "      <td>60451.601562</td>\n",
       "      <td>4.606892e+10</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>448.071289</td>\n",
       "      <td>54.965805</td>\n",
       "      <td>-1.055490e-04</td>\n",
       "      <td>0.668457</td>\n",
       "      <td>3.262573</td>\n",
       "      <td>43.989807</td>\n",
       "      <td>144.009399</td>\n",
       "      <td>208.012390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.816029</td>\n",
       "      <td>222334.625000</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.553173e-05</td>\n",
       "      <td>-2.199446e-01</td>\n",
       "      <td>1.553173e+07</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>58.028320</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>3983.347656</td>\n",
       "      <td>41168.976562</td>\n",
       "      <td>2.860001e+10</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>41.206360</td>\n",
       "      <td>-2.697963e-04</td>\n",
       "      <td>0.479248</td>\n",
       "      <td>2.485840</td>\n",
       "      <td>28.020142</td>\n",
       "      <td>120.012390</td>\n",
       "      <td>191.995361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.959114</td>\n",
       "      <td>253979.453125</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-3.223807e-06</td>\n",
       "      <td>-4.895579e-03</td>\n",
       "      <td>-3.223807e+06</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>66.287956</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>5526.204590</td>\n",
       "      <td>81316.234375</td>\n",
       "      <td>1.393747e+11</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.040283</td>\n",
       "      <td>48.643196</td>\n",
       "      <td>5.542580e-06</td>\n",
       "      <td>0.612976</td>\n",
       "      <td>3.004028</td>\n",
       "      <td>35.998398</td>\n",
       "      <td>143.988342</td>\n",
       "      <td>207.992432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.171612</td>\n",
       "      <td>186653.390625</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>-2.392116e-06</td>\n",
       "      <td>4.066739e-02</td>\n",
       "      <td>-5.882148e-05</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>91.859833</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>3956.901123</td>\n",
       "      <td>38724.601562</td>\n",
       "      <td>1.120426e+10</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>448.106934</td>\n",
       "      <td>68.162651</td>\n",
       "      <td>1.360824e-04</td>\n",
       "      <td>0.721802</td>\n",
       "      <td>3.668144</td>\n",
       "      <td>51.974609</td>\n",
       "      <td>192.001785</td>\n",
       "      <td>256.014282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>70.334183</td>\n",
       "      <td>347517.656250</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-3.602708e-06</td>\n",
       "      <td>-6.330750e-03</td>\n",
       "      <td>-3.602708e+06</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>104.732697</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>4940.950195</td>\n",
       "      <td>52958.476562</td>\n",
       "      <td>2.783574e+10</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>82.906509</td>\n",
       "      <td>-6.393679e-05</td>\n",
       "      <td>1.258545</td>\n",
       "      <td>6.489685</td>\n",
       "      <td>71.979492</td>\n",
       "      <td>207.998367</td>\n",
       "      <td>287.980591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>54.366833</td>\n",
       "      <td>34.047428</td>\n",
       "      <td>1.596797</td>\n",
       "      <td>-1.708427e-04</td>\n",
       "      <td>-7.752867e-05</td>\n",
       "      <td>-1.708427e+08</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>1.596790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>1.182130</td>\n",
       "      <td>8.236053</td>\n",
       "      <td>3.431704e+06</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>0.486572</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>-3.039527e-03</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.985538</td>\n",
       "      <td>274074.875000</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>5.314093e-07</td>\n",
       "      <td>8.933453e-03</td>\n",
       "      <td>5.948532e-05</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>71.532806</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5960.023926</td>\n",
       "      <td>76537.062500</td>\n",
       "      <td>1.891633e+11</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>53.644447</td>\n",
       "      <td>-1.450413e-05</td>\n",
       "      <td>0.628754</td>\n",
       "      <td>3.246826</td>\n",
       "      <td>40.012817</td>\n",
       "      <td>144.003555</td>\n",
       "      <td>208.011047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.188286</td>\n",
       "      <td>213671.890625</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>7.053688e-06</td>\n",
       "      <td>-2.400984e-01</td>\n",
       "      <td>7.053688e+06</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>55.767273</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>4017.274170</td>\n",
       "      <td>45879.109375</td>\n",
       "      <td>6.686219e+10</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>448.050049</td>\n",
       "      <td>39.280289</td>\n",
       "      <td>-2.074025e-04</td>\n",
       "      <td>0.444611</td>\n",
       "      <td>2.246552</td>\n",
       "      <td>27.978882</td>\n",
       "      <td>119.991455</td>\n",
       "      <td>176.019653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.167343</td>\n",
       "      <td>242867.578125</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-4.167405e-06</td>\n",
       "      <td>-9.471465e-03</td>\n",
       "      <td>-4.167405e+06</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>63.387787</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5377.061523</td>\n",
       "      <td>56659.636719</td>\n",
       "      <td>6.108398e+10</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>46.169350</td>\n",
       "      <td>2.426678e-04</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>2.765137</td>\n",
       "      <td>32.015625</td>\n",
       "      <td>128.004211</td>\n",
       "      <td>192.015625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.067039</td>\n",
       "      <td>175714.812500</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-6.090719e-06</td>\n",
       "      <td>-2.176526e-02</td>\n",
       "      <td>-6.090718e+06</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>86.476509</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>3581.117920</td>\n",
       "      <td>30605.884766</td>\n",
       "      <td>2.699694e+09</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>448.158203</td>\n",
       "      <td>63.707577</td>\n",
       "      <td>-4.979322e-04</td>\n",
       "      <td>0.673218</td>\n",
       "      <td>3.286133</td>\n",
       "      <td>47.974609</td>\n",
       "      <td>176.025757</td>\n",
       "      <td>255.984680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>71.968002</td>\n",
       "      <td>331438.187500</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>5.583176e-06</td>\n",
       "      <td>4.792462e-03</td>\n",
       "      <td>1.164991e-03</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>99.886757</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>4605.354980</td>\n",
       "      <td>48379.199219</td>\n",
       "      <td>2.114446e+10</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>78.596474</td>\n",
       "      <td>1.050658e-04</td>\n",
       "      <td>1.209961</td>\n",
       "      <td>5.997131</td>\n",
       "      <td>64.000008</td>\n",
       "      <td>192.031250</td>\n",
       "      <td>256.021973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>53.960705</td>\n",
       "      <td>33.469986</td>\n",
       "      <td>1.612212</td>\n",
       "      <td>-1.149284e-04</td>\n",
       "      <td>-3.365870e-05</td>\n",
       "      <td>-1.149284e+08</td>\n",
       "      <td>0.039834</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>1.612207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>1.177651</td>\n",
       "      <td>7.581616</td>\n",
       "      <td>3.099565e+06</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>-1.364358e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.308689</td>\n",
       "      <td>270485.625000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>4.064856e-07</td>\n",
       "      <td>-1.043761e-02</td>\n",
       "      <td>4.064856e+05</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>70.596008</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>5599.109375</td>\n",
       "      <td>86737.960938</td>\n",
       "      <td>2.145388e+11</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>448.042969</td>\n",
       "      <td>52.913498</td>\n",
       "      <td>2.298434e-05</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>3.233643</td>\n",
       "      <td>40.007080</td>\n",
       "      <td>143.999985</td>\n",
       "      <td>208.004059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.150475</td>\n",
       "      <td>212072.375000</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.142472e-05</td>\n",
       "      <td>-2.508570e-01</td>\n",
       "      <td>1.142472e+07</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>55.349747</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3916.353027</td>\n",
       "      <td>106709.531250</td>\n",
       "      <td>6.066271e+11</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>39.291393</td>\n",
       "      <td>-7.743487e-05</td>\n",
       "      <td>0.460754</td>\n",
       "      <td>2.257935</td>\n",
       "      <td>27.991882</td>\n",
       "      <td>119.977173</td>\n",
       "      <td>176.010315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.262604</td>\n",
       "      <td>241527.921875</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-4.910673e-06</td>\n",
       "      <td>9.193955e-03</td>\n",
       "      <td>-5.341198e-04</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>63.038136</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>5110.338867</td>\n",
       "      <td>51973.976562</td>\n",
       "      <td>2.164393e+10</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>46.139214</td>\n",
       "      <td>3.565793e-04</td>\n",
       "      <td>0.571045</td>\n",
       "      <td>2.984863</td>\n",
       "      <td>35.966553</td>\n",
       "      <td>128.001205</td>\n",
       "      <td>192.008362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.026100</td>\n",
       "      <td>179884.656250</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>6.047038e-06</td>\n",
       "      <td>-4.908935e-02</td>\n",
       "      <td>6.047038e+06</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>88.528648</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>3669.161621</td>\n",
       "      <td>37208.312500</td>\n",
       "      <td>5.726623e+09</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>448.118164</td>\n",
       "      <td>65.399979</td>\n",
       "      <td>-1.855232e-04</td>\n",
       "      <td>0.660522</td>\n",
       "      <td>3.263916</td>\n",
       "      <td>48.004364</td>\n",
       "      <td>191.969849</td>\n",
       "      <td>255.994751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>74.409676</td>\n",
       "      <td>346724.875000</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-1.429682e-06</td>\n",
       "      <td>4.509106e-02</td>\n",
       "      <td>-3.170655e-05</td>\n",
       "      <td>0.022425</td>\n",
       "      <td>104.493759</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>4659.674805</td>\n",
       "      <td>67023.195312</td>\n",
       "      <td>1.444614e+11</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>448.074707</td>\n",
       "      <td>82.702156</td>\n",
       "      <td>1.101691e-04</td>\n",
       "      <td>1.261719</td>\n",
       "      <td>6.485657</td>\n",
       "      <td>71.975464</td>\n",
       "      <td>207.997055</td>\n",
       "      <td>287.977539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>52.822144</td>\n",
       "      <td>34.614334</td>\n",
       "      <td>1.526019</td>\n",
       "      <td>-1.508373e-04</td>\n",
       "      <td>2.858262e-05</td>\n",
       "      <td>-5.277240e+00</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>1.526009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>1.198452</td>\n",
       "      <td>6.573598</td>\n",
       "      <td>6.546205e+05</td>\n",
       "      <td>-0.005238</td>\n",
       "      <td>0.544861</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>-4.668207e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>49.340076</td>\n",
       "      <td>268255.343750</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>5.842824e-07</td>\n",
       "      <td>-9.231600e-03</td>\n",
       "      <td>5.842824e+05</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>70.013916</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5436.865234</td>\n",
       "      <td>124730.500000</td>\n",
       "      <td>1.055531e+12</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>448.057861</td>\n",
       "      <td>51.854233</td>\n",
       "      <td>2.746141e-05</td>\n",
       "      <td>0.618427</td>\n",
       "      <td>3.012268</td>\n",
       "      <td>39.995605</td>\n",
       "      <td>143.999695</td>\n",
       "      <td>208.039307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.313282</td>\n",
       "      <td>248781.703125</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>3.733487e-06</td>\n",
       "      <td>-3.760223e-01</td>\n",
       "      <td>3.733487e+06</td>\n",
       "      <td>0.014176</td>\n",
       "      <td>64.930260</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>4580.493652</td>\n",
       "      <td>42255.625000</td>\n",
       "      <td>1.075609e+10</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>448.058594</td>\n",
       "      <td>46.975239</td>\n",
       "      <td>5.735542e-04</td>\n",
       "      <td>0.558792</td>\n",
       "      <td>2.754822</td>\n",
       "      <td>32.014160</td>\n",
       "      <td>143.977051</td>\n",
       "      <td>207.990723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.547146</td>\n",
       "      <td>254547.875000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>2.896968e-06</td>\n",
       "      <td>2.988487e-03</td>\n",
       "      <td>9.693764e-04</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>66.436310</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5243.312988</td>\n",
       "      <td>53005.238281</td>\n",
       "      <td>2.699694e+10</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>448.058350</td>\n",
       "      <td>48.525593</td>\n",
       "      <td>-5.084596e-05</td>\n",
       "      <td>0.617065</td>\n",
       "      <td>3.007172</td>\n",
       "      <td>35.997879</td>\n",
       "      <td>143.986267</td>\n",
       "      <td>208.003204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.848537</td>\n",
       "      <td>172664.937500</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.885699e-06</td>\n",
       "      <td>6.064153e-02</td>\n",
       "      <td>6.407653e-05</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>84.975517</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>3267.165771</td>\n",
       "      <td>31396.652344</td>\n",
       "      <td>1.327913e+10</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>448.151367</td>\n",
       "      <td>62.332523</td>\n",
       "      <td>8.414559e-05</td>\n",
       "      <td>0.581787</td>\n",
       "      <td>2.988281</td>\n",
       "      <td>44.045654</td>\n",
       "      <td>176.010742</td>\n",
       "      <td>255.972412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.089249</td>\n",
       "      <td>348893.781250</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>8.868068e-06</td>\n",
       "      <td>-6.743153e-03</td>\n",
       "      <td>8.868068e+06</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>105.147415</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>4525.841797</td>\n",
       "      <td>44827.691406</td>\n",
       "      <td>2.439745e+10</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>83.261055</td>\n",
       "      <td>3.946591e-04</td>\n",
       "      <td>1.266602</td>\n",
       "      <td>6.493195</td>\n",
       "      <td>71.980835</td>\n",
       "      <td>208.000824</td>\n",
       "      <td>287.981689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>51.809036</td>\n",
       "      <td>33.058929</td>\n",
       "      <td>1.567172</td>\n",
       "      <td>-1.320829e-04</td>\n",
       "      <td>-4.541640e-05</td>\n",
       "      <td>-1.320829e+08</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>1.567166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>1.187365</td>\n",
       "      <td>6.077863</td>\n",
       "      <td>4.487540e+05</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.521851</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>-1.161391e-03</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029602</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.625832</td>\n",
       "      <td>274444.125000</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-1.152634e-06</td>\n",
       "      <td>-1.972780e-03</td>\n",
       "      <td>-1.152634e+06</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>71.629173</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>5643.998047</td>\n",
       "      <td>76338.273438</td>\n",
       "      <td>1.815707e+11</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>448.057617</td>\n",
       "      <td>53.525856</td>\n",
       "      <td>4.596278e-05</td>\n",
       "      <td>0.623199</td>\n",
       "      <td>3.237793</td>\n",
       "      <td>40.012573</td>\n",
       "      <td>144.003281</td>\n",
       "      <td>223.985962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.440929</td>\n",
       "      <td>239390.265625</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>8.834773e-06</td>\n",
       "      <td>-2.911580e-01</td>\n",
       "      <td>8.834773e+06</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>62.479534</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>4397.247070</td>\n",
       "      <td>74510.414062</td>\n",
       "      <td>2.679013e+11</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>448.051514</td>\n",
       "      <td>44.431938</td>\n",
       "      <td>7.626922e-04</td>\n",
       "      <td>0.492065</td>\n",
       "      <td>2.499317</td>\n",
       "      <td>30.018188</td>\n",
       "      <td>128.008423</td>\n",
       "      <td>207.977051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.147461</td>\n",
       "      <td>248760.671875</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.993115e-06</td>\n",
       "      <td>8.235618e-03</td>\n",
       "      <td>2.420116e-04</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>64.925858</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>5276.226562</td>\n",
       "      <td>76995.984375</td>\n",
       "      <td>2.403304e+11</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>47.508385</td>\n",
       "      <td>-1.157660e-04</td>\n",
       "      <td>0.610718</td>\n",
       "      <td>3.002182</td>\n",
       "      <td>35.993134</td>\n",
       "      <td>128.012451</td>\n",
       "      <td>207.992279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.150894</td>\n",
       "      <td>147863.421875</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3.030488e-06</td>\n",
       "      <td>-3.417383e-02</td>\n",
       "      <td>3.030488e+06</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>72.769676</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>2781.955566</td>\n",
       "      <td>27765.283203</td>\n",
       "      <td>7.150003e+09</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>448.124512</td>\n",
       "      <td>52.785561</td>\n",
       "      <td>2.040821e-04</td>\n",
       "      <td>0.602783</td>\n",
       "      <td>3.005890</td>\n",
       "      <td>36.035889</td>\n",
       "      <td>159.971313</td>\n",
       "      <td>224.009644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>78.304436</td>\n",
       "      <td>348700.437500</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-1.396485e-07</td>\n",
       "      <td>-8.308860e-03</td>\n",
       "      <td>-1.396485e+05</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>105.089142</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>4453.137695</td>\n",
       "      <td>70075.609375</td>\n",
       "      <td>1.736071e+11</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>83.240868</td>\n",
       "      <td>5.324460e-05</td>\n",
       "      <td>1.266479</td>\n",
       "      <td>6.491821</td>\n",
       "      <td>71.980591</td>\n",
       "      <td>208.000214</td>\n",
       "      <td>287.979736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>51.533623</td>\n",
       "      <td>32.673985</td>\n",
       "      <td>1.577207</td>\n",
       "      <td>-1.692496e-04</td>\n",
       "      <td>2.098504e-05</td>\n",
       "      <td>-8.065253e+00</td>\n",
       "      <td>0.038042</td>\n",
       "      <td>0.024120</td>\n",
       "      <td>1.577191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>1.185274</td>\n",
       "      <td>6.299329</td>\n",
       "      <td>3.625386e+05</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>-1.705085e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.569614</td>\n",
       "      <td>254154.312500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>4.154171e-06</td>\n",
       "      <td>-7.816254e-03</td>\n",
       "      <td>4.154171e+06</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>66.333588</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>5342.787109</td>\n",
       "      <td>59439.398438</td>\n",
       "      <td>5.235770e+10</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>448.159180</td>\n",
       "      <td>48.815750</td>\n",
       "      <td>-2.073805e-04</td>\n",
       "      <td>0.555023</td>\n",
       "      <td>2.754578</td>\n",
       "      <td>36.006866</td>\n",
       "      <td>128.018677</td>\n",
       "      <td>207.999466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.026478</td>\n",
       "      <td>237929.937500</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.108182e-06</td>\n",
       "      <td>-2.339160e-01</td>\n",
       "      <td>1.108182e+06</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>62.098629</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>4403.949219</td>\n",
       "      <td>45753.617188</td>\n",
       "      <td>2.174175e+10</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>44.380424</td>\n",
       "      <td>5.241273e-04</td>\n",
       "      <td>0.500254</td>\n",
       "      <td>2.507050</td>\n",
       "      <td>31.976440</td>\n",
       "      <td>128.003845</td>\n",
       "      <td>192.018799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.178051</td>\n",
       "      <td>228491.671875</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>6.086235e-07</td>\n",
       "      <td>-9.359336e-03</td>\n",
       "      <td>6.086235e+05</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>59.635708</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>4843.177246</td>\n",
       "      <td>55582.941406</td>\n",
       "      <td>8.737841e+10</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>448.058105</td>\n",
       "      <td>42.723488</td>\n",
       "      <td>3.337132e-04</td>\n",
       "      <td>0.502991</td>\n",
       "      <td>2.509155</td>\n",
       "      <td>30.007202</td>\n",
       "      <td>127.977539</td>\n",
       "      <td>192.002441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.218193</td>\n",
       "      <td>169141.671875</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>2.475617e-05</td>\n",
       "      <td>-1.117020e-01</td>\n",
       "      <td>2.475617e+07</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>83.241516</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>3178.268555</td>\n",
       "      <td>28743.703125</td>\n",
       "      <td>4.393026e+09</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>448.109863</td>\n",
       "      <td>60.987366</td>\n",
       "      <td>-1.598460e-04</td>\n",
       "      <td>0.655762</td>\n",
       "      <td>3.261292</td>\n",
       "      <td>44.003860</td>\n",
       "      <td>176.000885</td>\n",
       "      <td>255.961670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.360214</td>\n",
       "      <td>339649.406250</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>7.585611e-06</td>\n",
       "      <td>4.504902e-03</td>\n",
       "      <td>1.683857e-03</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>102.361404</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>4390.492676</td>\n",
       "      <td>51387.316406</td>\n",
       "      <td>3.824388e+10</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>80.860954</td>\n",
       "      <td>6.449795e-05</td>\n",
       "      <td>1.247299</td>\n",
       "      <td>6.033691</td>\n",
       "      <td>64.027588</td>\n",
       "      <td>207.979248</td>\n",
       "      <td>256.057861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.803822</td>\n",
       "      <td>33.005226</td>\n",
       "      <td>1.539266</td>\n",
       "      <td>-1.491089e-04</td>\n",
       "      <td>-1.254909e-04</td>\n",
       "      <td>-1.491089e+08</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>1.539274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>1.192828</td>\n",
       "      <td>5.917994</td>\n",
       "      <td>6.260166e+05</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.553589</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>2.500160e-04</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.462849</td>\n",
       "      <td>265520.093750</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.236842e-06</td>\n",
       "      <td>1.374267e-02</td>\n",
       "      <td>-2.355323e-04</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>69.300026</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>5594.271973</td>\n",
       "      <td>61939.054688</td>\n",
       "      <td>7.910156e+10</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>52.318501</td>\n",
       "      <td>3.122127e-04</td>\n",
       "      <td>0.626183</td>\n",
       "      <td>3.246338</td>\n",
       "      <td>40.010071</td>\n",
       "      <td>143.990540</td>\n",
       "      <td>207.996735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.385624</td>\n",
       "      <td>254744.312500</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1.347473e-05</td>\n",
       "      <td>-2.921647e-01</td>\n",
       "      <td>1.347473e+07</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>66.486938</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>4599.465820</td>\n",
       "      <td>50886.019531</td>\n",
       "      <td>2.876629e+10</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>48.241295</td>\n",
       "      <td>3.567025e-04</td>\n",
       "      <td>0.575989</td>\n",
       "      <td>2.988342</td>\n",
       "      <td>35.986511</td>\n",
       "      <td>143.991516</td>\n",
       "      <td>208.000931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.529091</td>\n",
       "      <td>250556.265625</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-2.656181e-06</td>\n",
       "      <td>-2.184244e-02</td>\n",
       "      <td>-2.656181e+06</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>65.394508</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>5163.011719</td>\n",
       "      <td>46956.445312</td>\n",
       "      <td>1.863579e+10</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>448.052734</td>\n",
       "      <td>48.439747</td>\n",
       "      <td>1.253908e-04</td>\n",
       "      <td>0.629395</td>\n",
       "      <td>3.240234</td>\n",
       "      <td>36.003799</td>\n",
       "      <td>128.012878</td>\n",
       "      <td>192.026733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.422222</td>\n",
       "      <td>185918.343750</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-3.073183e-05</td>\n",
       "      <td>-9.216955e-02</td>\n",
       "      <td>-3.073183e+07</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>91.498039</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>3920.489258</td>\n",
       "      <td>40093.097656</td>\n",
       "      <td>6.544712e+09</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>448.156250</td>\n",
       "      <td>67.872482</td>\n",
       "      <td>6.362249e-04</td>\n",
       "      <td>0.797241</td>\n",
       "      <td>3.980713</td>\n",
       "      <td>48.024414</td>\n",
       "      <td>192.001892</td>\n",
       "      <td>256.016235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.470337</td>\n",
       "      <td>351829.625000</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>8.923560e-07</td>\n",
       "      <td>1.168493e-02</td>\n",
       "      <td>7.636809e-05</td>\n",
       "      <td>0.019430</td>\n",
       "      <td>106.032204</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>5457.231934</td>\n",
       "      <td>64612.523438</td>\n",
       "      <td>5.957945e+10</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>84.026520</td>\n",
       "      <td>2.146558e-04</td>\n",
       "      <td>1.274536</td>\n",
       "      <td>6.499390</td>\n",
       "      <td>71.990662</td>\n",
       "      <td>208.004761</td>\n",
       "      <td>287.989929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.808838</td>\n",
       "      <td>31.944159</td>\n",
       "      <td>1.590552</td>\n",
       "      <td>-1.105045e-04</td>\n",
       "      <td>-1.708675e-04</td>\n",
       "      <td>-1.105045e+08</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>1.590587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.180704</td>\n",
       "      <td>6.530527</td>\n",
       "      <td>4.013059e+05</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.411194</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>1.486029e-03</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.174149</td>\n",
       "      <td>264156.875000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.395854e-07</td>\n",
       "      <td>-2.267782e-03</td>\n",
       "      <td>1.395854e+05</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>68.944221</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>5720.882324</td>\n",
       "      <td>62654.824219</td>\n",
       "      <td>2.617885e+10</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>52.007900</td>\n",
       "      <td>-3.376304e-04</td>\n",
       "      <td>0.610962</td>\n",
       "      <td>3.008484</td>\n",
       "      <td>40.004211</td>\n",
       "      <td>143.992798</td>\n",
       "      <td>192.032715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.878120</td>\n",
       "      <td>238560.093750</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>4.846256e-06</td>\n",
       "      <td>-1.937132e-01</td>\n",
       "      <td>4.846256e+06</td>\n",
       "      <td>0.014062</td>\n",
       "      <td>62.263241</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>4427.772461</td>\n",
       "      <td>51412.230469</td>\n",
       "      <td>1.355562e+11</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>45.252541</td>\n",
       "      <td>6.383160e-04</td>\n",
       "      <td>0.556610</td>\n",
       "      <td>2.752640</td>\n",
       "      <td>32.003006</td>\n",
       "      <td>128.000900</td>\n",
       "      <td>192.006592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.584557</td>\n",
       "      <td>246313.625000</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-1.477660e-06</td>\n",
       "      <td>-2.003634e-02</td>\n",
       "      <td>-1.477660e+06</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>64.287193</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>5287.452148</td>\n",
       "      <td>65662.820312</td>\n",
       "      <td>9.213785e+10</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>448.042236</td>\n",
       "      <td>47.736370</td>\n",
       "      <td>6.608267e-04</td>\n",
       "      <td>0.620056</td>\n",
       "      <td>3.009399</td>\n",
       "      <td>35.999550</td>\n",
       "      <td>128.007019</td>\n",
       "      <td>192.003510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.028133</td>\n",
       "      <td>169801.312500</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-1.492910e-05</td>\n",
       "      <td>-3.902095e-02</td>\n",
       "      <td>-1.492910e+07</td>\n",
       "      <td>0.024621</td>\n",
       "      <td>83.566223</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>3394.116699</td>\n",
       "      <td>37682.843750</td>\n",
       "      <td>2.256460e+10</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>448.126953</td>\n",
       "      <td>61.171196</td>\n",
       "      <td>2.381159e-04</td>\n",
       "      <td>0.667358</td>\n",
       "      <td>3.280151</td>\n",
       "      <td>43.994263</td>\n",
       "      <td>176.003540</td>\n",
       "      <td>255.916626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.203667</td>\n",
       "      <td>349750.625000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-4.557790e-06</td>\n",
       "      <td>5.746814e-02</td>\n",
       "      <td>-7.930986e-05</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>105.405632</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>4843.945312</td>\n",
       "      <td>63310.359375</td>\n",
       "      <td>1.183331e+11</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>448.069336</td>\n",
       "      <td>83.316315</td>\n",
       "      <td>-7.628865e-05</td>\n",
       "      <td>1.262846</td>\n",
       "      <td>6.489075</td>\n",
       "      <td>71.980103</td>\n",
       "      <td>208.004089</td>\n",
       "      <td>287.987915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.471760</td>\n",
       "      <td>32.046082</td>\n",
       "      <td>1.574974</td>\n",
       "      <td>-1.121770e-04</td>\n",
       "      <td>-1.210259e-04</td>\n",
       "      <td>-1.121770e+08</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>1.574988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>1.183439</td>\n",
       "      <td>6.977399</td>\n",
       "      <td>1.141552e+06</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.456177</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>2.814621e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.086182</td>\n",
       "      <td>0.117554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.096180</td>\n",
       "      <td>251339.109375</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5.785394e-07</td>\n",
       "      <td>-6.294029e-03</td>\n",
       "      <td>5.785394e+05</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>65.598831</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>5452.493652</td>\n",
       "      <td>66814.710938</td>\n",
       "      <td>5.871179e+10</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>48.993149</td>\n",
       "      <td>1.676418e-05</td>\n",
       "      <td>0.556915</td>\n",
       "      <td>2.761780</td>\n",
       "      <td>36.015503</td>\n",
       "      <td>128.010010</td>\n",
       "      <td>192.006805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.693172</td>\n",
       "      <td>239392.328125</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-2.532516e-06</td>\n",
       "      <td>-2.024581e-01</td>\n",
       "      <td>-2.532516e+06</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>62.480423</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>4543.137207</td>\n",
       "      <td>48758.203125</td>\n",
       "      <td>9.995561e+10</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>448.042725</td>\n",
       "      <td>44.963810</td>\n",
       "      <td>6.734787e-05</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>2.731812</td>\n",
       "      <td>31.994019</td>\n",
       "      <td>128.004547</td>\n",
       "      <td>192.015137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.256454</td>\n",
       "      <td>232850.640625</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>4.575153e-06</td>\n",
       "      <td>-9.745409e-03</td>\n",
       "      <td>4.575152e+06</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>60.773392</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>5033.905762</td>\n",
       "      <td>50613.683594</td>\n",
       "      <td>3.616815e+10</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>448.051758</td>\n",
       "      <td>44.308361</td>\n",
       "      <td>5.938404e-04</td>\n",
       "      <td>0.554260</td>\n",
       "      <td>2.748375</td>\n",
       "      <td>31.997894</td>\n",
       "      <td>127.991211</td>\n",
       "      <td>191.993317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.403919</td>\n",
       "      <td>161578.359375</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>8.130700e-06</td>\n",
       "      <td>2.347322e-02</td>\n",
       "      <td>3.463819e-04</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>79.519371</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>3143.308838</td>\n",
       "      <td>27983.072266</td>\n",
       "      <td>5.655924e+09</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>448.196289</td>\n",
       "      <td>57.879272</td>\n",
       "      <td>-6.406042e-04</td>\n",
       "      <td>0.614685</td>\n",
       "      <td>3.025146</td>\n",
       "      <td>40.012573</td>\n",
       "      <td>160.071289</td>\n",
       "      <td>239.993317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>76.326584</td>\n",
       "      <td>353690.687500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>4.217153e-06</td>\n",
       "      <td>-5.704076e-03</td>\n",
       "      <td>4.217153e+06</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>106.593079</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>4633.912598</td>\n",
       "      <td>54179.046875</td>\n",
       "      <td>6.663707e+10</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>84.452888</td>\n",
       "      <td>-2.786990e-04</td>\n",
       "      <td>1.284668</td>\n",
       "      <td>6.504669</td>\n",
       "      <td>71.990234</td>\n",
       "      <td>208.010986</td>\n",
       "      <td>287.990723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.295757</td>\n",
       "      <td>30.401682</td>\n",
       "      <td>1.654374</td>\n",
       "      <td>-1.869524e-04</td>\n",
       "      <td>-5.243882e-05</td>\n",
       "      <td>-1.869524e+08</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>1.654358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>1.167676</td>\n",
       "      <td>5.328950</td>\n",
       "      <td>2.070192e+05</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.461042</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>2.463521e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.028381</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.349049</td>\n",
       "      <td>253563.968750</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>-2.036382e-06</td>\n",
       "      <td>-5.447127e-03</td>\n",
       "      <td>-2.036382e+06</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>66.179512</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>5470.748535</td>\n",
       "      <td>74789.625000</td>\n",
       "      <td>2.152890e+11</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>448.037109</td>\n",
       "      <td>49.486153</td>\n",
       "      <td>-4.554685e-04</td>\n",
       "      <td>0.561890</td>\n",
       "      <td>2.984741</td>\n",
       "      <td>39.986206</td>\n",
       "      <td>128.009094</td>\n",
       "      <td>192.027710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.696072</td>\n",
       "      <td>243363.437500</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>6.955045e-06</td>\n",
       "      <td>-1.972267e-01</td>\n",
       "      <td>6.955044e+06</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>63.516895</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>4532.237793</td>\n",
       "      <td>46713.707031</td>\n",
       "      <td>5.320217e+10</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>448.056641</td>\n",
       "      <td>45.890270</td>\n",
       "      <td>1.008127e-03</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>2.744934</td>\n",
       "      <td>32.002930</td>\n",
       "      <td>128.011230</td>\n",
       "      <td>192.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.525772</td>\n",
       "      <td>233164.468750</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>4.115060e-07</td>\n",
       "      <td>-2.233913e-03</td>\n",
       "      <td>4.115060e+05</td>\n",
       "      <td>0.012404</td>\n",
       "      <td>60.855301</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>4906.063965</td>\n",
       "      <td>57213.574219</td>\n",
       "      <td>7.374773e+10</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>448.043213</td>\n",
       "      <td>44.357609</td>\n",
       "      <td>-2.295087e-04</td>\n",
       "      <td>0.558771</td>\n",
       "      <td>2.752243</td>\n",
       "      <td>32.000149</td>\n",
       "      <td>127.988220</td>\n",
       "      <td>191.997543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.421379</td>\n",
       "      <td>157419.468750</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-1.187304e-05</td>\n",
       "      <td>8.978627e-04</td>\n",
       "      <td>-1.322367e-02</td>\n",
       "      <td>0.020877</td>\n",
       "      <td>77.472610</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>3710.853271</td>\n",
       "      <td>67299.632812</td>\n",
       "      <td>1.499334e+11</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>448.242188</td>\n",
       "      <td>55.413795</td>\n",
       "      <td>-8.030227e-04</td>\n",
       "      <td>0.594971</td>\n",
       "      <td>2.994995</td>\n",
       "      <td>36.044434</td>\n",
       "      <td>160.031982</td>\n",
       "      <td>240.004547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.475895</td>\n",
       "      <td>351937.812500</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>2.778476e-06</td>\n",
       "      <td>4.981333e-02</td>\n",
       "      <td>5.577775e-05</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>106.064796</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>5917.318359</td>\n",
       "      <td>139264.093750</td>\n",
       "      <td>4.833018e+11</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>448.061035</td>\n",
       "      <td>84.174171</td>\n",
       "      <td>-1.307745e-04</td>\n",
       "      <td>1.285645</td>\n",
       "      <td>6.502768</td>\n",
       "      <td>71.993652</td>\n",
       "      <td>208.003372</td>\n",
       "      <td>287.989502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>48.734970</td>\n",
       "      <td>30.269274</td>\n",
       "      <td>1.610048</td>\n",
       "      <td>-1.270078e-04</td>\n",
       "      <td>-1.192450e-04</td>\n",
       "      <td>-1.270078e+08</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>1.610060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>1.175244</td>\n",
       "      <td>8.325297</td>\n",
       "      <td>1.611370e+06</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.440552</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>5.005906e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.112549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.782246</td>\n",
       "      <td>264826.281250</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-2.627695e-06</td>\n",
       "      <td>5.786971e-03</td>\n",
       "      <td>-4.540709e-04</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>69.118950</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>5660.828613</td>\n",
       "      <td>324381.187500</td>\n",
       "      <td>3.728145e+12</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>448.034668</td>\n",
       "      <td>52.028522</td>\n",
       "      <td>3.012657e-04</td>\n",
       "      <td>0.567902</td>\n",
       "      <td>2.994263</td>\n",
       "      <td>40.003403</td>\n",
       "      <td>143.994476</td>\n",
       "      <td>207.986816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.809319</td>\n",
       "      <td>249959.890625</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-6.566966e-06</td>\n",
       "      <td>-2.019484e-01</td>\n",
       "      <td>-6.566966e+06</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>65.238548</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>4733.252930</td>\n",
       "      <td>62941.453125</td>\n",
       "      <td>1.232211e+11</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>448.049072</td>\n",
       "      <td>47.894119</td>\n",
       "      <td>5.587788e-04</td>\n",
       "      <td>0.602173</td>\n",
       "      <td>2.998399</td>\n",
       "      <td>35.994904</td>\n",
       "      <td>128.019897</td>\n",
       "      <td>207.981934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.837463</td>\n",
       "      <td>246854.312500</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-3.257190e-06</td>\n",
       "      <td>-8.360455e-03</td>\n",
       "      <td>-3.257190e+06</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>64.428314</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5160.271973</td>\n",
       "      <td>53996.414062</td>\n",
       "      <td>7.365149e+10</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>448.044678</td>\n",
       "      <td>47.846733</td>\n",
       "      <td>1.614659e-04</td>\n",
       "      <td>0.621674</td>\n",
       "      <td>3.016968</td>\n",
       "      <td>36.000328</td>\n",
       "      <td>128.007935</td>\n",
       "      <td>192.004944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.146156</td>\n",
       "      <td>166726.796875</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>5.031710e-06</td>\n",
       "      <td>7.347168e-03</td>\n",
       "      <td>6.848503e-04</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>82.053139</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>3259.811279</td>\n",
       "      <td>33941.050781</td>\n",
       "      <td>9.817069e+09</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>448.096680</td>\n",
       "      <td>59.874821</td>\n",
       "      <td>9.044335e-05</td>\n",
       "      <td>0.726318</td>\n",
       "      <td>3.595703</td>\n",
       "      <td>43.978394</td>\n",
       "      <td>175.999115</td>\n",
       "      <td>255.977539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.038696</td>\n",
       "      <td>322530.968750</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-3.341826e-06</td>\n",
       "      <td>-1.406137e-02</td>\n",
       "      <td>-3.341826e+06</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>97.202354</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>4186.609863</td>\n",
       "      <td>75614.359375</td>\n",
       "      <td>2.513169e+11</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>76.485435</td>\n",
       "      <td>-3.062702e-04</td>\n",
       "      <td>1.142822</td>\n",
       "      <td>5.977295</td>\n",
       "      <td>63.982422</td>\n",
       "      <td>192.005890</td>\n",
       "      <td>256.007019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>46.998287</td>\n",
       "      <td>29.635151</td>\n",
       "      <td>1.585897</td>\n",
       "      <td>-1.830576e-04</td>\n",
       "      <td>-1.751987e-04</td>\n",
       "      <td>-1.830576e+08</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>1.585925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>1.179102</td>\n",
       "      <td>10.375254</td>\n",
       "      <td>6.325101e+06</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.389709</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>6.643293e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.026825</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.448711</td>\n",
       "      <td>249535.968750</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-6.396671e-07</td>\n",
       "      <td>-7.341177e-03</td>\n",
       "      <td>-6.396671e+05</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>65.128220</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>5490.496582</td>\n",
       "      <td>50347.285156</td>\n",
       "      <td>1.914572e+10</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>448.043457</td>\n",
       "      <td>48.936752</td>\n",
       "      <td>-1.968005e-04</td>\n",
       "      <td>0.556549</td>\n",
       "      <td>2.762268</td>\n",
       "      <td>39.982788</td>\n",
       "      <td>128.003357</td>\n",
       "      <td>192.002640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>50.511700</td>\n",
       "      <td>247315.750000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>8.624909e-06</td>\n",
       "      <td>-1.405958e-01</td>\n",
       "      <td>8.624909e+06</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>64.548592</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>4896.206055</td>\n",
       "      <td>68080.296875</td>\n",
       "      <td>2.229424e+11</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>448.040039</td>\n",
       "      <td>47.032265</td>\n",
       "      <td>9.940417e-04</td>\n",
       "      <td>0.570557</td>\n",
       "      <td>2.982788</td>\n",
       "      <td>35.979248</td>\n",
       "      <td>128.014954</td>\n",
       "      <td>207.982422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.237614</td>\n",
       "      <td>228836.593750</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>6.162876e-07</td>\n",
       "      <td>-3.677541e-02</td>\n",
       "      <td>6.162876e+05</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>59.725723</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>4949.143555</td>\n",
       "      <td>58560.859375</td>\n",
       "      <td>1.293543e+11</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>448.038574</td>\n",
       "      <td>44.166080</td>\n",
       "      <td>4.640776e-04</td>\n",
       "      <td>0.570679</td>\n",
       "      <td>2.984436</td>\n",
       "      <td>32.007996</td>\n",
       "      <td>120.009033</td>\n",
       "      <td>176.014404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.286785</td>\n",
       "      <td>159359.562500</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-6.090324e-06</td>\n",
       "      <td>-3.130476e-02</td>\n",
       "      <td>-6.090324e+06</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>78.427406</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>3169.015137</td>\n",
       "      <td>27479.613281</td>\n",
       "      <td>3.939333e+09</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>448.134766</td>\n",
       "      <td>56.279320</td>\n",
       "      <td>3.306607e-04</td>\n",
       "      <td>0.625412</td>\n",
       "      <td>3.045898</td>\n",
       "      <td>39.979614</td>\n",
       "      <td>175.965820</td>\n",
       "      <td>240.018433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>70.098717</td>\n",
       "      <td>354023.062500</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-1.144068e-05</td>\n",
       "      <td>5.585783e-02</td>\n",
       "      <td>-2.048178e-04</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>106.693237</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>5050.350586</td>\n",
       "      <td>53393.441406</td>\n",
       "      <td>2.617885e+10</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>448.069336</td>\n",
       "      <td>84.626434</td>\n",
       "      <td>-1.208794e-04</td>\n",
       "      <td>1.297607</td>\n",
       "      <td>6.506775</td>\n",
       "      <td>71.993256</td>\n",
       "      <td>208.009338</td>\n",
       "      <td>287.990234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.978374</td>\n",
       "      <td>29.709774</td>\n",
       "      <td>1.513925</td>\n",
       "      <td>-1.210729e-04</td>\n",
       "      <td>-1.989673e-04</td>\n",
       "      <td>-1.210729e+08</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>1.513977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>1.195682</td>\n",
       "      <td>7.656887</td>\n",
       "      <td>1.653523e+06</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.377197</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>5.908003e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>0.077759</td>\n",
       "      <td>0.105713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.732426</td>\n",
       "      <td>246747.593750</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.206265e-06</td>\n",
       "      <td>3.226588e-02</td>\n",
       "      <td>6.837764e-05</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>64.400452</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>5516.079102</td>\n",
       "      <td>51380.972656</td>\n",
       "      <td>1.018066e+10</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>48.669384</td>\n",
       "      <td>6.766855e-05</td>\n",
       "      <td>0.552368</td>\n",
       "      <td>2.757599</td>\n",
       "      <td>39.984375</td>\n",
       "      <td>127.999840</td>\n",
       "      <td>191.991821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>51.111565</td>\n",
       "      <td>247076.625000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>5.742945e-06</td>\n",
       "      <td>-1.902667e-01</td>\n",
       "      <td>5.742945e+06</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>64.486053</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>4834.063965</td>\n",
       "      <td>49648.539062</td>\n",
       "      <td>2.733592e+10</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>448.082520</td>\n",
       "      <td>46.914322</td>\n",
       "      <td>9.604982e-04</td>\n",
       "      <td>0.565582</td>\n",
       "      <td>2.768921</td>\n",
       "      <td>35.968750</td>\n",
       "      <td>128.014160</td>\n",
       "      <td>207.983398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.126278</td>\n",
       "      <td>235508.343750</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>2.934498e-06</td>\n",
       "      <td>1.086098e-02</td>\n",
       "      <td>2.701873e-04</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>61.467045</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>5218.874512</td>\n",
       "      <td>52574.664062</td>\n",
       "      <td>5.497558e+10</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>448.041260</td>\n",
       "      <td>45.833378</td>\n",
       "      <td>-5.040774e-04</td>\n",
       "      <td>0.614357</td>\n",
       "      <td>3.003098</td>\n",
       "      <td>35.991760</td>\n",
       "      <td>127.986755</td>\n",
       "      <td>176.021729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.099186</td>\n",
       "      <td>176098.312500</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>9.309763e-06</td>\n",
       "      <td>-2.666127e-02</td>\n",
       "      <td>9.309763e+06</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>86.665237</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>3446.206055</td>\n",
       "      <td>64964.792969</td>\n",
       "      <td>1.332741e+11</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>448.138672</td>\n",
       "      <td>63.714077</td>\n",
       "      <td>-5.134047e-05</td>\n",
       "      <td>0.688517</td>\n",
       "      <td>3.487366</td>\n",
       "      <td>47.945068</td>\n",
       "      <td>176.030762</td>\n",
       "      <td>255.991089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>75.349091</td>\n",
       "      <td>357103.000000</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-6.279362e-06</td>\n",
       "      <td>2.139048e-03</td>\n",
       "      <td>-2.935587e-03</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>107.621468</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4739.313965</td>\n",
       "      <td>49000.750000</td>\n",
       "      <td>1.627567e+10</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>85.509880</td>\n",
       "      <td>1.197895e-04</td>\n",
       "      <td>1.354370</td>\n",
       "      <td>6.522461</td>\n",
       "      <td>71.999550</td>\n",
       "      <td>208.015747</td>\n",
       "      <td>287.992126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.902657</td>\n",
       "      <td>29.010998</td>\n",
       "      <td>1.547781</td>\n",
       "      <td>-1.609426e-04</td>\n",
       "      <td>-1.404632e-04</td>\n",
       "      <td>-1.609426e+08</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>1.547796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>1.188272</td>\n",
       "      <td>7.097365</td>\n",
       "      <td>2.189672e+06</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.434937</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>5.312983e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>0.104614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.755562</td>\n",
       "      <td>230694.109375</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>3.613284e-06</td>\n",
       "      <td>-6.485780e-03</td>\n",
       "      <td>3.613284e+06</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>60.210541</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>5154.535156</td>\n",
       "      <td>49732.816406</td>\n",
       "      <td>2.210074e+10</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>448.051758</td>\n",
       "      <td>44.747868</td>\n",
       "      <td>2.549679e-05</td>\n",
       "      <td>0.499810</td>\n",
       "      <td>2.513611</td>\n",
       "      <td>35.989014</td>\n",
       "      <td>120.001884</td>\n",
       "      <td>176.017578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.204166</td>\n",
       "      <td>244833.046875</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-7.717815e-06</td>\n",
       "      <td>-2.031770e-01</td>\n",
       "      <td>-7.717814e+06</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>63.900448</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>4689.913574</td>\n",
       "      <td>42603.464844</td>\n",
       "      <td>1.460704e+10</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>448.042725</td>\n",
       "      <td>46.344582</td>\n",
       "      <td>1.381631e-04</td>\n",
       "      <td>0.557392</td>\n",
       "      <td>2.752533</td>\n",
       "      <td>32.012573</td>\n",
       "      <td>128.010315</td>\n",
       "      <td>207.972290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.635883</td>\n",
       "      <td>229273.031250</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>3.854368e-06</td>\n",
       "      <td>1.034002e-02</td>\n",
       "      <td>3.727620e-04</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>59.839645</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5136.518555</td>\n",
       "      <td>52229.101562</td>\n",
       "      <td>4.363142e+10</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>448.037354</td>\n",
       "      <td>44.284389</td>\n",
       "      <td>3.172052e-04</td>\n",
       "      <td>0.574463</td>\n",
       "      <td>2.993896</td>\n",
       "      <td>32.012329</td>\n",
       "      <td>120.004944</td>\n",
       "      <td>176.023560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.237015</td>\n",
       "      <td>153083.781250</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>-3.273722e-06</td>\n",
       "      <td>-5.559136e-02</td>\n",
       "      <td>-3.273722e+06</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>75.338821</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>3047.230957</td>\n",
       "      <td>25103.058594</td>\n",
       "      <td>3.011611e+09</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>448.259766</td>\n",
       "      <td>53.972969</td>\n",
       "      <td>5.291823e-04</td>\n",
       "      <td>0.583089</td>\n",
       "      <td>2.977539</td>\n",
       "      <td>36.021851</td>\n",
       "      <td>160.009460</td>\n",
       "      <td>239.980225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>74.993248</td>\n",
       "      <td>347749.062500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>8.232048e-06</td>\n",
       "      <td>3.023849e-02</td>\n",
       "      <td>2.722374e-04</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>104.802429</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>4637.071777</td>\n",
       "      <td>45390.710938</td>\n",
       "      <td>1.458536e+10</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>448.070801</td>\n",
       "      <td>83.016846</td>\n",
       "      <td>-1.836349e-04</td>\n",
       "      <td>1.264893</td>\n",
       "      <td>6.490601</td>\n",
       "      <td>71.980103</td>\n",
       "      <td>207.997803</td>\n",
       "      <td>287.978760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.251369</td>\n",
       "      <td>28.274366</td>\n",
       "      <td>1.565070</td>\n",
       "      <td>-1.530798e-04</td>\n",
       "      <td>-1.352092e-04</td>\n",
       "      <td>-1.530798e+08</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.020872</td>\n",
       "      <td>1.565086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>1.184185</td>\n",
       "      <td>6.926130</td>\n",
       "      <td>2.296250e+06</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>6.259082e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.357864</td>\n",
       "      <td>236758.187500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-4.030531e-06</td>\n",
       "      <td>-7.940068e-03</td>\n",
       "      <td>-4.030531e+06</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>61.793247</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>5337.457031</td>\n",
       "      <td>63366.921875</td>\n",
       "      <td>7.761259e+10</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>46.188362</td>\n",
       "      <td>2.676618e-04</td>\n",
       "      <td>0.503769</td>\n",
       "      <td>2.739807</td>\n",
       "      <td>36.001610</td>\n",
       "      <td>120.012207</td>\n",
       "      <td>191.991943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.258675</td>\n",
       "      <td>242143.906250</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>2.750955e-06</td>\n",
       "      <td>-1.850301e-01</td>\n",
       "      <td>2.750955e+06</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>63.198639</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>4546.562500</td>\n",
       "      <td>42753.277344</td>\n",
       "      <td>2.568952e+10</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>46.005123</td>\n",
       "      <td>2.948609e-04</td>\n",
       "      <td>0.564148</td>\n",
       "      <td>2.762280</td>\n",
       "      <td>32.014038</td>\n",
       "      <td>128.004333</td>\n",
       "      <td>192.015991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.021950</td>\n",
       "      <td>233435.046875</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-1.456514e-06</td>\n",
       "      <td>1.647042e-02</td>\n",
       "      <td>-8.843213e-05</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>60.925915</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>5425.952637</td>\n",
       "      <td>53935.484375</td>\n",
       "      <td>4.557561e+10</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>448.037598</td>\n",
       "      <td>45.269539</td>\n",
       "      <td>-6.348122e-05</td>\n",
       "      <td>0.617126</td>\n",
       "      <td>3.005371</td>\n",
       "      <td>35.988525</td>\n",
       "      <td>120.015137</td>\n",
       "      <td>191.987915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.222435</td>\n",
       "      <td>181203.046875</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>4.592324e-06</td>\n",
       "      <td>-4.400600e-02</td>\n",
       "      <td>4.592324e+06</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>89.177483</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>3404.636230</td>\n",
       "      <td>164057.468750</td>\n",
       "      <td>4.113281e+11</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>448.130859</td>\n",
       "      <td>66.646599</td>\n",
       "      <td>4.083858e-04</td>\n",
       "      <td>0.842651</td>\n",
       "      <td>4.032227</td>\n",
       "      <td>48.025513</td>\n",
       "      <td>191.978149</td>\n",
       "      <td>256.001831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>73.530098</td>\n",
       "      <td>331982.937500</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>4.888307e-06</td>\n",
       "      <td>4.533396e-03</td>\n",
       "      <td>1.078288e-03</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>100.050941</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>4514.926270</td>\n",
       "      <td>47570.929688</td>\n",
       "      <td>1.121951e+10</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>78.170517</td>\n",
       "      <td>-1.743136e-04</td>\n",
       "      <td>1.139343</td>\n",
       "      <td>5.971436</td>\n",
       "      <td>63.988464</td>\n",
       "      <td>207.962891</td>\n",
       "      <td>287.953369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.192734</td>\n",
       "      <td>27.867537</td>\n",
       "      <td>1.585814</td>\n",
       "      <td>-1.046044e-04</td>\n",
       "      <td>-9.810292e-05</td>\n",
       "      <td>-1.046044e+08</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>1.585824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>1.178657</td>\n",
       "      <td>6.962451</td>\n",
       "      <td>1.811176e+06</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.486694</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>8.104665e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.025330</td>\n",
       "      <td>0.075241</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.674278</td>\n",
       "      <td>236165.750000</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>3.017280e-06</td>\n",
       "      <td>2.051894e-02</td>\n",
       "      <td>1.470485e-04</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>61.638622</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>5407.433105</td>\n",
       "      <td>56981.671875</td>\n",
       "      <td>8.298201e+10</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>46.059299</td>\n",
       "      <td>1.109678e-04</td>\n",
       "      <td>0.495667</td>\n",
       "      <td>2.511902</td>\n",
       "      <td>35.997787</td>\n",
       "      <td>127.983398</td>\n",
       "      <td>176.021484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.291489</td>\n",
       "      <td>239228.000000</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>3.023840e-06</td>\n",
       "      <td>-6.742522e-02</td>\n",
       "      <td>3.023840e+06</td>\n",
       "      <td>0.014170</td>\n",
       "      <td>62.437828</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>4406.362305</td>\n",
       "      <td>46007.796875</td>\n",
       "      <td>4.133502e+10</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>45.025131</td>\n",
       "      <td>6.357791e-04</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>2.744202</td>\n",
       "      <td>31.998016</td>\n",
       "      <td>128.001678</td>\n",
       "      <td>192.020508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.223412</td>\n",
       "      <td>223178.593750</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.261310e-06</td>\n",
       "      <td>1.738634e-02</td>\n",
       "      <td>7.254606e-05</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>58.249008</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>5163.373047</td>\n",
       "      <td>48538.796875</td>\n",
       "      <td>1.991869e+10</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>448.037354</td>\n",
       "      <td>43.076241</td>\n",
       "      <td>1.679831e-05</td>\n",
       "      <td>0.564117</td>\n",
       "      <td>2.759705</td>\n",
       "      <td>31.999149</td>\n",
       "      <td>119.997650</td>\n",
       "      <td>176.002441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>45.840549</td>\n",
       "      <td>162606.562500</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-1.813067e-06</td>\n",
       "      <td>-6.622984e-02</td>\n",
       "      <td>-1.813067e+06</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>80.025360</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>3547.221436</td>\n",
       "      <td>37411.636719</td>\n",
       "      <td>2.664015e+10</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>448.135742</td>\n",
       "      <td>57.219238</td>\n",
       "      <td>-9.910561e-04</td>\n",
       "      <td>0.635498</td>\n",
       "      <td>3.244751</td>\n",
       "      <td>39.982056</td>\n",
       "      <td>175.993958</td>\n",
       "      <td>255.963623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.775063</td>\n",
       "      <td>346763.250000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>1.783787e-06</td>\n",
       "      <td>-3.087820e-02</td>\n",
       "      <td>1.783786e+06</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>104.505333</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>4764.863770</td>\n",
       "      <td>45184.449219</td>\n",
       "      <td>1.257064e+10</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>82.734909</td>\n",
       "      <td>-1.828451e-05</td>\n",
       "      <td>1.264648</td>\n",
       "      <td>6.486694</td>\n",
       "      <td>71.976807</td>\n",
       "      <td>207.996353</td>\n",
       "      <td>287.978394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>41.863281</td>\n",
       "      <td>26.720890</td>\n",
       "      <td>1.566687</td>\n",
       "      <td>-1.596463e-04</td>\n",
       "      <td>-1.207755e-04</td>\n",
       "      <td>-1.596463e+08</td>\n",
       "      <td>0.030904</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>1.566696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>1.183551</td>\n",
       "      <td>7.063575</td>\n",
       "      <td>2.130708e+06</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>5.721314e-03</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.071442</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.783043</td>\n",
       "      <td>240158.453125</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-2.821200e-06</td>\n",
       "      <td>3.617537e-03</td>\n",
       "      <td>-7.798676e-04</td>\n",
       "      <td>0.011427</td>\n",
       "      <td>62.680706</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>5485.193359</td>\n",
       "      <td>69517.117188</td>\n",
       "      <td>1.324713e+11</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>448.059814</td>\n",
       "      <td>46.030537</td>\n",
       "      <td>1.993600e-04</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>2.739319</td>\n",
       "      <td>35.991455</td>\n",
       "      <td>127.993927</td>\n",
       "      <td>192.010864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.768604</td>\n",
       "      <td>257880.921875</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-7.959879e-06</td>\n",
       "      <td>-1.582177e-01</td>\n",
       "      <td>-7.959880e+06</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>67.306038</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>4796.124023</td>\n",
       "      <td>48101.644531</td>\n",
       "      <td>3.012361e+10</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>448.057373</td>\n",
       "      <td>48.837246</td>\n",
       "      <td>4.556970e-04</td>\n",
       "      <td>0.579468</td>\n",
       "      <td>2.993408</td>\n",
       "      <td>35.995239</td>\n",
       "      <td>143.993561</td>\n",
       "      <td>208.013306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.861973</td>\n",
       "      <td>226822.234375</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-7.313890e-06</td>\n",
       "      <td>5.653849e-03</td>\n",
       "      <td>-1.293612e-03</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>59.199986</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>5291.922852</td>\n",
       "      <td>52456.207031</td>\n",
       "      <td>1.682926e+10</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>448.038818</td>\n",
       "      <td>43.042099</td>\n",
       "      <td>-3.289511e-04</td>\n",
       "      <td>0.556610</td>\n",
       "      <td>2.750534</td>\n",
       "      <td>31.993134</td>\n",
       "      <td>120.004333</td>\n",
       "      <td>191.995575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.777794</td>\n",
       "      <td>144451.828125</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>1.207770e-06</td>\n",
       "      <td>4.197418e-02</td>\n",
       "      <td>2.877413e-05</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>71.090698</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>2736.980469</td>\n",
       "      <td>23214.568359</td>\n",
       "      <td>3.817749e+09</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>51.204514</td>\n",
       "      <td>6.761709e-04</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>2.983276</td>\n",
       "      <td>36.001892</td>\n",
       "      <td>144.049561</td>\n",
       "      <td>223.999252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>66.715645</td>\n",
       "      <td>338362.750000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-2.672746e-06</td>\n",
       "      <td>1.946198e-02</td>\n",
       "      <td>-1.373317e-04</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>101.973648</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>5071.715332</td>\n",
       "      <td>54636.542969</td>\n",
       "      <td>1.917753e+10</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>448.073730</td>\n",
       "      <td>80.585632</td>\n",
       "      <td>3.964597e-04</td>\n",
       "      <td>1.244110</td>\n",
       "      <td>6.029785</td>\n",
       "      <td>64.021484</td>\n",
       "      <td>207.976685</td>\n",
       "      <td>256.035645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.910725</td>\n",
       "      <td>25.972263</td>\n",
       "      <td>1.575170</td>\n",
       "      <td>-1.012390e-04</td>\n",
       "      <td>-1.808002e-04</td>\n",
       "      <td>-1.012390e+08</td>\n",
       "      <td>0.030201</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>1.575231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>1.182441</td>\n",
       "      <td>14.109981</td>\n",
       "      <td>1.452872e+07</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>4.338760e-03</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.287209</td>\n",
       "      <td>260490.750000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>1.819590e-06</td>\n",
       "      <td>2.766303e-03</td>\n",
       "      <td>6.577697e-04</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>67.987389</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>6160.037109</td>\n",
       "      <td>69636.281250</td>\n",
       "      <td>1.699728e+11</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>50.225204</td>\n",
       "      <td>-1.212179e-04</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>2.749714</td>\n",
       "      <td>39.973511</td>\n",
       "      <td>143.992279</td>\n",
       "      <td>208.003357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.979279</td>\n",
       "      <td>266612.125000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>2.148646e-05</td>\n",
       "      <td>-2.301417e-01</td>\n",
       "      <td>2.148646e+07</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>69.584663</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>4849.319824</td>\n",
       "      <td>48564.054688</td>\n",
       "      <td>2.987803e+10</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>50.489311</td>\n",
       "      <td>6.598887e-04</td>\n",
       "      <td>0.614563</td>\n",
       "      <td>3.006714</td>\n",
       "      <td>36.004059</td>\n",
       "      <td>144.005737</td>\n",
       "      <td>223.991211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.763363</td>\n",
       "      <td>242888.062500</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-7.760198e-07</td>\n",
       "      <td>-1.859942e-02</td>\n",
       "      <td>-7.760198e+05</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>63.393131</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>5815.816895</td>\n",
       "      <td>60397.398438</td>\n",
       "      <td>4.474757e+10</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>448.040771</td>\n",
       "      <td>46.630215</td>\n",
       "      <td>-2.742977e-05</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>3.003830</td>\n",
       "      <td>35.991699</td>\n",
       "      <td>128.001282</td>\n",
       "      <td>192.011719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>46.789642</td>\n",
       "      <td>136687.203125</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>6.802001e-06</td>\n",
       "      <td>-2.692598e-02</td>\n",
       "      <td>6.802002e+06</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>67.269402</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>2921.314209</td>\n",
       "      <td>28729.501953</td>\n",
       "      <td>1.627567e+10</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>47.985260</td>\n",
       "      <td>-6.119655e-04</td>\n",
       "      <td>0.474365</td>\n",
       "      <td>2.467285</td>\n",
       "      <td>32.010681</td>\n",
       "      <td>143.998413</td>\n",
       "      <td>208.005554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>61.593723</td>\n",
       "      <td>343426.281250</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-1.184558e-05</td>\n",
       "      <td>4.968539e-02</td>\n",
       "      <td>-2.384118e-04</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>103.499649</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>5575.669922</td>\n",
       "      <td>72250.726562</td>\n",
       "      <td>7.156584e+10</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>448.057129</td>\n",
       "      <td>81.831963</td>\n",
       "      <td>1.884710e-06</td>\n",
       "      <td>1.253776</td>\n",
       "      <td>6.474609</td>\n",
       "      <td>71.963623</td>\n",
       "      <td>207.992218</td>\n",
       "      <td>287.976318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.967010</td>\n",
       "      <td>25.516438</td>\n",
       "      <td>1.605515</td>\n",
       "      <td>-1.089947e-04</td>\n",
       "      <td>-1.687905e-04</td>\n",
       "      <td>-1.089947e+08</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>1.605569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>1.174486</td>\n",
       "      <td>8.580814</td>\n",
       "      <td>2.498458e+06</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>8.459683e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023491</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.911053</td>\n",
       "      <td>266518.906250</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-5.961533e-06</td>\n",
       "      <td>6.079135e-03</td>\n",
       "      <td>-9.806550e-04</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>69.560707</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>6359.155762</td>\n",
       "      <td>82208.375000</td>\n",
       "      <td>3.190293e+11</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>448.044678</td>\n",
       "      <td>51.970615</td>\n",
       "      <td>-1.642748e-04</td>\n",
       "      <td>0.559769</td>\n",
       "      <td>2.989624</td>\n",
       "      <td>40.000893</td>\n",
       "      <td>143.997330</td>\n",
       "      <td>208.004883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.824352</td>\n",
       "      <td>265747.937500</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-6.168965e-06</td>\n",
       "      <td>-2.367010e-01</td>\n",
       "      <td>-6.168965e+06</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>69.359093</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>4760.429199</td>\n",
       "      <td>46493.609375</td>\n",
       "      <td>8.975605e+10</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>50.315189</td>\n",
       "      <td>7.506667e-04</td>\n",
       "      <td>0.612183</td>\n",
       "      <td>3.003387</td>\n",
       "      <td>36.003143</td>\n",
       "      <td>144.004578</td>\n",
       "      <td>223.988892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.388466</td>\n",
       "      <td>241293.421875</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-4.853365e-06</td>\n",
       "      <td>1.312750e-04</td>\n",
       "      <td>-3.697098e-02</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>62.976933</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>5829.967285</td>\n",
       "      <td>65039.093750</td>\n",
       "      <td>6.214631e+10</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>46.345890</td>\n",
       "      <td>3.700178e-04</td>\n",
       "      <td>0.613525</td>\n",
       "      <td>3.002823</td>\n",
       "      <td>35.989441</td>\n",
       "      <td>127.999931</td>\n",
       "      <td>192.007690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.699005</td>\n",
       "      <td>184263.796875</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-4.431110e-06</td>\n",
       "      <td>-9.210092e-02</td>\n",
       "      <td>-4.431110e+06</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>90.683762</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>4122.324707</td>\n",
       "      <td>40340.566406</td>\n",
       "      <td>1.304800e+10</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>448.097656</td>\n",
       "      <td>66.549110</td>\n",
       "      <td>-3.216275e-04</td>\n",
       "      <td>0.693319</td>\n",
       "      <td>3.495403</td>\n",
       "      <td>47.993896</td>\n",
       "      <td>191.999619</td>\n",
       "      <td>256.011230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>54.549786</td>\n",
       "      <td>348280.156250</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3.629224e-06</td>\n",
       "      <td>-2.747159e-02</td>\n",
       "      <td>3.629224e+06</td>\n",
       "      <td>0.016440</td>\n",
       "      <td>104.962486</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>6384.629395</td>\n",
       "      <td>76075.992188</td>\n",
       "      <td>3.123613e+10</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>83.202171</td>\n",
       "      <td>1.685682e-04</td>\n",
       "      <td>1.264465</td>\n",
       "      <td>6.495850</td>\n",
       "      <td>71.988403</td>\n",
       "      <td>207.998962</td>\n",
       "      <td>287.985840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>41.393047</td>\n",
       "      <td>24.754883</td>\n",
       "      <td>1.672117</td>\n",
       "      <td>-9.340945e-05</td>\n",
       "      <td>-1.160686e-04</td>\n",
       "      <td>-9.340945e+07</td>\n",
       "      <td>0.030557</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>1.672143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>1.162253</td>\n",
       "      <td>4.913018</td>\n",
       "      <td>1.075075e+05</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.497725</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>6.839227e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>0.069397</td>\n",
       "      <td>0.093384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.868046</td>\n",
       "      <td>264151.750000</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>2.065495e-06</td>\n",
       "      <td>-8.322178e-03</td>\n",
       "      <td>2.065495e+06</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>68.942902</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>6309.149414</td>\n",
       "      <td>68588.726562</td>\n",
       "      <td>6.731704e+10</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>51.094738</td>\n",
       "      <td>4.490079e-04</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>2.753357</td>\n",
       "      <td>39.991760</td>\n",
       "      <td>143.997162</td>\n",
       "      <td>208.006226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.572136</td>\n",
       "      <td>269599.500000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-9.959461e-08</td>\n",
       "      <td>-1.904464e-01</td>\n",
       "      <td>-9.959461e+04</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>70.364494</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>4851.342773</td>\n",
       "      <td>59792.234375</td>\n",
       "      <td>5.577233e+10</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>448.049805</td>\n",
       "      <td>51.351974</td>\n",
       "      <td>7.915903e-04</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>3.238525</td>\n",
       "      <td>36.014771</td>\n",
       "      <td>144.008667</td>\n",
       "      <td>223.993042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.009579</td>\n",
       "      <td>243532.406250</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>2.872873e-07</td>\n",
       "      <td>-1.776119e-02</td>\n",
       "      <td>2.872873e+05</td>\n",
       "      <td>0.010964</td>\n",
       "      <td>63.561302</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>5797.069336</td>\n",
       "      <td>157433.500000</td>\n",
       "      <td>1.297784e+12</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>448.033936</td>\n",
       "      <td>46.773361</td>\n",
       "      <td>-4.251097e-04</td>\n",
       "      <td>0.620972</td>\n",
       "      <td>3.007544</td>\n",
       "      <td>35.992798</td>\n",
       "      <td>128.002625</td>\n",
       "      <td>192.015991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.209965</td>\n",
       "      <td>172654.687500</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>-3.225490e-06</td>\n",
       "      <td>2.155166e-02</td>\n",
       "      <td>-1.496631e-04</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>84.970497</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>3995.715332</td>\n",
       "      <td>56327.046875</td>\n",
       "      <td>3.509080e+10</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>448.077637</td>\n",
       "      <td>62.526688</td>\n",
       "      <td>-4.013054e-05</td>\n",
       "      <td>0.690928</td>\n",
       "      <td>3.497015</td>\n",
       "      <td>44.019165</td>\n",
       "      <td>176.009155</td>\n",
       "      <td>255.982788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>55.441502</td>\n",
       "      <td>345941.156250</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-6.610821e-06</td>\n",
       "      <td>-3.157791e-03</td>\n",
       "      <td>-6.610822e+06</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>104.257576</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>6239.751465</td>\n",
       "      <td>85830.742188</td>\n",
       "      <td>7.156584e+10</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>448.078613</td>\n",
       "      <td>82.545204</td>\n",
       "      <td>-1.167669e-04</td>\n",
       "      <td>1.255890</td>\n",
       "      <td>6.488159</td>\n",
       "      <td>71.981812</td>\n",
       "      <td>207.996201</td>\n",
       "      <td>287.983276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>39.940376</td>\n",
       "      <td>24.357220</td>\n",
       "      <td>1.639776</td>\n",
       "      <td>-1.819975e-04</td>\n",
       "      <td>-1.049985e-04</td>\n",
       "      <td>-1.819975e+08</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>1.639772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>1.169132</td>\n",
       "      <td>12.287910</td>\n",
       "      <td>1.018355e+07</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.515320</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>5.296745e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.022797</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.090515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.579712</td>\n",
       "      <td>258156.953125</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-3.709344e-06</td>\n",
       "      <td>-3.467460e-02</td>\n",
       "      <td>-3.709344e+06</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>67.378258</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>6208.724121</td>\n",
       "      <td>59561.312500</td>\n",
       "      <td>2.342709e+10</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>49.717842</td>\n",
       "      <td>-1.167812e-04</td>\n",
       "      <td>0.517456</td>\n",
       "      <td>2.748688</td>\n",
       "      <td>36.012329</td>\n",
       "      <td>143.991028</td>\n",
       "      <td>208.000671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.334579</td>\n",
       "      <td>266024.468750</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-2.191403e-05</td>\n",
       "      <td>-1.845903e-01</td>\n",
       "      <td>-2.191403e+07</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>69.431419</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>4807.561523</td>\n",
       "      <td>55200.367188</td>\n",
       "      <td>5.186376e+10</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>50.322086</td>\n",
       "      <td>1.110060e-03</td>\n",
       "      <td>0.610413</td>\n",
       "      <td>3.004761</td>\n",
       "      <td>36.002411</td>\n",
       "      <td>144.005402</td>\n",
       "      <td>223.991272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.802856</td>\n",
       "      <td>238225.250000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>7.321877e-07</td>\n",
       "      <td>-1.483387e-03</td>\n",
       "      <td>7.321878e+05</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>62.176151</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5838.445801</td>\n",
       "      <td>123184.773438</td>\n",
       "      <td>8.747496e+11</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>448.036377</td>\n",
       "      <td>45.715626</td>\n",
       "      <td>2.584271e-04</td>\n",
       "      <td>0.605957</td>\n",
       "      <td>2.998970</td>\n",
       "      <td>35.983398</td>\n",
       "      <td>127.995636</td>\n",
       "      <td>192.005768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.474453</td>\n",
       "      <td>162472.593750</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>5.950097e-06</td>\n",
       "      <td>5.554332e-02</td>\n",
       "      <td>1.071253e-04</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>79.959450</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>3096.222656</td>\n",
       "      <td>29731.494141</td>\n",
       "      <td>1.278502e+10</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>448.141602</td>\n",
       "      <td>57.190922</td>\n",
       "      <td>3.464538e-04</td>\n",
       "      <td>0.636658</td>\n",
       "      <td>3.230347</td>\n",
       "      <td>39.986267</td>\n",
       "      <td>175.991638</td>\n",
       "      <td>255.967529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>73.557915</td>\n",
       "      <td>340124.093750</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-1.052833e-05</td>\n",
       "      <td>3.655579e-02</td>\n",
       "      <td>-2.880072e-04</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>102.504456</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>4623.895508</td>\n",
       "      <td>53108.781250</td>\n",
       "      <td>7.186351e+10</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>81.018059</td>\n",
       "      <td>2.196512e-04</td>\n",
       "      <td>1.249262</td>\n",
       "      <td>6.046143</td>\n",
       "      <td>64.031738</td>\n",
       "      <td>207.981079</td>\n",
       "      <td>256.065918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>39.181675</td>\n",
       "      <td>23.561365</td>\n",
       "      <td>1.662963</td>\n",
       "      <td>-1.531837e-04</td>\n",
       "      <td>-1.507561e-04</td>\n",
       "      <td>-1.531837e+08</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>1.663002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>1.164390</td>\n",
       "      <td>7.146149</td>\n",
       "      <td>1.054305e+06</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.406006</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>6.245933e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.065796</td>\n",
       "      <td>0.088257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.402748</td>\n",
       "      <td>274071.906250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-3.844635e-06</td>\n",
       "      <td>6.481429e-03</td>\n",
       "      <td>-5.931771e-04</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>71.532028</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>6463.541016</td>\n",
       "      <td>116853.351562</td>\n",
       "      <td>4.435005e+11</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>448.032959</td>\n",
       "      <td>53.563866</td>\n",
       "      <td>4.448465e-05</td>\n",
       "      <td>0.559662</td>\n",
       "      <td>2.993866</td>\n",
       "      <td>40.010132</td>\n",
       "      <td>144.004913</td>\n",
       "      <td>208.011780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>57.039303</td>\n",
       "      <td>263386.218750</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-4.383844e-06</td>\n",
       "      <td>-2.694015e-01</td>\n",
       "      <td>-4.383844e+06</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>68.742569</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>4617.626465</td>\n",
       "      <td>46510.121094</td>\n",
       "      <td>2.350930e+10</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>448.064453</td>\n",
       "      <td>49.847744</td>\n",
       "      <td>9.679577e-04</td>\n",
       "      <td>0.607666</td>\n",
       "      <td>3.001869</td>\n",
       "      <td>36.001144</td>\n",
       "      <td>144.001587</td>\n",
       "      <td>223.986389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.339771</td>\n",
       "      <td>250485.078125</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>3.685792e-07</td>\n",
       "      <td>5.844287e-03</td>\n",
       "      <td>6.306659e-05</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>65.375931</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>6059.179688</td>\n",
       "      <td>67946.906250</td>\n",
       "      <td>5.235770e+10</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>48.745476</td>\n",
       "      <td>1.663517e-05</td>\n",
       "      <td>0.645874</td>\n",
       "      <td>3.253784</td>\n",
       "      <td>36.008606</td>\n",
       "      <td>128.009705</td>\n",
       "      <td>192.014893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.515038</td>\n",
       "      <td>160357.781250</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>7.729338e-06</td>\n",
       "      <td>-2.947754e-02</td>\n",
       "      <td>7.729338e+06</td>\n",
       "      <td>0.025845</td>\n",
       "      <td>78.918671</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3053.559326</td>\n",
       "      <td>40286.941406</td>\n",
       "      <td>4.106060e+10</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>448.089844</td>\n",
       "      <td>58.321678</td>\n",
       "      <td>-1.388629e-04</td>\n",
       "      <td>0.687287</td>\n",
       "      <td>3.481445</td>\n",
       "      <td>43.978149</td>\n",
       "      <td>160.019897</td>\n",
       "      <td>239.973022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>63.924370</td>\n",
       "      <td>347385.187500</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>3.315716e-07</td>\n",
       "      <td>-3.104924e-02</td>\n",
       "      <td>3.315717e+05</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>104.692764</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>5434.315918</td>\n",
       "      <td>55110.109375</td>\n",
       "      <td>1.520062e+10</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>448.083496</td>\n",
       "      <td>82.653221</td>\n",
       "      <td>-6.724389e-04</td>\n",
       "      <td>1.256500</td>\n",
       "      <td>6.479736</td>\n",
       "      <td>71.973999</td>\n",
       "      <td>208.000305</td>\n",
       "      <td>287.987549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>38.341373</td>\n",
       "      <td>23.653309</td>\n",
       "      <td>1.620973</td>\n",
       "      <td>-1.386354e-04</td>\n",
       "      <td>-1.537078e-04</td>\n",
       "      <td>-1.386354e+08</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>0.017460</td>\n",
       "      <td>1.621016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>1.171178</td>\n",
       "      <td>5.952379</td>\n",
       "      <td>5.672131e+05</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.416016</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>8.420032e-03</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.682983</td>\n",
       "      <td>258502.312500</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>1.346152e-06</td>\n",
       "      <td>-1.024971e-02</td>\n",
       "      <td>1.346152e+06</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>67.468399</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>6056.332031</td>\n",
       "      <td>65280.046875</td>\n",
       "      <td>7.036875e+10</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>448.035400</td>\n",
       "      <td>49.505333</td>\n",
       "      <td>7.916406e-05</td>\n",
       "      <td>0.513367</td>\n",
       "      <td>2.745636</td>\n",
       "      <td>36.005402</td>\n",
       "      <td>143.993927</td>\n",
       "      <td>208.001312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.438549</td>\n",
       "      <td>267154.718750</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-2.579942e-05</td>\n",
       "      <td>-3.413542e-01</td>\n",
       "      <td>-2.579942e+07</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>69.725830</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>4733.549805</td>\n",
       "      <td>67106.992188</td>\n",
       "      <td>1.851809e+11</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>448.052246</td>\n",
       "      <td>50.594616</td>\n",
       "      <td>6.921013e-04</td>\n",
       "      <td>0.624485</td>\n",
       "      <td>3.031494</td>\n",
       "      <td>36.005768</td>\n",
       "      <td>144.006348</td>\n",
       "      <td>223.996689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.821194</td>\n",
       "      <td>253036.984375</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.576601e-06</td>\n",
       "      <td>3.249281e-03</td>\n",
       "      <td>4.852152e-04</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>66.041969</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>6198.667480</td>\n",
       "      <td>72974.531250</td>\n",
       "      <td>7.635498e+10</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>448.035889</td>\n",
       "      <td>48.948296</td>\n",
       "      <td>-2.343239e-04</td>\n",
       "      <td>0.631744</td>\n",
       "      <td>3.246155</td>\n",
       "      <td>36.006409</td>\n",
       "      <td>128.019897</td>\n",
       "      <td>207.990601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.905533</td>\n",
       "      <td>180060.421875</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.503743e-05</td>\n",
       "      <td>-3.311199e-02</td>\n",
       "      <td>1.503743e+07</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>88.615150</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>3758.656006</td>\n",
       "      <td>43898.667969</td>\n",
       "      <td>1.727804e+10</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>448.126953</td>\n",
       "      <td>65.467949</td>\n",
       "      <td>-1.291276e-04</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>3.531738</td>\n",
       "      <td>47.992218</td>\n",
       "      <td>191.977051</td>\n",
       "      <td>255.996140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.010201</td>\n",
       "      <td>335954.250000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>8.073707e-06</td>\n",
       "      <td>-3.664225e-02</td>\n",
       "      <td>8.073708e+06</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>101.247780</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>5248.449219</td>\n",
       "      <td>60099.574219</td>\n",
       "      <td>7.093623e+10</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>448.055908</td>\n",
       "      <td>79.793724</td>\n",
       "      <td>-4.726739e-04</td>\n",
       "      <td>1.237000</td>\n",
       "      <td>6.007996</td>\n",
       "      <td>64.009338</td>\n",
       "      <td>207.970581</td>\n",
       "      <td>256.032715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>37.370094</td>\n",
       "      <td>21.695557</td>\n",
       "      <td>1.722477</td>\n",
       "      <td>-7.633631e-05</td>\n",
       "      <td>-1.765326e-04</td>\n",
       "      <td>-7.633631e+07</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>1.722575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>1.155191</td>\n",
       "      <td>5.608924</td>\n",
       "      <td>3.359505e+05</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>4.248821e-03</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.433987</td>\n",
       "      <td>253758.671875</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-2.738451e-06</td>\n",
       "      <td>4.667359e-03</td>\n",
       "      <td>-5.867240e-04</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>66.230324</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>5980.081055</td>\n",
       "      <td>60588.476562</td>\n",
       "      <td>2.213782e+10</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>448.046143</td>\n",
       "      <td>48.660442</td>\n",
       "      <td>9.990737e-06</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>2.740845</td>\n",
       "      <td>36.002350</td>\n",
       "      <td>143.984131</td>\n",
       "      <td>207.995636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.619488</td>\n",
       "      <td>263933.625000</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-2.242682e-05</td>\n",
       "      <td>-2.347590e-01</td>\n",
       "      <td>-2.242682e+07</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>68.885559</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>4502.488770</td>\n",
       "      <td>72163.531250</td>\n",
       "      <td>3.023657e+11</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>448.057861</td>\n",
       "      <td>49.945812</td>\n",
       "      <td>-2.644935e-06</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>3.008850</td>\n",
       "      <td>36.002029</td>\n",
       "      <td>144.002167</td>\n",
       "      <td>223.992004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.589417</td>\n",
       "      <td>246767.109375</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-5.489941e-06</td>\n",
       "      <td>-3.485284e-02</td>\n",
       "      <td>-5.489941e+06</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>64.405540</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>6079.592773</td>\n",
       "      <td>69012.031250</td>\n",
       "      <td>5.890241e+10</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>448.046631</td>\n",
       "      <td>47.737759</td>\n",
       "      <td>-3.452895e-04</td>\n",
       "      <td>0.626836</td>\n",
       "      <td>3.239502</td>\n",
       "      <td>36.000782</td>\n",
       "      <td>128.005127</td>\n",
       "      <td>192.012756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.849182</td>\n",
       "      <td>182301.687500</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4.912959e-06</td>\n",
       "      <td>-4.510187e-02</td>\n",
       "      <td>4.912959e+06</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>89.718170</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>3657.064453</td>\n",
       "      <td>41153.359375</td>\n",
       "      <td>1.212697e+10</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>448.070312</td>\n",
       "      <td>66.892845</td>\n",
       "      <td>7.146989e-04</td>\n",
       "      <td>0.739604</td>\n",
       "      <td>3.740662</td>\n",
       "      <td>51.950928</td>\n",
       "      <td>191.978394</td>\n",
       "      <td>255.999725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.376747</td>\n",
       "      <td>314651.562500</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>7.497435e-06</td>\n",
       "      <td>-3.885011e-02</td>\n",
       "      <td>7.497435e+06</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>94.827713</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4887.658691</td>\n",
       "      <td>55091.910156</td>\n",
       "      <td>9.115122e+10</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>448.063965</td>\n",
       "      <td>73.885269</td>\n",
       "      <td>3.619854e-04</td>\n",
       "      <td>1.109558</td>\n",
       "      <td>5.497147</td>\n",
       "      <td>60.001022</td>\n",
       "      <td>191.996735</td>\n",
       "      <td>256.005188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>35.798725</td>\n",
       "      <td>21.656708</td>\n",
       "      <td>1.653009</td>\n",
       "      <td>-1.216935e-04</td>\n",
       "      <td>-9.439918e-05</td>\n",
       "      <td>-1.216935e+08</td>\n",
       "      <td>0.026427</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>1.653020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>1.166367</td>\n",
       "      <td>7.772630</td>\n",
       "      <td>3.962209e+06</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.393822</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>6.406918e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.254421</td>\n",
       "      <td>258464.078125</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-9.516548e-07</td>\n",
       "      <td>-1.052500e-02</td>\n",
       "      <td>-9.516548e+05</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>67.458427</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6116.853027</td>\n",
       "      <td>77353.398438</td>\n",
       "      <td>8.408030e+10</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>50.039043</td>\n",
       "      <td>1.521224e-04</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>2.966797</td>\n",
       "      <td>36.025391</td>\n",
       "      <td>143.990356</td>\n",
       "      <td>207.995789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>57.487576</td>\n",
       "      <td>267196.437500</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-3.175724e-05</td>\n",
       "      <td>-1.723170e-01</td>\n",
       "      <td>-3.175724e+07</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>69.737335</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>4647.899414</td>\n",
       "      <td>54278.503906</td>\n",
       "      <td>7.853655e+10</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>50.312813</td>\n",
       "      <td>-3.153391e-04</td>\n",
       "      <td>0.618896</td>\n",
       "      <td>3.010681</td>\n",
       "      <td>36.001839</td>\n",
       "      <td>144.007507</td>\n",
       "      <td>224.003357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.106983</td>\n",
       "      <td>252560.531250</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>3.281851e-07</td>\n",
       "      <td>-1.137515e-02</td>\n",
       "      <td>3.281851e+05</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>65.917618</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>6143.980957</td>\n",
       "      <td>63881.269531</td>\n",
       "      <td>3.967310e+10</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>448.038818</td>\n",
       "      <td>49.004391</td>\n",
       "      <td>2.035016e-04</td>\n",
       "      <td>0.636353</td>\n",
       "      <td>3.249995</td>\n",
       "      <td>36.007721</td>\n",
       "      <td>128.018433</td>\n",
       "      <td>207.978516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.294857</td>\n",
       "      <td>176369.859375</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-1.530643e-05</td>\n",
       "      <td>-1.975615e-03</td>\n",
       "      <td>-1.530643e+07</td>\n",
       "      <td>0.020815</td>\n",
       "      <td>86.798882</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>4170.007812</td>\n",
       "      <td>42843.574219</td>\n",
       "      <td>9.629481e+09</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>63.692081</td>\n",
       "      <td>-4.158668e-04</td>\n",
       "      <td>0.690430</td>\n",
       "      <td>3.494690</td>\n",
       "      <td>44.027344</td>\n",
       "      <td>176.030762</td>\n",
       "      <td>255.994659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>51.717434</td>\n",
       "      <td>347355.125000</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-7.407287e-07</td>\n",
       "      <td>2.083170e-02</td>\n",
       "      <td>-3.555777e-05</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>104.683708</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>6716.402344</td>\n",
       "      <td>245204.984375</td>\n",
       "      <td>1.607408e+12</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>448.057129</td>\n",
       "      <td>82.612213</td>\n",
       "      <td>4.707460e-04</td>\n",
       "      <td>1.250813</td>\n",
       "      <td>6.477905</td>\n",
       "      <td>71.977783</td>\n",
       "      <td>208.000305</td>\n",
       "      <td>287.989502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>36.117199</td>\n",
       "      <td>20.357906</td>\n",
       "      <td>1.774112</td>\n",
       "      <td>-4.039209e-05</td>\n",
       "      <td>-1.072185e-04</td>\n",
       "      <td>-4.039209e+07</td>\n",
       "      <td>0.026662</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>1.774155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>1.146590</td>\n",
       "      <td>4.780324</td>\n",
       "      <td>1.094827e+05</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.361908</td>\n",
       "      <td>0.024207</td>\n",
       "      <td>3.614819e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.080185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.344177</td>\n",
       "      <td>256965.453125</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>4.297632e-06</td>\n",
       "      <td>7.255935e-03</td>\n",
       "      <td>5.922920e-04</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>67.067284</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>5928.488281</td>\n",
       "      <td>65095.105469</td>\n",
       "      <td>6.731704e+10</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>50.065414</td>\n",
       "      <td>3.031318e-04</td>\n",
       "      <td>0.580322</td>\n",
       "      <td>3.000080</td>\n",
       "      <td>39.988708</td>\n",
       "      <td>143.977539</td>\n",
       "      <td>207.989136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.638844</td>\n",
       "      <td>274772.812500</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-4.038461e-05</td>\n",
       "      <td>-1.469817e-01</td>\n",
       "      <td>-4.038461e+07</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>71.714813</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>4685.849609</td>\n",
       "      <td>80761.898438</td>\n",
       "      <td>2.549592e+11</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>448.081543</td>\n",
       "      <td>52.161930</td>\n",
       "      <td>4.090447e-04</td>\n",
       "      <td>0.639404</td>\n",
       "      <td>3.249382</td>\n",
       "      <td>36.044189</td>\n",
       "      <td>144.021973</td>\n",
       "      <td>224.010498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.496319</td>\n",
       "      <td>268099.093750</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.203183e-06</td>\n",
       "      <td>4.487616e-03</td>\n",
       "      <td>2.681118e-04</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>69.973145</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>6308.760254</td>\n",
       "      <td>72835.218750</td>\n",
       "      <td>8.567623e+10</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>448.035400</td>\n",
       "      <td>52.742100</td>\n",
       "      <td>9.467788e-05</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>3.524048</td>\n",
       "      <td>40.006012</td>\n",
       "      <td>143.998444</td>\n",
       "      <td>208.000793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.518063</td>\n",
       "      <td>166118.187500</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-6.869784e-06</td>\n",
       "      <td>1.160942e-02</td>\n",
       "      <td>-5.917421e-04</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>81.753609</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>3817.223877</td>\n",
       "      <td>44322.226562</td>\n",
       "      <td>4.140420e+10</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>448.056152</td>\n",
       "      <td>59.618183</td>\n",
       "      <td>1.034701e-04</td>\n",
       "      <td>0.617371</td>\n",
       "      <td>3.022705</td>\n",
       "      <td>43.984619</td>\n",
       "      <td>175.991760</td>\n",
       "      <td>240.019897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>46.662914</td>\n",
       "      <td>336636.906250</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-1.299218e-06</td>\n",
       "      <td>2.403503e-02</td>\n",
       "      <td>-5.405517e-05</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>101.453522</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>7214.228027</td>\n",
       "      <td>95299.117188</td>\n",
       "      <td>8.012635e+10</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>448.049072</td>\n",
       "      <td>80.103516</td>\n",
       "      <td>1.683750e-04</td>\n",
       "      <td>1.244904</td>\n",
       "      <td>6.011108</td>\n",
       "      <td>64.009460</td>\n",
       "      <td>207.978394</td>\n",
       "      <td>256.021362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>34.743210</td>\n",
       "      <td>19.548061</td>\n",
       "      <td>1.777323</td>\n",
       "      <td>-2.811972e-05</td>\n",
       "      <td>-4.951217e-05</td>\n",
       "      <td>-2.811972e+07</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>1.777332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>1.144950</td>\n",
       "      <td>16.797567</td>\n",
       "      <td>1.917396e+07</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.356506</td>\n",
       "      <td>0.023236</td>\n",
       "      <td>5.722261e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>0.077087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.350349</td>\n",
       "      <td>259602.890625</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-2.246785e-06</td>\n",
       "      <td>1.121911e-02</td>\n",
       "      <td>-2.002640e-04</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>67.755661</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>5988.484863</td>\n",
       "      <td>75500.585938</td>\n",
       "      <td>2.094308e+11</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>50.332382</td>\n",
       "      <td>3.149825e-04</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>2.998650</td>\n",
       "      <td>39.977539</td>\n",
       "      <td>143.992401</td>\n",
       "      <td>207.992676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>60.991867</td>\n",
       "      <td>277887.031250</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>-2.877171e-05</td>\n",
       "      <td>-1.678354e-01</td>\n",
       "      <td>-2.877171e+07</td>\n",
       "      <td>0.015919</td>\n",
       "      <td>72.527573</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>4556.131348</td>\n",
       "      <td>52136.453125</td>\n",
       "      <td>8.914959e+10</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>53.017929</td>\n",
       "      <td>6.087371e-04</td>\n",
       "      <td>0.676636</td>\n",
       "      <td>3.275024</td>\n",
       "      <td>39.989685</td>\n",
       "      <td>144.148438</td>\n",
       "      <td>224.012817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.234421</td>\n",
       "      <td>275242.437500</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>6.647404e-06</td>\n",
       "      <td>-2.566931e-02</td>\n",
       "      <td>6.647404e+06</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>71.837524</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>6366.280273</td>\n",
       "      <td>83311.023438</td>\n",
       "      <td>2.426508e+11</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>448.036133</td>\n",
       "      <td>54.482510</td>\n",
       "      <td>3.576197e-07</td>\n",
       "      <td>0.751625</td>\n",
       "      <td>3.751640</td>\n",
       "      <td>43.987427</td>\n",
       "      <td>144.005005</td>\n",
       "      <td>208.004181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.597591</td>\n",
       "      <td>183532.031250</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>-1.887155e-05</td>\n",
       "      <td>5.164166e-02</td>\n",
       "      <td>-3.654328e-04</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>90.323662</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>3855.910156</td>\n",
       "      <td>38593.156250</td>\n",
       "      <td>9.370838e+09</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>448.096680</td>\n",
       "      <td>67.729317</td>\n",
       "      <td>-1.948271e-04</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>4.023926</td>\n",
       "      <td>51.974976</td>\n",
       "      <td>191.986206</td>\n",
       "      <td>256.002899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>57.733204</td>\n",
       "      <td>339363.062500</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.106712e-06</td>\n",
       "      <td>2.848307e-02</td>\n",
       "      <td>1.090722e-04</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>102.275108</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>5878.126953</td>\n",
       "      <td>103989.742188</td>\n",
       "      <td>2.145388e+11</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>448.060059</td>\n",
       "      <td>80.500168</td>\n",
       "      <td>-2.287797e-04</td>\n",
       "      <td>1.240295</td>\n",
       "      <td>6.008118</td>\n",
       "      <td>64.011169</td>\n",
       "      <td>207.988342</td>\n",
       "      <td>287.973877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>33.904938</td>\n",
       "      <td>19.602224</td>\n",
       "      <td>1.729648</td>\n",
       "      <td>-1.243669e-04</td>\n",
       "      <td>-1.508405e-05</td>\n",
       "      <td>-1.243669e+08</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>1.729627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>1.153161</td>\n",
       "      <td>6.369375</td>\n",
       "      <td>1.516401e+06</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.389984</td>\n",
       "      <td>0.022817</td>\n",
       "      <td>4.758421e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.075806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.071590</td>\n",
       "      <td>254212.046875</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-5.526402e-08</td>\n",
       "      <td>-4.684624e-03</td>\n",
       "      <td>-5.526402e+04</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>66.348656</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>5640.184570</td>\n",
       "      <td>84146.710938</td>\n",
       "      <td>1.713525e+11</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>448.035889</td>\n",
       "      <td>48.836674</td>\n",
       "      <td>-6.697464e-04</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>2.764221</td>\n",
       "      <td>36.002304</td>\n",
       "      <td>143.984741</td>\n",
       "      <td>207.985535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>64.227753</td>\n",
       "      <td>278233.968750</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-3.936243e-05</td>\n",
       "      <td>-2.186561e-01</td>\n",
       "      <td>-3.936243e+07</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>72.617989</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>4331.990234</td>\n",
       "      <td>46617.175781</td>\n",
       "      <td>2.411210e+10</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>448.094238</td>\n",
       "      <td>53.295658</td>\n",
       "      <td>-2.178474e-04</td>\n",
       "      <td>0.683075</td>\n",
       "      <td>3.478271</td>\n",
       "      <td>39.994385</td>\n",
       "      <td>144.045410</td>\n",
       "      <td>224.008850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.738163</td>\n",
       "      <td>279941.000000</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-1.128455e-06</td>\n",
       "      <td>-1.713091e-02</td>\n",
       "      <td>-1.128455e+06</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>73.063843</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>6120.513184</td>\n",
       "      <td>63511.289062</td>\n",
       "      <td>6.052358e+10</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>55.354233</td>\n",
       "      <td>-1.234664e-04</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>3.763062</td>\n",
       "      <td>43.993744</td>\n",
       "      <td>144.010803</td>\n",
       "      <td>208.019897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.971287</td>\n",
       "      <td>165510.984375</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>1.439222e-05</td>\n",
       "      <td>-1.083697e-02</td>\n",
       "      <td>1.439222e+07</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>81.454781</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>3851.665283</td>\n",
       "      <td>63072.113281</td>\n",
       "      <td>5.975606e+10</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>448.182617</td>\n",
       "      <td>62.526688</td>\n",
       "      <td>-7.203819e-05</td>\n",
       "      <td>0.901611</td>\n",
       "      <td>4.501552</td>\n",
       "      <td>48.033936</td>\n",
       "      <td>160.017578</td>\n",
       "      <td>239.981079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>56.423298</td>\n",
       "      <td>324759.031250</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-6.326462e-06</td>\n",
       "      <td>-1.447186e-02</td>\n",
       "      <td>-6.326462e+06</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>97.873833</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>5755.760742</td>\n",
       "      <td>83934.046875</td>\n",
       "      <td>9.124578e+10</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>448.064941</td>\n",
       "      <td>75.822250</td>\n",
       "      <td>1.265295e-04</td>\n",
       "      <td>1.112183</td>\n",
       "      <td>5.495941</td>\n",
       "      <td>60.008240</td>\n",
       "      <td>192.019165</td>\n",
       "      <td>256.028564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>33.004986</td>\n",
       "      <td>20.246275</td>\n",
       "      <td>1.630176</td>\n",
       "      <td>-7.202942e-05</td>\n",
       "      <td>9.072167e-05</td>\n",
       "      <td>-7.939605e-01</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>1.630199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>1.173660</td>\n",
       "      <td>5.969302</td>\n",
       "      <td>2.051572e+05</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>-4.413895e-04</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.850452</td>\n",
       "      <td>248567.453125</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-1.933409e-06</td>\n",
       "      <td>7.639631e-03</td>\n",
       "      <td>-2.530763e-04</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>64.875435</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>5305.550781</td>\n",
       "      <td>52250.949219</td>\n",
       "      <td>2.228740e+10</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>448.056152</td>\n",
       "      <td>47.467190</td>\n",
       "      <td>-5.179914e-05</td>\n",
       "      <td>0.554565</td>\n",
       "      <td>2.748894</td>\n",
       "      <td>35.991272</td>\n",
       "      <td>128.015320</td>\n",
       "      <td>192.016602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>65.613007</td>\n",
       "      <td>278620.093750</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-4.827616e-05</td>\n",
       "      <td>1.218323e-01</td>\n",
       "      <td>-3.962510e-04</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>72.719002</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>4246.416016</td>\n",
       "      <td>56015.222656</td>\n",
       "      <td>6.911216e+10</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>53.671066</td>\n",
       "      <td>-4.600205e-05</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>3.496948</td>\n",
       "      <td>40.000343</td>\n",
       "      <td>144.031738</td>\n",
       "      <td>224.004028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.656509</td>\n",
       "      <td>268330.593750</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-4.617706e-06</td>\n",
       "      <td>4.263859e-03</td>\n",
       "      <td>-1.082987e-03</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>70.033562</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>5514.793457</td>\n",
       "      <td>63015.148438</td>\n",
       "      <td>1.628906e+11</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>53.023014</td>\n",
       "      <td>-2.049523e-04</td>\n",
       "      <td>0.740906</td>\n",
       "      <td>3.738159</td>\n",
       "      <td>40.012207</td>\n",
       "      <td>143.998077</td>\n",
       "      <td>207.997208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.285824</td>\n",
       "      <td>192984.609375</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>-3.834824e-06</td>\n",
       "      <td>1.003834e-01</td>\n",
       "      <td>-3.820178e-05</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>94.975632</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4563.813477</td>\n",
       "      <td>62297.203125</td>\n",
       "      <td>3.555635e+10</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>448.092285</td>\n",
       "      <td>74.100739</td>\n",
       "      <td>3.001667e-04</td>\n",
       "      <td>1.113342</td>\n",
       "      <td>5.498935</td>\n",
       "      <td>60.005157</td>\n",
       "      <td>191.996811</td>\n",
       "      <td>256.003357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>47.141296</td>\n",
       "      <td>278748.437500</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-6.660851e-06</td>\n",
       "      <td>1.602416e-02</td>\n",
       "      <td>-4.156755e-04</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>84.007454</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>5913.041504</td>\n",
       "      <td>297973.250000</td>\n",
       "      <td>2.363130e+12</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>448.046143</td>\n",
       "      <td>63.545689</td>\n",
       "      <td>3.565136e-04</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>4.491394</td>\n",
       "      <td>48.009338</td>\n",
       "      <td>175.995361</td>\n",
       "      <td>240.026001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>30.243559</td>\n",
       "      <td>21.967958</td>\n",
       "      <td>1.376712</td>\n",
       "      <td>-1.165403e-04</td>\n",
       "      <td>1.126568e-04</td>\n",
       "      <td>-1.034472e+00</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>1.376727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>1.235276</td>\n",
       "      <td>8.624231</td>\n",
       "      <td>2.912710e+06</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.394775</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>4.939766e-04</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.073364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.900597</td>\n",
       "      <td>232829.328125</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-1.224481e-07</td>\n",
       "      <td>1.516126e-02</td>\n",
       "      <td>-8.076385e-06</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>60.767826</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>4964.314941</td>\n",
       "      <td>48132.335938</td>\n",
       "      <td>2.871859e+10</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>448.206055</td>\n",
       "      <td>44.010178</td>\n",
       "      <td>1.326976e-04</td>\n",
       "      <td>0.524170</td>\n",
       "      <td>2.735413</td>\n",
       "      <td>31.995209</td>\n",
       "      <td>127.991577</td>\n",
       "      <td>192.002243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>66.756119</td>\n",
       "      <td>253401.437500</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-6.539675e-05</td>\n",
       "      <td>1.408842e-01</td>\n",
       "      <td>-4.641880e-04</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>66.136940</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>3795.928711</td>\n",
       "      <td>54383.152344</td>\n",
       "      <td>7.626670e+10</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>48.809811</td>\n",
       "      <td>-2.693519e-04</td>\n",
       "      <td>0.635498</td>\n",
       "      <td>3.244934</td>\n",
       "      <td>36.005493</td>\n",
       "      <td>143.972412</td>\n",
       "      <td>207.995544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.777443</td>\n",
       "      <td>239059.500000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-2.859583e-06</td>\n",
       "      <td>-4.252552e-03</td>\n",
       "      <td>-2.859583e+06</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>62.393883</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>4901.025879</td>\n",
       "      <td>75714.164062</td>\n",
       "      <td>2.429860e+11</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>448.069824</td>\n",
       "      <td>46.818249</td>\n",
       "      <td>2.533953e-04</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>3.253448</td>\n",
       "      <td>36.003189</td>\n",
       "      <td>127.987244</td>\n",
       "      <td>191.994110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.823463</td>\n",
       "      <td>166728.703125</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>1.387867e-06</td>\n",
       "      <td>5.260651e-02</td>\n",
       "      <td>2.638203e-05</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>82.054054</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>3414.929932</td>\n",
       "      <td>30536.048828</td>\n",
       "      <td>3.031742e+09</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>448.095215</td>\n",
       "      <td>62.006210</td>\n",
       "      <td>2.690325e-04</td>\n",
       "      <td>0.843506</td>\n",
       "      <td>4.031494</td>\n",
       "      <td>47.995789</td>\n",
       "      <td>175.967529</td>\n",
       "      <td>240.002502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.075577</td>\n",
       "      <td>329189.125000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.281977e-07</td>\n",
       "      <td>-3.920203e-02</td>\n",
       "      <td>-3.281977e+05</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>99.208954</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>5572.338867</td>\n",
       "      <td>61945.824219</td>\n",
       "      <td>3.524076e+10</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>448.061035</td>\n",
       "      <td>77.599541</td>\n",
       "      <td>3.124934e-04</td>\n",
       "      <td>1.134583</td>\n",
       "      <td>5.964355</td>\n",
       "      <td>63.988464</td>\n",
       "      <td>192.023682</td>\n",
       "      <td>256.024170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>29.131956</td>\n",
       "      <td>29.370396</td>\n",
       "      <td>0.991882</td>\n",
       "      <td>-8.851806e-05</td>\n",
       "      <td>2.514182e-04</td>\n",
       "      <td>-3.520750e-01</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.991940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002488</td>\n",
       "      <td>1.421778</td>\n",
       "      <td>11.759218</td>\n",
       "      <td>2.415468e+06</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>0.530273</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>-3.187038e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.158073</td>\n",
       "      <td>202610.562500</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-5.081034e-06</td>\n",
       "      <td>-2.179184e-02</td>\n",
       "      <td>-5.081034e+06</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>52.880806</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>4389.493652</td>\n",
       "      <td>47949.730469</td>\n",
       "      <td>3.665039e+10</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>448.048584</td>\n",
       "      <td>35.982563</td>\n",
       "      <td>-1.557488e-04</td>\n",
       "      <td>0.349304</td>\n",
       "      <td>1.750744</td>\n",
       "      <td>23.991455</td>\n",
       "      <td>112.002792</td>\n",
       "      <td>176.009033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>64.730461</td>\n",
       "      <td>255341.218750</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-7.044782e-05</td>\n",
       "      <td>1.505888e-02</td>\n",
       "      <td>-4.678158e-03</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>66.643372</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>3944.684326</td>\n",
       "      <td>49669.804688</td>\n",
       "      <td>4.712193e+10</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>448.062500</td>\n",
       "      <td>49.567970</td>\n",
       "      <td>5.894285e-05</td>\n",
       "      <td>0.676636</td>\n",
       "      <td>3.275879</td>\n",
       "      <td>36.020386</td>\n",
       "      <td>143.978149</td>\n",
       "      <td>207.992828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>50.728722</td>\n",
       "      <td>222510.703125</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>4.082678e-07</td>\n",
       "      <td>1.042032e-02</td>\n",
       "      <td>3.917998e-05</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>58.074692</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>4386.286621</td>\n",
       "      <td>63520.992188</td>\n",
       "      <td>2.883965e+11</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>42.034321</td>\n",
       "      <td>-2.670212e-05</td>\n",
       "      <td>0.566742</td>\n",
       "      <td>2.766113</td>\n",
       "      <td>31.987305</td>\n",
       "      <td>119.986084</td>\n",
       "      <td>192.002914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.286278</td>\n",
       "      <td>185368.171875</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.049011e-05</td>\n",
       "      <td>2.346013e-02</td>\n",
       "      <td>4.471461e-04</td>\n",
       "      <td>0.023272</td>\n",
       "      <td>91.227325</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>3920.126709</td>\n",
       "      <td>53168.152344</td>\n",
       "      <td>4.398046e+10</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>448.095215</td>\n",
       "      <td>70.598984</td>\n",
       "      <td>2.658626e-06</td>\n",
       "      <td>1.008301</td>\n",
       "      <td>5.012756</td>\n",
       "      <td>56.009583</td>\n",
       "      <td>191.912109</td>\n",
       "      <td>255.989136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>56.993889</td>\n",
       "      <td>261524.468750</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>4.304269e-06</td>\n",
       "      <td>-2.489731e-02</td>\n",
       "      <td>4.304268e+06</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>78.816605</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>4588.641113</td>\n",
       "      <td>50657.347656</td>\n",
       "      <td>2.971653e+10</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>58.154953</td>\n",
       "      <td>-8.692507e-05</td>\n",
       "      <td>0.739685</td>\n",
       "      <td>3.735413</td>\n",
       "      <td>43.985229</td>\n",
       "      <td>160.017212</td>\n",
       "      <td>240.000900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer                                                  key  \\\n",
       "1        0                  model.layers.0.mlp.down_proj.weight   \n",
       "2        0                  model.layers.0.mlp.gate_proj.weight   \n",
       "3        0                    model.layers.0.mlp.up_proj.weight   \n",
       "6        0   model.layers.0.self_attn.kv_a_proj_with_mqa.weight   \n",
       "7        0            model.layers.0.self_attn.kv_b_proj.weight   \n",
       "8        0               model.layers.0.self_attn.o_proj.weight   \n",
       "10       0             model.layers.0.self_attn.q_a_proj.weight   \n",
       "11       0             model.layers.0.self_attn.q_b_proj.weight   \n",
       "13       1                  model.layers.1.mlp.down_proj.weight   \n",
       "14       1                  model.layers.1.mlp.gate_proj.weight   \n",
       "15       1                    model.layers.1.mlp.up_proj.weight   \n",
       "18       1   model.layers.1.self_attn.kv_a_proj_with_mqa.weight   \n",
       "19       1            model.layers.1.self_attn.kv_b_proj.weight   \n",
       "20       1               model.layers.1.self_attn.o_proj.weight   \n",
       "22       1             model.layers.1.self_attn.q_a_proj.weight   \n",
       "23       1             model.layers.1.self_attn.q_b_proj.weight   \n",
       "25       2                  model.layers.2.mlp.down_proj.weight   \n",
       "26       2                  model.layers.2.mlp.gate_proj.weight   \n",
       "27       2                    model.layers.2.mlp.up_proj.weight   \n",
       "30       2   model.layers.2.self_attn.kv_a_proj_with_mqa.weight   \n",
       "31       2            model.layers.2.self_attn.kv_b_proj.weight   \n",
       "32       2               model.layers.2.self_attn.o_proj.weight   \n",
       "34       2             model.layers.2.self_attn.q_a_proj.weight   \n",
       "35       2             model.layers.2.self_attn.q_b_proj.weight   \n",
       "38       3                       model.layers.3.mlp.gate.weight   \n",
       "39       3   model.layers.3.mlp.shared_experts.down_proj.weight   \n",
       "40       3   model.layers.3.mlp.shared_experts.gate_proj.weight   \n",
       "41       3     model.layers.3.mlp.shared_experts.up_proj.weight   \n",
       "44       3   model.layers.3.self_attn.kv_a_proj_with_mqa.weight   \n",
       "45       3            model.layers.3.self_attn.kv_b_proj.weight   \n",
       "46       3               model.layers.3.self_attn.o_proj.weight   \n",
       "48       3             model.layers.3.self_attn.q_a_proj.weight   \n",
       "49       3             model.layers.3.self_attn.q_b_proj.weight   \n",
       "52       4                       model.layers.4.mlp.gate.weight   \n",
       "53       4   model.layers.4.mlp.shared_experts.down_proj.weight   \n",
       "54       4   model.layers.4.mlp.shared_experts.gate_proj.weight   \n",
       "55       4     model.layers.4.mlp.shared_experts.up_proj.weight   \n",
       "58       4   model.layers.4.self_attn.kv_a_proj_with_mqa.weight   \n",
       "59       4            model.layers.4.self_attn.kv_b_proj.weight   \n",
       "60       4               model.layers.4.self_attn.o_proj.weight   \n",
       "62       4             model.layers.4.self_attn.q_a_proj.weight   \n",
       "63       4             model.layers.4.self_attn.q_b_proj.weight   \n",
       "66       5                       model.layers.5.mlp.gate.weight   \n",
       "67       5   model.layers.5.mlp.shared_experts.down_proj.weight   \n",
       "68       5   model.layers.5.mlp.shared_experts.gate_proj.weight   \n",
       "69       5     model.layers.5.mlp.shared_experts.up_proj.weight   \n",
       "72       5   model.layers.5.self_attn.kv_a_proj_with_mqa.weight   \n",
       "73       5            model.layers.5.self_attn.kv_b_proj.weight   \n",
       "74       5               model.layers.5.self_attn.o_proj.weight   \n",
       "76       5             model.layers.5.self_attn.q_a_proj.weight   \n",
       "77       5             model.layers.5.self_attn.q_b_proj.weight   \n",
       "80       6                       model.layers.6.mlp.gate.weight   \n",
       "81       6   model.layers.6.mlp.shared_experts.down_proj.weight   \n",
       "82       6   model.layers.6.mlp.shared_experts.gate_proj.weight   \n",
       "83       6     model.layers.6.mlp.shared_experts.up_proj.weight   \n",
       "86       6   model.layers.6.self_attn.kv_a_proj_with_mqa.weight   \n",
       "87       6            model.layers.6.self_attn.kv_b_proj.weight   \n",
       "88       6               model.layers.6.self_attn.o_proj.weight   \n",
       "90       6             model.layers.6.self_attn.q_a_proj.weight   \n",
       "91       6             model.layers.6.self_attn.q_b_proj.weight   \n",
       "94       7                       model.layers.7.mlp.gate.weight   \n",
       "95       7   model.layers.7.mlp.shared_experts.down_proj.weight   \n",
       "96       7   model.layers.7.mlp.shared_experts.gate_proj.weight   \n",
       "97       7     model.layers.7.mlp.shared_experts.up_proj.weight   \n",
       "100      7   model.layers.7.self_attn.kv_a_proj_with_mqa.weight   \n",
       "101      7            model.layers.7.self_attn.kv_b_proj.weight   \n",
       "102      7               model.layers.7.self_attn.o_proj.weight   \n",
       "104      7             model.layers.7.self_attn.q_a_proj.weight   \n",
       "105      7             model.layers.7.self_attn.q_b_proj.weight   \n",
       "108      8                       model.layers.8.mlp.gate.weight   \n",
       "109      8   model.layers.8.mlp.shared_experts.down_proj.weight   \n",
       "110      8   model.layers.8.mlp.shared_experts.gate_proj.weight   \n",
       "111      8     model.layers.8.mlp.shared_experts.up_proj.weight   \n",
       "114      8   model.layers.8.self_attn.kv_a_proj_with_mqa.weight   \n",
       "115      8            model.layers.8.self_attn.kv_b_proj.weight   \n",
       "116      8               model.layers.8.self_attn.o_proj.weight   \n",
       "118      8             model.layers.8.self_attn.q_a_proj.weight   \n",
       "119      8             model.layers.8.self_attn.q_b_proj.weight   \n",
       "122      9                       model.layers.9.mlp.gate.weight   \n",
       "123      9   model.layers.9.mlp.shared_experts.down_proj.weight   \n",
       "124      9   model.layers.9.mlp.shared_experts.gate_proj.weight   \n",
       "125      9     model.layers.9.mlp.shared_experts.up_proj.weight   \n",
       "128      9   model.layers.9.self_attn.kv_a_proj_with_mqa.weight   \n",
       "129      9            model.layers.9.self_attn.kv_b_proj.weight   \n",
       "130      9               model.layers.9.self_attn.o_proj.weight   \n",
       "132      9             model.layers.9.self_attn.q_a_proj.weight   \n",
       "133      9             model.layers.9.self_attn.q_b_proj.weight   \n",
       "136     10                      model.layers.10.mlp.gate.weight   \n",
       "137     10  model.layers.10.mlp.shared_experts.down_proj.weight   \n",
       "138     10  model.layers.10.mlp.shared_experts.gate_proj.weight   \n",
       "139     10    model.layers.10.mlp.shared_experts.up_proj.weight   \n",
       "142     10  model.layers.10.self_attn.kv_a_proj_with_mqa.weight   \n",
       "143     10           model.layers.10.self_attn.kv_b_proj.weight   \n",
       "144     10              model.layers.10.self_attn.o_proj.weight   \n",
       "146     10            model.layers.10.self_attn.q_a_proj.weight   \n",
       "147     10            model.layers.10.self_attn.q_b_proj.weight   \n",
       "150     11                      model.layers.11.mlp.gate.weight   \n",
       "151     11  model.layers.11.mlp.shared_experts.down_proj.weight   \n",
       "152     11  model.layers.11.mlp.shared_experts.gate_proj.weight   \n",
       "153     11    model.layers.11.mlp.shared_experts.up_proj.weight   \n",
       "156     11  model.layers.11.self_attn.kv_a_proj_with_mqa.weight   \n",
       "157     11           model.layers.11.self_attn.kv_b_proj.weight   \n",
       "158     11              model.layers.11.self_attn.o_proj.weight   \n",
       "160     11            model.layers.11.self_attn.q_a_proj.weight   \n",
       "161     11            model.layers.11.self_attn.q_b_proj.weight   \n",
       "164     12                      model.layers.12.mlp.gate.weight   \n",
       "165     12  model.layers.12.mlp.shared_experts.down_proj.weight   \n",
       "166     12  model.layers.12.mlp.shared_experts.gate_proj.weight   \n",
       "167     12    model.layers.12.mlp.shared_experts.up_proj.weight   \n",
       "170     12  model.layers.12.self_attn.kv_a_proj_with_mqa.weight   \n",
       "171     12           model.layers.12.self_attn.kv_b_proj.weight   \n",
       "172     12              model.layers.12.self_attn.o_proj.weight   \n",
       "174     12            model.layers.12.self_attn.q_a_proj.weight   \n",
       "175     12            model.layers.12.self_attn.q_b_proj.weight   \n",
       "178     13                      model.layers.13.mlp.gate.weight   \n",
       "179     13  model.layers.13.mlp.shared_experts.down_proj.weight   \n",
       "180     13  model.layers.13.mlp.shared_experts.gate_proj.weight   \n",
       "181     13    model.layers.13.mlp.shared_experts.up_proj.weight   \n",
       "184     13  model.layers.13.self_attn.kv_a_proj_with_mqa.weight   \n",
       "185     13           model.layers.13.self_attn.kv_b_proj.weight   \n",
       "186     13              model.layers.13.self_attn.o_proj.weight   \n",
       "188     13            model.layers.13.self_attn.q_a_proj.weight   \n",
       "189     13            model.layers.13.self_attn.q_b_proj.weight   \n",
       "192     14                      model.layers.14.mlp.gate.weight   \n",
       "193     14  model.layers.14.mlp.shared_experts.down_proj.weight   \n",
       "194     14  model.layers.14.mlp.shared_experts.gate_proj.weight   \n",
       "195     14    model.layers.14.mlp.shared_experts.up_proj.weight   \n",
       "198     14  model.layers.14.self_attn.kv_a_proj_with_mqa.weight   \n",
       "199     14           model.layers.14.self_attn.kv_b_proj.weight   \n",
       "200     14              model.layers.14.self_attn.o_proj.weight   \n",
       "202     14            model.layers.14.self_attn.q_a_proj.weight   \n",
       "203     14            model.layers.14.self_attn.q_b_proj.weight   \n",
       "206     15                      model.layers.15.mlp.gate.weight   \n",
       "207     15  model.layers.15.mlp.shared_experts.down_proj.weight   \n",
       "208     15  model.layers.15.mlp.shared_experts.gate_proj.weight   \n",
       "209     15    model.layers.15.mlp.shared_experts.up_proj.weight   \n",
       "212     15  model.layers.15.self_attn.kv_a_proj_with_mqa.weight   \n",
       "213     15           model.layers.15.self_attn.kv_b_proj.weight   \n",
       "214     15              model.layers.15.self_attn.o_proj.weight   \n",
       "216     15            model.layers.15.self_attn.q_a_proj.weight   \n",
       "217     15            model.layers.15.self_attn.q_b_proj.weight   \n",
       "220     16                      model.layers.16.mlp.gate.weight   \n",
       "221     16  model.layers.16.mlp.shared_experts.down_proj.weight   \n",
       "222     16  model.layers.16.mlp.shared_experts.gate_proj.weight   \n",
       "223     16    model.layers.16.mlp.shared_experts.up_proj.weight   \n",
       "226     16  model.layers.16.self_attn.kv_a_proj_with_mqa.weight   \n",
       "227     16           model.layers.16.self_attn.kv_b_proj.weight   \n",
       "228     16              model.layers.16.self_attn.o_proj.weight   \n",
       "230     16            model.layers.16.self_attn.q_a_proj.weight   \n",
       "231     16            model.layers.16.self_attn.q_b_proj.weight   \n",
       "234     17                      model.layers.17.mlp.gate.weight   \n",
       "235     17  model.layers.17.mlp.shared_experts.down_proj.weight   \n",
       "236     17  model.layers.17.mlp.shared_experts.gate_proj.weight   \n",
       "237     17    model.layers.17.mlp.shared_experts.up_proj.weight   \n",
       "240     17  model.layers.17.self_attn.kv_a_proj_with_mqa.weight   \n",
       "241     17           model.layers.17.self_attn.kv_b_proj.weight   \n",
       "242     17              model.layers.17.self_attn.o_proj.weight   \n",
       "244     17            model.layers.17.self_attn.q_a_proj.weight   \n",
       "245     17            model.layers.17.self_attn.q_b_proj.weight   \n",
       "248     18                      model.layers.18.mlp.gate.weight   \n",
       "249     18  model.layers.18.mlp.shared_experts.down_proj.weight   \n",
       "250     18  model.layers.18.mlp.shared_experts.gate_proj.weight   \n",
       "251     18    model.layers.18.mlp.shared_experts.up_proj.weight   \n",
       "254     18  model.layers.18.self_attn.kv_a_proj_with_mqa.weight   \n",
       "255     18           model.layers.18.self_attn.kv_b_proj.weight   \n",
       "256     18              model.layers.18.self_attn.o_proj.weight   \n",
       "258     18            model.layers.18.self_attn.q_a_proj.weight   \n",
       "259     18            model.layers.18.self_attn.q_b_proj.weight   \n",
       "262     19                      model.layers.19.mlp.gate.weight   \n",
       "263     19  model.layers.19.mlp.shared_experts.down_proj.weight   \n",
       "264     19  model.layers.19.mlp.shared_experts.gate_proj.weight   \n",
       "265     19    model.layers.19.mlp.shared_experts.up_proj.weight   \n",
       "268     19  model.layers.19.self_attn.kv_a_proj_with_mqa.weight   \n",
       "269     19           model.layers.19.self_attn.kv_b_proj.weight   \n",
       "270     19              model.layers.19.self_attn.o_proj.weight   \n",
       "272     19            model.layers.19.self_attn.q_a_proj.weight   \n",
       "273     19            model.layers.19.self_attn.q_b_proj.weight   \n",
       "276     20                      model.layers.20.mlp.gate.weight   \n",
       "277     20  model.layers.20.mlp.shared_experts.down_proj.weight   \n",
       "278     20  model.layers.20.mlp.shared_experts.gate_proj.weight   \n",
       "279     20    model.layers.20.mlp.shared_experts.up_proj.weight   \n",
       "282     20  model.layers.20.self_attn.kv_a_proj_with_mqa.weight   \n",
       "283     20           model.layers.20.self_attn.kv_b_proj.weight   \n",
       "284     20              model.layers.20.self_attn.o_proj.weight   \n",
       "286     20            model.layers.20.self_attn.q_a_proj.weight   \n",
       "287     20            model.layers.20.self_attn.q_b_proj.weight   \n",
       "290     21                      model.layers.21.mlp.gate.weight   \n",
       "291     21  model.layers.21.mlp.shared_experts.down_proj.weight   \n",
       "292     21  model.layers.21.mlp.shared_experts.gate_proj.weight   \n",
       "293     21    model.layers.21.mlp.shared_experts.up_proj.weight   \n",
       "296     21  model.layers.21.self_attn.kv_a_proj_with_mqa.weight   \n",
       "297     21           model.layers.21.self_attn.kv_b_proj.weight   \n",
       "298     21              model.layers.21.self_attn.o_proj.weight   \n",
       "300     21            model.layers.21.self_attn.q_a_proj.weight   \n",
       "301     21            model.layers.21.self_attn.q_b_proj.weight   \n",
       "304     22                      model.layers.22.mlp.gate.weight   \n",
       "305     22  model.layers.22.mlp.shared_experts.down_proj.weight   \n",
       "306     22  model.layers.22.mlp.shared_experts.gate_proj.weight   \n",
       "307     22    model.layers.22.mlp.shared_experts.up_proj.weight   \n",
       "310     22  model.layers.22.self_attn.kv_a_proj_with_mqa.weight   \n",
       "311     22           model.layers.22.self_attn.kv_b_proj.weight   \n",
       "312     22              model.layers.22.self_attn.o_proj.weight   \n",
       "314     22            model.layers.22.self_attn.q_a_proj.weight   \n",
       "315     22            model.layers.22.self_attn.q_b_proj.weight   \n",
       "318     23                      model.layers.23.mlp.gate.weight   \n",
       "319     23  model.layers.23.mlp.shared_experts.down_proj.weight   \n",
       "320     23  model.layers.23.mlp.shared_experts.gate_proj.weight   \n",
       "321     23    model.layers.23.mlp.shared_experts.up_proj.weight   \n",
       "324     23  model.layers.23.self_attn.kv_a_proj_with_mqa.weight   \n",
       "325     23           model.layers.23.self_attn.kv_b_proj.weight   \n",
       "326     23              model.layers.23.self_attn.o_proj.weight   \n",
       "328     23            model.layers.23.self_attn.q_a_proj.weight   \n",
       "329     23            model.layers.23.self_attn.q_b_proj.weight   \n",
       "332     24                      model.layers.24.mlp.gate.weight   \n",
       "333     24  model.layers.24.mlp.shared_experts.down_proj.weight   \n",
       "334     24  model.layers.24.mlp.shared_experts.gate_proj.weight   \n",
       "335     24    model.layers.24.mlp.shared_experts.up_proj.weight   \n",
       "338     24  model.layers.24.self_attn.kv_a_proj_with_mqa.weight   \n",
       "339     24           model.layers.24.self_attn.kv_b_proj.weight   \n",
       "340     24              model.layers.24.self_attn.o_proj.weight   \n",
       "342     24            model.layers.24.self_attn.q_a_proj.weight   \n",
       "343     24            model.layers.24.self_attn.q_b_proj.weight   \n",
       "346     25                      model.layers.25.mlp.gate.weight   \n",
       "347     25  model.layers.25.mlp.shared_experts.down_proj.weight   \n",
       "348     25  model.layers.25.mlp.shared_experts.gate_proj.weight   \n",
       "349     25    model.layers.25.mlp.shared_experts.up_proj.weight   \n",
       "352     25  model.layers.25.self_attn.kv_a_proj_with_mqa.weight   \n",
       "353     25           model.layers.25.self_attn.kv_b_proj.weight   \n",
       "354     25              model.layers.25.self_attn.o_proj.weight   \n",
       "356     25            model.layers.25.self_attn.q_a_proj.weight   \n",
       "357     25            model.layers.25.self_attn.q_b_proj.weight   \n",
       "360     26                      model.layers.26.mlp.gate.weight   \n",
       "361     26  model.layers.26.mlp.shared_experts.down_proj.weight   \n",
       "362     26  model.layers.26.mlp.shared_experts.gate_proj.weight   \n",
       "363     26    model.layers.26.mlp.shared_experts.up_proj.weight   \n",
       "366     26  model.layers.26.self_attn.kv_a_proj_with_mqa.weight   \n",
       "367     26           model.layers.26.self_attn.kv_b_proj.weight   \n",
       "368     26              model.layers.26.self_attn.o_proj.weight   \n",
       "370     26            model.layers.26.self_attn.q_a_proj.weight   \n",
       "371     26            model.layers.26.self_attn.q_b_proj.weight   \n",
       "374     27                      model.layers.27.mlp.gate.weight   \n",
       "375     27  model.layers.27.mlp.shared_experts.down_proj.weight   \n",
       "376     27  model.layers.27.mlp.shared_experts.gate_proj.weight   \n",
       "377     27    model.layers.27.mlp.shared_experts.up_proj.weight   \n",
       "380     27  model.layers.27.self_attn.kv_a_proj_with_mqa.weight   \n",
       "381     27           model.layers.27.self_attn.kv_b_proj.weight   \n",
       "382     27              model.layers.27.self_attn.o_proj.weight   \n",
       "384     27            model.layers.27.self_attn.q_a_proj.weight   \n",
       "385     27            model.layers.27.self_attn.q_b_proj.weight   \n",
       "388     28                      model.layers.28.mlp.gate.weight   \n",
       "389     28  model.layers.28.mlp.shared_experts.down_proj.weight   \n",
       "390     28  model.layers.28.mlp.shared_experts.gate_proj.weight   \n",
       "391     28    model.layers.28.mlp.shared_experts.up_proj.weight   \n",
       "394     28  model.layers.28.self_attn.kv_a_proj_with_mqa.weight   \n",
       "395     28           model.layers.28.self_attn.kv_b_proj.weight   \n",
       "396     28              model.layers.28.self_attn.o_proj.weight   \n",
       "398     28            model.layers.28.self_attn.q_a_proj.weight   \n",
       "399     28            model.layers.28.self_attn.q_b_proj.weight   \n",
       "402     29                      model.layers.29.mlp.gate.weight   \n",
       "403     29  model.layers.29.mlp.shared_experts.down_proj.weight   \n",
       "404     29  model.layers.29.mlp.shared_experts.gate_proj.weight   \n",
       "405     29    model.layers.29.mlp.shared_experts.up_proj.weight   \n",
       "408     29  model.layers.29.self_attn.kv_a_proj_with_mqa.weight   \n",
       "409     29           model.layers.29.self_attn.kv_b_proj.weight   \n",
       "410     29              model.layers.29.self_attn.o_proj.weight   \n",
       "412     29            model.layers.29.self_attn.q_a_proj.weight   \n",
       "413     29            model.layers.29.self_attn.q_b_proj.weight   \n",
       "416     30                      model.layers.30.mlp.gate.weight   \n",
       "417     30  model.layers.30.mlp.shared_experts.down_proj.weight   \n",
       "418     30  model.layers.30.mlp.shared_experts.gate_proj.weight   \n",
       "419     30    model.layers.30.mlp.shared_experts.up_proj.weight   \n",
       "422     30  model.layers.30.self_attn.kv_a_proj_with_mqa.weight   \n",
       "423     30           model.layers.30.self_attn.kv_b_proj.weight   \n",
       "424     30              model.layers.30.self_attn.o_proj.weight   \n",
       "426     30            model.layers.30.self_attn.q_a_proj.weight   \n",
       "427     30            model.layers.30.self_attn.q_b_proj.weight   \n",
       "430     31                      model.layers.31.mlp.gate.weight   \n",
       "431     31  model.layers.31.mlp.shared_experts.down_proj.weight   \n",
       "432     31  model.layers.31.mlp.shared_experts.gate_proj.weight   \n",
       "433     31    model.layers.31.mlp.shared_experts.up_proj.weight   \n",
       "436     31  model.layers.31.self_attn.kv_a_proj_with_mqa.weight   \n",
       "437     31           model.layers.31.self_attn.kv_b_proj.weight   \n",
       "438     31              model.layers.31.self_attn.o_proj.weight   \n",
       "440     31            model.layers.31.self_attn.q_a_proj.weight   \n",
       "441     31            model.layers.31.self_attn.q_b_proj.weight   \n",
       "444     32                      model.layers.32.mlp.gate.weight   \n",
       "445     32  model.layers.32.mlp.shared_experts.down_proj.weight   \n",
       "446     32  model.layers.32.mlp.shared_experts.gate_proj.weight   \n",
       "447     32    model.layers.32.mlp.shared_experts.up_proj.weight   \n",
       "450     32  model.layers.32.self_attn.kv_a_proj_with_mqa.weight   \n",
       "451     32           model.layers.32.self_attn.kv_b_proj.weight   \n",
       "452     32              model.layers.32.self_attn.o_proj.weight   \n",
       "454     32            model.layers.32.self_attn.q_a_proj.weight   \n",
       "455     32            model.layers.32.self_attn.q_b_proj.weight   \n",
       "458     33                      model.layers.33.mlp.gate.weight   \n",
       "459     33  model.layers.33.mlp.shared_experts.down_proj.weight   \n",
       "460     33  model.layers.33.mlp.shared_experts.gate_proj.weight   \n",
       "461     33    model.layers.33.mlp.shared_experts.up_proj.weight   \n",
       "464     33  model.layers.33.self_attn.kv_a_proj_with_mqa.weight   \n",
       "465     33           model.layers.33.self_attn.kv_b_proj.weight   \n",
       "466     33              model.layers.33.self_attn.o_proj.weight   \n",
       "468     33            model.layers.33.self_attn.q_a_proj.weight   \n",
       "469     33            model.layers.33.self_attn.q_b_proj.weight   \n",
       "472     34                      model.layers.34.mlp.gate.weight   \n",
       "473     34  model.layers.34.mlp.shared_experts.down_proj.weight   \n",
       "474     34  model.layers.34.mlp.shared_experts.gate_proj.weight   \n",
       "475     34    model.layers.34.mlp.shared_experts.up_proj.weight   \n",
       "478     34  model.layers.34.self_attn.kv_a_proj_with_mqa.weight   \n",
       "479     34           model.layers.34.self_attn.kv_b_proj.weight   \n",
       "480     34              model.layers.34.self_attn.o_proj.weight   \n",
       "482     34            model.layers.34.self_attn.q_a_proj.weight   \n",
       "483     34            model.layers.34.self_attn.q_b_proj.weight   \n",
       "486     35                      model.layers.35.mlp.gate.weight   \n",
       "487     35  model.layers.35.mlp.shared_experts.down_proj.weight   \n",
       "488     35  model.layers.35.mlp.shared_experts.gate_proj.weight   \n",
       "489     35    model.layers.35.mlp.shared_experts.up_proj.weight   \n",
       "492     35  model.layers.35.self_attn.kv_a_proj_with_mqa.weight   \n",
       "493     35           model.layers.35.self_attn.kv_b_proj.weight   \n",
       "494     35              model.layers.35.self_attn.o_proj.weight   \n",
       "496     35            model.layers.35.self_attn.q_a_proj.weight   \n",
       "497     35            model.layers.35.self_attn.q_b_proj.weight   \n",
       "500     36                      model.layers.36.mlp.gate.weight   \n",
       "501     36  model.layers.36.mlp.shared_experts.down_proj.weight   \n",
       "502     36  model.layers.36.mlp.shared_experts.gate_proj.weight   \n",
       "503     36    model.layers.36.mlp.shared_experts.up_proj.weight   \n",
       "506     36  model.layers.36.self_attn.kv_a_proj_with_mqa.weight   \n",
       "507     36           model.layers.36.self_attn.kv_b_proj.weight   \n",
       "508     36              model.layers.36.self_attn.o_proj.weight   \n",
       "510     36            model.layers.36.self_attn.q_a_proj.weight   \n",
       "511     36            model.layers.36.self_attn.q_b_proj.weight   \n",
       "514     37                      model.layers.37.mlp.gate.weight   \n",
       "515     37  model.layers.37.mlp.shared_experts.down_proj.weight   \n",
       "516     37  model.layers.37.mlp.shared_experts.gate_proj.weight   \n",
       "517     37    model.layers.37.mlp.shared_experts.up_proj.weight   \n",
       "520     37  model.layers.37.self_attn.kv_a_proj_with_mqa.weight   \n",
       "521     37           model.layers.37.self_attn.kv_b_proj.weight   \n",
       "522     37              model.layers.37.self_attn.o_proj.weight   \n",
       "524     37            model.layers.37.self_attn.q_a_proj.weight   \n",
       "525     37            model.layers.37.self_attn.q_b_proj.weight   \n",
       "528     38                      model.layers.38.mlp.gate.weight   \n",
       "529     38  model.layers.38.mlp.shared_experts.down_proj.weight   \n",
       "530     38  model.layers.38.mlp.shared_experts.gate_proj.weight   \n",
       "531     38    model.layers.38.mlp.shared_experts.up_proj.weight   \n",
       "534     38  model.layers.38.self_attn.kv_a_proj_with_mqa.weight   \n",
       "535     38           model.layers.38.self_attn.kv_b_proj.weight   \n",
       "536     38              model.layers.38.self_attn.o_proj.weight   \n",
       "538     38            model.layers.38.self_attn.q_a_proj.weight   \n",
       "539     38            model.layers.38.self_attn.q_b_proj.weight   \n",
       "542     39                      model.layers.39.mlp.gate.weight   \n",
       "543     39  model.layers.39.mlp.shared_experts.down_proj.weight   \n",
       "544     39  model.layers.39.mlp.shared_experts.gate_proj.weight   \n",
       "545     39    model.layers.39.mlp.shared_experts.up_proj.weight   \n",
       "548     39  model.layers.39.self_attn.kv_a_proj_with_mqa.weight   \n",
       "549     39           model.layers.39.self_attn.kv_b_proj.weight   \n",
       "550     39              model.layers.39.self_attn.o_proj.weight   \n",
       "552     39            model.layers.39.self_attn.q_a_proj.weight   \n",
       "553     39            model.layers.39.self_attn.q_b_proj.weight   \n",
       "556     40                      model.layers.40.mlp.gate.weight   \n",
       "557     40  model.layers.40.mlp.shared_experts.down_proj.weight   \n",
       "558     40  model.layers.40.mlp.shared_experts.gate_proj.weight   \n",
       "559     40    model.layers.40.mlp.shared_experts.up_proj.weight   \n",
       "562     40  model.layers.40.self_attn.kv_a_proj_with_mqa.weight   \n",
       "563     40           model.layers.40.self_attn.kv_b_proj.weight   \n",
       "564     40              model.layers.40.self_attn.o_proj.weight   \n",
       "566     40            model.layers.40.self_attn.q_a_proj.weight   \n",
       "567     40            model.layers.40.self_attn.q_b_proj.weight   \n",
       "570     41                      model.layers.41.mlp.gate.weight   \n",
       "571     41  model.layers.41.mlp.shared_experts.down_proj.weight   \n",
       "572     41  model.layers.41.mlp.shared_experts.gate_proj.weight   \n",
       "573     41    model.layers.41.mlp.shared_experts.up_proj.weight   \n",
       "576     41  model.layers.41.self_attn.kv_a_proj_with_mqa.weight   \n",
       "577     41           model.layers.41.self_attn.kv_b_proj.weight   \n",
       "578     41              model.layers.41.self_attn.o_proj.weight   \n",
       "580     41            model.layers.41.self_attn.q_a_proj.weight   \n",
       "581     41            model.layers.41.self_attn.q_b_proj.weight   \n",
       "584     42                      model.layers.42.mlp.gate.weight   \n",
       "585     42  model.layers.42.mlp.shared_experts.down_proj.weight   \n",
       "586     42  model.layers.42.mlp.shared_experts.gate_proj.weight   \n",
       "587     42    model.layers.42.mlp.shared_experts.up_proj.weight   \n",
       "590     42  model.layers.42.self_attn.kv_a_proj_with_mqa.weight   \n",
       "591     42           model.layers.42.self_attn.kv_b_proj.weight   \n",
       "592     42              model.layers.42.self_attn.o_proj.weight   \n",
       "594     42            model.layers.42.self_attn.q_a_proj.weight   \n",
       "595     42            model.layers.42.self_attn.q_b_proj.weight   \n",
       "598     43                      model.layers.43.mlp.gate.weight   \n",
       "599     43  model.layers.43.mlp.shared_experts.down_proj.weight   \n",
       "600     43  model.layers.43.mlp.shared_experts.gate_proj.weight   \n",
       "601     43    model.layers.43.mlp.shared_experts.up_proj.weight   \n",
       "604     43  model.layers.43.self_attn.kv_a_proj_with_mqa.weight   \n",
       "605     43           model.layers.43.self_attn.kv_b_proj.weight   \n",
       "606     43              model.layers.43.self_attn.o_proj.weight   \n",
       "608     43            model.layers.43.self_attn.q_a_proj.weight   \n",
       "609     43            model.layers.43.self_attn.q_b_proj.weight   \n",
       "612     44                      model.layers.44.mlp.gate.weight   \n",
       "613     44  model.layers.44.mlp.shared_experts.down_proj.weight   \n",
       "614     44  model.layers.44.mlp.shared_experts.gate_proj.weight   \n",
       "615     44    model.layers.44.mlp.shared_experts.up_proj.weight   \n",
       "618     44  model.layers.44.self_attn.kv_a_proj_with_mqa.weight   \n",
       "619     44           model.layers.44.self_attn.kv_b_proj.weight   \n",
       "620     44              model.layers.44.self_attn.o_proj.weight   \n",
       "622     44            model.layers.44.self_attn.q_a_proj.weight   \n",
       "623     44            model.layers.44.self_attn.q_b_proj.weight   \n",
       "626     45                      model.layers.45.mlp.gate.weight   \n",
       "627     45  model.layers.45.mlp.shared_experts.down_proj.weight   \n",
       "628     45  model.layers.45.mlp.shared_experts.gate_proj.weight   \n",
       "629     45    model.layers.45.mlp.shared_experts.up_proj.weight   \n",
       "632     45  model.layers.45.self_attn.kv_a_proj_with_mqa.weight   \n",
       "633     45           model.layers.45.self_attn.kv_b_proj.weight   \n",
       "634     45              model.layers.45.self_attn.o_proj.weight   \n",
       "636     45            model.layers.45.self_attn.q_a_proj.weight   \n",
       "637     45            model.layers.45.self_attn.q_b_proj.weight   \n",
       "640     46                      model.layers.46.mlp.gate.weight   \n",
       "641     46  model.layers.46.mlp.shared_experts.down_proj.weight   \n",
       "642     46  model.layers.46.mlp.shared_experts.gate_proj.weight   \n",
       "643     46    model.layers.46.mlp.shared_experts.up_proj.weight   \n",
       "646     46  model.layers.46.self_attn.kv_a_proj_with_mqa.weight   \n",
       "647     46           model.layers.46.self_attn.kv_b_proj.weight   \n",
       "648     46              model.layers.46.self_attn.o_proj.weight   \n",
       "650     46            model.layers.46.self_attn.q_a_proj.weight   \n",
       "651     46            model.layers.46.self_attn.q_b_proj.weight   \n",
       "654     47                      model.layers.47.mlp.gate.weight   \n",
       "655     47  model.layers.47.mlp.shared_experts.down_proj.weight   \n",
       "656     47  model.layers.47.mlp.shared_experts.gate_proj.weight   \n",
       "657     47    model.layers.47.mlp.shared_experts.up_proj.weight   \n",
       "660     47  model.layers.47.self_attn.kv_a_proj_with_mqa.weight   \n",
       "661     47           model.layers.47.self_attn.kv_b_proj.weight   \n",
       "662     47              model.layers.47.self_attn.o_proj.weight   \n",
       "664     47            model.layers.47.self_attn.q_a_proj.weight   \n",
       "665     47            model.layers.47.self_attn.q_b_proj.weight   \n",
       "668     48                      model.layers.48.mlp.gate.weight   \n",
       "669     48  model.layers.48.mlp.shared_experts.down_proj.weight   \n",
       "670     48  model.layers.48.mlp.shared_experts.gate_proj.weight   \n",
       "671     48    model.layers.48.mlp.shared_experts.up_proj.weight   \n",
       "674     48  model.layers.48.self_attn.kv_a_proj_with_mqa.weight   \n",
       "675     48           model.layers.48.self_attn.kv_b_proj.weight   \n",
       "676     48              model.layers.48.self_attn.o_proj.weight   \n",
       "678     48            model.layers.48.self_attn.q_a_proj.weight   \n",
       "679     48            model.layers.48.self_attn.q_b_proj.weight   \n",
       "682     49                      model.layers.49.mlp.gate.weight   \n",
       "683     49  model.layers.49.mlp.shared_experts.down_proj.weight   \n",
       "684     49  model.layers.49.mlp.shared_experts.gate_proj.weight   \n",
       "685     49    model.layers.49.mlp.shared_experts.up_proj.weight   \n",
       "688     49  model.layers.49.self_attn.kv_a_proj_with_mqa.weight   \n",
       "689     49           model.layers.49.self_attn.kv_b_proj.weight   \n",
       "690     49              model.layers.49.self_attn.o_proj.weight   \n",
       "692     49            model.layers.49.self_attn.q_a_proj.weight   \n",
       "693     49            model.layers.49.self_attn.q_b_proj.weight   \n",
       "696     50                      model.layers.50.mlp.gate.weight   \n",
       "697     50  model.layers.50.mlp.shared_experts.down_proj.weight   \n",
       "698     50  model.layers.50.mlp.shared_experts.gate_proj.weight   \n",
       "699     50    model.layers.50.mlp.shared_experts.up_proj.weight   \n",
       "702     50  model.layers.50.self_attn.kv_a_proj_with_mqa.weight   \n",
       "703     50           model.layers.50.self_attn.kv_b_proj.weight   \n",
       "704     50              model.layers.50.self_attn.o_proj.weight   \n",
       "706     50            model.layers.50.self_attn.q_a_proj.weight   \n",
       "707     50            model.layers.50.self_attn.q_b_proj.weight   \n",
       "710     51                      model.layers.51.mlp.gate.weight   \n",
       "711     51  model.layers.51.mlp.shared_experts.down_proj.weight   \n",
       "712     51  model.layers.51.mlp.shared_experts.gate_proj.weight   \n",
       "713     51    model.layers.51.mlp.shared_experts.up_proj.weight   \n",
       "716     51  model.layers.51.self_attn.kv_a_proj_with_mqa.weight   \n",
       "717     51           model.layers.51.self_attn.kv_b_proj.weight   \n",
       "718     51              model.layers.51.self_attn.o_proj.weight   \n",
       "720     51            model.layers.51.self_attn.q_a_proj.weight   \n",
       "721     51            model.layers.51.self_attn.q_b_proj.weight   \n",
       "724     52                      model.layers.52.mlp.gate.weight   \n",
       "725     52  model.layers.52.mlp.shared_experts.down_proj.weight   \n",
       "726     52  model.layers.52.mlp.shared_experts.gate_proj.weight   \n",
       "727     52    model.layers.52.mlp.shared_experts.up_proj.weight   \n",
       "730     52  model.layers.52.self_attn.kv_a_proj_with_mqa.weight   \n",
       "731     52           model.layers.52.self_attn.kv_b_proj.weight   \n",
       "732     52              model.layers.52.self_attn.o_proj.weight   \n",
       "734     52            model.layers.52.self_attn.q_a_proj.weight   \n",
       "735     52            model.layers.52.self_attn.q_b_proj.weight   \n",
       "738     53                      model.layers.53.mlp.gate.weight   \n",
       "739     53  model.layers.53.mlp.shared_experts.down_proj.weight   \n",
       "740     53  model.layers.53.mlp.shared_experts.gate_proj.weight   \n",
       "741     53    model.layers.53.mlp.shared_experts.up_proj.weight   \n",
       "744     53  model.layers.53.self_attn.kv_a_proj_with_mqa.weight   \n",
       "745     53           model.layers.53.self_attn.kv_b_proj.weight   \n",
       "746     53              model.layers.53.self_attn.o_proj.weight   \n",
       "748     53            model.layers.53.self_attn.q_a_proj.weight   \n",
       "749     53            model.layers.53.self_attn.q_b_proj.weight   \n",
       "752     54                      model.layers.54.mlp.gate.weight   \n",
       "753     54  model.layers.54.mlp.shared_experts.down_proj.weight   \n",
       "754     54  model.layers.54.mlp.shared_experts.gate_proj.weight   \n",
       "755     54    model.layers.54.mlp.shared_experts.up_proj.weight   \n",
       "758     54  model.layers.54.self_attn.kv_a_proj_with_mqa.weight   \n",
       "759     54           model.layers.54.self_attn.kv_b_proj.weight   \n",
       "760     54              model.layers.54.self_attn.o_proj.weight   \n",
       "762     54            model.layers.54.self_attn.q_a_proj.weight   \n",
       "763     54            model.layers.54.self_attn.q_b_proj.weight   \n",
       "766     55                      model.layers.55.mlp.gate.weight   \n",
       "767     55  model.layers.55.mlp.shared_experts.down_proj.weight   \n",
       "768     55  model.layers.55.mlp.shared_experts.gate_proj.weight   \n",
       "769     55    model.layers.55.mlp.shared_experts.up_proj.weight   \n",
       "772     55  model.layers.55.self_attn.kv_a_proj_with_mqa.weight   \n",
       "773     55           model.layers.55.self_attn.kv_b_proj.weight   \n",
       "774     55              model.layers.55.self_attn.o_proj.weight   \n",
       "776     55            model.layers.55.self_attn.q_a_proj.weight   \n",
       "777     55            model.layers.55.self_attn.q_b_proj.weight   \n",
       "780     56                      model.layers.56.mlp.gate.weight   \n",
       "781     56  model.layers.56.mlp.shared_experts.down_proj.weight   \n",
       "782     56  model.layers.56.mlp.shared_experts.gate_proj.weight   \n",
       "783     56    model.layers.56.mlp.shared_experts.up_proj.weight   \n",
       "786     56  model.layers.56.self_attn.kv_a_proj_with_mqa.weight   \n",
       "787     56           model.layers.56.self_attn.kv_b_proj.weight   \n",
       "788     56              model.layers.56.self_attn.o_proj.weight   \n",
       "790     56            model.layers.56.self_attn.q_a_proj.weight   \n",
       "791     56            model.layers.56.self_attn.q_b_proj.weight   \n",
       "794     57                      model.layers.57.mlp.gate.weight   \n",
       "795     57  model.layers.57.mlp.shared_experts.down_proj.weight   \n",
       "796     57  model.layers.57.mlp.shared_experts.gate_proj.weight   \n",
       "797     57    model.layers.57.mlp.shared_experts.up_proj.weight   \n",
       "800     57  model.layers.57.self_attn.kv_a_proj_with_mqa.weight   \n",
       "801     57           model.layers.57.self_attn.kv_b_proj.weight   \n",
       "802     57              model.layers.57.self_attn.o_proj.weight   \n",
       "804     57            model.layers.57.self_attn.q_a_proj.weight   \n",
       "805     57            model.layers.57.self_attn.q_b_proj.weight   \n",
       "808     58                      model.layers.58.mlp.gate.weight   \n",
       "809     58  model.layers.58.mlp.shared_experts.down_proj.weight   \n",
       "810     58  model.layers.58.mlp.shared_experts.gate_proj.weight   \n",
       "811     58    model.layers.58.mlp.shared_experts.up_proj.weight   \n",
       "814     58  model.layers.58.self_attn.kv_a_proj_with_mqa.weight   \n",
       "815     58           model.layers.58.self_attn.kv_b_proj.weight   \n",
       "816     58              model.layers.58.self_attn.o_proj.weight   \n",
       "818     58            model.layers.58.self_attn.q_a_proj.weight   \n",
       "819     58            model.layers.58.self_attn.q_b_proj.weight   \n",
       "822     59                      model.layers.59.mlp.gate.weight   \n",
       "823     59  model.layers.59.mlp.shared_experts.down_proj.weight   \n",
       "824     59  model.layers.59.mlp.shared_experts.gate_proj.weight   \n",
       "825     59    model.layers.59.mlp.shared_experts.up_proj.weight   \n",
       "828     59  model.layers.59.self_attn.kv_a_proj_with_mqa.weight   \n",
       "829     59           model.layers.59.self_attn.kv_b_proj.weight   \n",
       "830     59              model.layers.59.self_attn.o_proj.weight   \n",
       "832     59            model.layers.59.self_attn.q_a_proj.weight   \n",
       "833     59            model.layers.59.self_attn.q_b_proj.weight   \n",
       "836     60                      model.layers.60.mlp.gate.weight   \n",
       "837     60  model.layers.60.mlp.shared_experts.down_proj.weight   \n",
       "838     60  model.layers.60.mlp.shared_experts.gate_proj.weight   \n",
       "839     60    model.layers.60.mlp.shared_experts.up_proj.weight   \n",
       "842     60  model.layers.60.self_attn.kv_a_proj_with_mqa.weight   \n",
       "843     60           model.layers.60.self_attn.kv_b_proj.weight   \n",
       "844     60              model.layers.60.self_attn.o_proj.weight   \n",
       "846     60            model.layers.60.self_attn.q_a_proj.weight   \n",
       "847     60            model.layers.60.self_attn.q_b_proj.weight   \n",
       "\n",
       "             shape        numel     norm_a         norm_b  norm_ratio  \\\n",
       "1    (7168, 18432)  132120576.0  59.667873  428978.468750    0.000139   \n",
       "2    (18432, 7168)  132120576.0  56.593945  233500.296875    0.000242   \n",
       "3    (18432, 7168)  132120576.0  51.375027  589028.500000    0.000087   \n",
       "6      (576, 7168)    4128768.0  42.883209  143063.109375    0.000300   \n",
       "7              NaN          NaN        NaN            NaN         NaN   \n",
       "8              NaN          NaN        NaN            NaN         NaN   \n",
       "10    (1536, 7168)   11010048.0  32.806965  295782.718750    0.000111   \n",
       "11             NaN          NaN        NaN            NaN         NaN   \n",
       "13   (7168, 18432)  132120576.0  31.056589  311506.968750    0.000100   \n",
       "14   (18432, 7168)  132120576.0  46.198711  275344.031250    0.000168   \n",
       "15   (18432, 7168)  132120576.0  24.128511  398866.781250    0.000060   \n",
       "18     (576, 7168)    4128768.0  28.544937  119154.664062    0.000240   \n",
       "19             NaN          NaN        NaN            NaN         NaN   \n",
       "20             NaN          NaN        NaN            NaN         NaN   \n",
       "22    (1536, 7168)   11010048.0  17.876047  176267.359375    0.000101   \n",
       "23             NaN          NaN        NaN            NaN         NaN   \n",
       "25   (7168, 18432)  132120576.0  35.113667  253710.390625    0.000138   \n",
       "26   (18432, 7168)  132120576.0  47.933502  201596.265625    0.000238   \n",
       "27   (18432, 7168)  132120576.0  28.609304  325057.093750    0.000088   \n",
       "30     (576, 7168)    4128768.0  27.854443   98536.000000    0.000283   \n",
       "31             NaN          NaN        NaN            NaN         NaN   \n",
       "32             NaN          NaN        NaN            NaN         NaN   \n",
       "34    (1536, 7168)   11010048.0  23.909323  193261.531250    0.000124   \n",
       "35             NaN          NaN        NaN            NaN         NaN   \n",
       "38     (256, 7168)    1835008.0  29.393806      33.376320    0.880678   \n",
       "39    (7168, 2048)   14680064.0  28.635567  241520.312500    0.000119   \n",
       "40    (2048, 7168)   14680064.0  31.387489  230882.187500    0.000136   \n",
       "41    (2048, 7168)   14680064.0  25.626366  355590.343750    0.000072   \n",
       "44     (576, 7168)    4128768.0  34.273003  139565.296875    0.000246   \n",
       "45             NaN          NaN        NaN            NaN         NaN   \n",
       "46             NaN          NaN        NaN            NaN         NaN   \n",
       "48    (1536, 7168)   11010048.0  37.585987  223475.562500    0.000168   \n",
       "49             NaN          NaN        NaN            NaN         NaN   \n",
       "52     (256, 7168)    1835008.0  40.083839      38.301109    1.046545   \n",
       "53    (7168, 2048)   14680064.0  31.385395  252685.328125    0.000124   \n",
       "54    (2048, 7168)   14680064.0  53.515797  200585.921875    0.000267   \n",
       "55    (2048, 7168)   14680064.0  30.086203  340374.531250    0.000088   \n",
       "58     (576, 7168)    4128768.0  34.652184  153807.328125    0.000225   \n",
       "59             NaN          NaN        NaN            NaN         NaN   \n",
       "60             NaN          NaN        NaN            NaN         NaN   \n",
       "62    (1536, 7168)   11010048.0  29.676378  286426.500000    0.000104   \n",
       "63             NaN          NaN        NaN            NaN         NaN   \n",
       "66     (256, 7168)    1835008.0  47.636959      47.007324    1.013394   \n",
       "67    (7168, 2048)   14680064.0  32.378353  258382.609375    0.000125   \n",
       "68    (2048, 7168)   14680064.0  58.461613  204030.687500    0.000287   \n",
       "69    (2048, 7168)   14680064.0  32.674606  322552.281250    0.000101   \n",
       "72     (576, 7168)    4128768.0  39.866913  127441.625000    0.000313   \n",
       "73             NaN          NaN        NaN            NaN         NaN   \n",
       "74             NaN          NaN        NaN            NaN         NaN   \n",
       "76    (1536, 7168)   11010048.0  35.922665  268944.281250    0.000134   \n",
       "77             NaN          NaN        NaN            NaN         NaN   \n",
       "80     (256, 7168)    1835008.0  52.055973      51.258682    1.015554   \n",
       "81    (7168, 2048)   14680064.0  35.252045  265794.281250    0.000133   \n",
       "82    (2048, 7168)   14680064.0  65.565948  208179.843750    0.000315   \n",
       "83    (2048, 7168)   14680064.0  35.650501  316225.750000    0.000113   \n",
       "86     (576, 7168)    4128768.0  35.578690  165172.265625    0.000215   \n",
       "87             NaN          NaN        NaN            NaN         NaN   \n",
       "88             NaN          NaN        NaN            NaN         NaN   \n",
       "90    (1536, 7168)   11010048.0  32.842499  272285.156250    0.000121   \n",
       "91             NaN          NaN        NaN            NaN         NaN   \n",
       "94     (256, 7168)    1835008.0  62.166615      56.682781    1.096746   \n",
       "95    (7168, 2048)   14680064.0  34.187748  274685.562500    0.000124   \n",
       "96    (2048, 7168)   14680064.0  73.995186  214966.609375    0.000344   \n",
       "97    (2048, 7168)   14680064.0  36.493416  296291.062500    0.000123   \n",
       "100    (576, 7168)    4128768.0  44.163628  158275.140625    0.000279   \n",
       "101            NaN          NaN        NaN            NaN         NaN   \n",
       "102            NaN          NaN        NaN            NaN         NaN   \n",
       "104   (1536, 7168)   11010048.0  44.411427  286513.031250    0.000155   \n",
       "105            NaN          NaN        NaN            NaN         NaN   \n",
       "108    (256, 7168)    1835008.0  63.920872      52.985229    1.206390   \n",
       "109   (7168, 2048)   14680064.0  37.425797  232908.671875    0.000161   \n",
       "110   (2048, 7168)   14680064.0  83.790474  224043.687500    0.000374   \n",
       "111   (2048, 7168)   14680064.0  39.538883  287792.812500    0.000137   \n",
       "114    (576, 7168)    4128768.0  44.211086  148725.421875    0.000297   \n",
       "115            NaN          NaN        NaN            NaN         NaN   \n",
       "116            NaN          NaN        NaN            NaN         NaN   \n",
       "118   (1536, 7168)   11010048.0  43.829700  275328.781250    0.000159   \n",
       "119            NaN          NaN        NaN            NaN         NaN   \n",
       "122    (256, 7168)    1835008.0  61.512337      53.668427    1.146155   \n",
       "123   (7168, 2048)   14680064.0  40.872108  251042.640625    0.000163   \n",
       "124   (2048, 7168)   14680064.0  86.544426  211574.093750    0.000409   \n",
       "125   (2048, 7168)   14680064.0  41.083069  264269.031250    0.000155   \n",
       "128    (576, 7168)    4128768.0  43.943066  171746.765625    0.000256   \n",
       "129            NaN          NaN        NaN            NaN         NaN   \n",
       "130            NaN          NaN        NaN            NaN         NaN   \n",
       "132   (1536, 7168)   11010048.0  42.547871  322357.468750    0.000132   \n",
       "133            NaN          NaN        NaN            NaN         NaN   \n",
       "136    (256, 7168)    1835008.0  59.963379      56.496185    1.061370   \n",
       "137   (7168, 2048)   14680064.0  45.310238  263960.593750    0.000172   \n",
       "138   (2048, 7168)   14680064.0  91.581459  205267.031250    0.000446   \n",
       "139   (2048, 7168)   14680064.0  43.552773  262363.000000    0.000166   \n",
       "142    (576, 7168)    4128768.0  46.502293  165971.343750    0.000280   \n",
       "143            NaN          NaN        NaN            NaN         NaN   \n",
       "144            NaN          NaN        NaN            NaN         NaN   \n",
       "146   (1536, 7168)   11010048.0  43.622997  324044.500000    0.000135   \n",
       "147            NaN          NaN        NaN            NaN         NaN   \n",
       "150    (256, 7168)    1835008.0  61.361385      57.482117    1.067487   \n",
       "151   (7168, 2048)   14680064.0  41.967201  250408.062500    0.000168   \n",
       "152   (2048, 7168)   14680064.0  94.314461  206260.328125    0.000457   \n",
       "153   (2048, 7168)   14680064.0  42.831738  254143.609375    0.000169   \n",
       "156    (576, 7168)    4128768.0  50.810741  192736.578125    0.000264   \n",
       "157            NaN          NaN        NaN            NaN         NaN   \n",
       "158            NaN          NaN        NaN            NaN         NaN   \n",
       "160   (1536, 7168)   11010048.0  52.763145  307570.718750    0.000172   \n",
       "161            NaN          NaN        NaN            NaN         NaN   \n",
       "164    (256, 7168)    1835008.0  60.909180      55.247620    1.102476   \n",
       "165   (7168, 2048)   14680064.0  44.653931  261757.046875    0.000171   \n",
       "166   (2048, 7168)   14680064.0  88.550323  213861.343750    0.000414   \n",
       "167   (2048, 7168)   14680064.0  44.156055  254356.968750    0.000174   \n",
       "170    (576, 7168)    4128768.0  48.693699  179631.687500    0.000271   \n",
       "171            NaN          NaN        NaN            NaN         NaN   \n",
       "172            NaN          NaN        NaN            NaN         NaN   \n",
       "174   (1536, 7168)   11010048.0  47.013763  299907.625000    0.000157   \n",
       "175            NaN          NaN        NaN            NaN         NaN   \n",
       "178    (256, 7168)    1835008.0  62.685085      54.026512    1.160265   \n",
       "179   (7168, 2048)   14680064.0  42.977657  255123.500000    0.000168   \n",
       "180   (2048, 7168)   14680064.0  80.258064  197298.640625    0.000407   \n",
       "181   (2048, 7168)   14680064.0  43.370766  249163.703125    0.000174   \n",
       "184    (576, 7168)    4128768.0  50.868774  186268.890625    0.000273   \n",
       "185            NaN          NaN        NaN            NaN         NaN   \n",
       "186            NaN          NaN        NaN            NaN         NaN   \n",
       "188   (1536, 7168)   11010048.0  54.821720  303415.875000    0.000181   \n",
       "189            NaN          NaN        NaN            NaN         NaN   \n",
       "192    (256, 7168)    1835008.0  63.182152      52.010090    1.214806   \n",
       "193   (7168, 2048)   14680064.0  43.694138  253349.312500    0.000172   \n",
       "194   (2048, 7168)   14680064.0  83.070198  152293.328125    0.000545   \n",
       "195   (2048, 7168)   14680064.0  44.037579  238882.812500    0.000184   \n",
       "198    (576, 7168)    4128768.0  51.171547  189226.890625    0.000270   \n",
       "199            NaN          NaN        NaN            NaN         NaN   \n",
       "200            NaN          NaN        NaN            NaN         NaN   \n",
       "202   (1536, 7168)   11010048.0  62.171219  314810.125000    0.000197   \n",
       "203            NaN          NaN        NaN            NaN         NaN   \n",
       "206    (256, 7168)    1835008.0  63.850780      49.865566    1.280458   \n",
       "207   (7168, 2048)   14680064.0  42.938866  231562.562500    0.000185   \n",
       "208   (2048, 7168)   14680064.0  76.841179  154447.515625    0.000498   \n",
       "209   (2048, 7168)   14680064.0  42.662048  231356.515625    0.000184   \n",
       "212    (576, 7168)    4128768.0  51.585777  194538.734375    0.000265   \n",
       "213            NaN          NaN        NaN            NaN         NaN   \n",
       "214            NaN          NaN        NaN            NaN         NaN   \n",
       "216   (1536, 7168)   11010048.0  67.028961  323574.531250    0.000207   \n",
       "217            NaN          NaN        NaN            NaN         NaN   \n",
       "220    (256, 7168)    1835008.0  62.051323      51.242741    1.210929   \n",
       "221   (7168, 2048)   14680064.0  45.100792  251104.656250    0.000180   \n",
       "222   (2048, 7168)   14680064.0  75.130760  130005.640625    0.000578   \n",
       "223   (2048, 7168)   14680064.0  44.422676  231655.156250    0.000192   \n",
       "226    (576, 7168)    4128768.0  48.504116  189007.765625    0.000257   \n",
       "227            NaN          NaN        NaN            NaN         NaN   \n",
       "228            NaN          NaN        NaN            NaN         NaN   \n",
       "230   (1536, 7168)   11010048.0  59.526833  333944.687500    0.000178   \n",
       "231            NaN          NaN        NaN            NaN         NaN   \n",
       "234    (256, 7168)    1835008.0  62.750134      49.359756    1.271281   \n",
       "235   (7168, 2048)   14680064.0  42.149212  247063.156250    0.000171   \n",
       "236   (2048, 7168)   14680064.0  72.227585  181604.406250    0.000398   \n",
       "237   (2048, 7168)   14680064.0  42.069752  252705.421875    0.000166   \n",
       "240    (576, 7168)    4128768.0  52.250446  170246.734375    0.000307   \n",
       "241            NaN          NaN        NaN            NaN         NaN   \n",
       "242            NaN          NaN        NaN            NaN         NaN   \n",
       "244   (1536, 7168)   11010048.0  65.144463  321128.125000    0.000203   \n",
       "245            NaN          NaN        NaN            NaN         NaN   \n",
       "248    (256, 7168)    1835008.0  62.404762      47.435638    1.315567   \n",
       "249   (7168, 2048)   14680064.0  43.535549  240439.250000    0.000181   \n",
       "250   (2048, 7168)   14680064.0  68.102524  174105.203125    0.000391   \n",
       "251   (2048, 7168)   14680064.0  43.068176  245458.218750    0.000175   \n",
       "254    (576, 7168)    4128768.0  50.018276  186641.953125    0.000268   \n",
       "255            NaN          NaN        NaN            NaN         NaN   \n",
       "256            NaN          NaN        NaN            NaN         NaN   \n",
       "258   (1536, 7168)   11010048.0  55.811195  335747.656250    0.000166   \n",
       "259            NaN          NaN        NaN            NaN         NaN   \n",
       "262    (256, 7168)    1835008.0  63.084209      45.760281    1.378580   \n",
       "263   (7168, 2048)   14680064.0  46.389908  230632.750000    0.000201   \n",
       "264   (2048, 7168)   14680064.0  74.325966  183386.718750    0.000405   \n",
       "265   (2048, 7168)   14680064.0  46.460163  235976.156250    0.000197   \n",
       "268    (576, 7168)    4128768.0  53.282570  191723.765625    0.000278   \n",
       "269            NaN          NaN        NaN            NaN         NaN   \n",
       "270            NaN          NaN        NaN            NaN         NaN   \n",
       "272   (1536, 7168)   11010048.0  67.073479  341160.906250    0.000197   \n",
       "273            NaN          NaN        NaN            NaN         NaN   \n",
       "276    (256, 7168)    1835008.0  61.973553      46.179924    1.342002   \n",
       "277   (7168, 2048)   14680064.0  45.197800  247829.406250    0.000182   \n",
       "278   (2048, 7168)   14680064.0  70.298676  199909.265625    0.000352   \n",
       "279   (2048, 7168)   14680064.0  44.633236  251577.046875    0.000177   \n",
       "282    (576, 7168)    4128768.0  52.084736  189800.718750    0.000274   \n",
       "283            NaN          NaN        NaN            NaN         NaN   \n",
       "284            NaN          NaN        NaN            NaN         NaN   \n",
       "286   (1536, 7168)   11010048.0  58.247837  352249.687500    0.000165   \n",
       "287            NaN          NaN        NaN            NaN         NaN   \n",
       "290    (256, 7168)    1835008.0  60.863007      43.545822    1.397677   \n",
       "291   (7168, 2048)   14680064.0  47.931683  258967.203125    0.000185   \n",
       "292   (2048, 7168)   14680064.0  68.468765  223264.484375    0.000307   \n",
       "293   (2048, 7168)   14680064.0  46.949577  258003.062500    0.000182   \n",
       "296    (576, 7168)    4128768.0  50.602535  185338.343750    0.000273   \n",
       "297            NaN          NaN        NaN            NaN         NaN   \n",
       "298            NaN          NaN        NaN            NaN         NaN   \n",
       "300   (1536, 7168)   11010048.0  57.460434  349251.406250    0.000165   \n",
       "301            NaN          NaN        NaN            NaN         NaN   \n",
       "304    (256, 7168)    1835008.0  61.605721      41.730858    1.476263   \n",
       "305   (7168, 2048)   14680064.0  46.564346  237526.000000    0.000196   \n",
       "306   (2048, 7168)   14680064.0  66.990974  220415.093750    0.000304   \n",
       "307   (2048, 7168)   14680064.0  46.014114  243710.812500    0.000189   \n",
       "310    (576, 7168)    4128768.0  52.571045  178447.593750    0.000295   \n",
       "311            NaN          NaN        NaN            NaN         NaN   \n",
       "312            NaN          NaN        NaN            NaN         NaN   \n",
       "314   (1536, 7168)   11010048.0  65.445320  350310.343750    0.000187   \n",
       "315            NaN          NaN        NaN            NaN         NaN   \n",
       "318    (256, 7168)    1835008.0  61.044193      38.723587    1.576409   \n",
       "319   (7168, 2048)   14680064.0  47.011139  245694.359375    0.000191   \n",
       "320   (2048, 7168)   14680064.0  61.929295  229450.031250    0.000270   \n",
       "321   (2048, 7168)   14680064.0  46.404636  237881.484375    0.000195   \n",
       "324    (576, 7168)    4128768.0  51.397686  185549.109375    0.000277   \n",
       "325            NaN          NaN        NaN            NaN         NaN   \n",
       "326            NaN          NaN        NaN            NaN         NaN   \n",
       "328   (1536, 7168)   11010048.0  67.362633  352155.875000    0.000191   \n",
       "329            NaN          NaN        NaN            NaN         NaN   \n",
       "332    (256, 7168)    1835008.0  60.068474      37.407093    1.605804   \n",
       "333   (7168, 2048)   14680064.0  45.927448  254102.531250    0.000181   \n",
       "334   (2048, 7168)   14680064.0  60.150677  223982.171875    0.000269   \n",
       "335   (2048, 7168)   14680064.0  45.011257  229948.515625    0.000196   \n",
       "338    (576, 7168)    4128768.0  53.090969  176628.812500    0.000301   \n",
       "339            NaN          NaN        NaN            NaN         NaN   \n",
       "340            NaN          NaN        NaN            NaN         NaN   \n",
       "342   (1536, 7168)   11010048.0  75.970032  351171.062500    0.000216   \n",
       "343            NaN          NaN        NaN            NaN         NaN   \n",
       "346    (256, 7168)    1835008.0  58.858749      37.209473    1.581822   \n",
       "347   (7168, 2048)   14680064.0  43.812443  263204.593750    0.000166   \n",
       "348   (2048, 7168)   14680064.0  56.144016  209996.078125    0.000267   \n",
       "349   (2048, 7168)   14680064.0  42.932861  230937.734375    0.000186   \n",
       "352    (576, 7168)    4128768.0  52.336922  166856.593750    0.000314   \n",
       "353            NaN          NaN        NaN            NaN         NaN   \n",
       "354            NaN          NaN        NaN            NaN         NaN   \n",
       "356   (1536, 7168)   11010048.0  72.086006  349273.781250    0.000206   \n",
       "357            NaN          NaN        NaN            NaN         NaN   \n",
       "360    (256, 7168)    1835008.0  58.200573      37.173981    1.565627   \n",
       "361   (7168, 2048)   14680064.0  45.615864  265324.500000    0.000172   \n",
       "362   (2048, 7168)   14680064.0  56.633945  216835.828125    0.000261   \n",
       "363   (2048, 7168)   14680064.0  44.797127  242268.687500    0.000185   \n",
       "366    (576, 7168)    4128768.0  51.520401  177910.296875    0.000290   \n",
       "367            NaN          NaN        NaN            NaN         NaN   \n",
       "368            NaN          NaN        NaN            NaN         NaN   \n",
       "370   (1536, 7168)   11010048.0  69.948273  347354.000000    0.000201   \n",
       "371            NaN          NaN        NaN            NaN         NaN   \n",
       "374    (256, 7168)    1835008.0  57.779716      36.448174    1.585257   \n",
       "375   (7168, 2048)   14680064.0  41.154556  284785.656250    0.000145   \n",
       "376   (2048, 7168)   14680064.0  49.128021  229124.890625    0.000214   \n",
       "377   (2048, 7168)   14680064.0  40.624657  256067.140625    0.000159   \n",
       "380    (576, 7168)    4128768.0  49.640358  164400.296875    0.000302   \n",
       "381            NaN          NaN        NaN            NaN         NaN   \n",
       "382            NaN          NaN        NaN            NaN         NaN   \n",
       "384   (1536, 7168)   11010048.0  68.983093  331264.437500    0.000208   \n",
       "385            NaN          NaN        NaN            NaN         NaN   \n",
       "388    (256, 7168)    1835008.0  57.039749      35.363419    1.612959   \n",
       "389   (7168, 2048)   14680064.0  47.880848  282893.593750    0.000169   \n",
       "390   (2048, 7168)   14680064.0  56.813526  212324.312500    0.000268   \n",
       "391   (2048, 7168)   14680064.0  46.198658  254270.328125    0.000182   \n",
       "394    (576, 7168)    4128768.0  52.230282  180721.046875    0.000289   \n",
       "395            NaN          NaN        NaN            NaN         NaN   \n",
       "396            NaN          NaN        NaN            NaN         NaN   \n",
       "398   (1536, 7168)   11010048.0  72.279205  351104.250000    0.000206   \n",
       "399            NaN          NaN        NaN            NaN         NaN   \n",
       "402    (256, 7168)    1835008.0  56.890789      35.420940    1.606134   \n",
       "403   (7168, 2048)   14680064.0  47.138607  278421.906250    0.000169   \n",
       "404   (2048, 7168)   14680064.0  54.204090  229367.781250    0.000236   \n",
       "405   (2048, 7168)   14680064.0  45.840836  256352.265625    0.000179   \n",
       "408    (576, 7168)    4128768.0  52.593529  186104.609375    0.000283   \n",
       "409            NaN          NaN        NaN            NaN         NaN   \n",
       "410            NaN          NaN        NaN            NaN         NaN   \n",
       "412   (1536, 7168)   11010048.0  79.557137  344495.843750    0.000231   \n",
       "413            NaN          NaN        NaN            NaN         NaN   \n",
       "416    (256, 7168)    1835008.0  56.199585      35.525330    1.581958   \n",
       "417   (7168, 2048)   14680064.0  46.984955  279280.562500    0.000168   \n",
       "418   (2048, 7168)   14680064.0  55.816029  222334.625000    0.000251   \n",
       "419   (2048, 7168)   14680064.0  45.959114  253979.453125    0.000181   \n",
       "422    (576, 7168)    4128768.0  47.171612  186653.390625    0.000253   \n",
       "423            NaN          NaN        NaN            NaN         NaN   \n",
       "424            NaN          NaN        NaN            NaN         NaN   \n",
       "426   (1536, 7168)   11010048.0  70.334183  347517.656250    0.000202   \n",
       "427            NaN          NaN        NaN            NaN         NaN   \n",
       "430    (256, 7168)    1835008.0  54.366833      34.047428    1.596797   \n",
       "431   (7168, 2048)   14680064.0  45.985538  274074.875000    0.000168   \n",
       "432   (2048, 7168)   14680064.0  53.188286  213671.890625    0.000249   \n",
       "433   (2048, 7168)   14680064.0  45.167343  242867.578125    0.000186   \n",
       "436    (576, 7168)    4128768.0  49.067039  175714.812500    0.000279   \n",
       "437            NaN          NaN        NaN            NaN         NaN   \n",
       "438            NaN          NaN        NaN            NaN         NaN   \n",
       "440   (1536, 7168)   11010048.0  71.968002  331438.187500    0.000217   \n",
       "441            NaN          NaN        NaN            NaN         NaN   \n",
       "444    (256, 7168)    1835008.0  53.960705      33.469986    1.612212   \n",
       "445   (7168, 2048)   14680064.0  48.308689  270485.625000    0.000179   \n",
       "446   (2048, 7168)   14680064.0  54.150475  212072.375000    0.000255   \n",
       "447   (2048, 7168)   14680064.0  47.262604  241527.921875    0.000196   \n",
       "450    (576, 7168)    4128768.0  49.026100  179884.656250    0.000273   \n",
       "451            NaN          NaN        NaN            NaN         NaN   \n",
       "452            NaN          NaN        NaN            NaN         NaN   \n",
       "454   (1536, 7168)   11010048.0  74.409676  346724.875000    0.000215   \n",
       "455            NaN          NaN        NaN            NaN         NaN   \n",
       "458    (256, 7168)    1835008.0  52.822144      34.614334    1.526019   \n",
       "459   (7168, 2048)   14680064.0  49.340076  268255.343750    0.000184   \n",
       "460   (2048, 7168)   14680064.0  54.313282  248781.703125    0.000218   \n",
       "461   (2048, 7168)   14680064.0  48.547146  254547.875000    0.000191   \n",
       "464    (576, 7168)    4128768.0  52.848537  172664.937500    0.000306   \n",
       "465            NaN          NaN        NaN            NaN         NaN   \n",
       "466            NaN          NaN        NaN            NaN         NaN   \n",
       "468   (1536, 7168)   11010048.0  77.089249  348893.781250    0.000221   \n",
       "469            NaN          NaN        NaN            NaN         NaN   \n",
       "472    (256, 7168)    1835008.0  51.809036      33.058929    1.567172   \n",
       "473   (7168, 2048)   14680064.0  48.625832  274444.125000    0.000177   \n",
       "474   (2048, 7168)   14680064.0  54.440929  239390.265625    0.000227   \n",
       "475   (2048, 7168)   14680064.0  47.147461  248760.671875    0.000190   \n",
       "478    (576, 7168)    4128768.0  53.150894  147863.421875    0.000359   \n",
       "479            NaN          NaN        NaN            NaN         NaN   \n",
       "480            NaN          NaN        NaN            NaN         NaN   \n",
       "482   (1536, 7168)   11010048.0  78.304436  348700.437500    0.000225   \n",
       "483            NaN          NaN        NaN            NaN         NaN   \n",
       "486    (256, 7168)    1835008.0  51.533623      32.673985    1.577207   \n",
       "487   (7168, 2048)   14680064.0  47.569614  254154.312500    0.000187   \n",
       "488   (2048, 7168)   14680064.0  54.026478  237929.937500    0.000227   \n",
       "489   (2048, 7168)   14680064.0  47.178051  228491.671875    0.000206   \n",
       "492    (576, 7168)    4128768.0  53.218193  169141.671875    0.000315   \n",
       "493            NaN          NaN        NaN            NaN         NaN   \n",
       "494            NaN          NaN        NaN            NaN         NaN   \n",
       "496   (1536, 7168)   11010048.0  77.360214  339649.406250    0.000228   \n",
       "497            NaN          NaN        NaN            NaN         NaN   \n",
       "500    (256, 7168)    1835008.0  50.803822      33.005226    1.539266   \n",
       "501   (7168, 2048)   14680064.0  47.462849  265520.093750    0.000179   \n",
       "502   (2048, 7168)   14680064.0  55.385624  254744.312500    0.000217   \n",
       "503   (2048, 7168)   14680064.0  48.529091  250556.265625    0.000194   \n",
       "506    (576, 7168)    4128768.0  47.422222  185918.343750    0.000255   \n",
       "507            NaN          NaN        NaN            NaN         NaN   \n",
       "508            NaN          NaN        NaN            NaN         NaN   \n",
       "510   (1536, 7168)   11010048.0  64.470337  351829.625000    0.000183   \n",
       "511            NaN          NaN        NaN            NaN         NaN   \n",
       "514    (256, 7168)    1835008.0  50.808838      31.944159    1.590552   \n",
       "515   (7168, 2048)   14680064.0  46.174149  264156.875000    0.000175   \n",
       "516   (2048, 7168)   14680064.0  53.878120  238560.093750    0.000226   \n",
       "517   (2048, 7168)   14680064.0  46.584557  246313.625000    0.000189   \n",
       "520    (576, 7168)    4128768.0  50.028133  169801.312500    0.000295   \n",
       "521            NaN          NaN        NaN            NaN         NaN   \n",
       "522            NaN          NaN        NaN            NaN         NaN   \n",
       "524   (1536, 7168)   11010048.0  72.203667  349750.625000    0.000206   \n",
       "525            NaN          NaN        NaN            NaN         NaN   \n",
       "528    (256, 7168)    1835008.0  50.471760      32.046082    1.574974   \n",
       "529   (7168, 2048)   14680064.0  46.096180  251339.109375    0.000183   \n",
       "530   (2048, 7168)   14680064.0  52.693172  239392.328125    0.000220   \n",
       "531   (2048, 7168)   14680064.0  46.256454  232850.640625    0.000199   \n",
       "534    (576, 7168)    4128768.0  51.403919  161578.359375    0.000318   \n",
       "535            NaN          NaN        NaN            NaN         NaN   \n",
       "536            NaN          NaN        NaN            NaN         NaN   \n",
       "538   (1536, 7168)   11010048.0  76.326584  353690.687500    0.000216   \n",
       "539            NaN          NaN        NaN            NaN         NaN   \n",
       "542    (256, 7168)    1835008.0  50.295757      30.401682    1.654374   \n",
       "543   (7168, 2048)   14680064.0  46.349049  253563.968750    0.000183   \n",
       "544   (2048, 7168)   14680064.0  53.696072  243363.437500    0.000221   \n",
       "545   (2048, 7168)   14680064.0  47.525772  233164.468750    0.000204   \n",
       "548    (576, 7168)    4128768.0  42.421379  157419.468750    0.000269   \n",
       "549            NaN          NaN        NaN            NaN         NaN   \n",
       "550            NaN          NaN        NaN            NaN         NaN   \n",
       "552   (1536, 7168)   11010048.0  59.475895  351937.812500    0.000169   \n",
       "553            NaN          NaN        NaN            NaN         NaN   \n",
       "556    (256, 7168)    1835008.0  48.734970      30.269274    1.610048   \n",
       "557   (7168, 2048)   14680064.0  46.782246  264826.281250    0.000177   \n",
       "558   (2048, 7168)   14680064.0  52.809319  249959.890625    0.000211   \n",
       "559   (2048, 7168)   14680064.0  47.837463  246854.312500    0.000194   \n",
       "562    (576, 7168)    4128768.0  51.146156  166726.796875    0.000307   \n",
       "563            NaN          NaN        NaN            NaN         NaN   \n",
       "564            NaN          NaN        NaN            NaN         NaN   \n",
       "566   (1536, 7168)   11010048.0  77.038696  322530.968750    0.000239   \n",
       "567            NaN          NaN        NaN            NaN         NaN   \n",
       "570    (256, 7168)    1835008.0  46.998287      29.635151    1.585897   \n",
       "571   (7168, 2048)   14680064.0  45.448711  249535.968750    0.000182   \n",
       "572   (2048, 7168)   14680064.0  50.511700  247315.750000    0.000204   \n",
       "573   (2048, 7168)   14680064.0  46.237614  228836.593750    0.000202   \n",
       "576    (576, 7168)    4128768.0  50.286785  159359.562500    0.000316   \n",
       "577            NaN          NaN        NaN            NaN         NaN   \n",
       "578            NaN          NaN        NaN            NaN         NaN   \n",
       "580   (1536, 7168)   11010048.0  70.098717  354023.062500    0.000198   \n",
       "581            NaN          NaN        NaN            NaN         NaN   \n",
       "584    (256, 7168)    1835008.0  44.978374      29.709774    1.513925   \n",
       "585   (7168, 2048)   14680064.0  44.732426  246747.593750    0.000181   \n",
       "586   (2048, 7168)   14680064.0  51.111565  247076.625000    0.000207   \n",
       "587   (2048, 7168)   14680064.0  45.126278  235508.343750    0.000192   \n",
       "590    (576, 7168)    4128768.0  51.099186  176098.312500    0.000290   \n",
       "591            NaN          NaN        NaN            NaN         NaN   \n",
       "592            NaN          NaN        NaN            NaN         NaN   \n",
       "594   (1536, 7168)   11010048.0  75.349091  357103.000000    0.000211   \n",
       "595            NaN          NaN        NaN            NaN         NaN   \n",
       "598    (256, 7168)    1835008.0  44.902657      29.010998    1.547781   \n",
       "599   (7168, 2048)   14680064.0  44.755562  230694.109375    0.000194   \n",
       "600   (2048, 7168)   14680064.0  52.204166  244833.046875    0.000213   \n",
       "601   (2048, 7168)   14680064.0  44.635883  229273.031250    0.000195   \n",
       "604    (576, 7168)    4128768.0  50.237015  153083.781250    0.000328   \n",
       "605            NaN          NaN        NaN            NaN         NaN   \n",
       "606            NaN          NaN        NaN            NaN         NaN   \n",
       "608   (1536, 7168)   11010048.0  74.993248  347749.062500    0.000216   \n",
       "609            NaN          NaN        NaN            NaN         NaN   \n",
       "612    (256, 7168)    1835008.0  44.251369      28.274366    1.565070   \n",
       "613   (7168, 2048)   14680064.0  44.357864  236758.187500    0.000187   \n",
       "614   (2048, 7168)   14680064.0  53.258675  242143.906250    0.000220   \n",
       "615   (2048, 7168)   14680064.0  43.021950  233435.046875    0.000184   \n",
       "618    (576, 7168)    4128768.0  53.222435  181203.046875    0.000294   \n",
       "619            NaN          NaN        NaN            NaN         NaN   \n",
       "620            NaN          NaN        NaN            NaN         NaN   \n",
       "622   (1536, 7168)   11010048.0  73.530098  331982.937500    0.000221   \n",
       "623            NaN          NaN        NaN            NaN         NaN   \n",
       "626    (256, 7168)    1835008.0  44.192734      27.867537    1.585814   \n",
       "627   (7168, 2048)   14680064.0  43.674278  236165.750000    0.000185   \n",
       "628   (2048, 7168)   14680064.0  54.291489  239228.000000    0.000227   \n",
       "629   (2048, 7168)   14680064.0  43.223412  223178.593750    0.000194   \n",
       "632    (576, 7168)    4128768.0  45.840549  162606.562500    0.000282   \n",
       "633            NaN          NaN        NaN            NaN         NaN   \n",
       "634            NaN          NaN        NaN            NaN         NaN   \n",
       "636   (1536, 7168)   11010048.0  72.775063  346763.250000    0.000210   \n",
       "637            NaN          NaN        NaN            NaN         NaN   \n",
       "640    (256, 7168)    1835008.0  41.863281      26.720890    1.566687   \n",
       "641   (7168, 2048)   14680064.0  43.783043  240158.453125    0.000182   \n",
       "642   (2048, 7168)   14680064.0  53.768604  257880.921875    0.000209   \n",
       "643   (2048, 7168)   14680064.0  42.861973  226822.234375    0.000189   \n",
       "646    (576, 7168)    4128768.0  52.777794  144451.828125    0.000365   \n",
       "647            NaN          NaN        NaN            NaN         NaN   \n",
       "648            NaN          NaN        NaN            NaN         NaN   \n",
       "650   (1536, 7168)   11010048.0  66.715645  338362.750000    0.000197   \n",
       "651            NaN          NaN        NaN            NaN         NaN   \n",
       "654    (256, 7168)    1835008.0  40.910725      25.972263    1.575170   \n",
       "655   (7168, 2048)   14680064.0  42.287209  260490.750000    0.000162   \n",
       "656   (2048, 7168)   14680064.0  54.979279  266612.125000    0.000206   \n",
       "657   (2048, 7168)   14680064.0  41.763363  242888.062500    0.000172   \n",
       "660    (576, 7168)    4128768.0  46.789642  136687.203125    0.000342   \n",
       "661            NaN          NaN        NaN            NaN         NaN   \n",
       "662            NaN          NaN        NaN            NaN         NaN   \n",
       "664   (1536, 7168)   11010048.0  61.593723  343426.281250    0.000179   \n",
       "665            NaN          NaN        NaN            NaN         NaN   \n",
       "668    (256, 7168)    1835008.0  40.967010      25.516438    1.605515   \n",
       "669   (7168, 2048)   14680064.0  41.911053  266518.906250    0.000157   \n",
       "670   (2048, 7168)   14680064.0  55.824352  265747.937500    0.000210   \n",
       "671   (2048, 7168)   14680064.0  41.388466  241293.421875    0.000172   \n",
       "674    (576, 7168)    4128768.0  44.699005  184263.796875    0.000243   \n",
       "675            NaN          NaN        NaN            NaN         NaN   \n",
       "676            NaN          NaN        NaN            NaN         NaN   \n",
       "678   (1536, 7168)   11010048.0  54.549786  348280.156250    0.000157   \n",
       "679            NaN          NaN        NaN            NaN         NaN   \n",
       "682    (256, 7168)    1835008.0  41.393047      24.754883    1.672117   \n",
       "683   (7168, 2048)   14680064.0  41.868046  264151.750000    0.000158   \n",
       "684   (2048, 7168)   14680064.0  55.572136  269599.500000    0.000206   \n",
       "685   (2048, 7168)   14680064.0  42.009579  243532.406250    0.000173   \n",
       "688    (576, 7168)    4128768.0  43.209965  172654.687500    0.000250   \n",
       "689            NaN          NaN        NaN            NaN         NaN   \n",
       "690            NaN          NaN        NaN            NaN         NaN   \n",
       "692   (1536, 7168)   11010048.0  55.441502  345941.156250    0.000160   \n",
       "693            NaN          NaN        NaN            NaN         NaN   \n",
       "696    (256, 7168)    1835008.0  39.940376      24.357220    1.639776   \n",
       "697   (7168, 2048)   14680064.0  41.579712  258156.953125    0.000161   \n",
       "698   (2048, 7168)   14680064.0  55.334579  266024.468750    0.000208   \n",
       "699   (2048, 7168)   14680064.0  40.802856  238225.250000    0.000171   \n",
       "702    (576, 7168)    4128768.0  52.474453  162472.593750    0.000323   \n",
       "703            NaN          NaN        NaN            NaN         NaN   \n",
       "704            NaN          NaN        NaN            NaN         NaN   \n",
       "706   (1536, 7168)   11010048.0  73.557915  340124.093750    0.000216   \n",
       "707            NaN          NaN        NaN            NaN         NaN   \n",
       "710    (256, 7168)    1835008.0  39.181675      23.561365    1.662963   \n",
       "711   (7168, 2048)   14680064.0  42.402748  274071.906250    0.000155   \n",
       "712   (2048, 7168)   14680064.0  57.039303  263386.218750    0.000217   \n",
       "713   (2048, 7168)   14680064.0  41.339771  250485.078125    0.000165   \n",
       "716    (576, 7168)    4128768.0  52.515038  160357.781250    0.000327   \n",
       "717            NaN          NaN        NaN            NaN         NaN   \n",
       "718            NaN          NaN        NaN            NaN         NaN   \n",
       "720   (1536, 7168)   11010048.0  63.924370  347385.187500    0.000184   \n",
       "721            NaN          NaN        NaN            NaN         NaN   \n",
       "724    (256, 7168)    1835008.0  38.341373      23.653309    1.620973   \n",
       "725   (7168, 2048)   14680064.0  42.682983  258502.312500    0.000165   \n",
       "726   (2048, 7168)   14680064.0  56.438549  267154.718750    0.000211   \n",
       "727   (2048, 7168)   14680064.0  40.821194  253036.984375    0.000161   \n",
       "730    (576, 7168)    4128768.0  47.905533  180060.421875    0.000266   \n",
       "731            NaN          NaN        NaN            NaN         NaN   \n",
       "732            NaN          NaN        NaN            NaN         NaN   \n",
       "734   (1536, 7168)   11010048.0  64.010201  335954.250000    0.000191   \n",
       "735            NaN          NaN        NaN            NaN         NaN   \n",
       "738    (256, 7168)    1835008.0  37.370094      21.695557    1.722477   \n",
       "739   (7168, 2048)   14680064.0  42.433987  253758.671875    0.000167   \n",
       "740   (2048, 7168)   14680064.0  58.619488  263933.625000    0.000222   \n",
       "741   (2048, 7168)   14680064.0  40.589417  246767.109375    0.000164   \n",
       "744    (576, 7168)    4128768.0  49.849182  182301.687500    0.000273   \n",
       "745            NaN          NaN        NaN            NaN         NaN   \n",
       "746            NaN          NaN        NaN            NaN         NaN   \n",
       "748   (1536, 7168)   11010048.0  64.376747  314651.562500    0.000205   \n",
       "749            NaN          NaN        NaN            NaN         NaN   \n",
       "752    (256, 7168)    1835008.0  35.798725      21.656708    1.653009   \n",
       "753   (7168, 2048)   14680064.0  42.254421  258464.078125    0.000163   \n",
       "754   (2048, 7168)   14680064.0  57.487576  267196.437500    0.000215   \n",
       "755   (2048, 7168)   14680064.0  41.106983  252560.531250    0.000163   \n",
       "758    (576, 7168)    4128768.0  42.294857  176369.859375    0.000240   \n",
       "759            NaN          NaN        NaN            NaN         NaN   \n",
       "760            NaN          NaN        NaN            NaN         NaN   \n",
       "762   (1536, 7168)   11010048.0  51.717434  347355.125000    0.000149   \n",
       "763            NaN          NaN        NaN            NaN         NaN   \n",
       "766    (256, 7168)    1835008.0  36.117199      20.357906    1.774112   \n",
       "767   (7168, 2048)   14680064.0  43.344177  256965.453125    0.000169   \n",
       "768   (2048, 7168)   14680064.0  58.638844  274772.812500    0.000213   \n",
       "769   (2048, 7168)   14680064.0  42.496319  268099.093750    0.000159   \n",
       "772    (576, 7168)    4128768.0  43.518063  166118.187500    0.000262   \n",
       "773            NaN          NaN        NaN            NaN         NaN   \n",
       "774            NaN          NaN        NaN            NaN         NaN   \n",
       "776   (1536, 7168)   11010048.0  46.662914  336636.906250    0.000139   \n",
       "777            NaN          NaN        NaN            NaN         NaN   \n",
       "780    (256, 7168)    1835008.0  34.743210      19.548061    1.777323   \n",
       "781   (7168, 2048)   14680064.0  43.350349  259602.890625    0.000167   \n",
       "782   (2048, 7168)   14680064.0  60.991867  277887.031250    0.000219   \n",
       "783   (2048, 7168)   14680064.0  43.234421  275242.437500    0.000157   \n",
       "786    (576, 7168)    4128768.0  47.597591  183532.031250    0.000259   \n",
       "787            NaN          NaN        NaN            NaN         NaN   \n",
       "788            NaN          NaN        NaN            NaN         NaN   \n",
       "790   (1536, 7168)   11010048.0  57.733204  339363.062500    0.000170   \n",
       "791            NaN          NaN        NaN            NaN         NaN   \n",
       "794    (256, 7168)    1835008.0  33.904938      19.602224    1.729648   \n",
       "795   (7168, 2048)   14680064.0  45.071590  254212.046875    0.000177   \n",
       "796   (2048, 7168)   14680064.0  64.227753  278233.968750    0.000231   \n",
       "797   (2048, 7168)   14680064.0  45.738163  279941.000000    0.000163   \n",
       "800    (576, 7168)    4128768.0  42.971287  165510.984375    0.000260   \n",
       "801            NaN          NaN        NaN            NaN         NaN   \n",
       "802            NaN          NaN        NaN            NaN         NaN   \n",
       "804   (1536, 7168)   11010048.0  56.423298  324759.031250    0.000174   \n",
       "805            NaN          NaN        NaN            NaN         NaN   \n",
       "808    (256, 7168)    1835008.0  33.004986      20.246275    1.630176   \n",
       "809   (7168, 2048)   14680064.0  46.850452  248567.453125    0.000188   \n",
       "810   (2048, 7168)   14680064.0  65.613007  278620.093750    0.000235   \n",
       "811   (2048, 7168)   14680064.0  48.656509  268330.593750    0.000181   \n",
       "814    (576, 7168)    4128768.0  42.285824  192984.609375    0.000219   \n",
       "815            NaN          NaN        NaN            NaN         NaN   \n",
       "816            NaN          NaN        NaN            NaN         NaN   \n",
       "818   (1536, 7168)   11010048.0  47.141296  278748.437500    0.000169   \n",
       "819            NaN          NaN        NaN            NaN         NaN   \n",
       "822    (256, 7168)    1835008.0  30.243559      21.967958    1.376712   \n",
       "823   (7168, 2048)   14680064.0  46.900597  232829.328125    0.000201   \n",
       "824   (2048, 7168)   14680064.0  66.756119  253401.437500    0.000263   \n",
       "825   (2048, 7168)   14680064.0  48.777443  239059.500000    0.000204   \n",
       "828    (576, 7168)    4128768.0  48.823463  166728.703125    0.000293   \n",
       "829            NaN          NaN        NaN            NaN         NaN   \n",
       "830            NaN          NaN        NaN            NaN         NaN   \n",
       "832   (1536, 7168)   11010048.0  59.075577  329189.125000    0.000179   \n",
       "833            NaN          NaN        NaN            NaN         NaN   \n",
       "836    (256, 7168)    1835008.0  29.131956      29.370396    0.991882   \n",
       "837   (7168, 2048)   14680064.0  46.158073  202610.562500    0.000228   \n",
       "838   (2048, 7168)   14680064.0  64.730461  255341.218750    0.000254   \n",
       "839   (2048, 7168)   14680064.0  50.728722  222510.703125    0.000228   \n",
       "842    (576, 7168)    4128768.0  47.286278  185368.171875    0.000255   \n",
       "843            NaN          NaN        NaN            NaN         NaN   \n",
       "844            NaN          NaN        NaN            NaN         NaN   \n",
       "846   (1536, 7168)   11010048.0  56.993889  261524.468750    0.000218   \n",
       "847            NaN          NaN        NaN            NaN         NaN   \n",
       "\n",
       "           mean_a        mean_b    mean_ratio     std_a       std_b  \\\n",
       "1    1.938400e-07 -5.042707e-03  1.938400e+05  0.005191   37.320744   \n",
       "2   -1.141391e-05  2.023005e-01 -5.642058e-05  0.004924   20.313309   \n",
       "3    4.222969e-07 -3.271475e-03  4.222969e+05  0.004470   51.244949   \n",
       "6    8.415574e-06 -5.285055e-02  8.415574e+06  0.021105   70.407242   \n",
       "7             NaN           NaN           NaN       NaN         NaN   \n",
       "8             NaN           NaN           NaN       NaN         NaN   \n",
       "10   1.081290e-06 -1.848673e-02  1.081290e+06  0.009887   89.141144   \n",
       "11            NaN           NaN           NaN       NaN         NaN   \n",
       "13   1.974590e-08 -6.014036e-03  1.974590e+04  0.002702   27.100826   \n",
       "14   7.893201e-06  2.129500e-01  3.706598e-05  0.004019   23.953739   \n",
       "15  -7.624888e-08  7.651516e-03 -9.965200e-06  0.002099   34.701054   \n",
       "18  -4.458476e-08 -2.386205e-02 -4.458476e+04  0.014048   58.640915   \n",
       "19            NaN           NaN           NaN       NaN         NaN   \n",
       "20            NaN           NaN           NaN       NaN         NaN   \n",
       "22   3.607209e-07 -9.147654e-03  3.607209e+05  0.005387   53.122345   \n",
       "23            NaN           NaN           NaN       NaN         NaN   \n",
       "25   2.642451e-07 -2.943784e-04  2.642451e+05  0.003055   22.072577   \n",
       "26   3.276502e-06  9.338737e-02  3.508507e-05  0.004170   17.538445   \n",
       "27   2.105856e-07  9.443110e-04  2.230045e-04  0.002489   28.279673   \n",
       "30  -3.046824e-06 -1.653090e-02 -3.046824e+06  0.013708   48.493622   \n",
       "31            NaN           NaN           NaN       NaN         NaN   \n",
       "32            NaN           NaN           NaN       NaN         NaN   \n",
       "34  -2.569489e-06 -1.133139e-02 -2.569488e+06  0.007206   58.243946   \n",
       "35            NaN           NaN           NaN       NaN         NaN   \n",
       "38   7.770116e-05  1.165834e-04  6.664856e-01  0.021699    0.024639   \n",
       "39  -2.374483e-06 -6.645652e-03 -2.374483e+06  0.007474   63.036152   \n",
       "40   3.296047e-05  2.247492e-01  1.466545e-04  0.008192   60.259205   \n",
       "41   6.067139e-07  1.293623e-03  4.690038e-04  0.006688   92.808113   \n",
       "44   5.541524e-06  3.586704e-02  1.545019e-04  0.016867   68.685829   \n",
       "45            NaN           NaN           NaN       NaN         NaN   \n",
       "46            NaN           NaN           NaN       NaN         NaN   \n",
       "48  -1.298052e-06  1.999416e-02 -6.492158e-05  0.011327   67.349655   \n",
       "49            NaN           NaN           NaN       NaN         NaN   \n",
       "52   9.968146e-05  1.027509e-04  9.701275e-01  0.029590    0.028274   \n",
       "53   9.522834e-07 -7.535151e-03  9.522834e+05  0.008192   65.950188   \n",
       "54   3.550852e-05  2.336629e-01  1.519648e-04  0.013967   52.351864   \n",
       "55   2.896452e-08 -2.909102e-02  2.896452e+04  0.007852   88.836830   \n",
       "58  -4.588853e-06  4.405908e-02 -1.041523e-04  0.017054   75.694916   \n",
       "59            NaN           NaN           NaN       NaN         NaN   \n",
       "60            NaN           NaN           NaN       NaN         NaN   \n",
       "62   8.800778e-07  3.902343e-03  2.255255e-04  0.008944   86.321419   \n",
       "63            NaN           NaN           NaN       NaN         NaN   \n",
       "66   6.166619e-05  1.320220e-04  4.670901e-01  0.035166    0.034701   \n",
       "67   3.037285e-06  4.000738e-03  7.591810e-04  0.008451   67.437164   \n",
       "68   3.864144e-05  4.771323e-01  8.098686e-05  0.015258   53.249321   \n",
       "69  -1.867902e-07 -7.872188e-03 -1.867902e+05  0.008528   84.185272   \n",
       "72  -3.083006e-06  2.253130e-02 -1.368322e-04  0.019620   62.719273   \n",
       "73            NaN           NaN           NaN       NaN         NaN   \n",
       "74            NaN           NaN           NaN       NaN         NaN   \n",
       "76  -6.152970e-06  6.052906e-03 -1.016532e-03  0.010826   81.052742   \n",
       "77            NaN           NaN           NaN       NaN         NaN   \n",
       "80   3.220308e-05 -1.018610e-04  3.220308e+07  0.038428    0.037840   \n",
       "81   1.716296e-06 -2.312120e-02  1.716296e+06  0.009201   69.371590   \n",
       "82  -7.949048e-06  2.292349e-01 -3.467642e-05  0.017113   54.333893   \n",
       "83   4.467801e-07 -1.222656e-02  4.467801e+05  0.009305   82.534065   \n",
       "86   7.151962e-07  5.476070e-02  1.306039e-05  0.017510   81.288063   \n",
       "87            NaN           NaN           NaN       NaN         NaN   \n",
       "88            NaN           NaN           NaN       NaN         NaN   \n",
       "90  -2.548874e-06 -2.222098e-02 -2.548874e+06  0.009898   82.059593   \n",
       "91            NaN           NaN           NaN       NaN         NaN   \n",
       "94   1.989925e-04 -5.538079e-05  1.989925e+08  0.045892    0.041844   \n",
       "95   6.911815e-07 -3.381542e-03  6.911815e+05  0.008923   71.692192   \n",
       "96   5.357097e-05  1.608118e-01  3.331284e-04  0.019312   56.105476   \n",
       "97  -3.694102e-06  2.692454e-02 -1.372020e-04  0.009525   77.331161   \n",
       "100 -3.632149e-06 -5.050855e-02 -3.632149e+06  0.021735   77.893707   \n",
       "101           NaN           NaN           NaN       NaN         NaN   \n",
       "102           NaN           NaN           NaN       NaN         NaN   \n",
       "104  3.162919e-06 -2.790407e-02  3.162919e+06  0.013384   86.347496   \n",
       "105           NaN           NaN           NaN       NaN         NaN   \n",
       "108  4.126995e-04  7.247948e-05  5.694018e+00  0.047185    0.039114   \n",
       "109  1.845480e-06 -2.657622e-03  1.845480e+06  0.009768   60.788536   \n",
       "110  2.012922e-04  3.143978e-01  6.402470e-04  0.021868   58.473953   \n",
       "111  6.882189e-07  3.672514e-02  1.873972e-05  0.010320   75.113144   \n",
       "114 -2.210979e-07  2.284615e-02 -9.677687e-06  0.021758   73.193909   \n",
       "115           NaN           NaN           NaN       NaN         NaN   \n",
       "116           NaN           NaN           NaN       NaN         NaN   \n",
       "118  1.262830e-05  2.441130e-03  5.173140e-03  0.013209   82.976860   \n",
       "119           NaN           NaN           NaN       NaN         NaN   \n",
       "122  3.828389e-04  1.262108e-04  3.033328e+00  0.045408    0.039618   \n",
       "123 -7.462968e-07 -5.120226e-05 -7.462969e+05  0.010668   65.521454   \n",
       "124  2.213672e-04  2.932894e-01  7.547740e-04  0.022587   55.219490   \n",
       "125 -2.680473e-07 -9.782354e-03 -2.680473e+05  0.010723   68.973503   \n",
       "128  1.195049e-06  5.308273e-02  2.251295e-05  0.021626   84.523651   \n",
       "129           NaN           NaN           NaN       NaN         NaN   \n",
       "130           NaN           NaN           NaN       NaN         NaN   \n",
       "132  5.205086e-06  2.235255e-02  2.328632e-04  0.012823   97.150070   \n",
       "133           NaN           NaN           NaN       NaN         NaN   \n",
       "136  4.075590e-04  1.312464e-04  3.105295e+00  0.044264    0.041706   \n",
       "137 -4.547229e-06 -2.533327e-03 -4.547230e+06  0.011826   68.893005   \n",
       "138  2.173313e-04  7.173754e-02  3.029533e-03  0.023902   53.574089   \n",
       "139 -6.160434e-06  9.338681e-03 -6.596685e-04  0.011367   68.476036   \n",
       "142 -3.878666e-06  1.243844e-03 -3.118289e-03  0.022886   81.681343   \n",
       "143           NaN           NaN           NaN       NaN         NaN   \n",
       "144           NaN           NaN           NaN       NaN         NaN   \n",
       "146 -5.362010e-06 -3.328361e-02 -5.362010e+06  0.013147   97.658493   \n",
       "147           NaN           NaN           NaN       NaN         NaN   \n",
       "150  4.563871e-04  2.085474e-04  2.188409e+00  0.045295    0.042433   \n",
       "151  1.679038e-06  1.292949e-02  1.298611e-04  0.010953   65.355827   \n",
       "152  2.190171e-04  1.562747e-02  1.401488e-02  0.024615   53.833389   \n",
       "153  7.714563e-07  8.034391e-03  9.601926e-05  0.011179   66.330795   \n",
       "156  2.028491e-06 -3.845371e-02  2.028491e+06  0.025006   94.853600   \n",
       "157           NaN           NaN           NaN       NaN         NaN   \n",
       "158           NaN           NaN           NaN       NaN         NaN   \n",
       "160  8.200746e-07  4.014836e-02  2.042610e-05  0.015901   92.693726   \n",
       "161           NaN           NaN           NaN       NaN         NaN   \n",
       "164  4.544015e-04  2.422025e-04  1.876122e+00  0.044962    0.040784   \n",
       "165 -2.420139e-06  1.095472e-02 -2.209221e-04  0.011655   68.317879   \n",
       "166  1.613195e-04 -4.928809e-02  1.613195e+08  0.023111   55.817215   \n",
       "167 -1.379924e-06  5.655065e-04 -2.440156e-03  0.011525   66.386482   \n",
       "170 -2.288964e-06  9.703936e-02 -2.358800e-05  0.023964   88.404106   \n",
       "171           NaN           NaN           NaN       NaN         NaN   \n",
       "172           NaN           NaN           NaN       NaN         NaN   \n",
       "174  3.287169e-06  4.231628e-03  7.768095e-04  0.014169   90.384285   \n",
       "175           NaN           NaN           NaN       NaN         NaN   \n",
       "178  2.984306e-04  2.348996e-04  1.270460e+00  0.046274    0.039882   \n",
       "179  2.263072e-06  2.233088e-02  1.013427e-04  0.011217   66.586540   \n",
       "180  9.398915e-05  9.880558e-02  9.512535e-04  0.020947   51.494320   \n",
       "181  1.542116e-06  3.286558e-02  4.692192e-05  0.011320   65.031044   \n",
       "184  4.309190e-06  7.512900e-02  5.735721e-05  0.025035   91.670570   \n",
       "185           NaN           NaN           NaN       NaN         NaN   \n",
       "186           NaN           NaN           NaN       NaN         NaN   \n",
       "188 -1.320386e-06  1.594279e-02 -8.282024e-05  0.016522   91.441566   \n",
       "189           NaN           NaN           NaN       NaN         NaN   \n",
       "192  3.551023e-04  4.025494e-04  8.821335e-01  0.046640    0.038392   \n",
       "193 -3.134209e-06 -2.396222e-02 -3.134208e+06  0.011404   66.123482   \n",
       "194  8.412390e-05  8.334381e-02  1.009360e-03  0.021681   39.748058   \n",
       "195 -2.181807e-06 -1.616513e-02 -2.181807e+06  0.011494   62.347771   \n",
       "198 -1.168154e-05  3.427737e-02 -3.407946e-04  0.025184   93.126350   \n",
       "199           NaN           NaN           NaN       NaN         NaN   \n",
       "200           NaN           NaN           NaN       NaN         NaN   \n",
       "202  6.371345e-06 -2.448407e-03  6.371344e+06  0.018737   94.875511   \n",
       "203           NaN           NaN           NaN       NaN         NaN   \n",
       "206  1.851208e-04  3.350106e-04  5.525820e-01  0.047135    0.036810   \n",
       "207  2.060468e-06  7.649785e-03  2.693498e-04  0.011207   60.437206   \n",
       "208  4.140424e-05  7.981002e-02  5.187850e-04  0.020055   40.310303   \n",
       "209  2.608207e-06 -1.491899e-02  2.608207e+06  0.011135   60.383430   \n",
       "212 -2.157557e-05  3.859184e-03 -5.590707e-03  0.025387   95.740532   \n",
       "213           NaN           NaN           NaN       NaN         NaN   \n",
       "214           NaN           NaN           NaN       NaN         NaN   \n",
       "216  9.261754e-06  3.194254e-02  2.899505e-04  0.020201   97.516869   \n",
       "217           NaN           NaN           NaN       NaN         NaN   \n",
       "220  5.022708e-05  4.078590e-04  1.231481e-01  0.045807    0.037826   \n",
       "221 -1.771797e-06 -2.997688e-05 -1.771797e+06  0.011771   65.537636   \n",
       "222  1.298265e-05  5.368698e-02  2.418213e-04  0.019609   33.931076   \n",
       "223  5.882713e-07 -2.174682e-02  5.882714e+05  0.011594   60.461372   \n",
       "226  1.287167e-05 -2.249974e-02  1.287167e+07  0.023871   93.018517   \n",
       "227           NaN           NaN           NaN       NaN         NaN   \n",
       "228           NaN           NaN           NaN       NaN         NaN   \n",
       "230  7.903849e-07 -3.563926e-02  7.903849e+05  0.017940  100.642151   \n",
       "231           NaN           NaN           NaN       NaN         NaN   \n",
       "234  4.912720e-05  2.551288e-04  1.925584e-01  0.046323    0.036437   \n",
       "235 -1.787721e-06 -1.017821e-02 -1.787721e+06  0.011001   64.482819   \n",
       "236  1.781603e-05  1.264764e-02  1.408644e-03  0.018851   47.398262   \n",
       "237  3.127269e-06 -2.167179e-03  3.127269e+06  0.010980   65.955437   \n",
       "240  1.038563e-05 -2.859824e-02  1.038563e+07  0.025715   83.785439   \n",
       "241           NaN           NaN           NaN       NaN         NaN   \n",
       "242           NaN           NaN           NaN       NaN         NaN   \n",
       "244 -4.929692e-06 -1.455903e-02 -4.929692e+06  0.019633   96.779587   \n",
       "245           NaN           NaN           NaN       NaN         NaN   \n",
       "248 -1.113991e-06  6.144195e-05 -1.813078e-02  0.046068    0.035017   \n",
       "249  1.445487e-06 -1.753473e-04  1.445487e+06  0.011363   62.753994   \n",
       "250 -1.824098e-06 -1.665290e-02 -1.824098e+06  0.017775   45.440990   \n",
       "251  4.456436e-06 -2.655647e-02  4.456436e+06  0.011241   64.063927   \n",
       "254  9.768949e-06 -3.703205e-02  9.768949e+06  0.024616   91.854195   \n",
       "255           NaN           NaN           NaN       NaN         NaN   \n",
       "256           NaN           NaN           NaN       NaN         NaN   \n",
       "258 -1.355623e-06  6.798734e-02 -1.993935e-05  0.016820  101.185501   \n",
       "259           NaN           NaN           NaN       NaN         NaN   \n",
       "262 -1.221991e-05  1.062308e-04 -1.150317e-01  0.046570    0.033781   \n",
       "263  5.718708e-07 -1.643468e-02  5.718708e+05  0.012108   60.194527   \n",
       "264 -1.808949e-05 -8.035551e-02 -1.808949e+07  0.019399   47.863373   \n",
       "265  1.905539e-06 -1.813463e-02  1.905539e+06  0.012126   61.589142   \n",
       "268  1.245191e-05 -1.889592e-02  1.245192e+07  0.026223   94.355164   \n",
       "269           NaN           NaN           NaN       NaN         NaN   \n",
       "270           NaN           NaN           NaN       NaN         NaN   \n",
       "272  3.105785e-06  3.046496e-02  1.019461e-04  0.020214  102.816933   \n",
       "273           NaN           NaN           NaN       NaN         NaN   \n",
       "276 -5.842796e-06  2.846467e-05 -2.052648e-01  0.045750    0.034091   \n",
       "277  9.818995e-06  1.695100e-02  5.792574e-04  0.011797   64.682808   \n",
       "278  1.465653e-05 -1.079188e-01  1.465653e+07  0.018348   52.175667   \n",
       "279  2.387375e-06 -3.892486e-03  2.387375e+06  0.011649   65.660934   \n",
       "282 -6.229685e-06  7.405902e-02 -8.411784e-05  0.025633   93.408730   \n",
       "283           NaN           NaN           NaN       NaN         NaN   \n",
       "284           NaN           NaN           NaN       NaN         NaN   \n",
       "286  7.624965e-06 -1.217848e-02  7.624965e+06  0.017554  106.158806   \n",
       "287           NaN           NaN           NaN       NaN         NaN   \n",
       "290 -4.725270e-05  7.091826e-05 -6.662980e-01  0.044930    0.032146   \n",
       "291  1.960684e-06 -1.130648e-02  1.960684e+06  0.012510   67.589737   \n",
       "292 -1.311062e-05 -7.179382e-02 -1.311062e+07  0.017870   58.271381   \n",
       "293 -1.868062e-06 -6.031224e-04 -1.868062e+06  0.012254   67.338104   \n",
       "296 -1.446391e-05  5.707364e-02 -2.534253e-04  0.024904   91.212624   \n",
       "297           NaN           NaN           NaN       NaN         NaN   \n",
       "298           NaN           NaN           NaN       NaN         NaN   \n",
       "300  1.119392e-06 -2.197577e-02  1.119392e+06  0.017317  105.255188   \n",
       "301           NaN           NaN           NaN       NaN         NaN   \n",
       "304 -1.530145e-04  2.700510e-05 -5.666134e+00  0.045478    0.030806   \n",
       "305  2.318720e-06 -1.888927e-03  2.318720e+06  0.012153   61.993645   \n",
       "306 -4.016560e-06 -1.647688e-01 -4.016560e+06  0.017484   57.527512   \n",
       "307  5.867026e-06 -6.488448e-03  5.867026e+06  0.012010   63.607864   \n",
       "310  1.410764e-05 -7.414980e-02  1.410764e+07  0.025872   87.821396   \n",
       "311           NaN           NaN           NaN       NaN         NaN   \n",
       "312           NaN           NaN           NaN       NaN         NaN   \n",
       "314 -6.649078e-06 -5.937477e-02 -6.649078e+06  0.019724  105.574318   \n",
       "315           NaN           NaN           NaN       NaN         NaN   \n",
       "318 -2.331353e-04  1.089518e-07 -2.139803e+03  0.045063    0.028586   \n",
       "319  5.785107e-07 -1.659142e-02  5.785106e+05  0.012270   64.125565   \n",
       "320  1.733290e-06 -2.156630e-01  1.733290e+06  0.016163   59.885452   \n",
       "321 -1.802183e-06 -1.224682e-02 -1.802183e+06  0.012111   62.086426   \n",
       "324 -7.090073e-06  3.424453e-02 -2.070425e-04  0.025295   91.316360   \n",
       "325           NaN           NaN           NaN       NaN         NaN   \n",
       "326           NaN           NaN           NaN       NaN         NaN   \n",
       "328 -1.075843e-05  1.588381e-02 -6.773203e-04  0.020301  106.130531   \n",
       "329           NaN           NaN           NaN       NaN         NaN   \n",
       "332 -2.001737e-04  1.250116e-05 -1.601241e+01  0.044343    0.027614   \n",
       "333  2.557896e-06 -5.352998e-03  2.557896e+06  0.011987   66.320076   \n",
       "334 -5.872026e-06 -2.892585e-01 -5.872026e+06  0.015699   58.458031   \n",
       "335  3.839652e-06 -7.054937e-03  3.839652e+06  0.011748   60.015942   \n",
       "338 -9.493078e-06  3.381686e-02 -2.807202e-04  0.026128   86.926315   \n",
       "339           NaN           NaN           NaN       NaN         NaN   \n",
       "340           NaN           NaN           NaN       NaN         NaN   \n",
       "342 -8.975815e-06  9.288421e-02 -9.663446e-05  0.022895  105.833694   \n",
       "343           NaN           NaN           NaN       NaN         NaN   \n",
       "346 -2.069383e-04 -1.533429e-05 -2.069384e+08  0.043450    0.027468   \n",
       "347  4.622842e-06  1.639827e-02  2.819104e-04  0.011435   68.695694   \n",
       "348 -5.015406e-06 -3.113505e-01 -5.015406e+06  0.014653   54.807526   \n",
       "349 -3.569238e-07 -2.094859e-02 -3.569238e+05  0.011205   60.274117   \n",
       "352 -3.956973e-06  5.946008e-02 -6.654839e-05  0.025757   82.116997   \n",
       "353           NaN           NaN           NaN       NaN         NaN   \n",
       "354           NaN           NaN           NaN       NaN         NaN   \n",
       "356 -7.950891e-06  1.419720e-02 -5.600323e-04  0.021725  105.261940   \n",
       "357           NaN           NaN           NaN       NaN         NaN   \n",
       "360 -2.780234e-04  4.305819e-05 -6.456923e+00  0.042963    0.027442   \n",
       "361 -2.007923e-06 -1.622766e-02 -2.007923e+06  0.011906   69.248978   \n",
       "362 -5.254829e-06 -3.287365e-01 -5.254830e+06  0.014781   56.592617   \n",
       "363  1.348566e-06 -2.978748e-03  1.348566e+06  0.011692   63.231472   \n",
       "366  1.296716e-05 -2.945281e-03  1.296716e+07  0.025355   87.556984   \n",
       "367           NaN           NaN           NaN       NaN         NaN   \n",
       "368           NaN           NaN           NaN       NaN         NaN   \n",
       "370  8.303167e-08  5.813380e-03  1.428286e-05  0.021081  104.683365   \n",
       "371           NaN           NaN           NaN       NaN         NaN   \n",
       "374 -1.634033e-04  3.412114e-05 -4.788915e+00  0.042653    0.026906   \n",
       "375 -2.963604e-06 -3.467131e-03 -2.963604e+06  0.010741   74.328285   \n",
       "376 -2.033020e-06 -3.252713e-01 -2.033020e+06  0.012822   59.800095   \n",
       "377  1.440451e-06 -8.315486e-03  1.440451e+06  0.010603   66.832832   \n",
       "380  2.422474e-05 -2.134536e-02  2.422474e+07  0.024430   80.908165   \n",
       "381           NaN           NaN           NaN       NaN         NaN   \n",
       "382           NaN           NaN           NaN       NaN         NaN   \n",
       "384  6.848127e-06 -1.303290e-02  6.848127e+06  0.020790   99.834404   \n",
       "385           NaN           NaN           NaN       NaN         NaN   \n",
       "388 -1.894469e-04 -1.777002e-05 -1.894469e+08  0.042107    0.026106   \n",
       "389  2.965367e-06  3.939144e-02  7.527947e-05  0.012497   73.834450   \n",
       "390  1.570648e-07 -2.391088e-01  1.570648e+05  0.014828   55.415562   \n",
       "391  2.451872e-06  3.403801e-02  7.203335e-05  0.012058   66.363869   \n",
       "394 -1.555544e-05 -4.958065e-02 -1.555544e+07  0.025705   88.940269   \n",
       "395           NaN           NaN           NaN       NaN         NaN   \n",
       "396           NaN           NaN           NaN       NaN         NaN   \n",
       "398  4.962117e-06  1.478509e-02  3.356162e-04  0.021783  105.813599   \n",
       "399           NaN           NaN           NaN       NaN         NaN   \n",
       "402 -2.449994e-04  4.622344e-05 -5.300328e+00  0.041997    0.026148   \n",
       "403  6.203331e-06  7.772340e-03  7.981291e-04  0.012303   72.667374   \n",
       "404 -9.100067e-06 -3.669771e-01 -9.100068e+06  0.014147   59.863251   \n",
       "405 -3.288569e-06 -1.102681e-02 -3.288569e+06  0.011964   66.907257   \n",
       "408 -1.703942e-07  4.032629e-03 -4.225387e-05  0.025883   91.589745   \n",
       "409           NaN           NaN           NaN       NaN         NaN   \n",
       "410           NaN           NaN           NaN       NaN         NaN   \n",
       "412  4.319254e-07  3.405518e-02  1.268310e-05  0.023976  103.821999   \n",
       "413           NaN           NaN           NaN       NaN         NaN   \n",
       "416 -1.777210e-04 -7.934801e-05 -1.777210e+08  0.041487    0.026225   \n",
       "417 -2.315411e-06  5.455615e-03 -4.244088e-04  0.012263   72.891472   \n",
       "418  1.553173e-05 -2.199446e-01  1.553173e+07  0.014568   58.028320   \n",
       "419 -3.223807e-06 -4.895579e-03 -3.223807e+06  0.011995   66.287956   \n",
       "422 -2.392116e-06  4.066739e-02 -5.882148e-05  0.023215   91.859833   \n",
       "423           NaN           NaN           NaN       NaN         NaN   \n",
       "424           NaN           NaN           NaN       NaN         NaN   \n",
       "426 -3.602708e-06 -6.330750e-03 -3.602708e+06  0.021197  104.732697   \n",
       "427           NaN           NaN           NaN       NaN         NaN   \n",
       "430 -1.708427e-04 -7.752867e-05 -1.708427e+08  0.040134    0.025134   \n",
       "431  5.314093e-07  8.933453e-03  5.948532e-05  0.012002   71.532806   \n",
       "432  7.053688e-06 -2.400984e-01  7.053688e+06  0.013882   55.767273   \n",
       "433 -4.167405e-06 -9.471465e-03 -4.167405e+06  0.011789   63.387787   \n",
       "436 -6.090719e-06 -2.176526e-02 -6.090718e+06  0.024148   86.476509   \n",
       "437           NaN           NaN           NaN       NaN         NaN   \n",
       "438           NaN           NaN           NaN       NaN         NaN   \n",
       "440  5.583176e-06  4.792462e-03  1.164991e-03  0.021689   99.886757   \n",
       "441           NaN           NaN           NaN       NaN         NaN   \n",
       "444 -1.149284e-04 -3.365870e-05 -1.149284e+08  0.039834    0.024708   \n",
       "445  4.064856e-07 -1.043761e-02  4.064856e+05  0.012608   70.596008   \n",
       "446  1.142472e-05 -2.508570e-01  1.142472e+07  0.014133   55.349747   \n",
       "447 -4.910673e-06  9.193955e-03 -5.341198e-04  0.012335   63.038136   \n",
       "450  6.047038e-06 -4.908935e-02  6.047038e+06  0.024128   88.528648   \n",
       "451           NaN           NaN           NaN       NaN         NaN   \n",
       "452           NaN           NaN           NaN       NaN         NaN   \n",
       "454 -1.429682e-06  4.509106e-02 -3.170655e-05  0.022425  104.493759   \n",
       "455           NaN           NaN           NaN       NaN         NaN   \n",
       "458 -1.508373e-04  2.858262e-05 -5.277240e+00  0.038994    0.025553   \n",
       "459  5.842824e-07 -9.231600e-03  5.842824e+05  0.012878   70.013916   \n",
       "460  3.733487e-06 -3.760223e-01  3.733487e+06  0.014176   64.930260   \n",
       "461  2.896968e-06  2.988487e-03  9.693764e-04  0.012671   66.436310   \n",
       "464  3.885699e-06  6.064153e-02  6.407653e-05  0.026009   84.975517   \n",
       "465           NaN           NaN           NaN       NaN         NaN   \n",
       "466           NaN           NaN           NaN       NaN         NaN   \n",
       "468  8.868068e-06 -6.743153e-03  8.868068e+06  0.023233  105.147415   \n",
       "469           NaN           NaN           NaN       NaN         NaN   \n",
       "472 -1.320829e-04 -4.541640e-05 -1.320829e+08  0.038246    0.024404   \n",
       "473 -1.152634e-06 -1.972780e-03 -1.152634e+06  0.012691   71.629173   \n",
       "474  8.834773e-06 -2.911580e-01  8.834773e+06  0.014209   62.479534   \n",
       "475  1.993115e-06  8.235618e-03  2.420116e-04  0.012305   64.925858   \n",
       "478  3.030488e-06 -3.417383e-02  3.030488e+06  0.026158   72.769676   \n",
       "479           NaN           NaN           NaN       NaN         NaN   \n",
       "480           NaN           NaN           NaN       NaN         NaN   \n",
       "482 -1.396485e-07 -8.308860e-03 -1.396485e+05  0.023599  105.089142   \n",
       "483           NaN           NaN           NaN       NaN         NaN   \n",
       "486 -1.692496e-04  2.098504e-05 -8.065253e+00  0.038042    0.024120   \n",
       "487  4.154171e-06 -7.816254e-03  4.154171e+06  0.012416   66.333588   \n",
       "488  1.108182e-06 -2.339160e-01  1.108182e+06  0.014101   62.098629   \n",
       "489  6.086235e-07 -9.359336e-03  6.086235e+05  0.012313   59.635708   \n",
       "492  2.475617e-05 -1.117020e-01  2.475617e+07  0.026191   83.241516   \n",
       "493           NaN           NaN           NaN       NaN         NaN   \n",
       "494           NaN           NaN           NaN       NaN         NaN   \n",
       "496  7.585611e-06  4.504902e-03  1.683857e-03  0.023314  102.361404   \n",
       "497           NaN           NaN           NaN       NaN         NaN   \n",
       "500 -1.491089e-04 -1.254909e-04 -1.491089e+08  0.037504    0.024365   \n",
       "501 -3.236842e-06  1.374267e-02 -2.355323e-04  0.012388   69.300026   \n",
       "502  1.347473e-05 -2.921647e-01  1.347473e+07  0.014455   66.486938   \n",
       "503 -2.656181e-06 -2.184244e-02 -2.656181e+06  0.012666   65.394508   \n",
       "506 -3.073183e-05 -9.216955e-02 -3.073183e+07  0.023338   91.498039   \n",
       "507           NaN           NaN           NaN       NaN         NaN   \n",
       "508           NaN           NaN           NaN       NaN         NaN   \n",
       "510  8.923560e-07  1.168493e-02  7.636809e-05  0.019430  106.032204   \n",
       "511           NaN           NaN           NaN       NaN         NaN   \n",
       "514 -1.105045e-04 -1.708675e-04 -1.105045e+08  0.037508    0.023581   \n",
       "515  1.395854e-07 -2.267782e-03  1.395854e+05  0.012051   68.944221   \n",
       "516  4.846256e-06 -1.937132e-01  4.846256e+06  0.014062   62.263241   \n",
       "517 -1.477660e-06 -2.003634e-02 -1.477660e+06  0.012158   64.287193   \n",
       "520 -1.492910e-05 -3.902095e-02 -1.492910e+07  0.024621   83.566223   \n",
       "521           NaN           NaN           NaN       NaN         NaN   \n",
       "522           NaN           NaN           NaN       NaN         NaN   \n",
       "524 -4.557790e-06  5.746814e-02 -7.930986e-05  0.021760  105.405632   \n",
       "525           NaN           NaN           NaN       NaN         NaN   \n",
       "528 -1.121770e-04 -1.210259e-04 -1.121770e+08  0.037259    0.023656   \n",
       "529  5.785394e-07 -6.294029e-03  5.785394e+05  0.012031   65.598831   \n",
       "530 -2.532516e-06 -2.024581e-01 -2.532516e+06  0.013753   62.480423   \n",
       "531  4.575153e-06 -9.745409e-03  4.575152e+06  0.012073   60.773392   \n",
       "534  8.130700e-06  2.347322e-02  3.463819e-04  0.025298   79.519371   \n",
       "535           NaN           NaN           NaN       NaN         NaN   \n",
       "536           NaN           NaN           NaN       NaN         NaN   \n",
       "538  4.217153e-06 -5.704076e-03  4.217153e+06  0.023003  106.593079   \n",
       "539           NaN           NaN           NaN       NaN         NaN   \n",
       "542 -1.869524e-04 -5.243882e-05 -1.869524e+08  0.037128    0.022443   \n",
       "543 -2.036382e-06 -5.447127e-03 -2.036382e+06  0.012097   66.179512   \n",
       "544  6.955045e-06 -1.972267e-01  6.955044e+06  0.014015   63.516895   \n",
       "545  4.115060e-07 -2.233913e-03  4.115060e+05  0.012404   60.855301   \n",
       "548 -1.187304e-05  8.978627e-04 -1.322367e-02  0.020877   77.472610   \n",
       "549           NaN           NaN           NaN       NaN         NaN   \n",
       "550           NaN           NaN           NaN       NaN         NaN   \n",
       "552  2.778476e-06  4.981333e-02  5.577775e-05  0.017924  106.064796   \n",
       "553           NaN           NaN           NaN       NaN         NaN   \n",
       "556 -1.270078e-04 -1.192450e-04 -1.270078e+08  0.035977    0.022345   \n",
       "557 -2.627695e-06  5.786971e-03 -4.540709e-04  0.012210   69.118950   \n",
       "558 -6.566966e-06 -2.019484e-01 -6.566966e+06  0.013783   65.238548   \n",
       "559 -3.257190e-06 -8.360455e-03 -3.257190e+06  0.012485   64.428314   \n",
       "562  5.031710e-06  7.347168e-03  6.848503e-04  0.025171   82.053139   \n",
       "563           NaN           NaN           NaN       NaN         NaN   \n",
       "564           NaN           NaN           NaN       NaN         NaN   \n",
       "566 -3.341826e-06 -1.406137e-02 -3.341826e+06  0.023217   97.202354   \n",
       "567           NaN           NaN           NaN       NaN         NaN   \n",
       "570 -1.830576e-04 -1.751987e-04 -1.830576e+08  0.034694    0.021876   \n",
       "571 -6.396671e-07 -7.341177e-03 -6.396671e+05  0.011862   65.128220   \n",
       "572  8.624909e-06 -1.405958e-01  8.624909e+06  0.013183   64.548592   \n",
       "573  6.162876e-07 -3.677541e-02  6.162876e+05  0.012068   59.725723   \n",
       "576 -6.090324e-06 -3.130476e-02 -6.090324e+06  0.024748   78.427406   \n",
       "577           NaN           NaN           NaN       NaN         NaN   \n",
       "578           NaN           NaN           NaN       NaN         NaN   \n",
       "580 -1.144068e-05  5.585783e-02 -2.048178e-04  0.021126  106.693237   \n",
       "581           NaN           NaN           NaN       NaN         NaN   \n",
       "584 -1.210729e-04 -1.989673e-04 -1.210729e+08  0.033203    0.021931   \n",
       "585  2.206265e-06  3.226588e-02  6.837764e-05  0.011675   64.400452   \n",
       "586  5.742945e-06 -1.902667e-01  5.742945e+06  0.013340   64.486053   \n",
       "587  2.934498e-06  1.086098e-02  2.701873e-04  0.011778   61.467045   \n",
       "590  9.309763e-06 -2.666127e-02  9.309763e+06  0.025148   86.665237   \n",
       "591           NaN           NaN           NaN       NaN         NaN   \n",
       "592           NaN           NaN           NaN       NaN         NaN   \n",
       "594 -6.279362e-06  2.139048e-03 -2.935587e-03  0.022708  107.621468   \n",
       "595           NaN           NaN           NaN       NaN         NaN   \n",
       "598 -1.609426e-04 -1.404632e-04 -1.609426e+08  0.033147    0.021416   \n",
       "599  3.613284e-06 -6.485780e-03  3.613284e+06  0.011681   60.210541   \n",
       "600 -7.717815e-06 -2.031770e-01 -7.717814e+06  0.013625   63.900448   \n",
       "601  3.854368e-06  1.034002e-02  3.727620e-04  0.011650   59.839645   \n",
       "604 -3.273722e-06 -5.559136e-02 -3.273722e+06  0.024724   75.338821   \n",
       "605           NaN           NaN           NaN       NaN         NaN   \n",
       "606           NaN           NaN           NaN       NaN         NaN   \n",
       "608  8.232048e-06  3.023849e-02  2.722374e-04  0.022601  104.802429   \n",
       "609           NaN           NaN           NaN       NaN         NaN   \n",
       "612 -1.530798e-04 -1.352092e-04 -1.530798e+08  0.032667    0.020872   \n",
       "613 -4.030531e-06 -7.940068e-03 -4.030531e+06  0.011577   61.793247   \n",
       "614  2.750955e-06 -1.850301e-01  2.750955e+06  0.013900   63.198639   \n",
       "615 -1.456514e-06  1.647042e-02 -8.843213e-05  0.011229   60.925915   \n",
       "618  4.592324e-06 -4.400600e-02  4.592324e+06  0.026193   89.177483   \n",
       "619           NaN           NaN           NaN       NaN         NaN   \n",
       "620           NaN           NaN           NaN       NaN         NaN   \n",
       "622  4.888307e-06  4.533396e-03  1.078288e-03  0.022160  100.050941   \n",
       "623           NaN           NaN           NaN       NaN         NaN   \n",
       "626 -1.046044e-04 -9.810292e-05 -1.046044e+08  0.032623    0.020572   \n",
       "627  3.017280e-06  2.051894e-02  1.470485e-04  0.011399   61.638622   \n",
       "628  3.023840e-06 -6.742522e-02  3.023840e+06  0.014170   62.437828   \n",
       "629  1.261310e-06  1.738634e-02  7.254606e-05  0.011281   58.249008   \n",
       "632 -1.813067e-06 -6.622984e-02 -1.813067e+06  0.022560   80.025360   \n",
       "633           NaN           NaN           NaN       NaN         NaN   \n",
       "634           NaN           NaN           NaN       NaN         NaN   \n",
       "636  1.783787e-06 -3.087820e-02  1.783786e+06  0.021932  104.505333   \n",
       "637           NaN           NaN           NaN       NaN         NaN   \n",
       "640 -1.596463e-04 -1.207755e-04 -1.596463e+08  0.030904    0.019725   \n",
       "641 -2.821200e-06  3.617537e-03 -7.798676e-04  0.011427   62.680706   \n",
       "642 -7.959879e-06 -1.582177e-01 -7.959880e+06  0.014033   67.306038   \n",
       "643 -7.313890e-06  5.653849e-03 -1.293612e-03  0.011187   59.199986   \n",
       "646  1.207770e-06  4.197418e-02  2.877413e-05  0.025974   71.090698   \n",
       "647           NaN           NaN           NaN       NaN         NaN   \n",
       "648           NaN           NaN           NaN       NaN         NaN   \n",
       "650 -2.672746e-06  1.946198e-02 -1.373317e-04  0.020106  101.973648   \n",
       "651           NaN           NaN           NaN       NaN         NaN   \n",
       "654 -1.012390e-04 -1.808002e-04 -1.012390e+08  0.030201    0.019172   \n",
       "655  1.819590e-06  2.766303e-03  6.577697e-04  0.011037   67.987389   \n",
       "656  2.148646e-05 -2.301417e-01  2.148646e+07  0.014349   69.584663   \n",
       "657 -7.760198e-07 -1.859942e-02 -7.760198e+05  0.010900   63.393131   \n",
       "660  6.802001e-06 -2.692598e-02  6.802002e+06  0.023027   67.269402   \n",
       "661           NaN           NaN           NaN       NaN         NaN   \n",
       "662           NaN           NaN           NaN       NaN         NaN   \n",
       "664 -1.184558e-05  4.968539e-02 -2.384118e-04  0.018563  103.499649   \n",
       "665           NaN           NaN           NaN       NaN         NaN   \n",
       "668 -1.089947e-04 -1.687905e-04 -1.089947e+08  0.030242    0.018836   \n",
       "669 -5.961533e-06  6.079135e-03 -9.806550e-04  0.010939   69.560707   \n",
       "670 -6.168965e-06 -2.367010e-01 -6.168965e+06  0.014570   69.359093   \n",
       "671 -4.853365e-06  1.312750e-04 -3.697098e-02  0.010802   62.976933   \n",
       "674 -4.431110e-06 -9.210092e-02 -4.431110e+06  0.021998   90.683762   \n",
       "675           NaN           NaN           NaN       NaN         NaN   \n",
       "676           NaN           NaN           NaN       NaN         NaN   \n",
       "678  3.629224e-06 -2.747159e-02  3.629224e+06  0.016440  104.962486   \n",
       "679           NaN           NaN           NaN       NaN         NaN   \n",
       "682 -9.340945e-05 -1.160686e-04 -9.340945e+07  0.030557    0.018274   \n",
       "683  2.065495e-06 -8.322178e-03  2.065495e+06  0.010927   68.942902   \n",
       "684 -9.959461e-08 -1.904464e-01 -9.959461e+04  0.014504   70.364494   \n",
       "685  2.872873e-07 -1.776119e-02  2.872873e+05  0.010964   63.561302   \n",
       "688 -3.225490e-06  2.155166e-02 -1.496631e-04  0.021265   84.970497   \n",
       "689           NaN           NaN           NaN       NaN         NaN   \n",
       "690           NaN           NaN           NaN       NaN         NaN   \n",
       "692 -6.610821e-06 -3.157791e-03 -6.610822e+06  0.016709  104.257576   \n",
       "693           NaN           NaN           NaN       NaN         NaN   \n",
       "696 -1.819975e-04 -1.049985e-04 -1.819975e+08  0.029484    0.017980   \n",
       "697 -3.709344e-06 -3.467460e-02 -3.709344e+06  0.010852   67.378258   \n",
       "698 -2.191403e-05 -1.845903e-01 -2.191403e+07  0.014442   69.431419   \n",
       "699  7.321877e-07 -1.483387e-03  7.321878e+05  0.010649   62.176151   \n",
       "702  5.950097e-06  5.554332e-02  1.071253e-04  0.025825   79.959450   \n",
       "703           NaN           NaN           NaN       NaN         NaN   \n",
       "704           NaN           NaN           NaN       NaN         NaN   \n",
       "706 -1.052833e-05  3.655579e-02 -2.880072e-04  0.022168  102.504456   \n",
       "707           NaN           NaN           NaN       NaN         NaN   \n",
       "710 -1.531837e-04 -1.507561e-04 -1.531837e+08  0.028924    0.017393   \n",
       "711 -3.844635e-06  6.481429e-03 -5.931771e-04  0.011067   71.532028   \n",
       "712 -4.383844e-06 -2.694015e-01 -4.383844e+06  0.014887   68.742569   \n",
       "713  3.685792e-07  5.844287e-03  6.306659e-05  0.010790   65.375931   \n",
       "716  7.729338e-06 -2.947754e-02  7.729338e+06  0.025845   78.918671   \n",
       "717           NaN           NaN           NaN       NaN         NaN   \n",
       "718           NaN           NaN           NaN       NaN         NaN   \n",
       "720  3.315716e-07 -3.104924e-02  3.315717e+05  0.019265  104.692764   \n",
       "721           NaN           NaN           NaN       NaN         NaN   \n",
       "724 -1.386354e-04 -1.537078e-04 -1.386354e+08  0.028304    0.017460   \n",
       "725  1.346152e-06 -1.024971e-02  1.346152e+06  0.011140   67.468399   \n",
       "726 -2.579942e-05 -3.413542e-01 -2.579942e+07  0.014730   69.725830   \n",
       "727  1.576601e-06  3.249281e-03  4.852152e-04  0.010654   66.041969   \n",
       "730  1.503743e-05 -3.311199e-02  1.503743e+07  0.023576   88.615150   \n",
       "731           NaN           NaN           NaN       NaN         NaN   \n",
       "732           NaN           NaN           NaN       NaN         NaN   \n",
       "734  8.073707e-06 -3.664225e-02  8.073708e+06  0.019291  101.247780   \n",
       "735           NaN           NaN           NaN       NaN         NaN   \n",
       "738 -7.633631e-05 -1.765326e-04 -7.633631e+07  0.027587    0.016015   \n",
       "739 -2.738451e-06  4.667359e-03 -5.867240e-04  0.011075   66.230324   \n",
       "740 -2.242682e-05 -2.347590e-01 -2.242682e+07  0.015300   68.885559   \n",
       "741 -5.489941e-06 -3.485284e-02 -5.489941e+06  0.010594   64.405540   \n",
       "744  4.912959e-06 -4.510187e-02  4.912959e+06  0.024533   89.718170   \n",
       "745           NaN           NaN           NaN       NaN         NaN   \n",
       "746           NaN           NaN           NaN       NaN         NaN   \n",
       "748  7.497435e-06 -3.885011e-02  7.497435e+06  0.019401   94.827713   \n",
       "749           NaN           NaN           NaN       NaN         NaN   \n",
       "752 -1.216935e-04 -9.439918e-05 -1.216935e+08  0.026427    0.015987   \n",
       "753 -9.516548e-07 -1.052500e-02 -9.516548e+05  0.011028   67.458427   \n",
       "754 -3.175724e-05 -1.723170e-01 -3.175724e+07  0.015004   69.737335   \n",
       "755  3.281851e-07 -1.137515e-02  3.281851e+05  0.010729   65.917618   \n",
       "758 -1.530643e-05 -1.975615e-03 -1.530643e+07  0.020815   86.798882   \n",
       "759           NaN           NaN           NaN       NaN         NaN   \n",
       "760           NaN           NaN           NaN       NaN         NaN   \n",
       "762 -7.407287e-07  2.083170e-02 -3.555777e-05  0.015586  104.683708   \n",
       "763           NaN           NaN           NaN       NaN         NaN   \n",
       "766 -4.039209e-05 -1.072185e-04 -4.039209e+07  0.026662    0.015028   \n",
       "767  4.297632e-06  7.255935e-03  5.922920e-04  0.011313   67.067284   \n",
       "768 -4.038461e-05 -1.469817e-01 -4.038461e+07  0.015305   71.714813   \n",
       "769  1.203183e-06  4.487616e-03  2.681118e-04  0.011091   69.973145   \n",
       "772 -6.869784e-06  1.160942e-02 -5.917421e-04  0.021417   81.753609   \n",
       "773           NaN           NaN           NaN       NaN         NaN   \n",
       "774           NaN           NaN           NaN       NaN         NaN   \n",
       "776 -1.299218e-06  2.403503e-02 -5.405517e-05  0.014063  101.453522   \n",
       "777           NaN           NaN           NaN       NaN         NaN   \n",
       "780 -2.811972e-05 -4.951217e-05 -2.811972e+07  0.025648    0.014431   \n",
       "781 -2.246785e-06  1.121911e-02 -2.002640e-04  0.011314   67.755661   \n",
       "782 -2.877171e-05 -1.678354e-01 -2.877171e+07  0.015919   72.527573   \n",
       "783  6.647404e-06 -2.566931e-02  6.647404e+06  0.011284   71.837524   \n",
       "786 -1.887155e-05  5.164166e-02 -3.654328e-04  0.023425   90.323662   \n",
       "787           NaN           NaN           NaN       NaN         NaN   \n",
       "788           NaN           NaN           NaN       NaN         NaN   \n",
       "790  3.106712e-06  2.848307e-02  1.090722e-04  0.017399  102.275108   \n",
       "791           NaN           NaN           NaN       NaN         NaN   \n",
       "794 -1.243669e-04 -1.508405e-05 -1.243669e+08  0.025029    0.014471   \n",
       "795 -5.526402e-08 -4.684624e-03 -5.526402e+04  0.011764   66.348656   \n",
       "796 -3.936243e-05 -2.186561e-01 -3.936243e+07  0.016763   72.617989   \n",
       "797 -1.128455e-06 -1.713091e-02 -1.128455e+06  0.011938   73.063843   \n",
       "800  1.439222e-05 -1.083697e-02  1.439222e+07  0.021148   81.454781   \n",
       "801           NaN           NaN           NaN       NaN         NaN   \n",
       "802           NaN           NaN           NaN       NaN         NaN   \n",
       "804 -6.326462e-06 -1.447186e-02 -6.326462e+06  0.017004   97.873833   \n",
       "805           NaN           NaN           NaN       NaN         NaN   \n",
       "808 -7.202942e-05  9.072167e-05 -7.939605e-01  0.024365    0.014946   \n",
       "809 -1.933409e-06  7.639631e-03 -2.530763e-04  0.012228   64.875435   \n",
       "810 -4.827616e-05  1.218323e-01 -3.962510e-04  0.017125   72.719002   \n",
       "811 -4.617706e-06  4.263859e-03 -1.082987e-03  0.012699   70.033562   \n",
       "814 -3.834824e-06  1.003834e-01 -3.820178e-05  0.020811   94.975632   \n",
       "815           NaN           NaN           NaN       NaN         NaN   \n",
       "816           NaN           NaN           NaN       NaN         NaN   \n",
       "818 -6.660851e-06  1.602416e-02 -4.156755e-04  0.014207   84.007454   \n",
       "819           NaN           NaN           NaN       NaN         NaN   \n",
       "822 -1.165403e-04  1.126568e-04 -1.034472e+00  0.022326    0.016217   \n",
       "823 -1.224481e-07  1.516126e-02 -8.076385e-06  0.012241   60.767826   \n",
       "824 -6.539675e-05  1.408842e-01 -4.641880e-04  0.017423   66.136940   \n",
       "825 -2.859583e-06 -4.252552e-03 -2.859583e+06  0.012731   62.393883   \n",
       "828  1.387867e-06  5.260651e-02  2.638203e-05  0.024028   82.054054   \n",
       "829           NaN           NaN           NaN       NaN         NaN   \n",
       "830           NaN           NaN           NaN       NaN         NaN   \n",
       "832 -3.281977e-07 -3.920203e-02 -3.281977e+05  0.017804   99.208954   \n",
       "833           NaN           NaN           NaN       NaN         NaN   \n",
       "836 -8.851806e-05  2.514182e-04 -3.520750e-01  0.021505    0.021680   \n",
       "837 -5.081034e-06 -2.179184e-02 -5.081034e+06  0.012047   52.880806   \n",
       "838 -7.044782e-05  1.505888e-02 -4.678158e-03  0.016894   66.643372   \n",
       "839  4.082678e-07  1.042032e-02  3.917998e-05  0.013240   58.074692   \n",
       "842  1.049011e-05  2.346013e-02  4.471461e-04  0.023272   91.227325   \n",
       "843           NaN           NaN           NaN       NaN         NaN   \n",
       "844           NaN           NaN           NaN       NaN         NaN   \n",
       "846  4.304269e-06 -2.489731e-02  4.304268e+06  0.017176   78.816605   \n",
       "847           NaN           NaN           NaN       NaN         NaN   \n",
       "\n",
       "     std_ratio  zero_frac_a  zero_frac_b   cos_sim    rel_l2_err  \\\n",
       "1     0.000139          0.0     0.000047  0.000037   7189.438477   \n",
       "2     0.000242          0.0     0.000274 -0.000151   4125.888672   \n",
       "3     0.000087          0.0     0.000026 -0.000017  11465.268555   \n",
       "6     0.000300          0.0     0.000023 -0.000718   3336.111328   \n",
       "7          NaN          NaN          NaN       NaN           NaN   \n",
       "8          NaN          NaN          NaN       NaN           NaN   \n",
       "10    0.000111          0.0     0.000010  0.000173   9015.852539   \n",
       "11         NaN          NaN          NaN       NaN           NaN   \n",
       "13    0.000100          0.0     0.000067 -0.000085  10030.302734   \n",
       "14    0.000168          0.0     0.000473 -0.002543   5959.996582   \n",
       "15    0.000060          0.0     0.000058  0.000031  16530.933594   \n",
       "18    0.000240          0.0     0.000030  0.000140   4174.283691   \n",
       "19         NaN          NaN          NaN       NaN           NaN   \n",
       "20         NaN          NaN          NaN       NaN           NaN   \n",
       "22    0.000101          0.0     0.000024 -0.000554   9860.533203   \n",
       "23         NaN          NaN          NaN       NaN           NaN   \n",
       "25    0.000138          0.0     0.000084 -0.000120   7225.403320   \n",
       "26    0.000238          0.0     0.000526 -0.000183   4205.749023   \n",
       "27    0.000088          0.0     0.000063 -0.000124  11361.936523   \n",
       "30    0.000283          0.0     0.000038 -0.001011   3537.533447   \n",
       "31         NaN          NaN          NaN       NaN           NaN   \n",
       "32         NaN          NaN          NaN       NaN           NaN   \n",
       "34    0.000124          0.0     0.000021 -0.000291   8083.104004   \n",
       "35         NaN          NaN          NaN       NaN           NaN   \n",
       "38    0.880683          0.0     0.000000 -0.003374      1.515584   \n",
       "39    0.000119          0.0     0.000018  0.000154   8434.277344   \n",
       "40    0.000136          0.0     0.000024  0.007713   7355.858887   \n",
       "41    0.000072          0.0     0.000009  0.000455  13875.956055   \n",
       "44    0.000246          0.0     0.000023 -0.000964   4072.165283   \n",
       "45         NaN          NaN          NaN       NaN           NaN   \n",
       "46         NaN          NaN          NaN       NaN           NaN   \n",
       "48    0.000168          0.0     0.000015 -0.000191   5945.715332   \n",
       "49         NaN          NaN          NaN       NaN           NaN   \n",
       "52    1.046546          0.0     0.000000 -0.005643      1.387016   \n",
       "53    0.000124          0.0     0.000015  0.000191   8051.048340   \n",
       "54    0.000267          0.0     0.000026 -0.002549   3748.165527   \n",
       "55    0.000088          0.0     0.000011 -0.000021  11313.309570   \n",
       "58    0.000225          0.0     0.000016  0.000142   4438.604004   \n",
       "59         NaN          NaN          NaN       NaN           NaN   \n",
       "60         NaN          NaN          NaN       NaN           NaN   \n",
       "62    0.000104          0.0     0.000010  0.000736   9651.665039   \n",
       "63         NaN          NaN          NaN       NaN           NaN   \n",
       "66    1.013400          0.0     0.000000  0.002856      1.402891   \n",
       "67    0.000125          0.0     0.000013  0.000072   7980.104004   \n",
       "68    0.000287          0.0     0.000025  0.007981   3489.986328   \n",
       "69    0.000101          0.0     0.000010 -0.000720   9871.651367   \n",
       "72    0.000313          0.0     0.000029  0.000555   3196.676270   \n",
       "73         NaN          NaN          NaN       NaN           NaN   \n",
       "74         NaN          NaN          NaN       NaN           NaN   \n",
       "76    0.000134          0.0     0.000011  0.000123   7486.757324   \n",
       "77         NaN          NaN          NaN       NaN           NaN   \n",
       "80    1.015558          0.0     0.000000  0.001635      1.402278   \n",
       "81    0.000133          0.0     0.000015  0.000040   7539.826172   \n",
       "82    0.000315          0.0     0.000029  0.006891   3175.114746   \n",
       "83    0.000113          0.0     0.000011 -0.000596   8870.164062   \n",
       "86    0.000215          0.0     0.000015  0.000162   4642.449219   \n",
       "87         NaN          NaN          NaN       NaN           NaN   \n",
       "88         NaN          NaN          NaN       NaN           NaN   \n",
       "90    0.000121          0.0     0.000010  0.000410   8290.634766   \n",
       "91         NaN          NaN          NaN       NaN           NaN   \n",
       "94    1.096737          0.0     0.000000 -0.000217      1.353423   \n",
       "95    0.000124          0.0     0.000014  0.000423   8034.620117   \n",
       "96    0.000344          0.0     0.000029  0.002579   2905.140869   \n",
       "97    0.000123          0.0     0.000012  0.000060   8119.027832   \n",
       "100   0.000279          0.0     0.000017 -0.001061   3583.836182   \n",
       "101        NaN          NaN          NaN       NaN           NaN   \n",
       "102        NaN          NaN          NaN       NaN           NaN   \n",
       "104   0.000155          0.0     0.000011 -0.000106   6451.335938   \n",
       "105        NaN          NaN          NaN       NaN           NaN   \n",
       "108   1.206346          0.0     0.000000 -0.002334      1.300376   \n",
       "109   0.000161          0.0     0.000019  0.000129   6223.212402   \n",
       "110   0.000374          0.0     0.000029  0.002176   2673.854492   \n",
       "111   0.000137          0.0     0.000014 -0.000741   7278.729492   \n",
       "114   0.000297          0.0     0.000013  0.001199   3363.983643   \n",
       "115        NaN          NaN          NaN       NaN           NaN   \n",
       "116        NaN          NaN          NaN       NaN           NaN   \n",
       "118   0.000159          0.0     0.000012  0.000191   6281.785645   \n",
       "119        NaN          NaN          NaN       NaN           NaN   \n",
       "122   1.146120          0.0     0.000000 -0.000197      1.327242   \n",
       "123   0.000163          0.0     0.000016  0.000436   6142.150391   \n",
       "124   0.000409          0.0     0.000033  0.001613   2444.686279   \n",
       "125   0.000155          0.0     0.000016  0.000223   6432.552734   \n",
       "128   0.000256          0.0     0.000015  0.000201   3908.392822   \n",
       "129        NaN          NaN          NaN       NaN           NaN   \n",
       "130        NaN          NaN          NaN       NaN           NaN   \n",
       "132   0.000132          0.0     0.000009 -0.000427   7576.348633   \n",
       "133        NaN          NaN          NaN       NaN           NaN   \n",
       "136   1.061331          0.0     0.000000 -0.004267      1.376859   \n",
       "137   0.000172          0.0     0.000015  0.000112   5825.627930   \n",
       "138   0.000446          0.0     0.000030 -0.000207   2241.360596   \n",
       "139   0.000166          0.0     0.000014 -0.000003   6024.025879   \n",
       "142   0.000280          0.0     0.000021  0.000038   3569.100342   \n",
       "143        NaN          NaN          NaN       NaN           NaN   \n",
       "144        NaN          NaN          NaN       NaN           NaN   \n",
       "146   0.000135          0.0     0.000010  0.000364   7428.295410   \n",
       "147        NaN          NaN          NaN       NaN           NaN   \n",
       "150   1.067445          0.0     0.000000 -0.002468      1.371926   \n",
       "151   0.000168          0.0     0.000016  0.000031   5966.756348   \n",
       "152   0.000457          0.0     0.000026 -0.000050   2186.943359   \n",
       "153   0.000169          0.0     0.000018 -0.000152   5933.535156   \n",
       "156   0.000264          0.0     0.000017 -0.000145   3793.225342   \n",
       "157        NaN          NaN          NaN       NaN           NaN   \n",
       "158        NaN          NaN          NaN       NaN           NaN   \n",
       "160   0.000172          0.0     0.000011 -0.000089   5829.271973   \n",
       "161        NaN          NaN          NaN       NaN           NaN   \n",
       "164   1.102439          0.0     0.000000 -0.001725      1.351247   \n",
       "165   0.000171          0.0     0.000014  0.000285   5861.903809   \n",
       "166   0.000414          0.0     0.000026 -0.001716   2415.140869   \n",
       "167   0.000174          0.0     0.000015  0.000034   5760.409668   \n",
       "170   0.000271          0.0     0.000014  0.000435   3689.012695   \n",
       "171        NaN          NaN          NaN       NaN           NaN   \n",
       "172        NaN          NaN          NaN       NaN           NaN   \n",
       "174   0.000157          0.0     0.000011 -0.000233   6379.145020   \n",
       "175        NaN          NaN          NaN       NaN           NaN   \n",
       "178   1.160261          0.0     0.000000 -0.002876      1.322036   \n",
       "179   0.000168          0.0     0.000017  0.000095   5936.188965   \n",
       "180   0.000407          0.0     0.000031 -0.002048   2458.305176   \n",
       "181   0.000174          0.0     0.000014 -0.000086   5744.969238   \n",
       "184   0.000273          0.0     0.000013  0.000074   3661.753174   \n",
       "185        NaN          NaN          NaN       NaN           NaN   \n",
       "186        NaN          NaN          NaN       NaN           NaN   \n",
       "188   0.000181          0.0     0.000011 -0.000043   5534.592773   \n",
       "189        NaN          NaN          NaN       NaN           NaN   \n",
       "192   1.214837          0.0     0.000000 -0.003300      1.297325   \n",
       "193   0.000172          0.0     0.000017 -0.000267   5798.245605   \n",
       "194   0.000545          0.0     0.000035 -0.002147   1833.311279   \n",
       "195   0.000184          0.0     0.000017  0.000183   5424.522461   \n",
       "198   0.000270          0.0     0.000016  0.000144   3697.892822   \n",
       "199        NaN          NaN          NaN       NaN           NaN   \n",
       "200        NaN          NaN          NaN       NaN           NaN   \n",
       "202   0.000197          0.0     0.000010 -0.000231   5063.599609   \n",
       "203        NaN          NaN          NaN       NaN           NaN   \n",
       "206   1.280502          0.0     0.000000 -0.003517      1.270987   \n",
       "207   0.000185          0.0     0.000017  0.000324   5392.842773   \n",
       "208   0.000498          0.0     0.000034 -0.000964   2009.958862   \n",
       "209   0.000184          0.0     0.000020  0.000047   5423.005859   \n",
       "212   0.000265          0.0     0.000013  0.000258   3771.169922   \n",
       "213        NaN          NaN          NaN       NaN           NaN   \n",
       "214        NaN          NaN          NaN       NaN           NaN   \n",
       "216   0.000207          0.0     0.000008 -0.000266   4827.384277   \n",
       "217        NaN          NaN          NaN       NaN           NaN   \n",
       "220   1.210999          0.0     0.000000 -0.006046      1.300750   \n",
       "221   0.000180          0.0     0.000016  0.000297   5567.632812   \n",
       "222   0.000578          0.0     0.000032 -0.000995   1730.392944   \n",
       "223   0.000192          0.0     0.000018  0.000332   5214.794922   \n",
       "226   0.000257          0.0     0.000012 -0.000334   3896.737061   \n",
       "227        NaN          NaN          NaN       NaN           NaN   \n",
       "228        NaN          NaN          NaN       NaN           NaN   \n",
       "230   0.000178          0.0     0.000007 -0.000515   5609.986328   \n",
       "231        NaN          NaN          NaN       NaN           NaN   \n",
       "234   1.271312          0.0     0.000000 -0.003551      1.274495   \n",
       "235   0.000171          0.0     0.000015  0.000072   5861.631836   \n",
       "236   0.000398          0.0     0.000027 -0.001624   2514.337891   \n",
       "237   0.000166          0.0     0.000015  0.000359   6006.819824   \n",
       "240   0.000307          0.0     0.000016 -0.000256   3258.283447   \n",
       "241        NaN          NaN          NaN       NaN           NaN   \n",
       "242        NaN          NaN          NaN       NaN           NaN   \n",
       "244   0.000203          0.0     0.000010 -0.000042   4929.477539   \n",
       "245        NaN          NaN          NaN       NaN           NaN   \n",
       "248   1.315569          0.0     0.000000 -0.004603      1.258886   \n",
       "249   0.000181          0.0     0.000018  0.000224   5522.825684   \n",
       "250   0.000391          0.0     0.000029 -0.001710   2556.518311   \n",
       "251   0.000175          0.0     0.000015  0.000542   5699.294434   \n",
       "254   0.000268          0.0     0.000017  0.000758   3731.474609   \n",
       "255        NaN          NaN          NaN       NaN           NaN   \n",
       "256        NaN          NaN          NaN       NaN           NaN   \n",
       "258   0.000166          0.0     0.000010  0.000164   6015.775879   \n",
       "259        NaN          NaN          NaN       NaN           NaN   \n",
       "262   1.378587          0.0     0.000000 -0.004642      1.238110   \n",
       "263   0.000201          0.0     0.000018 -0.000071   4971.615234   \n",
       "264   0.000405          0.0     0.000028 -0.001423   2467.332031   \n",
       "265   0.000197          0.0     0.000017 -0.000435   5079.107910   \n",
       "268   0.000278          0.0     0.000017  0.000148   3598.245117   \n",
       "269        NaN          NaN          NaN       NaN           NaN   \n",
       "270        NaN          NaN          NaN       NaN           NaN   \n",
       "272   0.000197          0.0     0.000008 -0.000265   5086.375488   \n",
       "273        NaN          NaN          NaN       NaN           NaN   \n",
       "276   1.342003          0.0     0.000000 -0.004085      1.249538   \n",
       "277   0.000182          0.0     0.000016 -0.000048   5483.218750   \n",
       "278   0.000352          0.0     0.000024 -0.001544   2843.714844   \n",
       "279   0.000177          0.0     0.000018  0.000041   5636.540527   \n",
       "282   0.000274          0.0     0.000016 -0.000930   3644.076660   \n",
       "283        NaN          NaN          NaN       NaN           NaN   \n",
       "284        NaN          NaN          NaN       NaN           NaN   \n",
       "286   0.000165          0.0     0.000007 -0.000271   6047.429688   \n",
       "287        NaN          NaN          NaN       NaN           NaN   \n",
       "290   1.397680          0.0     0.000000 -0.004670      1.232308   \n",
       "291   0.000185          0.0     0.000015 -0.000056   5402.839844   \n",
       "292   0.000307          0.0     0.000021 -0.001270   3260.823730   \n",
       "293   0.000182          0.0     0.000015 -0.000012   5495.322266   \n",
       "296   0.000273          0.0     0.000015 -0.000238   3662.629883   \n",
       "297        NaN          NaN          NaN       NaN           NaN   \n",
       "298        NaN          NaN          NaN       NaN           NaN   \n",
       "300   0.000165          0.0     0.000008  0.000236   6078.119141   \n",
       "301        NaN          NaN          NaN       NaN           NaN   \n",
       "304   1.476255          0.0     0.000000 -0.005641      1.210989   \n",
       "305   0.000196          0.0     0.000018  0.000548   5101.026855   \n",
       "306   0.000304          0.0     0.000019 -0.000112   3290.221191   \n",
       "307   0.000189          0.0     0.000015  0.000020   5296.436035   \n",
       "310   0.000295          0.0     0.000017  0.000013   3394.408691   \n",
       "311        NaN          NaN          NaN       NaN           NaN   \n",
       "312        NaN          NaN          NaN       NaN           NaN   \n",
       "314   0.000187          0.0     0.000007 -0.000069   5352.717773   \n",
       "315        NaN          NaN          NaN       NaN           NaN   \n",
       "318   1.576388          0.0     0.000000 -0.005457      1.187151   \n",
       "319   0.000191          0.0     0.000017  0.000154   5226.300781   \n",
       "320   0.000270          0.0     0.000022  0.000063   3705.032227   \n",
       "321   0.000195          0.0     0.000015 -0.000244   5126.244629   \n",
       "324   0.000277          0.0     0.000014  0.000189   3610.067383   \n",
       "325        NaN          NaN          NaN       NaN           NaN   \n",
       "326        NaN          NaN          NaN       NaN           NaN   \n",
       "328   0.000191          0.0     0.000007 -0.000013   5227.763184   \n",
       "329        NaN          NaN          NaN       NaN           NaN   \n",
       "332   1.605788          0.0     0.000000 -0.009123      1.182865   \n",
       "333   0.000181          0.0     0.000018  0.000174   5532.694336   \n",
       "334   0.000269          0.0     0.000021 -0.000206   3723.685547   \n",
       "335   0.000196          0.0     0.000019 -0.000082   5108.688965   \n",
       "338   0.000301          0.0     0.000014  0.000569   3326.908203   \n",
       "339        NaN          NaN          NaN       NaN           NaN   \n",
       "340        NaN          NaN          NaN       NaN           NaN   \n",
       "342   0.000216          0.0     0.000008  0.000233   4622.494629   \n",
       "343        NaN          NaN          NaN       NaN           NaN   \n",
       "346   1.581804          0.0     0.000000 -0.006099      1.186325   \n",
       "347   0.000166          0.0     0.000015 -0.000034   6007.531250   \n",
       "348   0.000267          0.0     0.000024  0.000063   3740.311035   \n",
       "349   0.000186          0.0     0.000017  0.000060   5379.043457   \n",
       "352   0.000314          0.0     0.000016 -0.000941   3188.125244   \n",
       "353        NaN          NaN          NaN       NaN           NaN   \n",
       "354        NaN          NaN          NaN       NaN           NaN   \n",
       "356   0.000206          0.0     0.000008  0.000214   4845.236816   \n",
       "357        NaN          NaN          NaN       NaN           NaN   \n",
       "360   1.565596          0.0     0.000000 -0.005773      1.189681   \n",
       "361   0.000172          0.0     0.000016  0.000214   5816.496094   \n",
       "362   0.000261          0.0     0.000024 -0.000412   3828.726318   \n",
       "363   0.000185          0.0     0.000016 -0.000302   5408.130371   \n",
       "366   0.000290          0.0     0.000013  0.000985   3453.199951   \n",
       "367        NaN          NaN          NaN       NaN           NaN   \n",
       "368        NaN          NaN          NaN       NaN           NaN   \n",
       "370   0.000201          0.0     0.000009 -0.000011   4965.869629   \n",
       "371        NaN          NaN          NaN       NaN           NaN   \n",
       "374   1.585246          0.0     0.000000 -0.008816      1.187033   \n",
       "375   0.000145          0.0     0.000014  0.000011   6919.906738   \n",
       "376   0.000214          0.0     0.000020 -0.000359   4663.833496   \n",
       "377   0.000159          0.0     0.000016 -0.000184   6303.244629   \n",
       "380   0.000302          0.0     0.000012 -0.000787   3311.828369   \n",
       "381        NaN          NaN          NaN       NaN           NaN   \n",
       "382        NaN          NaN          NaN       NaN           NaN   \n",
       "384   0.000208          0.0     0.000008  0.000261   4802.110352   \n",
       "385        NaN          NaN          NaN       NaN           NaN   \n",
       "388   1.612943          0.0     0.000000 -0.006990      1.180271   \n",
       "389   0.000169          0.0     0.000016  0.000260   5908.282715   \n",
       "390   0.000268          0.0     0.000020 -0.000692   3737.214844   \n",
       "391   0.000182          0.0     0.000016 -0.000280   5503.847168   \n",
       "394   0.000289          0.0     0.000015 -0.000186   3460.082031   \n",
       "395        NaN          NaN          NaN       NaN           NaN   \n",
       "396        NaN          NaN          NaN       NaN           NaN   \n",
       "398   0.000206          0.0     0.000008 -0.000038   4857.611328   \n",
       "399        NaN          NaN          NaN       NaN           NaN   \n",
       "402   1.606110          0.0     0.000000 -0.005633      1.180957   \n",
       "403   0.000169          0.0     0.000014  0.000093   5906.451660   \n",
       "404   0.000236          0.0     0.000020 -0.000279   4231.559082   \n",
       "405   0.000179          0.0     0.000015 -0.000108   5592.225098   \n",
       "408   0.000283          0.0     0.000015 -0.000274   3538.546143   \n",
       "409        NaN          NaN          NaN       NaN           NaN   \n",
       "410        NaN          NaN          NaN       NaN           NaN   \n",
       "412   0.000231          0.0     0.000008 -0.000219   4330.169434   \n",
       "413        NaN          NaN          NaN       NaN           NaN   \n",
       "416   1.581951          0.0     0.000000 -0.004024      1.185189   \n",
       "417   0.000168          0.0     0.000015  0.000122   5944.042480   \n",
       "418   0.000251          0.0     0.000019 -0.000218   3983.347656   \n",
       "419   0.000181          0.0     0.000015  0.000154   5526.204590   \n",
       "422   0.000253          0.0     0.000010 -0.000117   3956.901123   \n",
       "423        NaN          NaN          NaN       NaN           NaN   \n",
       "424        NaN          NaN          NaN       NaN           NaN   \n",
       "426   0.000202          0.0     0.000007 -0.000026   4940.950195   \n",
       "427        NaN          NaN          NaN       NaN           NaN   \n",
       "430   1.596790          0.0     0.000000 -0.004181      1.182130   \n",
       "431   0.000168          0.0     0.000015  0.000165   5960.023926   \n",
       "432   0.000249          0.0     0.000022 -0.000019   4017.274170   \n",
       "433   0.000186          0.0     0.000019  0.000165   5377.061523   \n",
       "436   0.000279          0.0     0.000011 -0.000494   3581.117920   \n",
       "437        NaN          NaN          NaN       NaN           NaN   \n",
       "438        NaN          NaN          NaN       NaN           NaN   \n",
       "440   0.000217          0.0     0.000007 -0.000026   4605.354980   \n",
       "441        NaN          NaN          NaN       NaN           NaN   \n",
       "444   1.612207          0.0     0.000000 -0.001719      1.177651   \n",
       "445   0.000179          0.0     0.000016 -0.000102   5599.109375   \n",
       "446   0.000255          0.0     0.000020  0.000059   3916.353027   \n",
       "447   0.000196          0.0     0.000016  0.000302   5110.338867   \n",
       "450   0.000273          0.0     0.000017 -0.000373   3669.161621   \n",
       "451        NaN          NaN          NaN       NaN           NaN   \n",
       "452        NaN          NaN          NaN       NaN           NaN   \n",
       "454   0.000215          0.0     0.000007  0.000098   4659.674805   \n",
       "455        NaN          NaN          NaN       NaN           NaN   \n",
       "458   1.526009          0.0     0.000000 -0.005242      1.198452   \n",
       "459   0.000184          0.0     0.000016  0.000011   5436.865234   \n",
       "460   0.000218          0.0     0.000018  0.001086   4580.493652   \n",
       "461   0.000191          0.0     0.000016  0.000004   5243.312988   \n",
       "464   0.000306          0.0     0.000019  0.000208   3267.165771   \n",
       "465        NaN          NaN          NaN       NaN           NaN   \n",
       "466        NaN          NaN          NaN       NaN           NaN   \n",
       "468   0.000221          0.0     0.000008  0.000341   4525.841797   \n",
       "469        NaN          NaN          NaN       NaN           NaN   \n",
       "472   1.567166          0.0     0.000000 -0.002095      1.187365   \n",
       "473   0.000177          0.0     0.000015  0.000255   5643.998047   \n",
       "474   0.000227          0.0     0.000021  0.001027   4397.247070   \n",
       "475   0.000190          0.0     0.000016 -0.000103   5276.226562   \n",
       "478   0.000359          0.0     0.000017  0.000319   2781.955566   \n",
       "479        NaN          NaN          NaN       NaN           NaN   \n",
       "480        NaN          NaN          NaN       NaN           NaN   \n",
       "482   0.000225          0.0     0.000009 -0.000041   4453.137695   \n",
       "483        NaN          NaN          NaN       NaN           NaN   \n",
       "486   1.577191          0.0     0.000000 -0.002269      1.185274   \n",
       "487   0.000187          0.0     0.000018 -0.000021   5342.787109   \n",
       "488   0.000227          0.0     0.000019  0.001031   4403.949219   \n",
       "489   0.000206          0.0     0.000020  0.000306   4843.177246   \n",
       "492   0.000315          0.0     0.000016 -0.000188   3178.268555   \n",
       "493        NaN          NaN          NaN       NaN           NaN   \n",
       "494        NaN          NaN          NaN       NaN           NaN   \n",
       "496   0.000228          0.0     0.000007  0.000045   4390.492676   \n",
       "497        NaN          NaN          NaN       NaN           NaN   \n",
       "500   1.539274          0.0     0.000000 -0.000600      1.192828   \n",
       "501   0.000179          0.0     0.000016  0.000181   5594.271973   \n",
       "502   0.000217          0.0     0.000016  0.000470   4599.465820   \n",
       "503   0.000194          0.0     0.000015  0.000217   5163.011719   \n",
       "506   0.000255          0.0     0.000013  0.000838   3920.489258   \n",
       "507        NaN          NaN          NaN       NaN           NaN   \n",
       "508        NaN          NaN          NaN       NaN           NaN   \n",
       "510   0.000183          0.0     0.000006  0.000268   5457.231934   \n",
       "511        NaN          NaN          NaN       NaN           NaN   \n",
       "514   1.590587          0.0     0.000000  0.000968      1.180704   \n",
       "515   0.000175          0.0     0.000015 -0.000129   5720.882324   \n",
       "516   0.000226          0.0     0.000019  0.000818   4427.772461   \n",
       "517   0.000189          0.0     0.000015  0.000551   5287.452148   \n",
       "520   0.000295          0.0     0.000012 -0.000145   3394.116699   \n",
       "521        NaN          NaN          NaN       NaN           NaN   \n",
       "522        NaN          NaN          NaN       NaN           NaN   \n",
       "524   0.000206          0.0     0.000010  0.000039   4843.945312   \n",
       "525        NaN          NaN          NaN       NaN           NaN   \n",
       "528   1.574988          0.0     0.000000  0.002056      1.183439   \n",
       "529   0.000183          0.0     0.000018 -0.000085   5452.493652   \n",
       "530   0.000220          0.0     0.000018  0.000412   4543.137207   \n",
       "531   0.000199          0.0     0.000018  0.000385   5033.905762   \n",
       "534   0.000318          0.0     0.000018 -0.000653   3143.308838   \n",
       "535        NaN          NaN          NaN       NaN           NaN   \n",
       "536        NaN          NaN          NaN       NaN           NaN   \n",
       "538   0.000216          0.0     0.000007 -0.000375   4633.912598   \n",
       "539        NaN          NaN          NaN       NaN           NaN   \n",
       "542   1.654358          0.0     0.000000  0.001574      1.167676   \n",
       "543   0.000183          0.0     0.000018 -0.000362   5470.748535   \n",
       "544   0.000221          0.0     0.000019  0.001321   4532.237793   \n",
       "545   0.000204          0.0     0.000019 -0.000232   4906.063965   \n",
       "548   0.000269          0.0     0.000013 -0.000706   3710.853271   \n",
       "549        NaN          NaN          NaN       NaN           NaN   \n",
       "550        NaN          NaN          NaN       NaN           NaN   \n",
       "552   0.000169          0.0     0.000006 -0.000089   5917.318359   \n",
       "553        NaN          NaN          NaN       NaN           NaN   \n",
       "556   1.610060          0.0     0.000000  0.003676      1.175244   \n",
       "557   0.000177          0.0     0.000019  0.000333   5660.828613   \n",
       "558   0.000211          0.0     0.000015  0.000725   4733.252930   \n",
       "559   0.000194          0.0     0.000016  0.000079   5160.271973   \n",
       "562   0.000307          0.0     0.000014 -0.000041   3259.811279   \n",
       "563        NaN          NaN          NaN       NaN           NaN   \n",
       "564        NaN          NaN          NaN       NaN           NaN   \n",
       "566   0.000239          0.0     0.000008 -0.000171   4186.609863   \n",
       "567        NaN          NaN          NaN       NaN           NaN   \n",
       "570   1.585925          0.0     0.000000  0.005806      1.179102   \n",
       "571   0.000182          0.0     0.000018 -0.000151   5490.496582   \n",
       "572   0.000204          0.0     0.000018  0.001144   4896.206055   \n",
       "573   0.000202          0.0     0.000017  0.000310   4949.143555   \n",
       "576   0.000316          0.0     0.000016 -0.000069   3169.015137   \n",
       "577        NaN          NaN          NaN       NaN           NaN   \n",
       "578        NaN          NaN          NaN       NaN           NaN   \n",
       "580   0.000198          0.0     0.000007 -0.000224   5050.350586   \n",
       "581        NaN          NaN          NaN       NaN           NaN   \n",
       "584   1.513977          0.0     0.000000  0.005035      1.195682   \n",
       "585   0.000181          0.0     0.000017  0.000071   5516.079102   \n",
       "586   0.000207          0.0     0.000016  0.001009   4834.063965   \n",
       "587   0.000192          0.0     0.000015 -0.000491   5218.874512   \n",
       "590   0.000290          0.0     0.000013 -0.000227   3446.206055   \n",
       "591        NaN          NaN          NaN       NaN           NaN   \n",
       "592        NaN          NaN          NaN       NaN           NaN   \n",
       "594   0.000211          0.0     0.000008  0.000167   4739.313965   \n",
       "595        NaN          NaN          NaN       NaN           NaN   \n",
       "598   1.547796          0.0     0.000000  0.004208      1.188272   \n",
       "599   0.000194          0.0     0.000019 -0.000003   5154.535156   \n",
       "600   0.000213          0.0     0.000019  0.000669   4689.913574   \n",
       "601   0.000195          0.0     0.000017  0.000061   5136.518555   \n",
       "604   0.000328          0.0     0.000018  0.000319   3047.230957   \n",
       "605        NaN          NaN          NaN       NaN           NaN   \n",
       "606        NaN          NaN          NaN       NaN           NaN   \n",
       "608   0.000216          0.0     0.000007 -0.000178   4637.071777   \n",
       "609        NaN          NaN          NaN       NaN           NaN   \n",
       "612   1.565086          0.0     0.000000  0.004665      1.184185   \n",
       "613   0.000187          0.0     0.000018  0.000238   5337.457031   \n",
       "614   0.000220          0.0     0.000018  0.000642   4546.562500   \n",
       "615   0.000184          0.0     0.000015 -0.000131   5425.952637   \n",
       "618   0.000294          0.0     0.000009  0.000564   3404.636230   \n",
       "619        NaN          NaN          NaN       NaN           NaN   \n",
       "620        NaN          NaN          NaN       NaN           NaN   \n",
       "622   0.000221          0.0     0.000009 -0.000222   4514.926270   \n",
       "623        NaN          NaN          NaN       NaN           NaN   \n",
       "626   1.585824          0.0     0.000000  0.006671      1.178657   \n",
       "627   0.000185          0.0     0.000017  0.000258   5407.433105   \n",
       "628   0.000227          0.0     0.000019  0.000764   4406.362305   \n",
       "629   0.000194          0.0     0.000016  0.000052   5163.373047   \n",
       "632   0.000282          0.0     0.000016 -0.000565   3547.221436   \n",
       "633        NaN          NaN          NaN       NaN           NaN   \n",
       "634        NaN          NaN          NaN       NaN           NaN   \n",
       "636   0.000210          0.0     0.000009  0.000150   4764.863770   \n",
       "637        NaN          NaN          NaN       NaN           NaN   \n",
       "640   1.566696          0.0     0.000000  0.005187      1.183551   \n",
       "641   0.000182          0.0     0.000018  0.000087   5485.193359   \n",
       "642   0.000209          0.0     0.000018  0.000672   4796.124023   \n",
       "643   0.000189          0.0     0.000017 -0.000362   5291.922852   \n",
       "646   0.000365          0.0     0.000016  0.000839   2736.980469   \n",
       "647        NaN          NaN          NaN       NaN           NaN   \n",
       "648        NaN          NaN          NaN       NaN           NaN   \n",
       "650   0.000197          0.0     0.000007  0.000233   5071.715332   \n",
       "651        NaN          NaN          NaN       NaN           NaN   \n",
       "654   1.575231          0.0     0.000000  0.003836      1.182441   \n",
       "655   0.000162          0.0     0.000020 -0.000156   6160.037109   \n",
       "656   0.000206          0.0     0.000016  0.000830   4849.319824   \n",
       "657   0.000172          0.0     0.000016  0.000049   5815.816895   \n",
       "660   0.000342          0.0     0.000022 -0.000720   2921.314209   \n",
       "661        NaN          NaN          NaN       NaN           NaN   \n",
       "662        NaN          NaN          NaN       NaN           NaN   \n",
       "664   0.000179          0.0     0.000008 -0.000198   5575.669922   \n",
       "665        NaN          NaN          NaN       NaN           NaN   \n",
       "668   1.605569          0.0     0.000000  0.006847      1.174486   \n",
       "669   0.000157          0.0     0.000017 -0.000014   6359.155762   \n",
       "670   0.000210          0.0     0.000016  0.000960   4760.429199   \n",
       "671   0.000172          0.0     0.000016  0.000481   5829.967285   \n",
       "674   0.000243          0.0     0.000013 -0.000421   4122.324707   \n",
       "675        NaN          NaN          NaN       NaN           NaN   \n",
       "676        NaN          NaN          NaN       NaN           NaN   \n",
       "678   0.000157          0.0     0.000008  0.000134   6384.629395   \n",
       "679        NaN          NaN          NaN       NaN           NaN   \n",
       "682   1.672143          0.0     0.000000  0.005707      1.162253   \n",
       "683   0.000158          0.0     0.000017  0.000404   6309.149414   \n",
       "684   0.000206          0.0     0.000015  0.000945   4851.342773   \n",
       "685   0.000173          0.0     0.000015 -0.000348   5797.069336   \n",
       "688   0.000250          0.0     0.000012 -0.000336   3995.715332   \n",
       "689        NaN          NaN          NaN       NaN           NaN   \n",
       "690        NaN          NaN          NaN       NaN           NaN   \n",
       "692   0.000160          0.0     0.000007 -0.000193   6239.751465   \n",
       "693        NaN          NaN          NaN       NaN           NaN   \n",
       "696   1.639772          0.0     0.000000  0.004127      1.169132   \n",
       "697   0.000161          0.0     0.000020 -0.000066   6208.724121   \n",
       "698   0.000208          0.0     0.000017  0.001389   4807.561523   \n",
       "699   0.000171          0.0     0.000015  0.000183   5838.445801   \n",
       "702   0.000323          0.0     0.000015  0.000347   3096.222656   \n",
       "703        NaN          NaN          NaN       NaN           NaN   \n",
       "704        NaN          NaN          NaN       NaN           NaN   \n",
       "706   0.000216          0.0     0.000008  0.000242   4623.895508   \n",
       "707        NaN          NaN          NaN       NaN           NaN   \n",
       "710   1.663002          0.0     0.000000  0.004823      1.164390   \n",
       "711   0.000155          0.0     0.000018 -0.000029   6463.541016   \n",
       "712   0.000217          0.0     0.000015  0.001002   4617.626465   \n",
       "713   0.000165          0.0     0.000014  0.000040   6059.179688   \n",
       "716   0.000327          0.0     0.000011  0.000039   3053.559326   \n",
       "717        NaN          NaN          NaN       NaN           NaN   \n",
       "718        NaN          NaN          NaN       NaN           NaN   \n",
       "720   0.000184          0.0     0.000009 -0.000412   5434.315918   \n",
       "721        NaN          NaN          NaN       NaN           NaN   \n",
       "724   1.621016          0.0     0.000000  0.007234      1.171178   \n",
       "725   0.000165          0.0     0.000019  0.000159   6056.332031   \n",
       "726   0.000211          0.0     0.000015  0.000667   4733.549805   \n",
       "727   0.000161          0.0     0.000015 -0.000285   6198.667480   \n",
       "730   0.000266          0.0     0.000015 -0.000055   3758.656006   \n",
       "731        NaN          NaN          NaN       NaN           NaN   \n",
       "732        NaN          NaN          NaN       NaN           NaN   \n",
       "734   0.000191          0.0     0.000007 -0.000404   5248.449219   \n",
       "735        NaN          NaN          NaN       NaN           NaN   \n",
       "738   1.722575          0.0     0.000000  0.002225      1.155191   \n",
       "739   0.000167          0.0     0.000019 -0.000120   5980.081055   \n",
       "740   0.000222          0.0     0.000016  0.000416   4502.488770   \n",
       "741   0.000164          0.0     0.000018 -0.000301   6079.592773   \n",
       "744   0.000273          0.0     0.000016  0.000570   3657.064453   \n",
       "745        NaN          NaN          NaN       NaN           NaN   \n",
       "746        NaN          NaN          NaN       NaN           NaN   \n",
       "748   0.000205          0.0     0.000009  0.000273   4887.658691   \n",
       "749        NaN          NaN          NaN       NaN           NaN   \n",
       "752   1.653020          0.0     0.000000  0.004597      1.166367   \n",
       "753   0.000163          0.0     0.000017 -0.000031   6116.853027   \n",
       "754   0.000215          0.0     0.000016 -0.000125   4647.899414   \n",
       "755   0.000163          0.0     0.000015  0.000285   6143.980957   \n",
       "758   0.000240          0.0     0.000013 -0.000439   4170.007812   \n",
       "759        NaN          NaN          NaN       NaN           NaN   \n",
       "760        NaN          NaN          NaN       NaN           NaN   \n",
       "762   0.000149          0.0     0.000009  0.000376   6716.402344   \n",
       "763        NaN          NaN          NaN       NaN           NaN   \n",
       "766   1.774155          0.0     0.000000  0.002703      1.146590   \n",
       "767   0.000169          0.0     0.000018  0.000364   5928.488281   \n",
       "768   0.000213          0.0     0.000015  0.000512   4685.849609   \n",
       "769   0.000159          0.0     0.000012  0.000099   6308.760254   \n",
       "772   0.000262          0.0     0.000015  0.000207   3817.223877   \n",
       "773        NaN          NaN          NaN       NaN           NaN   \n",
       "774        NaN          NaN          NaN       NaN           NaN   \n",
       "776   0.000139          0.0     0.000009  0.000137   7214.228027   \n",
       "777        NaN          NaN          NaN       NaN           NaN   \n",
       "780   1.777332          0.0     0.000000  0.005028      1.144950   \n",
       "781   0.000167          0.0     0.000018  0.000184   5988.484863   \n",
       "782   0.000219          0.0     0.000014  0.000713   4556.131348   \n",
       "783   0.000157          0.0     0.000012  0.000079   6366.280273   \n",
       "786   0.000259          0.0     0.000009 -0.000221   3855.910156   \n",
       "787        NaN          NaN          NaN       NaN           NaN   \n",
       "788        NaN          NaN          NaN       NaN           NaN   \n",
       "790   0.000170          0.0     0.000009 -0.000190   5878.126953   \n",
       "791        NaN          NaN          NaN       NaN           NaN   \n",
       "794   1.729627          0.0     0.000000  0.003875      1.153161   \n",
       "795   0.000177          0.0     0.000017 -0.000533   5640.184570   \n",
       "796   0.000231          0.0     0.000014 -0.000150   4331.990234   \n",
       "797   0.000163          0.0     0.000012 -0.000221   6120.513184   \n",
       "800   0.000260          0.0     0.000012 -0.000181   3851.665283   \n",
       "801        NaN          NaN          NaN       NaN           NaN   \n",
       "802        NaN          NaN          NaN       NaN           NaN   \n",
       "804   0.000174          0.0     0.000007  0.000243   5755.760742   \n",
       "805        NaN          NaN          NaN       NaN           NaN   \n",
       "808   1.630199          0.0     0.000000 -0.000962      1.173660   \n",
       "809   0.000188          0.0     0.000016 -0.000118   5305.550781   \n",
       "810   0.000235          0.0     0.000014 -0.000051   4246.416016   \n",
       "811   0.000181          0.0     0.000013 -0.000062   5514.793457   \n",
       "814   0.000219          0.0     0.000006  0.000020   4563.813477   \n",
       "815        NaN          NaN          NaN       NaN           NaN   \n",
       "816        NaN          NaN          NaN       NaN           NaN   \n",
       "818   0.000169          0.0     0.000010  0.000336   5913.041504   \n",
       "819        NaN          NaN          NaN       NaN           NaN   \n",
       "822   1.376727          0.0     0.000000  0.001173      1.235276   \n",
       "823   0.000201          0.0     0.000018 -0.000144   4964.314941   \n",
       "824   0.000263          0.0     0.000015 -0.000200   3795.928711   \n",
       "825   0.000204          0.0     0.000015  0.000156   4901.025879   \n",
       "828   0.000293          0.0     0.000011 -0.000025   3414.929932   \n",
       "829        NaN          NaN          NaN       NaN           NaN   \n",
       "830        NaN          NaN          NaN       NaN           NaN   \n",
       "832   0.000179          0.0     0.000008  0.000515   5572.338867   \n",
       "833        NaN          NaN          NaN       NaN           NaN   \n",
       "836   0.991940          0.0     0.000000 -0.002488      1.421778   \n",
       "837   0.000228          0.0     0.000027 -0.000164   4389.493652   \n",
       "838   0.000254          0.0     0.000015  0.000134   3944.684326   \n",
       "839   0.000228          0.0     0.000016  0.000219   4386.286621   \n",
       "842   0.000255          0.0     0.000010 -0.000478   3920.126709   \n",
       "843        NaN          NaN          NaN       NaN           NaN   \n",
       "844        NaN          NaN          NaN       NaN           NaN   \n",
       "846   0.000218          0.0     0.000015 -0.000156   4588.641113   \n",
       "847        NaN          NaN          NaN       NaN           NaN   \n",
       "\n",
       "     mean_rel_diff  max_rel_diff   pearson  max_abs_diff  mean_abs_diff  \\\n",
       "1     83933.062500  6.245747e+11  0.000037    448.040527      23.491154   \n",
       "2     94711.351562  1.379779e+12 -0.000128    448.040039       6.796145   \n",
       "3    144081.312500  6.944284e+11 -0.000017    448.027222      35.005745   \n",
       "6     27890.207031  5.200393e+09 -0.000717    448.052734      47.079998   \n",
       "7              NaN           NaN       NaN           NaN            NaN   \n",
       "8              NaN           NaN       NaN           NaN            NaN   \n",
       "10   108942.070312  8.457782e+10  0.000173    448.038086      68.106529   \n",
       "11             NaN           NaN       NaN           NaN            NaN   \n",
       "13    92496.351562  2.210074e+11 -0.000085    448.031982      15.785647   \n",
       "14    80385.343750  1.901858e+11 -0.002561    448.058594       5.853664   \n",
       "15   175742.328125  9.296684e+11  0.000031    448.016846      19.753969   \n",
       "18    40850.437500  1.004120e+10  0.000140    448.053955      38.335239   \n",
       "19             NaN           NaN       NaN           NaN            NaN   \n",
       "20             NaN           NaN       NaN           NaN            NaN   \n",
       "22   125684.679688  5.753258e+10 -0.000554    448.036865      36.667000   \n",
       "23             NaN           NaN       NaN           NaN            NaN   \n",
       "25    84006.882812  5.088649e+11 -0.000120    448.042480      12.308104   \n",
       "26    78158.953125  1.039538e+12 -0.000187    448.207031       4.621072   \n",
       "27   136232.515625  9.815383e+11 -0.000124    448.032227      15.789912   \n",
       "30    48838.906250  6.926057e+10 -0.001011    448.072754      30.269457   \n",
       "31             NaN           NaN       NaN           NaN            NaN   \n",
       "32             NaN           NaN       NaN           NaN            NaN   \n",
       "34   142250.140625  5.695312e+11 -0.000291    448.025635      41.066807   \n",
       "35             NaN           NaN       NaN           NaN            NaN   \n",
       "38       13.248475  1.562718e+06 -0.003391      0.277832       0.025607   \n",
       "39   111086.609375  1.099512e+11  0.000154    448.027954      45.915237   \n",
       "40   106107.656250  4.311810e+10  0.007698    448.034912      40.476818   \n",
       "41   188024.328125  2.638828e+11  0.000455    448.029175      72.166595   \n",
       "44    44838.820312  1.610613e+10 -0.000964    448.102539      47.355137   \n",
       "45             NaN           NaN       NaN           NaN            NaN   \n",
       "46             NaN           NaN       NaN           NaN            NaN   \n",
       "48    76040.718750  1.019415e+11 -0.000191    448.040527      49.336349   \n",
       "49             NaN           NaN       NaN           NaN            NaN   \n",
       "52       10.403044  2.972342e+06 -0.005655      0.514404       0.032241   \n",
       "53   104473.632812  2.286984e+11  0.000191    448.034668      48.497044   \n",
       "54    41904.957031  1.778622e+10 -0.002561    448.047607      35.467117   \n",
       "55   123050.289062  9.657872e+10 -0.000021    448.027832      68.796997   \n",
       "58   103584.546875  2.521173e+11  0.000142    448.075684      54.851147   \n",
       "59             NaN           NaN       NaN           NaN            NaN   \n",
       "60             NaN           NaN       NaN           NaN            NaN   \n",
       "62   128580.859375  2.133381e+11  0.000736    448.054688      66.160744   \n",
       "63             NaN           NaN       NaN           NaN            NaN   \n",
       "66       10.279372  1.655645e+06  0.002850      0.581055       0.038961   \n",
       "67    83325.734375  9.926146e+10  0.000072    448.026367      49.998989   \n",
       "68    59396.566406  1.157381e+11  0.007958    448.050293      35.807480   \n",
       "69   122963.664062  2.057566e+11 -0.000720    448.029419      64.861771   \n",
       "72    26617.050781  6.568774e+09  0.000556    448.097168      42.111485   \n",
       "73             NaN           NaN       NaN           NaN            NaN   \n",
       "74             NaN           NaN       NaN           NaN            NaN   \n",
       "76    78665.507812  9.458165e+10  0.000123    448.049316      60.950573   \n",
       "77             NaN           NaN       NaN           NaN            NaN   \n",
       "80       11.150939  1.377131e+06  0.001637      0.675049       0.042596   \n",
       "81    68780.289062  1.816374e+10  0.000040    448.034180      51.997993   \n",
       "82    42008.457031  7.996448e+10  0.006893    448.094727      34.640247   \n",
       "83    96643.554688  1.178048e+11 -0.000596    448.040527      63.304726   \n",
       "86    56666.421875  6.972513e+10  0.000162    448.085449      58.334003   \n",
       "87             NaN           NaN       NaN           NaN            NaN   \n",
       "88             NaN           NaN       NaN           NaN            NaN   \n",
       "90   106324.718750  2.278781e+11  0.000410    448.031982      61.963135   \n",
       "91             NaN           NaN       NaN           NaN            NaN   \n",
       "94        8.175681  5.932172e+05 -0.000211      0.621704       0.049081   \n",
       "95    86767.773438  1.824075e+11  0.000423    448.025879      53.748817   \n",
       "96    33285.167969  2.114446e+10  0.002571    448.061279      34.820297   \n",
       "97    90334.429688  1.449906e+11  0.000060    448.033447      58.566914   \n",
       "100   28647.994141  2.987803e+09 -0.001061    448.128906      54.644348   \n",
       "101            NaN           NaN       NaN           NaN            NaN   \n",
       "102            NaN           NaN       NaN           NaN            NaN   \n",
       "104   76815.914062  1.077953e+11 -0.000106    448.043213      65.227463   \n",
       "105            NaN           NaN       NaN           NaN            NaN   \n",
       "108       7.747681  6.337558e+05 -0.002351      0.675293       0.048485   \n",
       "109   72496.890625  1.360221e+11  0.000129    448.045654      43.508984   \n",
       "110   33780.730469  2.987803e+10  0.002126    448.072754      35.894470   \n",
       "111  326736.812500  2.645441e+12 -0.000741    448.039551      56.034348   \n",
       "114   31014.486328  6.921386e+09  0.001199    448.079590      53.058487   \n",
       "115            NaN           NaN       NaN           NaN            NaN   \n",
       "116            NaN           NaN       NaN           NaN            NaN   \n",
       "118   61390.054688  2.863311e+10  0.000191    448.050293      62.451614   \n",
       "119            NaN           NaN       NaN           NaN            NaN   \n",
       "122       9.150343  1.513408e+06 -0.000224      0.627930       0.047580   \n",
       "123   94325.835938  3.845286e+11  0.000436    448.035645      47.616280   \n",
       "124   36657.710938  3.642960e+10  0.001561    448.090332      33.766823   \n",
       "125   74949.867188  1.022802e+11  0.000223    448.033447      50.510826   \n",
       "128   38092.027344  1.365288e+10  0.000201    448.082031      61.989113   \n",
       "129            NaN           NaN       NaN           NaN            NaN   \n",
       "130            NaN           NaN       NaN           NaN            NaN   \n",
       "132  113839.148438  2.542223e+11 -0.000428    448.040527      75.271484   \n",
       "133            NaN           NaN       NaN           NaN            NaN   \n",
       "136       9.255237  5.682615e+05 -0.004296      0.527039       0.048087   \n",
       "137   75546.671875  1.027581e+11  0.000112    448.046387      51.127525   \n",
       "138   46266.199219  6.871948e+10 -0.000219    448.088867      32.213394   \n",
       "139   71460.921875  3.248557e+10 -0.000002    448.050537      50.749287   \n",
       "142   33626.273438  9.111975e+09  0.000038    448.125000      59.024380   \n",
       "143            NaN           NaN       NaN           NaN            NaN   \n",
       "144            NaN           NaN       NaN           NaN            NaN   \n",
       "146   98738.742188  8.084645e+10  0.000364    448.048828      75.587151   \n",
       "147            NaN           NaN       NaN           NaN            NaN   \n",
       "150      11.144596  1.712673e+06 -0.002518      0.501953       0.049011   \n",
       "151   87873.343750  1.917753e+11  0.000031    448.042480      47.950573   \n",
       "152   36411.246094  2.824088e+10 -0.000053    448.088379      32.682415   \n",
       "153   81376.351562  1.268667e+11 -0.000152    448.038330      48.853081   \n",
       "156   37852.476562  1.453681e+10 -0.000145    448.090820      70.807175   \n",
       "157            NaN           NaN       NaN           NaN            NaN   \n",
       "158            NaN           NaN       NaN           NaN            NaN   \n",
       "160   64734.238281  4.780485e+10 -0.000089    448.048096      70.225998   \n",
       "161            NaN           NaN       NaN           NaN            NaN   \n",
       "164      14.124280  1.053342e+07 -0.001786      0.590820       0.047986   \n",
       "165   67611.867188  2.224445e+10  0.000285    448.050049      50.335476   \n",
       "166   44485.601562  1.963414e+10 -0.001710    448.085449      34.325626   \n",
       "167   63613.476562  1.636178e+10  0.000034    448.053955      48.593182   \n",
       "170   33560.445312  4.805558e+09  0.000435    448.106934      65.864243   \n",
       "171            NaN           NaN       NaN           NaN            NaN   \n",
       "172            NaN           NaN       NaN           NaN            NaN   \n",
       "174   78593.039062  6.299286e+10 -0.000233    448.057373      68.812584   \n",
       "175            NaN           NaN       NaN           NaN            NaN   \n",
       "178      10.097334  1.601146e+06 -0.002914      0.601654       0.048259   \n",
       "179   72545.148438  5.429687e+10  0.000095    448.048340      48.868233   \n",
       "180   50679.742188  5.961208e+10 -0.002057    448.101074      31.786739   \n",
       "181  137100.203125  4.317101e+11 -0.000086    448.041748      47.781593   \n",
       "184   35885.093750  9.554579e+09  0.000074    448.188477      68.483772   \n",
       "185            NaN           NaN       NaN           NaN            NaN   \n",
       "186            NaN           NaN       NaN           NaN            NaN   \n",
       "188   56591.507812  1.502065e+10 -0.000043    448.063477      68.983444   \n",
       "189            NaN           NaN       NaN           NaN            NaN   \n",
       "192       7.492600  5.786942e+05 -0.003380      0.562012       0.047714   \n",
       "193  103942.492188  4.773074e+11 -0.000267    448.169922      49.261894   \n",
       "194   60341.679688  2.532906e+11 -0.002155    448.087402      25.531776   \n",
       "195   87642.031250  3.227924e+11  0.000183    448.052979      46.309608   \n",
       "198   43932.089844  3.435974e+10  0.000144    448.087891      68.981293   \n",
       "199            NaN           NaN       NaN           NaN            NaN   \n",
       "200            NaN           NaN       NaN           NaN            NaN   \n",
       "202   56138.335938  3.546812e+10 -0.000231    448.065430      72.510666   \n",
       "203            NaN           NaN       NaN           NaN            NaN   \n",
       "206       7.658829  1.154136e+06 -0.003553      0.554688       0.047247   \n",
       "207   89205.640625  2.199023e+11  0.000324    448.041016      44.529606   \n",
       "208   34416.296875  4.678773e+10 -0.000968    448.074219      26.249416   \n",
       "209   68517.617188  4.006318e+10  0.000047    448.041016      44.436245   \n",
       "212   36770.828125  6.650272e+09  0.000258    448.105957      71.288094   \n",
       "213            NaN           NaN       NaN           NaN            NaN   \n",
       "214            NaN           NaN       NaN           NaN            NaN   \n",
       "216   57141.085938  5.961208e+10 -0.000266    448.062256      75.351212   \n",
       "217            NaN           NaN       NaN           NaN            NaN   \n",
       "220       7.540335  7.418769e+05 -0.006058      0.579712       0.046998   \n",
       "221   65712.617188  8.078044e+10  0.000297    448.046387      48.383396   \n",
       "222   38455.523438  4.754645e+10 -0.000996    448.109863      23.628176   \n",
       "223   68696.265625  1.691556e+11  0.000332    448.041992      44.068352   \n",
       "226  108091.843750  1.809323e+11 -0.000334    448.100586      69.130898   \n",
       "227            NaN           NaN       NaN           NaN            NaN   \n",
       "228            NaN           NaN       NaN           NaN            NaN   \n",
       "230   65696.726562  6.944284e+10 -0.000515    448.056396      78.484642   \n",
       "231            NaN           NaN       NaN           NaN            NaN   \n",
       "234       8.138981  2.219794e+06 -0.003558      0.552246       0.046564   \n",
       "235   83600.359375  4.386349e+10  0.000072    448.059570      48.018024   \n",
       "236   46348.429688  4.898814e+10 -0.001624    448.113281      31.664038   \n",
       "237   78606.656250  8.144531e+10  0.000359    448.051270      48.941292   \n",
       "240   32944.500000  6.170728e+09 -0.000256    448.080566      62.261913   \n",
       "241            NaN           NaN       NaN           NaN            NaN   \n",
       "242            NaN           NaN       NaN           NaN            NaN   \n",
       "244   52557.511719  1.832519e+10 -0.000042    448.070801      74.487129   \n",
       "245            NaN           NaN       NaN           NaN            NaN   \n",
       "248       7.086387  4.426945e+05 -0.004603      0.573975       0.045766   \n",
       "249   59994.035156  1.871509e+10  0.000224    448.047119      46.171185   \n",
       "250   41185.980469  3.646339e+10 -0.001710    448.090332      30.620880   \n",
       "251  114335.671875  3.021559e+11  0.000542    448.049561      47.354362   \n",
       "254   38760.339844  8.191726e+09  0.000758    448.072754      68.218445   \n",
       "255            NaN           NaN       NaN           NaN            NaN   \n",
       "256            NaN           NaN       NaN           NaN            NaN   \n",
       "258  182631.156250  1.122905e+12  0.000164    448.060791      79.014297   \n",
       "259            NaN           NaN       NaN           NaN            NaN   \n",
       "262       8.630249  3.332972e+06 -0.004641      0.630844       0.045444   \n",
       "263   60915.753906  5.286114e+10 -0.000071    448.048340      44.023239   \n",
       "264   37515.609375  1.784921e+10 -0.001425    448.105469      32.712452   \n",
       "265   69824.281250  8.457782e+10 -0.000435    448.075195      45.274456   \n",
       "268   32920.160156  5.245762e+09  0.000148    448.094727      70.256126   \n",
       "269            NaN           NaN       NaN           NaN            NaN   \n",
       "270            NaN           NaN       NaN           NaN            NaN   \n",
       "272  113385.765625  4.429687e+11 -0.000265    448.061768      80.569618   \n",
       "273            NaN           NaN       NaN           NaN            NaN   \n",
       "276       8.309877  2.365393e+06 -0.004085      0.880859       0.045063   \n",
       "277   65615.882812  5.216661e+10 -0.000049    448.055664      47.841057   \n",
       "278   45011.886719  4.302437e+10 -0.001543    448.081055      35.923420   \n",
       "279   70258.507812  1.499334e+11  0.000041    448.055664      48.812527   \n",
       "282   55398.613281  5.662721e+10 -0.000930    448.102539      69.423103   \n",
       "283            NaN           NaN       NaN           NaN            NaN   \n",
       "284            NaN           NaN       NaN           NaN            NaN   \n",
       "286  118446.406250  4.123169e+11 -0.000270    448.054443      83.965500   \n",
       "287            NaN           NaN       NaN           NaN            NaN   \n",
       "290       7.579942  1.231282e+06 -0.004667      0.709900       0.043607   \n",
       "291   94233.632812  2.393495e+11 -0.000056    448.042480      49.313259   \n",
       "292   42319.062500  3.276690e+10 -0.001270    448.080078      40.509304   \n",
       "293   59840.785156  1.381296e+10 -0.000012    448.048340      49.617111   \n",
       "296   35816.812500  6.343336e+09 -0.000238    448.077148      67.374046   \n",
       "297            NaN           NaN       NaN           NaN            NaN   \n",
       "298            NaN           NaN       NaN           NaN            NaN   \n",
       "300  110719.929688  5.929950e+11  0.000236    448.061279      82.983955   \n",
       "301            NaN           NaN       NaN           NaN            NaN   \n",
       "304       6.799035  1.167164e+06 -0.005638      0.651154       0.043359   \n",
       "305   60454.804688  3.214946e+10  0.000548    448.050781      45.218090   \n",
       "306  154464.421875  1.599290e+12 -0.000112    448.083496      40.729774   \n",
       "307   54421.101562  1.906668e+10  0.000020    448.040283      46.840004   \n",
       "310   28110.822266  3.435974e+09  0.000014    448.089355      65.355232   \n",
       "311            NaN           NaN       NaN           NaN            NaN   \n",
       "312            NaN           NaN       NaN           NaN            NaN   \n",
       "314   73483.367188  1.951796e+11 -0.000070    448.059570      83.454048   \n",
       "315            NaN           NaN       NaN           NaN            NaN   \n",
       "318       6.806275  9.437174e+05 -0.005457      0.676025       0.042139   \n",
       "319   53237.601562  1.812382e+10  0.000154    448.056885      46.886604   \n",
       "320   51236.792969  1.124501e+11  0.000064    448.072754      42.024529   \n",
       "321   56260.359375  2.159755e+10 -0.000244    448.051270      45.346439   \n",
       "324   40893.218750  1.385939e+10  0.000189    448.090820      67.768341   \n",
       "325            NaN           NaN       NaN           NaN            NaN   \n",
       "326            NaN           NaN       NaN           NaN            NaN   \n",
       "328  101440.617188  4.143087e+11 -0.000013    448.081055      84.165985   \n",
       "329            NaN           NaN       NaN           NaN            NaN   \n",
       "332       6.967912  2.037659e+06 -0.009121      0.783661       0.041236   \n",
       "333   70815.179688  1.963414e+11  0.000174    448.044189      48.983410   \n",
       "334   53367.753906  3.515880e+10 -0.000207    448.079590      40.885448   \n",
       "335   57816.910156  2.237378e+10 -0.000082    448.062988      43.369343   \n",
       "338   34240.996094  1.275805e+10  0.000569    448.092773      63.937683   \n",
       "339            NaN           NaN       NaN           NaN            NaN   \n",
       "340            NaN           NaN       NaN           NaN            NaN   \n",
       "342   47613.683594  1.869918e+10  0.000233    448.076172      83.853996   \n",
       "343            NaN           NaN       NaN           NaN            NaN   \n",
       "346       6.157388  8.881391e+05 -0.006102      0.707642       0.040536   \n",
       "347   66962.312500  7.186351e+10 -0.000034    448.048828      51.221184   \n",
       "348   50413.109375  1.537778e+11  0.000061    448.066406      37.953381   \n",
       "349   59902.082031  2.411210e+10  0.000060    448.041992      43.627922   \n",
       "352   26756.935547  2.177730e+09 -0.000941    448.085449      60.438431   \n",
       "353            NaN           NaN       NaN           NaN            NaN   \n",
       "354            NaN           NaN       NaN           NaN            NaN   \n",
       "356   73109.187500  2.407690e+11  0.000214    448.098633      83.337296   \n",
       "357            NaN           NaN       NaN           NaN            NaN   \n",
       "360      28.079277  3.535601e+07 -0.005763      0.514099       0.040127   \n",
       "361   71131.429688  1.434146e+11  0.000214    448.053711      51.775349   \n",
       "362   46579.980469  6.077703e+10 -0.000415    448.072266      39.595421   \n",
       "363   53408.792969  3.133323e+10 -0.000302    448.043457      45.956284   \n",
       "366   38679.003906  2.466853e+10  0.000985    448.123047      64.604950   \n",
       "367            NaN           NaN       NaN           NaN            NaN   \n",
       "368            NaN           NaN       NaN           NaN            NaN   \n",
       "370   79836.742188  2.945120e+11 -0.000011    448.061768      82.751930   \n",
       "371            NaN           NaN       NaN           NaN            NaN   \n",
       "374       7.955982  2.352456e+06 -0.008811      0.592773       0.039701   \n",
       "375   81858.500000  8.457782e+10  0.000011    448.039062      56.084431   \n",
       "376   55310.933594  9.407586e+10 -0.000360    448.057617      42.273369   \n",
       "377   61047.878906  5.590737e+10 -0.000184    448.044922      48.959206   \n",
       "380   30653.859375  2.627510e+09 -0.000787    448.061279      59.762985   \n",
       "381            NaN           NaN       NaN           NaN            NaN   \n",
       "382            NaN           NaN       NaN           NaN            NaN   \n",
       "384   50730.894531  2.482768e+10  0.000261    448.082520      78.443085   \n",
       "385            NaN           NaN       NaN           NaN            NaN   \n",
       "388       6.859995  1.125183e+06 -0.006993      0.520508       0.039013   \n",
       "389   86174.664062  1.115447e+11  0.000260    448.049316      55.759281   \n",
       "390   38064.398438  1.182271e+10 -0.000692    448.062500      39.028008   \n",
       "391   55380.269531  4.228891e+10 -0.000280    448.041992      48.690922   \n",
       "394   30954.318359  2.614328e+09 -0.000186    448.137695      65.849876   \n",
       "395            NaN           NaN       NaN           NaN            NaN   \n",
       "396            NaN           NaN       NaN           NaN            NaN   \n",
       "398   62119.929688  5.023150e+10 -0.000038    448.077148      83.880600   \n",
       "399            NaN           NaN       NaN           NaN            NaN   \n",
       "402      10.829238  3.797211e+06 -0.005622      0.595947       0.038860   \n",
       "403   72467.890625  8.078044e+10  0.000093    448.052979      54.839592   \n",
       "404   39594.101562  8.371916e+09 -0.000283    448.049805      42.527416   \n",
       "405   69093.937500  8.365849e+10 -0.000108    448.038330      49.193718   \n",
       "408   32983.320312  7.362801e+09 -0.000274    448.108398      68.122375   \n",
       "409            NaN           NaN       NaN           NaN            NaN   \n",
       "410            NaN           NaN       NaN           NaN            NaN   \n",
       "412   69587.335938  2.209064e+11 -0.000219    448.072266      82.181435   \n",
       "413            NaN           NaN       NaN           NaN            NaN   \n",
       "416       6.934441  7.369352e+05 -0.004038      0.479492       0.038543   \n",
       "417   60451.601562  4.606892e+10  0.000122    448.071289      54.965805   \n",
       "418   41168.976562  2.860001e+10 -0.000214    448.076172      41.206360   \n",
       "419   81316.234375  1.393747e+11  0.000154    448.040283      48.643196   \n",
       "422   38724.601562  1.120426e+10 -0.000117    448.106934      68.162651   \n",
       "423            NaN           NaN       NaN           NaN            NaN   \n",
       "424            NaN           NaN       NaN           NaN            NaN   \n",
       "426   52958.476562  2.783574e+10 -0.000026    448.076172      82.906509   \n",
       "427            NaN           NaN       NaN           NaN            NaN   \n",
       "430       8.236053  3.431704e+06 -0.004194      0.486572       0.037195   \n",
       "431   76537.062500  1.891633e+11  0.000165    448.045898      53.644447   \n",
       "432   45879.109375  6.686219e+10 -0.000017    448.050049      39.280289   \n",
       "433   56659.636719  6.108398e+10  0.000165    448.044434      46.169350   \n",
       "436   30605.884766  2.699694e+09 -0.000494    448.158203      63.707577   \n",
       "437            NaN           NaN       NaN           NaN            NaN   \n",
       "438            NaN           NaN       NaN           NaN            NaN   \n",
       "440   48379.199219  2.114446e+10 -0.000026    448.065918      78.596474   \n",
       "441            NaN           NaN       NaN           NaN            NaN   \n",
       "444       7.581616  3.099565e+06 -0.001722      0.485107       0.036806   \n",
       "445   86737.960938  2.145388e+11 -0.000102    448.042969      52.913498   \n",
       "446  106709.531250  6.066271e+11  0.000063    448.050293      39.291393   \n",
       "447   51973.976562  2.164393e+10  0.000302    448.046387      46.139214   \n",
       "450   37208.312500  5.726623e+09 -0.000373    448.118164      65.399979   \n",
       "451            NaN           NaN       NaN           NaN            NaN   \n",
       "452            NaN           NaN       NaN           NaN            NaN   \n",
       "454   67023.195312  1.444614e+11  0.000098    448.074707      82.702156   \n",
       "455            NaN           NaN       NaN           NaN            NaN   \n",
       "458       6.573598  6.546205e+05 -0.005238      0.544861       0.036671   \n",
       "459  124730.500000  1.055531e+12  0.000011    448.057861      51.854233   \n",
       "460   42255.625000  1.075609e+10  0.001087    448.058594      46.975239   \n",
       "461   53005.238281  2.699694e+10  0.000004    448.058350      48.525593   \n",
       "464   31396.652344  1.327913e+10  0.000208    448.151367      62.332523   \n",
       "465            NaN           NaN       NaN           NaN            NaN   \n",
       "466            NaN           NaN       NaN           NaN            NaN   \n",
       "468   44827.691406  2.439745e+10  0.000341    448.077148      83.261055   \n",
       "469            NaN           NaN       NaN           NaN            NaN   \n",
       "472       6.077863  4.487540e+05 -0.002101      0.521851       0.035628   \n",
       "473   76338.273438  1.815707e+11  0.000255    448.057617      53.525856   \n",
       "474   74510.414062  2.679013e+11  0.001030    448.051514      44.431938   \n",
       "475   76995.984375  2.403304e+11 -0.000103    448.044434      47.508385   \n",
       "478   27765.283203  7.150003e+09  0.000319    448.124512      52.785561   \n",
       "479            NaN           NaN       NaN           NaN            NaN   \n",
       "480            NaN           NaN       NaN           NaN            NaN   \n",
       "482   70075.609375  1.736071e+11 -0.000041    448.075684      83.240868   \n",
       "483            NaN           NaN       NaN           NaN            NaN   \n",
       "486       6.299329  3.625386e+05 -0.002265      0.488525       0.035434   \n",
       "487   59439.398438  5.235770e+10 -0.000021    448.159180      48.815750   \n",
       "488   45753.617188  2.174175e+10  0.001031    448.072754      44.380424   \n",
       "489   55582.941406  8.737841e+10  0.000306    448.058105      42.723488   \n",
       "492   28743.703125  4.393026e+09 -0.000187    448.109863      60.987366   \n",
       "493            NaN           NaN       NaN           NaN            NaN   \n",
       "494            NaN           NaN       NaN           NaN            NaN   \n",
       "496   51387.316406  3.824388e+10  0.000045    448.066406      80.860954   \n",
       "497            NaN           NaN       NaN           NaN            NaN   \n",
       "500       5.917994  6.260166e+05 -0.000620      0.553589       0.035180   \n",
       "501   61939.054688  7.910156e+10  0.000181    448.038330      52.318501   \n",
       "502   50886.019531  2.876629e+10  0.000474    448.041748      48.241295   \n",
       "503   46956.445312  1.863579e+10  0.000217    448.052734      48.439747   \n",
       "506   40093.097656  6.544712e+09  0.000836    448.156250      67.872482   \n",
       "507            NaN           NaN       NaN           NaN            NaN   \n",
       "508            NaN           NaN       NaN           NaN            NaN   \n",
       "510   64612.523438  5.957945e+10  0.000268    448.066406      84.026520   \n",
       "511            NaN           NaN       NaN           NaN            NaN   \n",
       "514       6.530527  4.013059e+05  0.000946      0.411194       0.034828   \n",
       "515   62654.824219  2.617885e+10 -0.000129    448.039795      52.007900   \n",
       "516   51412.230469  1.355562e+11  0.000819    448.049316      45.252541   \n",
       "517   65662.820312  9.213785e+10  0.000551    448.042236      47.736370   \n",
       "520   37682.843750  2.256460e+10 -0.000145    448.126953      61.171196   \n",
       "521            NaN           NaN       NaN           NaN            NaN   \n",
       "522            NaN           NaN       NaN           NaN            NaN   \n",
       "524   63310.359375  1.183331e+11  0.000039    448.069336      83.316315   \n",
       "525            NaN           NaN       NaN           NaN            NaN   \n",
       "528       6.977399  1.141552e+06  0.002040      0.456177       0.034657   \n",
       "529   66814.710938  5.871179e+10 -0.000085    448.052979      48.993149   \n",
       "530   48758.203125  9.995561e+10  0.000411    448.042725      44.963810   \n",
       "531   50613.683594  3.616815e+10  0.000385    448.051758      44.308361   \n",
       "534   27983.072266  5.655924e+09 -0.000653    448.196289      57.879272   \n",
       "535            NaN           NaN       NaN           NaN            NaN   \n",
       "536            NaN           NaN       NaN           NaN            NaN   \n",
       "538   54179.046875  6.663707e+10 -0.000375    448.077148      84.452888   \n",
       "539            NaN           NaN       NaN           NaN            NaN   \n",
       "542       5.328950  2.070192e+05  0.001562      0.461042       0.034095   \n",
       "543   74789.625000  2.152890e+11 -0.000362    448.037109      49.486153   \n",
       "544   46713.707031  5.320217e+10  0.001322    448.056641      45.890270   \n",
       "545   57213.574219  7.374773e+10 -0.000232    448.043213      44.357609   \n",
       "548   67299.632812  1.499334e+11 -0.000706    448.242188      55.413795   \n",
       "549            NaN           NaN       NaN           NaN            NaN   \n",
       "550            NaN           NaN       NaN           NaN            NaN   \n",
       "552  139264.093750  4.833018e+11 -0.000089    448.061035      84.174171   \n",
       "553            NaN           NaN       NaN           NaN            NaN   \n",
       "556       8.325297  1.611370e+06  0.003657      0.440552       0.033292   \n",
       "557  324381.187500  3.728145e+12  0.000333    448.034668      52.028522   \n",
       "558   62941.453125  1.232211e+11  0.000723    448.049072      47.894119   \n",
       "559   53996.414062  7.365149e+10  0.000079    448.044678      47.846733   \n",
       "562   33941.050781  9.817069e+09 -0.000041    448.096680      59.874821   \n",
       "563            NaN           NaN       NaN           NaN            NaN   \n",
       "564            NaN           NaN       NaN           NaN            NaN   \n",
       "566   75614.359375  2.513169e+11 -0.000171    448.079590      76.485435   \n",
       "567            NaN           NaN       NaN           NaN            NaN   \n",
       "570      10.375254  6.325101e+06  0.005764      0.389709       0.032201   \n",
       "571   50347.285156  1.914572e+10 -0.000151    448.043457      48.936752   \n",
       "572   68080.296875  2.229424e+11  0.001146    448.040039      47.032265   \n",
       "573   58560.859375  1.293543e+11  0.000310    448.038574      44.166080   \n",
       "576   27479.613281  3.939333e+09 -0.000069    448.134766      56.279320   \n",
       "577            NaN           NaN       NaN           NaN            NaN   \n",
       "578            NaN           NaN       NaN           NaN            NaN   \n",
       "580   53393.441406  2.617885e+10 -0.000224    448.069336      84.626434   \n",
       "581            NaN           NaN       NaN           NaN            NaN   \n",
       "584       7.656887  1.653523e+06  0.005002      0.377197       0.031232   \n",
       "585   51380.972656  1.018066e+10  0.000071    448.039795      48.669384   \n",
       "586   49648.539062  2.733592e+10  0.001010    448.082520      46.914322   \n",
       "587   52574.664062  5.497558e+10 -0.000491    448.041260      45.833378   \n",
       "590   64964.792969  1.332741e+11 -0.000227    448.138672      63.714077   \n",
       "591            NaN           NaN       NaN           NaN            NaN   \n",
       "592            NaN           NaN       NaN           NaN            NaN   \n",
       "594   49000.750000  1.627567e+10  0.000167    448.077148      85.509880   \n",
       "595            NaN           NaN       NaN           NaN            NaN   \n",
       "598       7.097365  2.189672e+06  0.004176      0.434937       0.030982   \n",
       "599   49732.816406  2.210074e+10 -0.000003    448.051758      44.747868   \n",
       "600   42603.464844  1.460704e+10  0.000668    448.042725      46.344582   \n",
       "601   52229.101562  4.363142e+10  0.000061    448.037354      44.284389   \n",
       "604   25103.058594  3.011611e+09  0.000319    448.259766      53.972969   \n",
       "605            NaN           NaN       NaN           NaN            NaN   \n",
       "606            NaN           NaN       NaN           NaN            NaN   \n",
       "608   45390.710938  1.458536e+10 -0.000178    448.070801      83.016846   \n",
       "609            NaN           NaN       NaN           NaN            NaN   \n",
       "612       6.926130  2.296250e+06  0.004635      0.449829       0.030453   \n",
       "613   63366.921875  7.761259e+10  0.000238    448.036865      46.188362   \n",
       "614   42753.277344  2.568952e+10  0.000643    448.041748      46.005123   \n",
       "615   53935.484375  4.557561e+10 -0.000131    448.037598      45.269539   \n",
       "618  164057.468750  4.113281e+11  0.000564    448.130859      66.646599   \n",
       "619            NaN           NaN       NaN           NaN            NaN   \n",
       "620            NaN           NaN       NaN           NaN            NaN   \n",
       "622   47570.929688  1.121951e+10 -0.000222    448.075684      78.170517   \n",
       "623            NaN           NaN       NaN           NaN            NaN   \n",
       "626       6.962451  1.811176e+06  0.006656      0.486694       0.030317   \n",
       "627   56981.671875  8.298201e+10  0.000257    448.041016      46.059299   \n",
       "628   46007.796875  4.133502e+10  0.000765    448.063477      45.025131   \n",
       "629   48538.796875  1.991869e+10  0.000052    448.037354      43.076241   \n",
       "632   37411.636719  2.664015e+10 -0.000565    448.135742      57.219238   \n",
       "633            NaN           NaN       NaN           NaN            NaN   \n",
       "634            NaN           NaN       NaN           NaN            NaN   \n",
       "636   45184.449219  1.257064e+10  0.000150    448.085449      82.734909   \n",
       "637            NaN           NaN       NaN           NaN            NaN   \n",
       "640       7.063575  2.130708e+06  0.005155      0.442139       0.028849   \n",
       "641   69517.117188  1.324713e+11  0.000087    448.059814      46.030537   \n",
       "642   48101.644531  3.012361e+10  0.000670    448.057373      48.837246   \n",
       "643   52456.207031  1.682926e+10 -0.000362    448.038818      43.042099   \n",
       "646   23214.568359  3.817749e+09  0.000839    448.077148      51.204514   \n",
       "647            NaN           NaN       NaN           NaN            NaN   \n",
       "648            NaN           NaN       NaN           NaN            NaN   \n",
       "650   54636.542969  1.917753e+10  0.000233    448.073730      80.585632   \n",
       "651            NaN           NaN       NaN           NaN            NaN   \n",
       "654      14.109981  1.452872e+07  0.003805      0.458252       0.028205   \n",
       "655   69636.281250  1.699728e+11 -0.000156    448.039795      50.225204   \n",
       "656   48564.054688  2.987803e+10  0.000835    448.063477      50.489311   \n",
       "657   60397.398438  4.474757e+10  0.000049    448.040771      46.630215   \n",
       "660   28729.501953  1.627567e+10 -0.000720    448.094727      47.985260   \n",
       "661            NaN           NaN       NaN           NaN            NaN   \n",
       "662            NaN           NaN       NaN           NaN            NaN   \n",
       "664   72250.726562  7.156584e+10 -0.000197    448.057129      81.831963   \n",
       "665            NaN           NaN       NaN           NaN            NaN   \n",
       "668       8.580814  2.498458e+06  0.006815      0.382812       0.028055   \n",
       "669   82208.375000  3.190293e+11 -0.000014    448.044678      51.970615   \n",
       "670   46493.609375  8.975605e+10  0.000958    448.061279      50.315189   \n",
       "671   65039.093750  6.214631e+10  0.000481    448.044434      46.345890   \n",
       "674   40340.566406  1.304800e+10 -0.000421    448.097656      66.549110   \n",
       "675            NaN           NaN       NaN           NaN            NaN   \n",
       "676            NaN           NaN       NaN           NaN            NaN   \n",
       "678   76075.992188  3.123613e+10  0.000134    448.061768      83.202171   \n",
       "679            NaN           NaN       NaN           NaN            NaN   \n",
       "682       4.913018  1.075075e+05  0.005687      0.497725       0.028072   \n",
       "683   68588.726562  6.731704e+10  0.000404    448.050293      51.094738   \n",
       "684   59792.234375  5.577233e+10  0.000945    448.049805      51.351974   \n",
       "685  157433.500000  1.297784e+12 -0.000348    448.033936      46.773361   \n",
       "688   56327.046875  3.509080e+10 -0.000336    448.077637      62.526688   \n",
       "689            NaN           NaN       NaN           NaN            NaN   \n",
       "690            NaN           NaN       NaN           NaN            NaN   \n",
       "692   85830.742188  7.156584e+10 -0.000193    448.078613      82.545204   \n",
       "693            NaN           NaN       NaN           NaN            NaN   \n",
       "696      12.287910  1.018355e+07  0.004091      0.515320       0.027217   \n",
       "697   59561.312500  2.342709e+10 -0.000066    448.036865      49.717842   \n",
       "698   55200.367188  5.186376e+10  0.001385    448.045898      50.322086   \n",
       "699  123184.773438  8.747496e+11  0.000183    448.036377      45.715626   \n",
       "702   29731.494141  1.278502e+10  0.000347    448.141602      57.190922   \n",
       "703            NaN           NaN       NaN           NaN            NaN   \n",
       "704            NaN           NaN       NaN           NaN            NaN   \n",
       "706   53108.781250  7.186351e+10  0.000242    448.081055      81.018059   \n",
       "707            NaN           NaN       NaN           NaN            NaN   \n",
       "710       7.146149  1.054305e+06  0.004777      0.406006       0.026646   \n",
       "711  116853.351562  4.435005e+11 -0.000029    448.032959      53.563866   \n",
       "712   46510.121094  2.350930e+10  0.001001    448.064453      49.847744   \n",
       "713   67946.906250  5.235770e+10  0.000040    448.050781      48.745476   \n",
       "716   40286.941406  4.106060e+10  0.000039    448.089844      58.321678   \n",
       "717            NaN           NaN       NaN           NaN            NaN   \n",
       "718            NaN           NaN       NaN           NaN            NaN   \n",
       "720   55110.109375  1.520062e+10 -0.000412    448.083496      82.653221   \n",
       "721            NaN           NaN       NaN           NaN            NaN   \n",
       "724       5.952379  5.672131e+05  0.007191      0.416016       0.026215   \n",
       "725   65280.046875  7.036875e+10  0.000159    448.035400      49.505333   \n",
       "726   67106.992188  1.851809e+11  0.000658    448.052246      50.594616   \n",
       "727   72974.531250  7.635498e+10 -0.000285    448.035889      48.948296   \n",
       "730   43898.667969  1.727804e+10 -0.000054    448.126953      65.467949   \n",
       "731            NaN           NaN       NaN           NaN            NaN   \n",
       "732            NaN           NaN       NaN           NaN            NaN   \n",
       "734   60099.574219  7.093623e+10 -0.000404    448.055908      79.793724   \n",
       "735            NaN           NaN       NaN           NaN            NaN   \n",
       "738       5.608924  3.359505e+05  0.002194      0.529297       0.025217   \n",
       "739   60588.476562  2.213782e+10 -0.000120    448.046143      48.660442   \n",
       "740   72163.531250  3.023657e+11  0.000411    448.057861      49.945812   \n",
       "741   69012.031250  5.890241e+10 -0.000301    448.046631      47.737759   \n",
       "744   41153.359375  1.212697e+10  0.000570    448.070312      66.892845   \n",
       "745            NaN           NaN       NaN           NaN            NaN   \n",
       "746            NaN           NaN       NaN           NaN            NaN   \n",
       "748   55091.910156  9.115122e+10  0.000273    448.063965      73.885269   \n",
       "749            NaN           NaN       NaN           NaN            NaN   \n",
       "752       7.772630  3.962209e+06  0.004570      0.393822       0.024376   \n",
       "753   77353.398438  8.408030e+10 -0.000031    448.045898      50.039043   \n",
       "754   54278.503906  7.853655e+10 -0.000130    448.060791      50.312813   \n",
       "755   63881.269531  3.967310e+10  0.000285    448.038818      49.004391   \n",
       "758   42843.574219  9.629481e+09 -0.000439    448.065918      63.692081   \n",
       "759            NaN           NaN       NaN           NaN            NaN   \n",
       "760            NaN           NaN       NaN           NaN            NaN   \n",
       "762  245204.984375  1.607408e+12  0.000376    448.057129      82.612213   \n",
       "763            NaN           NaN       NaN           NaN            NaN   \n",
       "766       4.780324  1.094827e+05  0.002693      0.361908       0.024207   \n",
       "767   65095.105469  6.731704e+10  0.000364    448.049316      50.065414   \n",
       "768   80761.898438  2.549592e+11  0.000507    448.081543      52.161930   \n",
       "769   72835.218750  8.567623e+10  0.000099    448.035400      52.742100   \n",
       "772   44322.226562  4.140420e+10  0.000207    448.056152      59.618183   \n",
       "773            NaN           NaN       NaN           NaN            NaN   \n",
       "774            NaN           NaN       NaN           NaN            NaN   \n",
       "776   95299.117188  8.012635e+10  0.000137    448.049072      80.103516   \n",
       "777            NaN           NaN       NaN           NaN            NaN   \n",
       "780      16.797567  1.917396e+07  0.005024      0.356506       0.023236   \n",
       "781   75500.585938  2.094308e+11  0.000184    448.043701      50.332382   \n",
       "782   52136.453125  8.914959e+10  0.000709    448.060791      53.017929   \n",
       "783   83311.023438  2.426508e+11  0.000079    448.036133      54.482510   \n",
       "786   38593.156250  9.370838e+09 -0.000221    448.096680      67.729317   \n",
       "787            NaN           NaN       NaN           NaN            NaN   \n",
       "788            NaN           NaN       NaN           NaN            NaN   \n",
       "790  103989.742188  2.145388e+11 -0.000190    448.060059      80.500168   \n",
       "791            NaN           NaN       NaN           NaN            NaN   \n",
       "794       6.369375  1.516401e+06  0.003870      0.389984       0.022817   \n",
       "795   84146.710938  1.713525e+11 -0.000533    448.035889      48.836674   \n",
       "796   46617.175781  2.411210e+10 -0.000157    448.094238      53.295658   \n",
       "797   63511.289062  6.052358e+10 -0.000221    448.043701      55.354233   \n",
       "800   63072.113281  5.975606e+10 -0.000181    448.182617      62.526688   \n",
       "801            NaN           NaN       NaN           NaN            NaN   \n",
       "802            NaN           NaN       NaN           NaN            NaN   \n",
       "804   83934.046875  9.124578e+10  0.000243    448.064941      75.822250   \n",
       "805            NaN           NaN       NaN           NaN            NaN   \n",
       "808       5.969302  2.051572e+05 -0.000944      0.325684       0.022564   \n",
       "809   52250.949219  2.228740e+10 -0.000118    448.056152      47.467190   \n",
       "810   56015.222656  6.911216e+10 -0.000046    448.079590      53.671066   \n",
       "811   63015.148438  1.628906e+11 -0.000062    448.043701      53.023014   \n",
       "814   62297.203125  3.555635e+10  0.000020    448.092285      74.100739   \n",
       "815            NaN           NaN       NaN           NaN            NaN   \n",
       "816            NaN           NaN       NaN           NaN            NaN   \n",
       "818  297973.250000  2.363130e+12  0.000336    448.046143      63.545689   \n",
       "819            NaN           NaN       NaN           NaN            NaN   \n",
       "822       8.624231  2.912710e+06  0.001209      0.394775       0.021599   \n",
       "823   48132.335938  2.871859e+10 -0.000144    448.206055      44.010178   \n",
       "824   54383.152344  7.626670e+10 -0.000192    448.072754      48.809811   \n",
       "825   75714.164062  2.429860e+11  0.000156    448.069824      46.818249   \n",
       "828   30536.048828  3.031742e+09 -0.000025    448.095215      62.006210   \n",
       "829            NaN           NaN       NaN           NaN            NaN   \n",
       "830            NaN           NaN       NaN           NaN            NaN   \n",
       "832   61945.824219  3.524076e+10  0.000515    448.061035      77.599541   \n",
       "833            NaN           NaN       NaN           NaN            NaN   \n",
       "836      11.759218  2.415468e+06 -0.002441      0.530273       0.023758   \n",
       "837   47949.730469  3.665039e+10 -0.000164    448.048584      35.982563   \n",
       "838   49669.804688  4.712193e+10  0.000134    448.062500      49.567970   \n",
       "839   63520.992188  2.883965e+11  0.000219    448.050781      42.034321   \n",
       "842   53168.152344  4.398046e+10 -0.000478    448.095215      70.598984   \n",
       "843            NaN           NaN       NaN           NaN            NaN   \n",
       "844            NaN           NaN       NaN           NaN            NaN   \n",
       "846   50657.347656  2.971653e+10 -0.000156    448.065918      58.154953   \n",
       "847            NaN           NaN       NaN           NaN            NaN   \n",
       "\n",
       "         spearman  q01_abs_diff  q05_abs_diff  q50_abs_diff  q95_abs_diff  \\\n",
       "1   -6.912752e-06      0.207336      1.003906     13.997543     80.000687   \n",
       "2   -2.233854e-03      0.035805      0.186165      2.499613     23.998825   \n",
       "3    1.957554e-05      0.376633      1.876915     23.983521    111.997208   \n",
       "6   -8.733455e-04      0.450989      2.255432     27.993683    160.000259   \n",
       "7             NaN           NaN           NaN           NaN           NaN   \n",
       "8             NaN           NaN           NaN           NaN           NaN   \n",
       "10  -2.073852e-05      0.940406      4.515320     52.008484    176.012634   \n",
       "11            NaN           NaN           NaN           NaN           NaN   \n",
       "13  -8.367174e-05      0.142975      0.748177      9.001137     52.000927   \n",
       "14  -4.157898e-03      0.020668      0.102169      1.375315     17.999088   \n",
       "15   8.872247e-05      0.171158      0.872360     10.002838     72.000519   \n",
       "18   3.593929e-05      0.347580      1.748683     23.976929    127.997711   \n",
       "19            NaN           NaN           NaN           NaN           NaN   \n",
       "20            NaN           NaN           NaN           NaN           NaN   \n",
       "22  -5.945576e-04      0.406069      1.999565     24.006989    111.999786   \n",
       "23            NaN           NaN           NaN           NaN           NaN   \n",
       "25   3.585698e-05      0.115158      0.563599      7.004242     39.999340   \n",
       "26  -2.001503e-03      0.018661      0.093677      1.249559     15.999390   \n",
       "27  -6.906464e-05      0.155973      0.752869      9.000614     52.000919   \n",
       "30  -1.181142e-03      0.276855      1.376617     17.991028    104.005463   \n",
       "31            NaN           NaN           NaN           NaN           NaN   \n",
       "32            NaN           NaN           NaN           NaN           NaN   \n",
       "34  -5.489405e-04      0.488159      2.496185     28.007050    120.005280   \n",
       "35            NaN           NaN           NaN           NaN           NaN   \n",
       "38  -3.804966e-03      0.000366      0.001923      0.020859      0.065674   \n",
       "39   2.101869e-04      0.570087      2.995636     32.006226    128.003174   \n",
       "40  -3.379034e-03      0.409973      2.003235     26.005737    127.991394   \n",
       "41   3.838496e-04      1.007935      5.490479     59.993073    191.994324   \n",
       "44  -9.473588e-04      0.484375      2.491821     30.020508    144.023438   \n",
       "45            NaN           NaN           NaN           NaN           NaN   \n",
       "46            NaN           NaN           NaN           NaN           NaN   \n",
       "48  -1.592607e-04      0.629211      3.240967     36.002991    143.994354   \n",
       "49            NaN           NaN           NaN           NaN           NaN   \n",
       "52  -4.600448e-03      0.000488      0.002441      0.026611      0.081299   \n",
       "53   3.059335e-04      0.623932      3.016235     35.999348    143.989685   \n",
       "54  -7.591132e-03      0.379333      1.878891     23.997864    104.023315   \n",
       "55  -9.841732e-05      0.998769      5.001511     55.997406    176.004272   \n",
       "58   2.915825e-04      0.569122      2.974731     39.991089    160.002487   \n",
       "59            NaN           NaN           NaN           NaN           NaN   \n",
       "60            NaN           NaN           NaN           NaN           NaN   \n",
       "62   7.446480e-04      0.933838      4.505768     52.001846    175.999649   \n",
       "63            NaN           NaN           NaN           NaN           NaN   \n",
       "66   3.035732e-03      0.000610      0.002991      0.032471      0.097168   \n",
       "67   1.949253e-04      0.635193      3.250435     36.008972    143.994904   \n",
       "68   3.278170e-03      0.373726      1.872040     23.996719    111.992462   \n",
       "69  -6.318197e-04      0.935623      4.508240     51.999256    175.991150   \n",
       "72   7.890060e-04      0.415527      2.018799     26.019531    143.984955   \n",
       "73            NaN           NaN           NaN           NaN           NaN   \n",
       "74            NaN           NaN           NaN           NaN           NaN   \n",
       "76   3.757286e-05      0.811775      4.000033     47.989502    160.019287   \n",
       "77            NaN           NaN           NaN           NaN           NaN   \n",
       "80   1.835468e-03      0.000671      0.003296      0.035553      0.105957   \n",
       "81  -1.342449e-05      0.686539      3.494934     39.998970    143.998383   \n",
       "82   3.572013e-03      0.338318      1.726318     21.988647    112.004150   \n",
       "83  -5.896445e-04      0.918457      4.501740     51.987183    160.014648   \n",
       "86   2.724180e-05      0.632538      3.237610     40.003754    176.001343   \n",
       "87            NaN           NaN           NaN           NaN           NaN   \n",
       "88            NaN           NaN           NaN           NaN           NaN   \n",
       "90   3.921397e-04      0.833496      4.010559     47.998489    175.985352   \n",
       "91            NaN           NaN           NaN           NaN           NaN   \n",
       "94  -3.559407e-04      0.000732      0.003784      0.040955      0.122314   \n",
       "95   5.208848e-04      0.704590      3.508240     40.007050    144.005157   \n",
       "96  -1.786743e-03      0.329346      1.632996     20.013794    119.993774   \n",
       "97   1.396643e-04      0.806244      3.994720     44.012390    159.997574   \n",
       "100 -8.211295e-04      0.527466      2.732056     36.001358    175.983154   \n",
       "101           NaN           NaN           NaN           NaN           NaN   \n",
       "102           NaN           NaN           NaN           NaN           NaN   \n",
       "104 -1.600708e-04      0.875127      4.491943     51.966553    176.005432   \n",
       "105           NaN           NaN           NaN           NaN           NaN   \n",
       "108 -1.099915e-03      0.000732      0.003754      0.040474      0.120850   \n",
       "109  1.693380e-04      0.490967      2.497208     31.980713    127.994049   \n",
       "110 -1.253507e-03      0.335999      1.660400     20.009705    127.996002   \n",
       "111 -5.232000e-04      0.746902      3.745941     43.991028    159.990540   \n",
       "114  1.029713e-03      0.623327      3.216797     36.137207    159.985657   \n",
       "115           NaN           NaN           NaN           NaN           NaN   \n",
       "116           NaN           NaN           NaN           NaN           NaN   \n",
       "118  4.300878e-04      0.850277      4.020264     47.998512    175.991638   \n",
       "119           NaN           NaN           NaN           NaN           NaN   \n",
       "122  8.339830e-04      0.000732      0.003662      0.039650      0.118652   \n",
       "123  3.318621e-04      0.571205      2.990845     35.993347    128.019531   \n",
       "124 -3.190789e-04      0.333740      1.635498     19.997711    120.000870   \n",
       "125  2.795917e-04      0.621231      3.011292     36.010742    143.999207   \n",
       "128  3.512416e-04      0.514893      2.721191     44.042236    176.005432   \n",
       "129           NaN           NaN           NaN           NaN           NaN   \n",
       "130           NaN           NaN           NaN           NaN           NaN   \n",
       "132 -6.341565e-04      1.105835      5.493256     60.002914    192.009827   \n",
       "133           NaN           NaN           NaN           NaN           NaN   \n",
       "136 -2.849257e-03      0.000732      0.003723      0.040039      0.119873   \n",
       "137  2.469720e-04      0.671936      3.255890     39.991577    143.996109   \n",
       "138  2.221519e-04      0.326538      1.627747     19.988403    112.002502   \n",
       "139 -7.098765e-05      0.632996      3.247665     39.987732    143.994507   \n",
       "142  1.225635e-04      0.536621      2.743713     43.968994    175.995392   \n",
       "143           NaN           NaN           NaN           NaN           NaN   \n",
       "144           NaN           NaN           NaN           NaN           NaN   \n",
       "146  3.544447e-04      1.106934      5.491821     60.003540    192.013794   \n",
       "147           NaN           NaN           NaN           NaN           NaN   \n",
       "150 -1.191945e-03      0.000732      0.003784      0.040771      0.122314   \n",
       "151 -1.841962e-04      0.612549      3.001550     36.000183    128.007629   \n",
       "152  6.006173e-04      0.340088      1.700195     19.997894    112.004181   \n",
       "153 -9.829581e-06      0.617920      3.005066     36.004578    128.024780   \n",
       "156 -3.470240e-04      0.587402      2.997269     55.970459    192.017090   \n",
       "157           NaN           NaN           NaN           NaN           NaN   \n",
       "158           NaN           NaN           NaN           NaN           NaN   \n",
       "160 -8.608949e-05      0.888306      4.499134     52.032227    191.998734   \n",
       "161           NaN           NaN           NaN           NaN           NaN   \n",
       "164 -1.109093e-03      0.000732      0.003662      0.040039      0.119385   \n",
       "165  1.039982e-05      0.658813      3.253235     39.986267    143.991516   \n",
       "166 -6.342654e-04      0.359253      1.772827     21.949707    119.996979   \n",
       "167  1.552255e-04      0.619751      3.006042     36.002228    128.022827   \n",
       "170  3.001177e-04      0.628906      3.230469     51.960938    176.037842   \n",
       "171           NaN           NaN           NaN           NaN           NaN   \n",
       "172           NaN           NaN           NaN           NaN           NaN   \n",
       "174 -2.605715e-04      0.936611      4.515076     52.014038    191.983521   \n",
       "175           NaN           NaN           NaN           NaN           NaN   \n",
       "178 -2.003028e-03      0.000732      0.003712      0.040192      0.120361   \n",
       "179 -9.275613e-05      0.624369      3.232300     36.006989    128.011536   \n",
       "180 -8.464399e-04      0.337982      1.656738     19.997437    104.005585   \n",
       "181 -6.801366e-05      0.620422      3.008301     36.000195    128.005127   \n",
       "184  4.107679e-04      0.619507      3.217285     52.008484    191.992615   \n",
       "185           NaN           NaN           NaN           NaN           NaN   \n",
       "186           NaN           NaN           NaN           NaN           NaN   \n",
       "188 -1.252155e-04      0.880859      4.496109     52.004486    191.994751   \n",
       "189           NaN           NaN           NaN           NaN           NaN   \n",
       "192 -2.543100e-03      0.000732      0.003662      0.039706      0.118896   \n",
       "193 -1.668757e-04      0.567585      2.988892     36.024536    128.008850   \n",
       "194 -1.006113e-03      0.294250      1.496918     17.990234     72.002457   \n",
       "195  4.099178e-04      0.616943      3.004120     35.994324    127.995575   \n",
       "198  1.938382e-04      0.607259      3.019043     51.998413    192.010559   \n",
       "199           NaN           NaN           NaN           NaN           NaN   \n",
       "200           NaN           NaN           NaN           NaN           NaN   \n",
       "202 -2.761971e-04      0.952332      4.978561     56.007233    192.006836   \n",
       "203           NaN           NaN           NaN           NaN           NaN   \n",
       "206 -2.689425e-03      0.000732      0.003662      0.039324      0.117676   \n",
       "207  3.690844e-04      0.560165      2.753052     32.012451    120.006836   \n",
       "208 -8.827740e-04      0.307098      1.506195     17.998337     72.027344   \n",
       "209  1.883693e-04      0.563178      2.758484     32.004517    127.978271   \n",
       "212  1.848901e-04      0.623456      3.222778     55.962402    192.034424   \n",
       "213           NaN           NaN           NaN           NaN           NaN   \n",
       "214           NaN           NaN           NaN           NaN           NaN   \n",
       "216 -1.204373e-06      1.020264      5.461426     60.001373    192.020996   \n",
       "217           NaN           NaN           NaN           NaN           NaN   \n",
       "220 -5.781804e-03      0.000732      0.003662      0.039230      0.116943   \n",
       "221  2.285991e-04      0.565744      2.978027     36.000435    128.027222   \n",
       "222 -5.342925e-04      0.292969      1.493958     17.973511     64.004578   \n",
       "223  2.352858e-04      0.552856      2.747253     31.996460    127.993500   \n",
       "226 -4.219027e-04      0.634135      3.242462     52.002319    192.006134   \n",
       "227           NaN           NaN           NaN           NaN           NaN   \n",
       "228           NaN           NaN           NaN           NaN           NaN   \n",
       "230 -3.994679e-04      1.128547      5.526367     63.991028    207.982300   \n",
       "231           NaN           NaN           NaN           NaN           NaN   \n",
       "234 -3.055236e-03      0.000732      0.003655      0.038818      0.115967   \n",
       "235  3.088471e-04      0.629456      3.245850     36.007324    127.998901   \n",
       "236 -8.246223e-04      0.369293      1.865723     21.994659     95.987976   \n",
       "237  3.948596e-04      0.630859      3.244995     36.005676    128.016357   \n",
       "240 -3.090911e-04      0.568420      2.970825     47.990540    175.990295   \n",
       "241           NaN           NaN           NaN           NaN           NaN   \n",
       "242           NaN           NaN           NaN           NaN           NaN   \n",
       "244  1.362136e-04      0.996406      5.004059     59.988464    192.015503   \n",
       "245           NaN           NaN           NaN           NaN           NaN   \n",
       "248 -3.929820e-03      0.000732      0.003540      0.038177      0.113892   \n",
       "249  1.870972e-04      0.556641      2.750587     35.991638    127.995972   \n",
       "250 -6.035906e-04      0.361694      1.772949     21.965332     88.005005   \n",
       "251  3.372317e-04      0.614807      3.001030     35.996933    128.004608   \n",
       "254  7.925935e-04      0.640869      3.250557     51.990417    191.998032   \n",
       "255           NaN           NaN           NaN           NaN           NaN   \n",
       "256           NaN           NaN           NaN           NaN           NaN   \n",
       "258  3.621618e-04      1.133606      5.972412     63.995483    207.987122   \n",
       "259           NaN           NaN           NaN           NaN           NaN   \n",
       "262 -4.209928e-03      0.000732      0.003510      0.037842      0.113037   \n",
       "263 -1.658506e-04      0.527100      2.743347     32.004303    120.006378   \n",
       "264 -1.095551e-03      0.383545      1.889160     22.010559     95.999458   \n",
       "265 -4.907714e-04      0.568390      2.983276     32.012329    127.993652   \n",
       "268  1.060141e-04      0.630615      3.245422     52.023926    192.017212   \n",
       "269           NaN           NaN           NaN           NaN           NaN   \n",
       "270           NaN           NaN           NaN           NaN           NaN   \n",
       "272 -3.955459e-04      1.205078      5.996490     64.007874    207.994110   \n",
       "273           NaN           NaN           NaN           NaN           NaN   \n",
       "276 -3.411457e-03      0.000732      0.003433      0.037598      0.112061   \n",
       "277  1.265548e-04      0.578735      2.997284     36.004364    128.001801   \n",
       "278 -8.924748e-04      0.424988      2.035645     24.034180    104.005585   \n",
       "279 -2.093344e-04      0.632385      3.247543     36.006805    128.010742   \n",
       "282 -5.787857e-04      0.672485      3.324707     52.001808    192.010925   \n",
       "283           NaN           NaN           NaN           NaN           NaN   \n",
       "284           NaN           NaN           NaN           NaN           NaN   \n",
       "286 -2.292487e-04      1.261597      6.494751     71.989197    208.006378   \n",
       "287           NaN           NaN           NaN           NaN           NaN   \n",
       "290 -3.491116e-03      0.000679      0.003357      0.036316      0.108643   \n",
       "291 -1.862604e-04      0.618286      3.007172     36.006104    143.991577   \n",
       "292 -9.134573e-04      0.459961      2.256592     27.996506    120.006439   \n",
       "293 -1.027135e-04      0.634949      3.249195     36.008301    143.990601   \n",
       "296 -3.494063e-04      0.582845      2.994274     51.965332    191.995544   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "298           NaN           NaN           NaN           NaN           NaN   \n",
       "300  2.064742e-04      1.252747      6.475098     71.977539    208.003937   \n",
       "301           NaN           NaN           NaN           NaN           NaN   \n",
       "304 -4.214777e-03      0.000671      0.003357      0.036011      0.108215   \n",
       "305  5.208935e-04      0.554871      2.748199     32.011597    127.994049   \n",
       "306 -4.129802e-04      0.482666      2.490784     28.013306    119.999237   \n",
       "307 -1.056472e-04      0.617981      3.005493     35.992767    128.002899   \n",
       "310 -9.170552e-05      0.674968      3.474365     48.023193    176.031982   \n",
       "311           NaN           NaN           NaN           NaN           NaN   \n",
       "312           NaN           NaN           NaN           NaN           NaN   \n",
       "314  7.091999e-05      1.261597      6.491272     71.983521    208.004395   \n",
       "315           NaN           NaN           NaN           NaN           NaN   \n",
       "318 -4.461233e-03      0.000645      0.003242      0.035095      0.104980   \n",
       "319  2.620186e-04      0.561195      2.756317     35.993256    128.003708   \n",
       "320  3.742337e-06      0.476196      2.484131     28.022461    127.988831   \n",
       "321 -1.868989e-04      0.569519      2.988403     32.010132    127.996765   \n",
       "324  3.919393e-04      0.680461      3.486267     51.973633    191.995636   \n",
       "325           NaN           NaN           NaN           NaN           NaN   \n",
       "326           NaN           NaN           NaN           NaN           NaN   \n",
       "328 -8.860804e-05      1.282471      6.501228     71.991333    208.005585   \n",
       "329           NaN           NaN           NaN           NaN           NaN   \n",
       "332 -8.587734e-03      0.000610      0.003174      0.034241      0.102905   \n",
       "333  1.331191e-04      0.573914      2.993988     36.006317    143.959229   \n",
       "334 -1.275543e-04      0.458862      2.255890     27.998032    120.027466   \n",
       "335 -7.604867e-05      0.546936      2.742432     31.986145    127.987976   \n",
       "338  5.589550e-04      0.666138      3.280273     47.973511    176.037109   \n",
       "339           NaN           NaN           NaN           NaN           NaN   \n",
       "340           NaN           NaN           NaN           NaN           NaN   \n",
       "342  2.126476e-04      1.277466      6.499177     71.986572    208.004944   \n",
       "343           NaN           NaN           NaN           NaN           NaN   \n",
       "346 -5.414727e-03      0.000610      0.003159      0.033691      0.101074   \n",
       "347  1.382830e-05      0.623573      3.222900     39.994354    143.994781   \n",
       "348  1.617814e-04      0.422852      2.031128     25.992981    119.971191   \n",
       "349  1.329182e-04      0.550537      2.745544     31.989929    127.991577   \n",
       "352 -9.862677e-04      0.664551      3.271606     44.004913    175.987488   \n",
       "353           NaN           NaN           NaN           NaN           NaN   \n",
       "354           NaN           NaN           NaN           NaN           NaN   \n",
       "356  4.009024e-04      1.265503      6.492493     71.983154    208.001678   \n",
       "357           NaN           NaN           NaN           NaN           NaN   \n",
       "360 -4.877809e-03      0.000610      0.003113      0.033279      0.100220   \n",
       "361  2.043054e-04      0.626462      3.240356     39.998238    143.996628   \n",
       "362  9.823422e-05      0.442596      2.246964     26.025879    120.000984   \n",
       "363 -3.414328e-04      0.564034      2.760315     32.007812    128.006714   \n",
       "366  7.026309e-04      0.673584      3.460938     47.991333    176.046631   \n",
       "367           NaN           NaN           NaN           NaN           NaN   \n",
       "368           NaN           NaN           NaN           NaN           NaN   \n",
       "370 -9.464523e-05      1.259033      6.485718     71.975708    207.999298   \n",
       "371           NaN           NaN           NaN           NaN           NaN   \n",
       "374 -8.011762e-03      0.000610      0.003052      0.032898      0.099243   \n",
       "375  1.824292e-04      0.683960      3.493866     43.997589    144.019775   \n",
       "376 -6.983956e-04      0.469565      2.267334     29.979492    127.993225   \n",
       "377  1.930326e-06      0.617432      3.005371     35.999245    143.993927   \n",
       "380 -7.713508e-04      0.665161      3.274902     44.002380    175.961182   \n",
       "381           NaN           NaN           NaN           NaN           NaN   \n",
       "382           NaN           NaN           NaN           NaN           NaN   \n",
       "384  2.769766e-04      1.207520      5.993988     63.997574    192.032715   \n",
       "385           NaN           NaN           NaN           NaN           NaN   \n",
       "388 -6.854678e-03      0.000610      0.002991      0.032349      0.097412   \n",
       "389  4.105823e-04      0.684433      3.492798     43.996429    144.014587   \n",
       "390 -6.908864e-04      0.451454      2.251640     27.957520    119.983276   \n",
       "391 -1.330027e-04      0.620636      3.010559     35.998871    143.989746   \n",
       "394 -1.032151e-04      0.685664      3.489563     48.012695    191.972290   \n",
       "395           NaN           NaN           NaN           NaN           NaN   \n",
       "396           NaN           NaN           NaN           NaN           NaN   \n",
       "398  2.170406e-05      1.282227      6.500224     71.988464    208.004089   \n",
       "399           NaN           NaN           NaN           NaN           NaN   \n",
       "402 -4.465818e-03      0.000610      0.002934      0.032166      0.097107   \n",
       "403 -4.564773e-06      0.682007      3.488647     43.990662    144.007568   \n",
       "404 -9.614210e-05      0.483643      2.491272     29.993164    127.991882   \n",
       "405 -8.202424e-05      0.624697      3.223511     36.002594    143.991821   \n",
       "408 -1.174289e-04      0.719971      3.526123     51.981445    191.997528   \n",
       "409           NaN           NaN           NaN           NaN           NaN   \n",
       "410           NaN           NaN           NaN           NaN           NaN   \n",
       "412 -1.277678e-04      1.263855      6.480957     71.966553    207.990601   \n",
       "413           NaN           NaN           NaN           NaN           NaN   \n",
       "416 -3.889156e-03      0.000610      0.002930      0.031937      0.096313   \n",
       "417 -1.055490e-04      0.668457      3.262573     43.989807    144.009399   \n",
       "418 -2.697963e-04      0.479248      2.485840     28.020142    120.012390   \n",
       "419  5.542580e-06      0.612976      3.004028     35.998398    143.988342   \n",
       "422  1.360824e-04      0.721802      3.668144     51.974609    192.001785   \n",
       "423           NaN           NaN           NaN           NaN           NaN   \n",
       "424           NaN           NaN           NaN           NaN           NaN   \n",
       "426 -6.393679e-05      1.258545      6.489685     71.979492    207.998367   \n",
       "427           NaN           NaN           NaN           NaN           NaN   \n",
       "430 -3.039527e-03      0.000565      0.002869      0.030830      0.092896   \n",
       "431 -1.450413e-05      0.628754      3.246826     40.012817    144.003555   \n",
       "432 -2.074025e-04      0.444611      2.246552     27.978882    119.991455   \n",
       "433  2.426678e-04      0.565247      2.765137     32.015625    128.004211   \n",
       "436 -4.979322e-04      0.673218      3.286133     47.974609    176.025757   \n",
       "437           NaN           NaN           NaN           NaN           NaN   \n",
       "438           NaN           NaN           NaN           NaN           NaN   \n",
       "440  1.050658e-04      1.209961      5.997131     64.000008    192.031250   \n",
       "441           NaN           NaN           NaN           NaN           NaN   \n",
       "444 -1.364358e-03      0.000549      0.002808      0.030518      0.091797   \n",
       "445  2.298434e-05      0.622879      3.233643     40.007080    143.999985   \n",
       "446 -7.743487e-05      0.460754      2.257935     27.991882    119.977173   \n",
       "447  3.565793e-04      0.571045      2.984863     35.966553    128.001205   \n",
       "450 -1.855232e-04      0.660522      3.263916     48.004364    191.969849   \n",
       "451           NaN           NaN           NaN           NaN           NaN   \n",
       "452           NaN           NaN           NaN           NaN           NaN   \n",
       "454  1.101691e-04      1.261719      6.485657     71.975464    207.997055   \n",
       "455           NaN           NaN           NaN           NaN           NaN   \n",
       "458 -4.668207e-03      0.000549      0.002808      0.030457      0.091309   \n",
       "459  2.746141e-05      0.618427      3.012268     39.995605    143.999695   \n",
       "460  5.735542e-04      0.558792      2.754822     32.014160    143.977051   \n",
       "461 -5.084596e-05      0.617065      3.007172     35.997879    143.986267   \n",
       "464  8.414559e-05      0.581787      2.988281     44.045654    176.010742   \n",
       "465           NaN           NaN           NaN           NaN           NaN   \n",
       "466           NaN           NaN           NaN           NaN           NaN   \n",
       "468  3.946591e-04      1.266602      6.493195     71.980835    208.000824   \n",
       "469           NaN           NaN           NaN           NaN           NaN   \n",
       "472 -1.161391e-03      0.000534      0.002686      0.029602      0.088745   \n",
       "473  4.596278e-05      0.623199      3.237793     40.012573    144.003281   \n",
       "474  7.626922e-04      0.492065      2.499317     30.018188    128.008423   \n",
       "475 -1.157660e-04      0.610718      3.002182     35.993134    128.012451   \n",
       "478  2.040821e-04      0.602783      3.005890     36.035889    159.971313   \n",
       "479           NaN           NaN           NaN           NaN           NaN   \n",
       "480           NaN           NaN           NaN           NaN           NaN   \n",
       "482  5.324460e-05      1.266479      6.491821     71.980591    208.000214   \n",
       "483           NaN           NaN           NaN           NaN           NaN   \n",
       "486 -1.705085e-03      0.000549      0.002716      0.029480      0.088135   \n",
       "487 -2.073805e-04      0.555023      2.754578     36.006866    128.018677   \n",
       "488  5.241273e-04      0.500254      2.507050     31.976440    128.003845   \n",
       "489  3.337132e-04      0.502991      2.509155     30.007202    127.977539   \n",
       "492 -1.598460e-04      0.655762      3.261292     44.003860    176.000885   \n",
       "493           NaN           NaN           NaN           NaN           NaN   \n",
       "494           NaN           NaN           NaN           NaN           NaN   \n",
       "496  6.449795e-05      1.247299      6.033691     64.027588    207.979248   \n",
       "497           NaN           NaN           NaN           NaN           NaN   \n",
       "500  2.500160e-04      0.000519      0.002686      0.029297      0.087555   \n",
       "501  3.122127e-04      0.626183      3.246338     40.010071    143.990540   \n",
       "502  3.567025e-04      0.575989      2.988342     35.986511    143.991516   \n",
       "503  1.253908e-04      0.629395      3.240234     36.003799    128.012878   \n",
       "506  6.362249e-04      0.797241      3.980713     48.024414    192.001892   \n",
       "507           NaN           NaN           NaN           NaN           NaN   \n",
       "508           NaN           NaN           NaN           NaN           NaN   \n",
       "510  2.146558e-04      1.274536      6.499390     71.990662    208.004761   \n",
       "511           NaN           NaN           NaN           NaN           NaN   \n",
       "514  1.486029e-03      0.000508      0.002686      0.029022      0.086670   \n",
       "515 -3.376304e-04      0.610962      3.008484     40.004211    143.992798   \n",
       "516  6.383160e-04      0.556610      2.752640     32.003006    128.000900   \n",
       "517  6.608267e-04      0.620056      3.009399     35.999550    128.007019   \n",
       "520  2.381159e-04      0.667358      3.280151     43.994263    176.003540   \n",
       "521           NaN           NaN           NaN           NaN           NaN   \n",
       "522           NaN           NaN           NaN           NaN           NaN   \n",
       "524 -7.628865e-05      1.262846      6.489075     71.980103    208.004089   \n",
       "525           NaN           NaN           NaN           NaN           NaN   \n",
       "528  2.814621e-03      0.000488      0.002686      0.028809      0.086182   \n",
       "529  1.676418e-05      0.556915      2.761780     36.015503    128.010010   \n",
       "530  6.734787e-05      0.517822      2.731812     31.994019    128.004547   \n",
       "531  5.938404e-04      0.554260      2.748375     31.997894    127.991211   \n",
       "534 -6.406042e-04      0.614685      3.025146     40.012573    160.071289   \n",
       "535           NaN           NaN           NaN           NaN           NaN   \n",
       "536           NaN           NaN           NaN           NaN           NaN   \n",
       "538 -2.786990e-04      1.284668      6.504669     71.990234    208.010986   \n",
       "539           NaN           NaN           NaN           NaN           NaN   \n",
       "542  2.463521e-03      0.000488      0.002625      0.028381      0.084930   \n",
       "543 -4.554685e-04      0.561890      2.984741     39.986206    128.009094   \n",
       "544  1.008127e-03      0.548523      2.744934     32.002930    128.011230   \n",
       "545 -2.295087e-04      0.558771      2.752243     32.000149    127.988220   \n",
       "548 -8.030227e-04      0.594971      2.994995     36.044434    160.031982   \n",
       "549           NaN           NaN           NaN           NaN           NaN   \n",
       "550           NaN           NaN           NaN           NaN           NaN   \n",
       "552 -1.307745e-04      1.285645      6.502768     71.993652    208.003372   \n",
       "553           NaN           NaN           NaN           NaN           NaN   \n",
       "556  5.005906e-03      0.000488      0.002563      0.027771      0.082764   \n",
       "557  3.012657e-04      0.567902      2.994263     40.003403    143.994476   \n",
       "558  5.587788e-04      0.602173      2.998399     35.994904    128.019897   \n",
       "559  1.614659e-04      0.621674      3.016968     36.000328    128.007935   \n",
       "562  9.044335e-05      0.726318      3.595703     43.978394    175.999115   \n",
       "563           NaN           NaN           NaN           NaN           NaN   \n",
       "564           NaN           NaN           NaN           NaN           NaN   \n",
       "566 -3.062702e-04      1.142822      5.977295     63.982422    192.005890   \n",
       "567           NaN           NaN           NaN           NaN           NaN   \n",
       "570  6.643293e-03      0.000488      0.002480      0.026825      0.080078   \n",
       "571 -1.968005e-04      0.556549      2.762268     39.982788    128.003357   \n",
       "572  9.940417e-04      0.570557      2.982788     35.979248    128.014954   \n",
       "573  4.640776e-04      0.570679      2.984436     32.007996    120.009033   \n",
       "576  3.306607e-04      0.625412      3.045898     39.979614    175.965820   \n",
       "577           NaN           NaN           NaN           NaN           NaN   \n",
       "578           NaN           NaN           NaN           NaN           NaN   \n",
       "580 -1.208794e-04      1.297607      6.506775     71.993256    208.009338   \n",
       "581           NaN           NaN           NaN           NaN           NaN   \n",
       "584  5.908003e-03      0.000488      0.002441      0.026001      0.077759   \n",
       "585  6.766855e-05      0.552368      2.757599     39.984375    127.999840   \n",
       "586  9.604982e-04      0.565582      2.768921     35.968750    128.014160   \n",
       "587 -5.040774e-04      0.614357      3.003098     35.991760    127.986755   \n",
       "590 -5.134047e-05      0.688517      3.487366     47.945068    176.030762   \n",
       "591           NaN           NaN           NaN           NaN           NaN   \n",
       "592           NaN           NaN           NaN           NaN           NaN   \n",
       "594  1.197895e-04      1.354370      6.522461     71.999550    208.015747   \n",
       "595           NaN           NaN           NaN           NaN           NaN   \n",
       "598  5.312983e-03      0.000488      0.002384      0.025757      0.077026   \n",
       "599  2.549679e-05      0.499810      2.513611     35.989014    120.001884   \n",
       "600  1.381631e-04      0.557392      2.752533     32.012573    128.010315   \n",
       "601  3.172052e-04      0.574463      2.993896     32.012329    120.004944   \n",
       "604  5.291823e-04      0.583089      2.977539     36.021851    160.009460   \n",
       "605           NaN           NaN           NaN           NaN           NaN   \n",
       "606           NaN           NaN           NaN           NaN           NaN   \n",
       "608 -1.836349e-04      1.264893      6.490601     71.980103    207.997803   \n",
       "609           NaN           NaN           NaN           NaN           NaN   \n",
       "612  6.259082e-03      0.000488      0.002319      0.025391      0.075684   \n",
       "613  2.676618e-04      0.503769      2.739807     36.001610    120.012207   \n",
       "614  2.948609e-04      0.564148      2.762280     32.014038    128.004333   \n",
       "615 -6.348122e-05      0.617126      3.005371     35.988525    120.015137   \n",
       "618  4.083858e-04      0.842651      4.032227     48.025513    191.978149   \n",
       "619           NaN           NaN           NaN           NaN           NaN   \n",
       "620           NaN           NaN           NaN           NaN           NaN   \n",
       "622 -1.743136e-04      1.139343      5.971436     63.988464    207.962891   \n",
       "623           NaN           NaN           NaN           NaN           NaN   \n",
       "626  8.104665e-03      0.000488      0.002319      0.025330      0.075241   \n",
       "627  1.109678e-04      0.495667      2.511902     35.997787    127.983398   \n",
       "628  6.357791e-04      0.547546      2.744202     31.998016    128.001678   \n",
       "629  1.679831e-05      0.564117      2.759705     31.999149    119.997650   \n",
       "632 -9.910561e-04      0.635498      3.244751     39.982056    175.993958   \n",
       "633           NaN           NaN           NaN           NaN           NaN   \n",
       "634           NaN           NaN           NaN           NaN           NaN   \n",
       "636 -1.828451e-05      1.264648      6.486694     71.976807    207.996353   \n",
       "637           NaN           NaN           NaN           NaN           NaN   \n",
       "640  5.721314e-03      0.000465      0.002258      0.024097      0.071442   \n",
       "641  1.993600e-04      0.507660      2.739319     35.991455    127.993927   \n",
       "642  4.556970e-04      0.579468      2.993408     35.995239    143.993561   \n",
       "643 -3.289511e-04      0.556610      2.750534     31.993134    120.004333   \n",
       "646  6.761709e-04      0.581055      2.983276     36.001892    144.049561   \n",
       "647           NaN           NaN           NaN           NaN           NaN   \n",
       "648           NaN           NaN           NaN           NaN           NaN   \n",
       "650  3.964597e-04      1.244110      6.029785     64.021484    207.976685   \n",
       "651           NaN           NaN           NaN           NaN           NaN   \n",
       "654  4.338760e-03      0.000458      0.002197      0.023560      0.069824   \n",
       "655 -1.212179e-04      0.516602      2.749714     39.973511    143.992279   \n",
       "656  6.598887e-04      0.614563      3.006714     36.004059    144.005737   \n",
       "657 -2.742977e-05      0.616882      3.003830     35.991699    128.001282   \n",
       "660 -6.119655e-04      0.474365      2.467285     32.010681    143.998413   \n",
       "661           NaN           NaN           NaN           NaN           NaN   \n",
       "662           NaN           NaN           NaN           NaN           NaN   \n",
       "664  1.884710e-06      1.253776      6.474609     71.963623    207.992218   \n",
       "665           NaN           NaN           NaN           NaN           NaN   \n",
       "668  8.459683e-03      0.000427      0.002197      0.023491      0.069458   \n",
       "669 -1.642748e-04      0.559769      2.989624     40.000893    143.997330   \n",
       "670  7.506667e-04      0.612183      3.003387     36.003143    144.004578   \n",
       "671  3.700178e-04      0.613525      3.002823     35.989441    127.999931   \n",
       "674 -3.216275e-04      0.693319      3.495403     47.993896    191.999619   \n",
       "675           NaN           NaN           NaN           NaN           NaN   \n",
       "676           NaN           NaN           NaN           NaN           NaN   \n",
       "678  1.685682e-04      1.264465      6.495850     71.988403    207.998962   \n",
       "679           NaN           NaN           NaN           NaN           NaN   \n",
       "682  6.839227e-03      0.000427      0.002197      0.023519      0.069397   \n",
       "683  4.490079e-04      0.521317      2.753357     39.991760    143.997162   \n",
       "684  7.915903e-04      0.630280      3.238525     36.014771    144.008667   \n",
       "685 -4.251097e-04      0.620972      3.007544     35.992798    128.002625   \n",
       "688 -4.013054e-05      0.690928      3.497015     44.019165    176.009155   \n",
       "689           NaN           NaN           NaN           NaN           NaN   \n",
       "690           NaN           NaN           NaN           NaN           NaN   \n",
       "692 -1.167669e-04      1.255890      6.488159     71.981812    207.996201   \n",
       "693           NaN           NaN           NaN           NaN           NaN   \n",
       "696  5.296745e-03      0.000427      0.002102      0.022797      0.067383   \n",
       "697 -1.167812e-04      0.517456      2.748688     36.012329    143.991028   \n",
       "698  1.110060e-03      0.610413      3.004761     36.002411    144.005402   \n",
       "699  2.584271e-04      0.605957      2.998970     35.983398    127.995636   \n",
       "702  3.464538e-04      0.636658      3.230347     39.986267    175.991638   \n",
       "703           NaN           NaN           NaN           NaN           NaN   \n",
       "704           NaN           NaN           NaN           NaN           NaN   \n",
       "706  2.196512e-04      1.249262      6.046143     64.031738    207.981079   \n",
       "707           NaN           NaN           NaN           NaN           NaN   \n",
       "710  6.245933e-03      0.000427      0.002075      0.022339      0.065796   \n",
       "711  4.448465e-05      0.559662      2.993866     40.010132    144.004913   \n",
       "712  9.679577e-04      0.607666      3.001869     36.001144    144.001587   \n",
       "713  1.663517e-05      0.645874      3.253784     36.008606    128.009705   \n",
       "716 -1.388629e-04      0.687287      3.481445     43.978149    160.019897   \n",
       "717           NaN           NaN           NaN           NaN           NaN   \n",
       "718           NaN           NaN           NaN           NaN           NaN   \n",
       "720 -6.724389e-04      1.256500      6.479736     71.973999    208.000305   \n",
       "721           NaN           NaN           NaN           NaN           NaN   \n",
       "724  8.420032e-03      0.000424      0.002045      0.021973      0.064800   \n",
       "725  7.916406e-05      0.513367      2.745636     36.005402    143.993927   \n",
       "726  6.921013e-04      0.624485      3.031494     36.005768    144.006348   \n",
       "727 -2.343239e-04      0.631744      3.246155     36.006409    128.019897   \n",
       "730 -1.291276e-04      0.723022      3.531738     47.992218    191.977051   \n",
       "731           NaN           NaN           NaN           NaN           NaN   \n",
       "732           NaN           NaN           NaN           NaN           NaN   \n",
       "734 -4.726739e-04      1.237000      6.007996     64.009338    207.970581   \n",
       "735           NaN           NaN           NaN           NaN           NaN   \n",
       "738  4.248821e-03      0.000381      0.001953      0.021164      0.062225   \n",
       "739  9.990737e-06      0.503708      2.740845     36.002350    143.984131   \n",
       "740 -2.644935e-06      0.616882      3.008850     36.002029    144.002167   \n",
       "741 -3.452895e-04      0.626836      3.239502     36.000782    128.005127   \n",
       "744  7.146989e-04      0.739604      3.740662     51.950928    191.978394   \n",
       "745           NaN           NaN           NaN           NaN           NaN   \n",
       "746           NaN           NaN           NaN           NaN           NaN   \n",
       "748  3.619854e-04      1.109558      5.497147     60.001022    191.996735   \n",
       "749           NaN           NaN           NaN           NaN           NaN   \n",
       "752  6.406918e-03      0.000366      0.001892      0.020386      0.060303   \n",
       "753  1.521224e-04      0.563644      2.966797     36.025391    143.990356   \n",
       "754 -3.153391e-04      0.618896      3.010681     36.001839    144.007507   \n",
       "755  2.035016e-04      0.636353      3.249995     36.007721    128.018433   \n",
       "758 -4.158668e-04      0.690430      3.494690     44.027344    176.030762   \n",
       "759           NaN           NaN           NaN           NaN           NaN   \n",
       "760           NaN           NaN           NaN           NaN           NaN   \n",
       "762  4.707460e-04      1.250813      6.477905     71.977783    208.000305   \n",
       "763           NaN           NaN           NaN           NaN           NaN   \n",
       "766  3.614819e-03      0.000366      0.001892      0.020304      0.059814   \n",
       "767  3.031318e-04      0.580322      3.000080     39.988708    143.977539   \n",
       "768  4.090447e-04      0.639404      3.249382     36.044189    144.021973   \n",
       "769  9.467788e-05      0.736816      3.524048     40.006012    143.998444   \n",
       "772  1.034701e-04      0.617371      3.022705     43.984619    175.991760   \n",
       "773           NaN           NaN           NaN           NaN           NaN   \n",
       "774           NaN           NaN           NaN           NaN           NaN   \n",
       "776  1.683750e-04      1.244904      6.011108     64.009460    207.978394   \n",
       "777           NaN           NaN           NaN           NaN           NaN   \n",
       "780  5.722261e-03      0.000366      0.001823      0.019470      0.057434   \n",
       "781  3.149825e-04      0.581421      2.998650     39.977539    143.992401   \n",
       "782  6.087371e-04      0.676636      3.275024     39.989685    144.148438   \n",
       "783  3.576197e-07      0.751625      3.751640     43.987427    144.005005   \n",
       "786 -1.948271e-04      0.839844      4.023926     51.974976    191.986206   \n",
       "787           NaN           NaN           NaN           NaN           NaN   \n",
       "788           NaN           NaN           NaN           NaN           NaN   \n",
       "790 -2.287797e-04      1.240295      6.008118     64.011169    207.988342   \n",
       "791           NaN           NaN           NaN           NaN           NaN   \n",
       "794  4.758421e-03      0.000366      0.001770      0.019104      0.056396   \n",
       "795 -6.697464e-04      0.563644      2.764221     36.002304    143.984741   \n",
       "796 -2.178474e-04      0.683075      3.478271     39.994385    144.045410   \n",
       "797 -1.234664e-04      0.761780      3.763062     43.993744    144.010803   \n",
       "800 -7.203819e-05      0.901611      4.501552     48.033936    160.017578   \n",
       "801           NaN           NaN           NaN           NaN           NaN   \n",
       "802           NaN           NaN           NaN           NaN           NaN   \n",
       "804  1.265295e-04      1.112183      5.495941     60.008240    192.019165   \n",
       "805           NaN           NaN           NaN           NaN           NaN   \n",
       "808 -4.413895e-04      0.000366      0.001766      0.018860      0.055847   \n",
       "809 -5.179914e-05      0.554565      2.748894     35.991272    128.015320   \n",
       "810 -4.600205e-05      0.692657      3.496948     40.000343    144.031738   \n",
       "811 -2.049523e-04      0.740906      3.738159     40.012207    143.998077   \n",
       "814  3.001667e-04      1.113342      5.498935     60.005157    191.996811   \n",
       "815           NaN           NaN           NaN           NaN           NaN   \n",
       "816           NaN           NaN           NaN           NaN           NaN   \n",
       "818  3.565136e-04      0.874409      4.491394     48.009338    175.995361   \n",
       "819           NaN           NaN           NaN           NaN           NaN   \n",
       "822  4.939766e-04      0.000336      0.001672      0.017944      0.053589   \n",
       "823  1.326976e-04      0.524170      2.735413     31.995209    127.991577   \n",
       "824 -2.693519e-04      0.635498      3.244934     36.005493    143.972412   \n",
       "825  2.533953e-04      0.643799      3.253448     36.003189    127.987244   \n",
       "828  2.690325e-04      0.843506      4.031494     47.995789    175.967529   \n",
       "829           NaN           NaN           NaN           NaN           NaN   \n",
       "830           NaN           NaN           NaN           NaN           NaN   \n",
       "832  3.124934e-04      1.134583      5.964355     63.988464    192.023682   \n",
       "833           NaN           NaN           NaN           NaN           NaN   \n",
       "836 -3.187038e-03      0.000366      0.001801      0.019516      0.059937   \n",
       "837 -1.557488e-04      0.349304      1.750744     23.991455    112.002792   \n",
       "838  5.894285e-05      0.676636      3.275879     36.020386    143.978149   \n",
       "839 -2.670212e-05      0.566742      2.766113     31.987305    119.986084   \n",
       "842  2.658626e-06      1.008301      5.012756     56.009583    191.912109   \n",
       "843           NaN           NaN           NaN           NaN           NaN   \n",
       "844           NaN           NaN           NaN           NaN           NaN   \n",
       "846 -8.692507e-05      0.739685      3.735413     43.985229    160.017212   \n",
       "847           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     q99_abs_diff        shape_a        shape_b            note  \n",
       "1      143.996338            NaN            NaN             NaN  \n",
       "2       79.999825            NaN            NaN             NaN  \n",
       "3      176.000168            NaN            NaN             NaN  \n",
       "6      239.989075            NaN            NaN             NaN  \n",
       "7             NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "8             NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "10     255.995758            NaN            NaN             NaN  \n",
       "11            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "13     104.000656            NaN            NaN             NaN  \n",
       "14     111.999542            NaN            NaN             NaN  \n",
       "15     143.999527            NaN            NaN             NaN  \n",
       "18     208.010315            NaN            NaN             NaN  \n",
       "19            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "20            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "22     176.004730            NaN            NaN             NaN  \n",
       "23            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "25      87.996933            NaN            NaN             NaN  \n",
       "26      71.999466            NaN            NaN             NaN  \n",
       "27     112.000687            NaN            NaN             NaN  \n",
       "30     191.986572            NaN            NaN             NaN  \n",
       "31            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "32            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "34     192.003342            NaN            NaN             NaN  \n",
       "35            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "38       0.091064            NaN            NaN             NaN  \n",
       "39     192.008850            NaN            NaN             NaN  \n",
       "40     223.995483            NaN            NaN             NaN  \n",
       "41     255.998505            NaN            NaN             NaN  \n",
       "44     224.016846            NaN            NaN             NaN  \n",
       "45            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "46            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "48     208.007111            NaN            NaN             NaN  \n",
       "49            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "52       0.111084            NaN            NaN             NaN  \n",
       "53     207.994507            NaN            NaN             NaN  \n",
       "54     176.067383            NaN            NaN             NaN  \n",
       "55     255.986877            NaN            NaN             NaN  \n",
       "58     239.970703            NaN            NaN             NaN  \n",
       "59            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "60            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "62     240.010193            NaN            NaN             NaN  \n",
       "63            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "66       0.131348            NaN            NaN             NaN  \n",
       "67     207.996582            NaN            NaN             NaN  \n",
       "68     191.994537            NaN            NaN             NaN  \n",
       "69     239.998718            NaN            NaN             NaN  \n",
       "72     223.992340            NaN            NaN             NaN  \n",
       "73            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "74            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "76     240.001343            NaN            NaN             NaN  \n",
       "77            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "80       0.143066            NaN            NaN             NaN  \n",
       "81     207.999298            NaN            NaN             NaN  \n",
       "82     208.000977            NaN            NaN             NaN  \n",
       "83     239.997330            NaN            NaN             NaN  \n",
       "86     255.988953            NaN            NaN             NaN  \n",
       "87            NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "88            NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "90     240.002960            NaN            NaN             NaN  \n",
       "91            NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "94       0.165039            NaN            NaN             NaN  \n",
       "95     208.012329            NaN            NaN             NaN  \n",
       "96     223.989624            NaN            NaN             NaN  \n",
       "97     224.006592            NaN            NaN             NaN  \n",
       "100    240.047607            NaN            NaN             NaN  \n",
       "101           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "102           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "104    255.989624            NaN            NaN             NaN  \n",
       "105           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "108      0.163086            NaN            NaN             NaN  \n",
       "109    192.008850            NaN            NaN             NaN  \n",
       "110    224.015503            NaN            NaN             NaN  \n",
       "111    224.013000            NaN            NaN             NaN  \n",
       "114    224.022705            NaN            NaN             NaN  \n",
       "115           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "116           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "118    240.016113            NaN            NaN             NaN  \n",
       "119           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "122      0.160400            NaN            NaN             NaN  \n",
       "123    208.003082            NaN            NaN             NaN  \n",
       "124    223.992004            NaN            NaN             NaN  \n",
       "125    223.983276            NaN            NaN             NaN  \n",
       "128    240.064941            NaN            NaN             NaN  \n",
       "129           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "130           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "132    256.013733            NaN            NaN             NaN  \n",
       "133           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "136      0.163010            NaN            NaN             NaN  \n",
       "137    208.006927            NaN            NaN             NaN  \n",
       "138    224.000320            NaN            NaN             NaN  \n",
       "139    208.005646            NaN            NaN             NaN  \n",
       "142    255.968506            NaN            NaN             NaN  \n",
       "143           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "144           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "146    256.017578            NaN            NaN             NaN  \n",
       "147           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "150      0.166016            NaN            NaN             NaN  \n",
       "151    208.000015            NaN            NaN             NaN  \n",
       "152    224.000977            NaN            NaN             NaN  \n",
       "153    207.999374            NaN            NaN             NaN  \n",
       "156    256.023560            NaN            NaN             NaN  \n",
       "157           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "158           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "160    256.008057            NaN            NaN             NaN  \n",
       "161           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "164      0.161865            NaN            NaN             NaN  \n",
       "165    223.994385            NaN            NaN             NaN  \n",
       "166    224.009094            NaN            NaN             NaN  \n",
       "167    208.008850            NaN            NaN             NaN  \n",
       "170    255.989197            NaN            NaN             NaN  \n",
       "171           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "172           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "174    256.000092            NaN            NaN             NaN  \n",
       "175           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "178      0.162964            NaN            NaN             NaN  \n",
       "179    223.966553            NaN            NaN             NaN  \n",
       "180    208.006439            NaN            NaN             NaN  \n",
       "181    207.999573            NaN            NaN             NaN  \n",
       "184    256.006226            NaN            NaN             NaN  \n",
       "185           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "186           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "188    256.007629            NaN            NaN             NaN  \n",
       "189           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "192      0.161591            NaN            NaN             NaN  \n",
       "193    192.010742            NaN            NaN             NaN  \n",
       "194    159.990173            NaN            NaN             NaN  \n",
       "195    191.996231            NaN            NaN             NaN  \n",
       "198    256.025513            NaN            NaN             NaN  \n",
       "199           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "200           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "202    256.015137            NaN            NaN             NaN  \n",
       "203           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "206      0.159729            NaN            NaN             NaN  \n",
       "207    191.990845            NaN            NaN             NaN  \n",
       "208    159.937012            NaN            NaN             NaN  \n",
       "209    191.986328            NaN            NaN             NaN  \n",
       "212    256.044678            NaN            NaN             NaN  \n",
       "213           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "214           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "216    256.025513            NaN            NaN             NaN  \n",
       "217           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "220      0.158447            NaN            NaN             NaN  \n",
       "221    192.014282            NaN            NaN             NaN  \n",
       "222    104.011292            NaN            NaN             NaN  \n",
       "223    191.994934            NaN            NaN             NaN  \n",
       "226    256.014648            NaN            NaN             NaN  \n",
       "227           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "228           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "230    287.971436            NaN            NaN             NaN  \n",
       "231           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "234      0.157227            NaN            NaN             NaN  \n",
       "235    207.968506            NaN            NaN             NaN  \n",
       "236    175.998718            NaN            NaN             NaN  \n",
       "237    207.982422            NaN            NaN             NaN  \n",
       "240    240.007263            NaN            NaN             NaN  \n",
       "241           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "242           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "244    256.021118            NaN            NaN             NaN  \n",
       "245           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "248      0.154053            NaN            NaN             NaN  \n",
       "249    192.002701            NaN            NaN             NaN  \n",
       "250    160.004303            NaN            NaN             NaN  \n",
       "251    192.005432            NaN            NaN             NaN  \n",
       "254    256.009949            NaN            NaN             NaN  \n",
       "255           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "256           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "258    287.977295            NaN            NaN             NaN  \n",
       "259           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "262      0.153564            NaN            NaN             NaN  \n",
       "263    191.998077            NaN            NaN             NaN  \n",
       "264    160.028320            NaN            NaN             NaN  \n",
       "265    191.998138            NaN            NaN             NaN  \n",
       "268    256.026123            NaN            NaN             NaN  \n",
       "269           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "270           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "272    287.981934            NaN            NaN             NaN  \n",
       "273           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "276      0.152100            NaN            NaN             NaN  \n",
       "277    207.991699            NaN            NaN             NaN  \n",
       "278    176.023193            NaN            NaN             NaN  \n",
       "279    207.953613            NaN            NaN             NaN  \n",
       "282    256.019531            NaN            NaN             NaN  \n",
       "283           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "284           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "286    287.992310            NaN            NaN             NaN  \n",
       "287           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "290      0.147583            NaN            NaN             NaN  \n",
       "291    223.992554            NaN            NaN             NaN  \n",
       "292    192.013550            NaN            NaN             NaN  \n",
       "293    208.004974            NaN            NaN             NaN  \n",
       "296    256.009705            NaN            NaN             NaN  \n",
       "297           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "298           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "300    287.991150            NaN            NaN             NaN  \n",
       "301           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "304      0.147339            NaN            NaN             NaN  \n",
       "305    192.008179            NaN            NaN             NaN  \n",
       "306    191.995178            NaN            NaN             NaN  \n",
       "307    192.010803            NaN            NaN             NaN  \n",
       "310    255.986328            NaN            NaN             NaN  \n",
       "311           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "312           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "314    287.989746            NaN            NaN             NaN  \n",
       "315           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "318      0.142822            NaN            NaN             NaN  \n",
       "319    207.991394            NaN            NaN             NaN  \n",
       "320    192.015442            NaN            NaN             NaN  \n",
       "321    192.007874            NaN            NaN             NaN  \n",
       "324    256.010437            NaN            NaN             NaN  \n",
       "325           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "326           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "328    287.988403            NaN            NaN             NaN  \n",
       "329           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "332      0.140625            NaN            NaN             NaN  \n",
       "333    207.990845            NaN            NaN             NaN  \n",
       "334    192.003601            NaN            NaN             NaN  \n",
       "335    191.999283            NaN            NaN             NaN  \n",
       "338    255.991211            NaN            NaN             NaN  \n",
       "339           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "340           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "342    287.985779            NaN            NaN             NaN  \n",
       "343           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "346      0.138062            NaN            NaN             NaN  \n",
       "347    207.997833            NaN            NaN             NaN  \n",
       "348    191.924805            NaN            NaN             NaN  \n",
       "349    191.999146            NaN            NaN             NaN  \n",
       "352    240.024902            NaN            NaN             NaN  \n",
       "353           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "354           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "356    287.985107            NaN            NaN             NaN  \n",
       "357           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "360      0.137451            NaN            NaN             NaN  \n",
       "361    207.998383            NaN            NaN             NaN  \n",
       "362    191.988953            NaN            NaN             NaN  \n",
       "363    192.013916            NaN            NaN             NaN  \n",
       "366    255.992615            NaN            NaN             NaN  \n",
       "367           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "368           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "370    287.983643            NaN            NaN             NaN  \n",
       "371           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "374      0.136475            NaN            NaN             NaN  \n",
       "375    223.986206            NaN            NaN             NaN  \n",
       "376    192.003677            NaN            NaN             NaN  \n",
       "377    207.998749            NaN            NaN             NaN  \n",
       "380    240.003448            NaN            NaN             NaN  \n",
       "381           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "382           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "384    256.023438            NaN            NaN             NaN  \n",
       "385           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "388      0.133423            NaN            NaN             NaN  \n",
       "389    223.977173            NaN            NaN             NaN  \n",
       "390    176.018311            NaN            NaN             NaN  \n",
       "391    207.995758            NaN            NaN             NaN  \n",
       "394    255.999542            NaN            NaN             NaN  \n",
       "395           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "396           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "398    287.986694            NaN            NaN             NaN  \n",
       "399           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "402      0.133789            NaN            NaN             NaN  \n",
       "403    208.014832            NaN            NaN             NaN  \n",
       "404    192.003510            NaN            NaN             NaN  \n",
       "405    207.997772            NaN            NaN             NaN  \n",
       "408    256.011292            NaN            NaN             NaN  \n",
       "409           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "410           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "412    287.968018            NaN            NaN             NaN  \n",
       "413           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "416      0.132568            NaN            NaN             NaN  \n",
       "417    208.012390            NaN            NaN             NaN  \n",
       "418    191.995361            NaN            NaN             NaN  \n",
       "419    207.992432            NaN            NaN             NaN  \n",
       "422    256.014282            NaN            NaN             NaN  \n",
       "423           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "424           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "426    287.980591            NaN            NaN             NaN  \n",
       "427           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "430      0.127930            NaN            NaN             NaN  \n",
       "431    208.011047            NaN            NaN             NaN  \n",
       "432    176.019653            NaN            NaN             NaN  \n",
       "433    192.015625            NaN            NaN             NaN  \n",
       "436    255.984680            NaN            NaN             NaN  \n",
       "437           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "438           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "440    256.021973            NaN            NaN             NaN  \n",
       "441           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "444      0.125977            NaN            NaN             NaN  \n",
       "445    208.004059            NaN            NaN             NaN  \n",
       "446    176.010315            NaN            NaN             NaN  \n",
       "447    192.008362            NaN            NaN             NaN  \n",
       "450    255.994751            NaN            NaN             NaN  \n",
       "451           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "452           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "454    287.977539            NaN            NaN             NaN  \n",
       "455           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "458      0.125244            NaN            NaN             NaN  \n",
       "459    208.039307            NaN            NaN             NaN  \n",
       "460    207.990723            NaN            NaN             NaN  \n",
       "461    208.003204            NaN            NaN             NaN  \n",
       "464    255.972412            NaN            NaN             NaN  \n",
       "465           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "466           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "468    287.981689            NaN            NaN             NaN  \n",
       "469           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "472      0.121582            NaN            NaN             NaN  \n",
       "473    223.985962            NaN            NaN             NaN  \n",
       "474    207.977051            NaN            NaN             NaN  \n",
       "475    207.992279            NaN            NaN             NaN  \n",
       "478    224.009644            NaN            NaN             NaN  \n",
       "479           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "480           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "482    287.979736            NaN            NaN             NaN  \n",
       "483           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "486      0.120117            NaN            NaN             NaN  \n",
       "487    207.999466            NaN            NaN             NaN  \n",
       "488    192.018799            NaN            NaN             NaN  \n",
       "489    192.002441            NaN            NaN             NaN  \n",
       "492    255.961670            NaN            NaN             NaN  \n",
       "493           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "494           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "496    256.057861            NaN            NaN             NaN  \n",
       "497           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "500      0.119385            NaN            NaN             NaN  \n",
       "501    207.996735            NaN            NaN             NaN  \n",
       "502    208.000931            NaN            NaN             NaN  \n",
       "503    192.026733            NaN            NaN             NaN  \n",
       "506    256.016235            NaN            NaN             NaN  \n",
       "507           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "508           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "510    287.989929            NaN            NaN             NaN  \n",
       "511           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "514      0.118042            NaN            NaN             NaN  \n",
       "515    192.032715            NaN            NaN             NaN  \n",
       "516    192.006592            NaN            NaN             NaN  \n",
       "517    192.003510            NaN            NaN             NaN  \n",
       "520    255.916626            NaN            NaN             NaN  \n",
       "521           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "522           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "524    287.987915            NaN            NaN             NaN  \n",
       "525           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "528      0.117554            NaN            NaN             NaN  \n",
       "529    192.006805            NaN            NaN             NaN  \n",
       "530    192.015137            NaN            NaN             NaN  \n",
       "531    191.993317            NaN            NaN             NaN  \n",
       "534    239.993317            NaN            NaN             NaN  \n",
       "535           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "536           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "538    287.990723            NaN            NaN             NaN  \n",
       "539           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "542      0.115723            NaN            NaN             NaN  \n",
       "543    192.027710            NaN            NaN             NaN  \n",
       "544    192.023438            NaN            NaN             NaN  \n",
       "545    191.997543            NaN            NaN             NaN  \n",
       "548    240.004547            NaN            NaN             NaN  \n",
       "549           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "550           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "552    287.989502            NaN            NaN             NaN  \n",
       "553           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "556      0.112549            NaN            NaN             NaN  \n",
       "557    207.986816            NaN            NaN             NaN  \n",
       "558    207.981934            NaN            NaN             NaN  \n",
       "559    192.004944            NaN            NaN             NaN  \n",
       "562    255.977539            NaN            NaN             NaN  \n",
       "563           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "564           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "566    256.007019            NaN            NaN             NaN  \n",
       "567           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "570      0.108887            NaN            NaN             NaN  \n",
       "571    192.002640            NaN            NaN             NaN  \n",
       "572    207.982422            NaN            NaN             NaN  \n",
       "573    176.014404            NaN            NaN             NaN  \n",
       "576    240.018433            NaN            NaN             NaN  \n",
       "577           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "578           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "580    287.990234            NaN            NaN             NaN  \n",
       "581           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "584      0.105713            NaN            NaN             NaN  \n",
       "585    191.991821            NaN            NaN             NaN  \n",
       "586    207.983398            NaN            NaN             NaN  \n",
       "587    176.021729            NaN            NaN             NaN  \n",
       "590    255.991089            NaN            NaN             NaN  \n",
       "591           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "592           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "594    287.992126            NaN            NaN             NaN  \n",
       "595           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "598      0.104614            NaN            NaN             NaN  \n",
       "599    176.017578            NaN            NaN             NaN  \n",
       "600    207.972290            NaN            NaN             NaN  \n",
       "601    176.023560            NaN            NaN             NaN  \n",
       "604    239.980225            NaN            NaN             NaN  \n",
       "605           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "606           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "608    287.978760            NaN            NaN             NaN  \n",
       "609           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "612      0.102539            NaN            NaN             NaN  \n",
       "613    191.991943            NaN            NaN             NaN  \n",
       "614    192.015991            NaN            NaN             NaN  \n",
       "615    191.987915            NaN            NaN             NaN  \n",
       "618    256.001831            NaN            NaN             NaN  \n",
       "619           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "620           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "622    287.953369            NaN            NaN             NaN  \n",
       "623           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "626      0.101807            NaN            NaN             NaN  \n",
       "627    176.021484            NaN            NaN             NaN  \n",
       "628    192.020508            NaN            NaN             NaN  \n",
       "629    176.002441            NaN            NaN             NaN  \n",
       "632    255.963623            NaN            NaN             NaN  \n",
       "633           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "634           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "636    287.978394            NaN            NaN             NaN  \n",
       "637           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "640      0.096436            NaN            NaN             NaN  \n",
       "641    192.010864            NaN            NaN             NaN  \n",
       "642    208.013306            NaN            NaN             NaN  \n",
       "643    191.995575            NaN            NaN             NaN  \n",
       "646    223.999252            NaN            NaN             NaN  \n",
       "647           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "648           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "650    256.035645            NaN            NaN             NaN  \n",
       "651           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "654      0.093994            NaN            NaN             NaN  \n",
       "655    208.003357            NaN            NaN             NaN  \n",
       "656    223.991211            NaN            NaN             NaN  \n",
       "657    192.011719            NaN            NaN             NaN  \n",
       "660    208.005554            NaN            NaN             NaN  \n",
       "661           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "662           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "664    287.976318            NaN            NaN             NaN  \n",
       "665           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "668      0.093323            NaN            NaN             NaN  \n",
       "669    208.004883            NaN            NaN             NaN  \n",
       "670    223.988892            NaN            NaN             NaN  \n",
       "671    192.007690            NaN            NaN             NaN  \n",
       "674    256.011230            NaN            NaN             NaN  \n",
       "675           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "676           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "678    287.985840            NaN            NaN             NaN  \n",
       "679           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "682      0.093384            NaN            NaN             NaN  \n",
       "683    208.006226            NaN            NaN             NaN  \n",
       "684    223.993042            NaN            NaN             NaN  \n",
       "685    192.015991            NaN            NaN             NaN  \n",
       "688    255.982788            NaN            NaN             NaN  \n",
       "689           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "690           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "692    287.983276            NaN            NaN             NaN  \n",
       "693           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "696      0.090515            NaN            NaN             NaN  \n",
       "697    208.000671            NaN            NaN             NaN  \n",
       "698    223.991272            NaN            NaN             NaN  \n",
       "699    192.005768            NaN            NaN             NaN  \n",
       "702    255.967529            NaN            NaN             NaN  \n",
       "703           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "704           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "706    256.065918            NaN            NaN             NaN  \n",
       "707           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "710      0.088257            NaN            NaN             NaN  \n",
       "711    208.011780            NaN            NaN             NaN  \n",
       "712    223.986389            NaN            NaN             NaN  \n",
       "713    192.014893            NaN            NaN             NaN  \n",
       "716    239.973022            NaN            NaN             NaN  \n",
       "717           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "718           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "720    287.987549            NaN            NaN             NaN  \n",
       "721           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "724      0.086914            NaN            NaN             NaN  \n",
       "725    208.001312            NaN            NaN             NaN  \n",
       "726    223.996689            NaN            NaN             NaN  \n",
       "727    207.990601            NaN            NaN             NaN  \n",
       "730    255.996140            NaN            NaN             NaN  \n",
       "731           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "732           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "734    256.032715            NaN            NaN             NaN  \n",
       "735           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "738      0.083496            NaN            NaN             NaN  \n",
       "739    207.995636            NaN            NaN             NaN  \n",
       "740    223.992004            NaN            NaN             NaN  \n",
       "741    192.012756            NaN            NaN             NaN  \n",
       "744    255.999725            NaN            NaN             NaN  \n",
       "745           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "746           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "748    256.005188            NaN            NaN             NaN  \n",
       "749           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "752      0.081055            NaN            NaN             NaN  \n",
       "753    207.995789            NaN            NaN             NaN  \n",
       "754    224.003357            NaN            NaN             NaN  \n",
       "755    207.978516            NaN            NaN             NaN  \n",
       "758    255.994659            NaN            NaN             NaN  \n",
       "759           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "760           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "762    287.989502            NaN            NaN             NaN  \n",
       "763           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "766      0.080185            NaN            NaN             NaN  \n",
       "767    207.989136            NaN            NaN             NaN  \n",
       "768    224.010498            NaN            NaN             NaN  \n",
       "769    208.000793            NaN            NaN             NaN  \n",
       "772    240.019897            NaN            NaN             NaN  \n",
       "773           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "774           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "776    256.021362            NaN            NaN             NaN  \n",
       "777           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "780      0.077087            NaN            NaN             NaN  \n",
       "781    207.992676            NaN            NaN             NaN  \n",
       "782    224.012817            NaN            NaN             NaN  \n",
       "783    208.004181            NaN            NaN             NaN  \n",
       "786    256.002899            NaN            NaN             NaN  \n",
       "787           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "788           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "790    287.973877            NaN            NaN             NaN  \n",
       "791           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "794      0.075806            NaN            NaN             NaN  \n",
       "795    207.985535            NaN            NaN             NaN  \n",
       "796    224.008850            NaN            NaN             NaN  \n",
       "797    208.019897            NaN            NaN             NaN  \n",
       "800    239.981079            NaN            NaN             NaN  \n",
       "801           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "802           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "804    256.028564            NaN            NaN             NaN  \n",
       "805           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "808      0.075439            NaN            NaN             NaN  \n",
       "809    192.016602            NaN            NaN             NaN  \n",
       "810    224.004028            NaN            NaN             NaN  \n",
       "811    207.997208            NaN            NaN             NaN  \n",
       "814    256.003357            NaN            NaN             NaN  \n",
       "815           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "816           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "818    240.026001            NaN            NaN             NaN  \n",
       "819           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "822      0.073364            NaN            NaN             NaN  \n",
       "823    192.002243            NaN            NaN             NaN  \n",
       "824    207.995544            NaN            NaN             NaN  \n",
       "825    191.994110            NaN            NaN             NaN  \n",
       "828    240.002502            NaN            NaN             NaN  \n",
       "829           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "830           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "832    256.024170            NaN            NaN             NaN  \n",
       "833           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  \n",
       "836      0.083862            NaN            NaN             NaN  \n",
       "837    176.009033            NaN            NaN             NaN  \n",
       "838    207.992828            NaN            NaN             NaN  \n",
       "839    192.002914            NaN            NaN             NaN  \n",
       "842    255.989136            NaN            NaN             NaN  \n",
       "843           NaN   (20480, 512)   (32768, 512)  shape_mismatch  \n",
       "844           NaN  (7168, 12288)  (7168, 16384)  shape_mismatch  \n",
       "846    240.000900            NaN            NaN             NaN  \n",
       "847           NaN  (12288, 1536)  (24576, 1536)  shape_mismatch  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)        #  \n",
    "pd.set_option('display.max_columns', None)     #  \n",
    "pd.set_option('display.width', None)           #    \n",
    "pd.set_option('display.max_colwidth', None)    #    \n",
    "\n",
    "ln_mask = df[\"key\"].str.endswith(LAYERNORM_SUFFIXES, na=False)\n",
    "df_ln = df[ln_mask]\n",
    "df_nonln = df[~ln_mask]\n",
    "df_nonln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "255f623d-ed18-44a1-ae0d-053fd2f303c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>key</th>\n",
       "      <th>shape</th>\n",
       "      <th>numel</th>\n",
       "      <th>norm_a</th>\n",
       "      <th>norm_b</th>\n",
       "      <th>norm_ratio</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_a</th>\n",
       "      <th>std_b</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>zero_frac_a</th>\n",
       "      <th>zero_frac_b</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rel_l2_err</th>\n",
       "      <th>mean_rel_diff</th>\n",
       "      <th>max_rel_diff</th>\n",
       "      <th>pearson</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "      <th>spearman</th>\n",
       "      <th>q01_abs_diff</th>\n",
       "      <th>q05_abs_diff</th>\n",
       "      <th>q50_abs_diff</th>\n",
       "      <th>q95_abs_diff</th>\n",
       "      <th>q99_abs_diff</th>\n",
       "      <th>shape_a</th>\n",
       "      <th>shape_b</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>5.333566</td>\n",
       "      <td>3.708255</td>\n",
       "      <td>1.438295</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>0.041479</td>\n",
       "      <td>1.415882</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>1.620160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>0.505120</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>5.045249</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.272217</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>-0.007118</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>0.127278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>1.600154</td>\n",
       "      <td>1.976582</td>\n",
       "      <td>0.809556</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.548183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>0.964386</td>\n",
       "      <td>1.760695</td>\n",
       "      <td>4720.670898</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.676208</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.152460</td>\n",
       "      <td>0.231502</td>\n",
       "      <td>0.658569</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.506165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>1.277797</td>\n",
       "      <td>2.887821</td>\n",
       "      <td>84.512604</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.237963</td>\n",
       "      <td>17.689760</td>\n",
       "      <td>0.465691</td>\n",
       "      <td>0.193372</td>\n",
       "      <td>0.443633</td>\n",
       "      <td>0.435884</td>\n",
       "      <td>0.082398</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905126</td>\n",
       "      <td>1.312957</td>\n",
       "      <td>1.929219</td>\n",
       "      <td>23.032129</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>1.400146</td>\n",
       "      <td>0.252936</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>0.419006</td>\n",
       "      <td>0.477258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>4.966424</td>\n",
       "      <td>4.025096</td>\n",
       "      <td>1.233865</td>\n",
       "      <td>0.053581</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>1.205580</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>1.414466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.437025</td>\n",
       "      <td>12.734513</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>4.805261</td>\n",
       "      <td>5.418404</td>\n",
       "      <td>0.886841</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.048390</td>\n",
       "      <td>0.947874</td>\n",
       "      <td>0.033429</td>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.798134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607914</td>\n",
       "      <td>0.948953</td>\n",
       "      <td>1.461620</td>\n",
       "      <td>755.537292</td>\n",
       "      <td>-0.008112</td>\n",
       "      <td>0.530029</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>0.259021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.091417</td>\n",
       "      <td>0.262622</td>\n",
       "      <td>0.348093</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.348004</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.348181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>2.528081</td>\n",
       "      <td>19.070650</td>\n",
       "      <td>1066.807495</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>5.265309</td>\n",
       "      <td>17.526243</td>\n",
       "      <td>0.300424</td>\n",
       "      <td>0.116436</td>\n",
       "      <td>0.419999</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.153560</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813170</td>\n",
       "      <td>2.581912</td>\n",
       "      <td>5.037098</td>\n",
       "      <td>172.381821</td>\n",
       "      <td>-0.004717</td>\n",
       "      <td>0.845947</td>\n",
       "      <td>0.306409</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.704395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.698238</td>\n",
       "      <td>5.042212</td>\n",
       "      <td>1.328432</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.056358</td>\n",
       "      <td>1.324173</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>1.364385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.468261</td>\n",
       "      <td>0.384318</td>\n",
       "      <td>10.901235</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.073160</td>\n",
       "      <td>0.113362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>5.107561</td>\n",
       "      <td>3.691749</td>\n",
       "      <td>1.383507</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>1.372092</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>1.428917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>0.607275</td>\n",
       "      <td>0.457887</td>\n",
       "      <td>44.881279</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>0.277005</td>\n",
       "      <td>0.276632</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.260855</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556629</td>\n",
       "      <td>3.169114</td>\n",
       "      <td>14.854513</td>\n",
       "      <td>1442.955078</td>\n",
       "      <td>-0.007952</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>6.045459</td>\n",
       "      <td>18.126390</td>\n",
       "      <td>0.333517</td>\n",
       "      <td>0.147995</td>\n",
       "      <td>0.432889</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>0.267065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897100</td>\n",
       "      <td>2.147197</td>\n",
       "      <td>2.239266</td>\n",
       "      <td>25.785185</td>\n",
       "      <td>-0.009041</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.285435</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.591309</td>\n",
       "      <td>0.731934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.191147</td>\n",
       "      <td>4.541937</td>\n",
       "      <td>1.803448</td>\n",
       "      <td>0.092289</td>\n",
       "      <td>0.052340</td>\n",
       "      <td>1.763250</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>2.467632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>0.525156</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>3.993939</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>0.041516</td>\n",
       "      <td>-0.007745</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>100.150665</td>\n",
       "      <td>79.248253</td>\n",
       "      <td>1.263759</td>\n",
       "      <td>6.259399</td>\n",
       "      <td>4.953015</td>\n",
       "      <td>1.263755</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>6.715944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.208720</td>\n",
       "      <td>0.208703</td>\n",
       "      <td>0.211952</td>\n",
       "      <td>0.077591</td>\n",
       "      <td>1.331326</td>\n",
       "      <td>1.306384</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>1.291267</td>\n",
       "      <td>1.293877</td>\n",
       "      <td>1.298276</td>\n",
       "      <td>1.330326</td>\n",
       "      <td>1.331326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.430301</td>\n",
       "      <td>10.335238</td>\n",
       "      <td>0.718929</td>\n",
       "      <td>0.080654</td>\n",
       "      <td>0.110154</td>\n",
       "      <td>0.732189</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.657652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825780</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>2.027711</td>\n",
       "      <td>500.894745</td>\n",
       "      <td>-0.020555</td>\n",
       "      <td>0.302460</td>\n",
       "      <td>0.056521</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.416599</td>\n",
       "      <td>0.834195</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.606496</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>1.278002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>1.105839</td>\n",
       "      <td>18.509750</td>\n",
       "      <td>2520.660645</td>\n",
       "      <td>-0.080960</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>-0.080748</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>13.885664</td>\n",
       "      <td>19.065044</td>\n",
       "      <td>0.728331</td>\n",
       "      <td>0.345856</td>\n",
       "      <td>0.456453</td>\n",
       "      <td>0.757705</td>\n",
       "      <td>0.076888</td>\n",
       "      <td>0.168193</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>0.607787</td>\n",
       "      <td>0.518893</td>\n",
       "      <td>4.371428</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>0.165950</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.441406</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.282731</td>\n",
       "      <td>3.886504</td>\n",
       "      <td>1.616551</td>\n",
       "      <td>0.071074</td>\n",
       "      <td>0.043553</td>\n",
       "      <td>1.631882</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>1.471112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909860</td>\n",
       "      <td>0.506939</td>\n",
       "      <td>0.391246</td>\n",
       "      <td>3.827586</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>0.030028</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>0.103352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>94.486427</td>\n",
       "      <td>105.370796</td>\n",
       "      <td>0.896704</td>\n",
       "      <td>5.905396</td>\n",
       "      <td>6.585674</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>4.698055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>0.115199</td>\n",
       "      <td>0.121158</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.711805</td>\n",
       "      <td>0.680279</td>\n",
       "      <td>0.132161</td>\n",
       "      <td>0.648305</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.691467</td>\n",
       "      <td>0.711695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.501461</td>\n",
       "      <td>10.436382</td>\n",
       "      <td>1.006236</td>\n",
       "      <td>0.118008</td>\n",
       "      <td>0.108037</td>\n",
       "      <td>1.092297</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.059355</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>0.915274</td>\n",
       "      <td>263.826660</td>\n",
       "      <td>-0.028770</td>\n",
       "      <td>0.319336</td>\n",
       "      <td>0.058462</td>\n",
       "      <td>-0.025815</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.134967</td>\n",
       "      <td>0.180012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.145010</td>\n",
       "      <td>1.085993</td>\n",
       "      <td>0.133528</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>0.135009</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>6.717411</td>\n",
       "      <td>16.174299</td>\n",
       "      <td>2135.943359</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.120544</td>\n",
       "      <td>0.037131</td>\n",
       "      <td>0.027201</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.069806</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.648572</td>\n",
       "      <td>38.966732</td>\n",
       "      <td>0.221948</td>\n",
       "      <td>0.213636</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>0.220554</td>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.224259</td>\n",
       "      <td>0.246504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941680</td>\n",
       "      <td>3.579740</td>\n",
       "      <td>3.865564</td>\n",
       "      <td>11.202021</td>\n",
       "      <td>-0.026300</td>\n",
       "      <td>1.583984</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>-0.028483</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>0.369385</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>1.133057</td>\n",
       "      <td>1.293262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.362890</td>\n",
       "      <td>5.834433</td>\n",
       "      <td>1.433368</td>\n",
       "      <td>0.095684</td>\n",
       "      <td>0.066838</td>\n",
       "      <td>1.431584</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>1.461375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>0.418997</td>\n",
       "      <td>0.326038</td>\n",
       "      <td>11.643903</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.073932</td>\n",
       "      <td>0.113198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>114.025658</td>\n",
       "      <td>120.610062</td>\n",
       "      <td>0.945408</td>\n",
       "      <td>7.126587</td>\n",
       "      <td>7.538128</td>\n",
       "      <td>0.945405</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>8.115402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.057788</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.072176</td>\n",
       "      <td>0.069558</td>\n",
       "      <td>0.507486</td>\n",
       "      <td>0.411542</td>\n",
       "      <td>0.052694</td>\n",
       "      <td>0.379396</td>\n",
       "      <td>0.382086</td>\n",
       "      <td>0.413536</td>\n",
       "      <td>0.418936</td>\n",
       "      <td>0.472687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>11.926690</td>\n",
       "      <td>12.219624</td>\n",
       "      <td>0.976028</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.129416</td>\n",
       "      <td>1.044210</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.063898</td>\n",
       "      <td>0.622563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857210</td>\n",
       "      <td>0.541476</td>\n",
       "      <td>0.719009</td>\n",
       "      <td>83.879433</td>\n",
       "      <td>-0.023657</td>\n",
       "      <td>0.298401</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>-0.020848</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>0.184062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.164448</td>\n",
       "      <td>0.613759</td>\n",
       "      <td>0.267936</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.259980</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.482850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942494</td>\n",
       "      <td>2.809685</td>\n",
       "      <td>5.259251</td>\n",
       "      <td>399.822845</td>\n",
       "      <td>-0.069843</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.031139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>12.083183</td>\n",
       "      <td>29.750238</td>\n",
       "      <td>0.406154</td>\n",
       "      <td>0.297168</td>\n",
       "      <td>0.715038</td>\n",
       "      <td>0.415598</td>\n",
       "      <td>0.082129</td>\n",
       "      <td>0.254837</td>\n",
       "      <td>0.322280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904794</td>\n",
       "      <td>1.614500</td>\n",
       "      <td>1.662392</td>\n",
       "      <td>10.543379</td>\n",
       "      <td>-0.035047</td>\n",
       "      <td>1.167969</td>\n",
       "      <td>0.429652</td>\n",
       "      <td>-0.041957</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.842041</td>\n",
       "      <td>0.963525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.117170</td>\n",
       "      <td>5.769558</td>\n",
       "      <td>1.233573</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.067094</td>\n",
       "      <td>1.214450</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>1.732541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>0.331784</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>3.896552</td>\n",
       "      <td>-0.002211</td>\n",
       "      <td>0.307129</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.082681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>118.371513</td>\n",
       "      <td>95.961823</td>\n",
       "      <td>1.233527</td>\n",
       "      <td>7.398193</td>\n",
       "      <td>5.997613</td>\n",
       "      <td>1.233523</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>9.784381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.189332</td>\n",
       "      <td>0.189308</td>\n",
       "      <td>0.193728</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>1.440852</td>\n",
       "      <td>1.400580</td>\n",
       "      <td>0.085245</td>\n",
       "      <td>1.314402</td>\n",
       "      <td>1.347102</td>\n",
       "      <td>1.408402</td>\n",
       "      <td>1.411452</td>\n",
       "      <td>1.415401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>12.566309</td>\n",
       "      <td>13.817199</td>\n",
       "      <td>0.909469</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>0.928440</td>\n",
       "      <td>0.037405</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>0.719793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>0.442103</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>21.127659</td>\n",
       "      <td>-0.021555</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>-0.019529</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.130371</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.135344</td>\n",
       "      <td>0.454429</td>\n",
       "      <td>0.297833</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>0.275999</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.985429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>2.480313</td>\n",
       "      <td>4.264627</td>\n",
       "      <td>114.911110</td>\n",
       "      <td>-0.046069</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.600546</td>\n",
       "      <td>28.650684</td>\n",
       "      <td>0.300186</td>\n",
       "      <td>0.207385</td>\n",
       "      <td>0.687798</td>\n",
       "      <td>0.301520</td>\n",
       "      <td>0.071755</td>\n",
       "      <td>0.247687</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888783</td>\n",
       "      <td>2.485110</td>\n",
       "      <td>2.776003</td>\n",
       "      <td>11.489796</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>1.109375</td>\n",
       "      <td>0.483756</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.487305</td>\n",
       "      <td>0.884766</td>\n",
       "      <td>1.000293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.519102</td>\n",
       "      <td>5.417134</td>\n",
       "      <td>1.388022</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>0.062993</td>\n",
       "      <td>1.381284</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>1.585890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>0.358566</td>\n",
       "      <td>0.270462</td>\n",
       "      <td>3.243094</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.479004</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>106.918343</td>\n",
       "      <td>87.724533</td>\n",
       "      <td>1.218796</td>\n",
       "      <td>6.682373</td>\n",
       "      <td>5.482783</td>\n",
       "      <td>1.218792</td>\n",
       "      <td>0.017590</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>6.487113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.179534</td>\n",
       "      <td>0.179510</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>0.088802</td>\n",
       "      <td>1.239864</td>\n",
       "      <td>1.199590</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>1.140775</td>\n",
       "      <td>1.171515</td>\n",
       "      <td>1.203815</td>\n",
       "      <td>1.212064</td>\n",
       "      <td>1.237065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>14.079303</td>\n",
       "      <td>14.198127</td>\n",
       "      <td>0.991631</td>\n",
       "      <td>0.163313</td>\n",
       "      <td>0.160756</td>\n",
       "      <td>1.015910</td>\n",
       "      <td>0.031355</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.656547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940211</td>\n",
       "      <td>0.347361</td>\n",
       "      <td>0.387639</td>\n",
       "      <td>73.884354</td>\n",
       "      <td>-0.022177</td>\n",
       "      <td>0.218628</td>\n",
       "      <td>0.044104</td>\n",
       "      <td>-0.026056</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.426888</td>\n",
       "      <td>0.779261</td>\n",
       "      <td>0.547811</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.537793</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>1.174130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.887372</td>\n",
       "      <td>4.830700</td>\n",
       "      <td>1430.934937</td>\n",
       "      <td>-0.045017</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>13.775208</td>\n",
       "      <td>36.266392</td>\n",
       "      <td>0.379834</td>\n",
       "      <td>0.334484</td>\n",
       "      <td>0.863280</td>\n",
       "      <td>0.387457</td>\n",
       "      <td>0.107981</td>\n",
       "      <td>0.333213</td>\n",
       "      <td>0.324059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892380</td>\n",
       "      <td>1.797909</td>\n",
       "      <td>1.925852</td>\n",
       "      <td>10.154929</td>\n",
       "      <td>0.041392</td>\n",
       "      <td>1.418945</td>\n",
       "      <td>0.543642</td>\n",
       "      <td>0.042698</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>1.052002</td>\n",
       "      <td>1.183545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.110951</td>\n",
       "      <td>5.380949</td>\n",
       "      <td>1.693187</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>0.062231</td>\n",
       "      <td>1.703697</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>1.427530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.458113</td>\n",
       "      <td>0.407056</td>\n",
       "      <td>2.447005</td>\n",
       "      <td>-0.012705</td>\n",
       "      <td>0.354492</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>-0.006039</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>98.215782</td>\n",
       "      <td>86.622200</td>\n",
       "      <td>1.133841</td>\n",
       "      <td>6.138428</td>\n",
       "      <td>5.413887</td>\n",
       "      <td>1.133830</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>11.140157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.118017</td>\n",
       "      <td>0.122048</td>\n",
       "      <td>-0.016731</td>\n",
       "      <td>0.751359</td>\n",
       "      <td>0.724541</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.633897</td>\n",
       "      <td>0.679010</td>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.746760</td>\n",
       "      <td>0.749559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>15.492817</td>\n",
       "      <td>15.785369</td>\n",
       "      <td>0.981467</td>\n",
       "      <td>0.180642</td>\n",
       "      <td>0.181526</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.686859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960529</td>\n",
       "      <td>0.284235</td>\n",
       "      <td>0.283835</td>\n",
       "      <td>35.402115</td>\n",
       "      <td>-0.015849</td>\n",
       "      <td>0.222778</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>-0.019328</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.167114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.265736</td>\n",
       "      <td>0.534529</td>\n",
       "      <td>0.497139</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.506322</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965048</td>\n",
       "      <td>1.078778</td>\n",
       "      <td>3.367396</td>\n",
       "      <td>935.087830</td>\n",
       "      <td>-0.049529</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>-0.045209</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>15.508194</td>\n",
       "      <td>24.044184</td>\n",
       "      <td>0.644987</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.703098</td>\n",
       "      <td>0.107487</td>\n",
       "      <td>0.288125</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>0.880355</td>\n",
       "      <td>0.853385</td>\n",
       "      <td>6.896774</td>\n",
       "      <td>-0.014892</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>0.282334</td>\n",
       "      <td>-0.012600</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.839795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.394691</td>\n",
       "      <td>3.145885</td>\n",
       "      <td>2.668467</td>\n",
       "      <td>0.097636</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>2.652601</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>3.397628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>0.639980</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.945423</td>\n",
       "      <td>-0.012499</td>\n",
       "      <td>0.524414</td>\n",
       "      <td>0.060864</td>\n",
       "      <td>-0.002786</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.118001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>89.670647</td>\n",
       "      <td>77.074051</td>\n",
       "      <td>1.163435</td>\n",
       "      <td>5.604370</td>\n",
       "      <td>4.817127</td>\n",
       "      <td>1.163426</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>7.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.140528</td>\n",
       "      <td>0.140455</td>\n",
       "      <td>0.146678</td>\n",
       "      <td>-0.078326</td>\n",
       "      <td>0.825065</td>\n",
       "      <td>0.787243</td>\n",
       "      <td>-0.141759</td>\n",
       "      <td>0.713427</td>\n",
       "      <td>0.744767</td>\n",
       "      <td>0.779016</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.817516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>17.782528</td>\n",
       "      <td>16.459641</td>\n",
       "      <td>1.080372</td>\n",
       "      <td>0.208091</td>\n",
       "      <td>0.190776</td>\n",
       "      <td>1.090763</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.762141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>0.239751</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>13.511628</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.112305</td>\n",
       "      <td>0.179524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>2.375535</td>\n",
       "      <td>0.120433</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.104601</td>\n",
       "      <td>0.119603</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.204072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985790</td>\n",
       "      <td>7.319476</td>\n",
       "      <td>12.125095</td>\n",
       "      <td>2353.144287</td>\n",
       "      <td>-0.005494</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.092130</td>\n",
       "      <td>-0.033861</td>\n",
       "      <td>0.048609</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.100098</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>12.147147</td>\n",
       "      <td>58.573437</td>\n",
       "      <td>0.207383</td>\n",
       "      <td>0.291249</td>\n",
       "      <td>1.428330</td>\n",
       "      <td>0.203909</td>\n",
       "      <td>0.106005</td>\n",
       "      <td>0.439884</td>\n",
       "      <td>0.240985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>3.949352</td>\n",
       "      <td>4.783004</td>\n",
       "      <td>18.106796</td>\n",
       "      <td>-0.006946</td>\n",
       "      <td>1.940430</td>\n",
       "      <td>1.141272</td>\n",
       "      <td>-0.015383</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>1.252441</td>\n",
       "      <td>1.673828</td>\n",
       "      <td>1.804297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.541730</td>\n",
       "      <td>3.601893</td>\n",
       "      <td>2.371456</td>\n",
       "      <td>0.099587</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>2.353147</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>3.718390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.566980</td>\n",
       "      <td>0.921033</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.119707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>78.372345</td>\n",
       "      <td>64.967072</td>\n",
       "      <td>1.206339</td>\n",
       "      <td>4.898193</td>\n",
       "      <td>4.060442</td>\n",
       "      <td>1.206320</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>11.181231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.171006</td>\n",
       "      <td>0.178169</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>0.879712</td>\n",
       "      <td>0.837752</td>\n",
       "      <td>0.052533</td>\n",
       "      <td>0.705659</td>\n",
       "      <td>0.812012</td>\n",
       "      <td>0.845262</td>\n",
       "      <td>0.850311</td>\n",
       "      <td>0.877712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>19.708843</td>\n",
       "      <td>17.559284</td>\n",
       "      <td>1.122417</td>\n",
       "      <td>0.231204</td>\n",
       "      <td>0.204769</td>\n",
       "      <td>1.129095</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.823633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980439</td>\n",
       "      <td>0.216220</td>\n",
       "      <td>0.181954</td>\n",
       "      <td>12.239436</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.035862</td>\n",
       "      <td>-0.018406</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.103516</td>\n",
       "      <td>0.190022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.359084</td>\n",
       "      <td>1.876313</td>\n",
       "      <td>0.191378</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.190269</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.343094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>4.238711</td>\n",
       "      <td>4.865345</td>\n",
       "      <td>129.909088</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.067032</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0.076209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>14.437043</td>\n",
       "      <td>61.101032</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.350926</td>\n",
       "      <td>1.483577</td>\n",
       "      <td>0.236541</td>\n",
       "      <td>0.112010</td>\n",
       "      <td>0.479122</td>\n",
       "      <td>0.233783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904946</td>\n",
       "      <td>3.354393</td>\n",
       "      <td>3.807660</td>\n",
       "      <td>17.690266</td>\n",
       "      <td>-0.017125</td>\n",
       "      <td>1.956055</td>\n",
       "      <td>1.142103</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>1.288086</td>\n",
       "      <td>1.699219</td>\n",
       "      <td>1.824756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.118999</td>\n",
       "      <td>2.988442</td>\n",
       "      <td>3.051423</td>\n",
       "      <td>0.106996</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>3.063137</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>2.433828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>0.680383</td>\n",
       "      <td>0.670312</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.055908</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.089191</td>\n",
       "      <td>0.113770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.608574</td>\n",
       "      <td>60.910301</td>\n",
       "      <td>1.192057</td>\n",
       "      <td>4.537964</td>\n",
       "      <td>3.806892</td>\n",
       "      <td>1.192039</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>7.560077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.161199</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>0.171046</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.785744</td>\n",
       "      <td>0.731071</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.647481</td>\n",
       "      <td>0.691194</td>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.758743</td>\n",
       "      <td>0.766583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>20.472179</td>\n",
       "      <td>18.495205</td>\n",
       "      <td>1.106891</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.216203</td>\n",
       "      <td>1.112866</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>0.031279</td>\n",
       "      <td>0.769164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>0.192343</td>\n",
       "      <td>0.162446</td>\n",
       "      <td>20.810057</td>\n",
       "      <td>-0.006962</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.197263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>2.485416</td>\n",
       "      <td>0.316369</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.109573</td>\n",
       "      <td>0.315769</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.421386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>2.170675</td>\n",
       "      <td>24.702936</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.109955</td>\n",
       "      <td>0.075135</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.066296</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.092937</td>\n",
       "      <td>53.990604</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.538747</td>\n",
       "      <td>1.274603</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>0.165902</td>\n",
       "      <td>0.522651</td>\n",
       "      <td>0.317425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>1.631507</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>9.926829</td>\n",
       "      <td>-0.021215</td>\n",
       "      <td>1.792969</td>\n",
       "      <td>0.816552</td>\n",
       "      <td>-0.028128</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.877930</td>\n",
       "      <td>1.428955</td>\n",
       "      <td>1.593652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.310952</td>\n",
       "      <td>5.036315</td>\n",
       "      <td>1.848763</td>\n",
       "      <td>0.109255</td>\n",
       "      <td>0.059196</td>\n",
       "      <td>1.845658</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>2.141295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>0.472232</td>\n",
       "      <td>0.452887</td>\n",
       "      <td>0.791096</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.050131</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.089436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>68.907265</td>\n",
       "      <td>57.200222</td>\n",
       "      <td>1.204668</td>\n",
       "      <td>4.306641</td>\n",
       "      <td>3.575012</td>\n",
       "      <td>1.204651</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>6.953601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.169968</td>\n",
       "      <td>0.169859</td>\n",
       "      <td>0.178630</td>\n",
       "      <td>0.067644</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>0.060866</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>0.703027</td>\n",
       "      <td>0.736477</td>\n",
       "      <td>0.744476</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.192741</td>\n",
       "      <td>19.668037</td>\n",
       "      <td>1.077522</td>\n",
       "      <td>0.249318</td>\n",
       "      <td>0.230472</td>\n",
       "      <td>1.081770</td>\n",
       "      <td>0.022324</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.766179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>28.014925</td>\n",
       "      <td>-0.003010</td>\n",
       "      <td>0.266907</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>-0.011222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.194417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.493276</td>\n",
       "      <td>1.282483</td>\n",
       "      <td>0.384626</td>\n",
       "      <td>0.021726</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>0.383897</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.579381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>1.608467</td>\n",
       "      <td>1.686309</td>\n",
       "      <td>33.133335</td>\n",
       "      <td>-0.090782</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>16.539137</td>\n",
       "      <td>40.300804</td>\n",
       "      <td>0.410392</td>\n",
       "      <td>0.401939</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>0.424202</td>\n",
       "      <td>0.128579</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.321853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878062</td>\n",
       "      <td>1.630441</td>\n",
       "      <td>1.754232</td>\n",
       "      <td>8.842424</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>1.446289</td>\n",
       "      <td>0.589704</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.613770</td>\n",
       "      <td>1.129150</td>\n",
       "      <td>1.292969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.637804</td>\n",
       "      <td>4.383891</td>\n",
       "      <td>1.970351</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>1.968792</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>2.156290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.488571</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>-0.013793</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>60.936588</td>\n",
       "      <td>51.128990</td>\n",
       "      <td>1.191821</td>\n",
       "      <td>3.808472</td>\n",
       "      <td>3.195559</td>\n",
       "      <td>1.191802</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>4.891450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.161045</td>\n",
       "      <td>0.160905</td>\n",
       "      <td>0.173687</td>\n",
       "      <td>-0.077375</td>\n",
       "      <td>0.670324</td>\n",
       "      <td>0.612913</td>\n",
       "      <td>-0.026785</td>\n",
       "      <td>0.513128</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>0.615649</td>\n",
       "      <td>0.637124</td>\n",
       "      <td>0.648905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.127401</td>\n",
       "      <td>20.101664</td>\n",
       "      <td>1.051028</td>\n",
       "      <td>0.248703</td>\n",
       "      <td>0.235769</td>\n",
       "      <td>1.054858</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>0.730448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989647</td>\n",
       "      <td>0.148516</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>32.947826</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.260788</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>-0.015994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.186685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.791774</td>\n",
       "      <td>1.809377</td>\n",
       "      <td>0.437595</td>\n",
       "      <td>0.034928</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.437437</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.488275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>1.291228</td>\n",
       "      <td>1.392268</td>\n",
       "      <td>52.439999</td>\n",
       "      <td>-0.029082</td>\n",
       "      <td>0.080017</td>\n",
       "      <td>0.045048</td>\n",
       "      <td>-0.056886</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.933607</td>\n",
       "      <td>53.314022</td>\n",
       "      <td>0.430161</td>\n",
       "      <td>0.557188</td>\n",
       "      <td>1.237014</td>\n",
       "      <td>0.450430</td>\n",
       "      <td>0.178766</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.315864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>1.547568</td>\n",
       "      <td>1.756489</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>-0.027902</td>\n",
       "      <td>1.943359</td>\n",
       "      <td>0.780742</td>\n",
       "      <td>-0.032075</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>1.669580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.447861</td>\n",
       "      <td>4.184812</td>\n",
       "      <td>1.779736</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>0.049242</td>\n",
       "      <td>1.777459</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>2.057549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>0.433584</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.038317</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.117859</td>\n",
       "      <td>50.622261</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>3.694763</td>\n",
       "      <td>3.163889</td>\n",
       "      <td>1.167792</td>\n",
       "      <td>0.027581</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>7.246110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.143878</td>\n",
       "      <td>0.143632</td>\n",
       "      <td>0.153526</td>\n",
       "      <td>-0.037131</td>\n",
       "      <td>0.573322</td>\n",
       "      <td>0.530874</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.441612</td>\n",
       "      <td>0.496697</td>\n",
       "      <td>0.537072</td>\n",
       "      <td>0.555897</td>\n",
       "      <td>0.569222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.704342</td>\n",
       "      <td>20.226292</td>\n",
       "      <td>1.073076</td>\n",
       "      <td>0.255670</td>\n",
       "      <td>0.237395</td>\n",
       "      <td>1.076981</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.026780</td>\n",
       "      <td>0.701217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.146101</td>\n",
       "      <td>0.114674</td>\n",
       "      <td>47.490799</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.268997</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>-0.009827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.311881</td>\n",
       "      <td>2.227962</td>\n",
       "      <td>0.588826</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.098248</td>\n",
       "      <td>0.588375</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.683947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994724</td>\n",
       "      <td>0.711010</td>\n",
       "      <td>0.852622</td>\n",
       "      <td>52.106384</td>\n",
       "      <td>-0.030337</td>\n",
       "      <td>0.097137</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>-0.078225</td>\n",
       "      <td>0.029893</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>28.781591</td>\n",
       "      <td>62.755371</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.704034</td>\n",
       "      <td>1.500387</td>\n",
       "      <td>0.469235</td>\n",
       "      <td>0.208918</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.373548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>1.361276</td>\n",
       "      <td>1.660806</td>\n",
       "      <td>12.402597</td>\n",
       "      <td>-0.037486</td>\n",
       "      <td>2.171875</td>\n",
       "      <td>0.898635</td>\n",
       "      <td>-0.035233</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.583984</td>\n",
       "      <td>1.846289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.517498</td>\n",
       "      <td>3.358935</td>\n",
       "      <td>1.940346</td>\n",
       "      <td>0.076545</td>\n",
       "      <td>0.039542</td>\n",
       "      <td>1.935784</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>2.533557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.494089</td>\n",
       "      <td>0.478963</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>57.500515</td>\n",
       "      <td>50.311974</td>\n",
       "      <td>1.142879</td>\n",
       "      <td>3.593689</td>\n",
       "      <td>3.144496</td>\n",
       "      <td>1.142851</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>6.552856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.134385</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>0.487145</td>\n",
       "      <td>0.449193</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.326014</td>\n",
       "      <td>0.402821</td>\n",
       "      <td>0.451695</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>0.481145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.481438</td>\n",
       "      <td>20.713083</td>\n",
       "      <td>1.037095</td>\n",
       "      <td>0.253141</td>\n",
       "      <td>0.243359</td>\n",
       "      <td>1.040197</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.025106</td>\n",
       "      <td>0.685666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>87.480873</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.776436</td>\n",
       "      <td>3.292956</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.122195</td>\n",
       "      <td>0.145305</td>\n",
       "      <td>0.840955</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>1.380246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994207</td>\n",
       "      <td>0.219886</td>\n",
       "      <td>10.727682</td>\n",
       "      <td>5254.940918</td>\n",
       "      <td>-0.025096</td>\n",
       "      <td>0.148466</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.067779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.155495</td>\n",
       "      <td>73.755165</td>\n",
       "      <td>0.463093</td>\n",
       "      <td>0.837078</td>\n",
       "      <td>1.792213</td>\n",
       "      <td>0.467064</td>\n",
       "      <td>0.242495</td>\n",
       "      <td>0.574041</td>\n",
       "      <td>0.422434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>1.307852</td>\n",
       "      <td>1.871016</td>\n",
       "      <td>19.912281</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>2.329102</td>\n",
       "      <td>1.042509</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.036523</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>1.115234</td>\n",
       "      <td>1.775879</td>\n",
       "      <td>2.092383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.493422</td>\n",
       "      <td>3.122280</td>\n",
       "      <td>2.399984</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>2.405991</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>1.878375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.590640</td>\n",
       "      <td>0.582067</td>\n",
       "      <td>0.862103</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>-0.005634</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>0.039795</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>63.492413</td>\n",
       "      <td>47.654469</td>\n",
       "      <td>1.332350</td>\n",
       "      <td>3.968140</td>\n",
       "      <td>2.978401</td>\n",
       "      <td>1.332306</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>7.457530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.249551</td>\n",
       "      <td>0.249369</td>\n",
       "      <td>0.257533</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>1.030133</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>0.862356</td>\n",
       "      <td>0.931333</td>\n",
       "      <td>0.996683</td>\n",
       "      <td>1.019134</td>\n",
       "      <td>1.023662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.855965</td>\n",
       "      <td>21.130243</td>\n",
       "      <td>1.034345</td>\n",
       "      <td>0.257655</td>\n",
       "      <td>0.248375</td>\n",
       "      <td>1.037365</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.652296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>0.118595</td>\n",
       "      <td>0.081640</td>\n",
       "      <td>43.869564</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.266983</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.641315</td>\n",
       "      <td>3.123290</td>\n",
       "      <td>0.525508</td>\n",
       "      <td>0.072362</td>\n",
       "      <td>0.137754</td>\n",
       "      <td>0.525302</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.574459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995508</td>\n",
       "      <td>0.912338</td>\n",
       "      <td>0.957306</td>\n",
       "      <td>23.373056</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.137665</td>\n",
       "      <td>0.065671</td>\n",
       "      <td>-0.049760</td>\n",
       "      <td>0.039819</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>31.587980</td>\n",
       "      <td>59.614555</td>\n",
       "      <td>0.529870</td>\n",
       "      <td>0.757899</td>\n",
       "      <td>1.457768</td>\n",
       "      <td>0.519904</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.434334</td>\n",
       "      <td>0.631367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903922</td>\n",
       "      <td>1.072320</td>\n",
       "      <td>1.502367</td>\n",
       "      <td>10.138122</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>1.860352</td>\n",
       "      <td>0.775614</td>\n",
       "      <td>0.026777</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>1.458008</td>\n",
       "      <td>1.629541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.470176</td>\n",
       "      <td>2.893547</td>\n",
       "      <td>2.581667</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>2.589619</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>1.817235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.611855</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.053999</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.035076</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.072021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.110390</td>\n",
       "      <td>43.221100</td>\n",
       "      <td>1.483312</td>\n",
       "      <td>4.006653</td>\n",
       "      <td>2.701313</td>\n",
       "      <td>1.483224</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>8.092406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.325965</td>\n",
       "      <td>0.325706</td>\n",
       "      <td>0.337825</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>1.372413</td>\n",
       "      <td>1.305340</td>\n",
       "      <td>-0.025474</td>\n",
       "      <td>1.095804</td>\n",
       "      <td>1.236563</td>\n",
       "      <td>1.323164</td>\n",
       "      <td>1.338463</td>\n",
       "      <td>1.357954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.914175</td>\n",
       "      <td>21.914501</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.258373</td>\n",
       "      <td>0.257723</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.644272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993903</td>\n",
       "      <td>0.110431</td>\n",
       "      <td>0.084935</td>\n",
       "      <td>88.872337</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.266068</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.161284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.020492</td>\n",
       "      <td>4.783579</td>\n",
       "      <td>0.422381</td>\n",
       "      <td>0.089113</td>\n",
       "      <td>0.210982</td>\n",
       "      <td>0.422375</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.423756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>1.374585</td>\n",
       "      <td>1.434541</td>\n",
       "      <td>30.716814</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>0.211853</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>-0.065574</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.808437</td>\n",
       "      <td>71.422585</td>\n",
       "      <td>0.487359</td>\n",
       "      <td>0.841668</td>\n",
       "      <td>1.722112</td>\n",
       "      <td>0.488742</td>\n",
       "      <td>0.283576</td>\n",
       "      <td>0.596166</td>\n",
       "      <td>0.475666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>1.226518</td>\n",
       "      <td>1.678248</td>\n",
       "      <td>12.224490</td>\n",
       "      <td>0.072027</td>\n",
       "      <td>2.339844</td>\n",
       "      <td>0.991634</td>\n",
       "      <td>0.047350</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.771729</td>\n",
       "      <td>1.987158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.183807</td>\n",
       "      <td>3.338204</td>\n",
       "      <td>2.451560</td>\n",
       "      <td>0.096202</td>\n",
       "      <td>0.039203</td>\n",
       "      <td>2.453969</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>2.233580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>0.599349</td>\n",
       "      <td>0.589859</td>\n",
       "      <td>0.857021</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>-0.023784</td>\n",
       "      <td>0.037517</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>61.606770</td>\n",
       "      <td>41.250099</td>\n",
       "      <td>1.493494</td>\n",
       "      <td>3.850281</td>\n",
       "      <td>2.578124</td>\n",
       "      <td>1.493443</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>5.364066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.330511</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>0.339464</td>\n",
       "      <td>-0.022923</td>\n",
       "      <td>1.320729</td>\n",
       "      <td>1.272157</td>\n",
       "      <td>-0.058165</td>\n",
       "      <td>1.106757</td>\n",
       "      <td>1.217929</td>\n",
       "      <td>1.279280</td>\n",
       "      <td>1.304197</td>\n",
       "      <td>1.314295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>22.301815</td>\n",
       "      <td>22.705572</td>\n",
       "      <td>0.982218</td>\n",
       "      <td>0.262995</td>\n",
       "      <td>0.267114</td>\n",
       "      <td>0.984580</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.621356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>0.108024</td>\n",
       "      <td>0.080463</td>\n",
       "      <td>60.730495</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.266006</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.156084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.790116</td>\n",
       "      <td>3.660754</td>\n",
       "      <td>0.489002</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.161438</td>\n",
       "      <td>0.488288</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.633824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>1.055969</td>\n",
       "      <td>9.782271</td>\n",
       "      <td>4412.109863</td>\n",
       "      <td>0.014655</td>\n",
       "      <td>0.163049</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.928190</td>\n",
       "      <td>56.085789</td>\n",
       "      <td>0.408806</td>\n",
       "      <td>0.555045</td>\n",
       "      <td>1.375809</td>\n",
       "      <td>0.403432</td>\n",
       "      <td>0.184876</td>\n",
       "      <td>0.393799</td>\n",
       "      <td>0.469468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911530</td>\n",
       "      <td>1.588764</td>\n",
       "      <td>1.934185</td>\n",
       "      <td>8.409327</td>\n",
       "      <td>-0.006847</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.859472</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.497022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.698030</td>\n",
       "      <td>3.559573</td>\n",
       "      <td>2.162627</td>\n",
       "      <td>0.090643</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>2.164872</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>1.872844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>0.543855</td>\n",
       "      <td>0.536279</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>-0.014924</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.048805</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.838367</td>\n",
       "      <td>42.235420</td>\n",
       "      <td>1.156337</td>\n",
       "      <td>3.052063</td>\n",
       "      <td>2.639706</td>\n",
       "      <td>1.156213</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>7.089037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.135924</td>\n",
       "      <td>0.135136</td>\n",
       "      <td>0.157368</td>\n",
       "      <td>-0.021378</td>\n",
       "      <td>0.486856</td>\n",
       "      <td>0.412969</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>0.279165</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.420409</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>0.459749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>22.808533</td>\n",
       "      <td>24.000456</td>\n",
       "      <td>0.950337</td>\n",
       "      <td>0.269003</td>\n",
       "      <td>0.282359</td>\n",
       "      <td>0.952699</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.118641</td>\n",
       "      <td>0.105258</td>\n",
       "      <td>90.151512</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.272369</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.007612</td>\n",
       "      <td>6.082238</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>0.268124</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.302330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>2.036408</td>\n",
       "      <td>2.119742</td>\n",
       "      <td>31.705883</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>0.179885</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>0.139214</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.235523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.754414</td>\n",
       "      <td>62.438587</td>\n",
       "      <td>0.572633</td>\n",
       "      <td>0.869946</td>\n",
       "      <td>1.537322</td>\n",
       "      <td>0.565884</td>\n",
       "      <td>0.274722</td>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.657131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>0.920567</td>\n",
       "      <td>1.348303</td>\n",
       "      <td>12.226666</td>\n",
       "      <td>-0.042092</td>\n",
       "      <td>1.803711</td>\n",
       "      <td>0.762092</td>\n",
       "      <td>-0.032200</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>1.430420</td>\n",
       "      <td>1.642481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.941700</td>\n",
       "      <td>3.825140</td>\n",
       "      <td>2.337614</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>2.338668</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>2.184911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993408</td>\n",
       "      <td>0.577120</td>\n",
       "      <td>0.570422</td>\n",
       "      <td>0.843960</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.245605</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.071533</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>51.349850</td>\n",
       "      <td>41.333645</td>\n",
       "      <td>1.242326</td>\n",
       "      <td>3.208984</td>\n",
       "      <td>2.583346</td>\n",
       "      <td>1.242181</td>\n",
       "      <td>0.049468</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>8.288301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.195568</td>\n",
       "      <td>0.194755</td>\n",
       "      <td>0.211148</td>\n",
       "      <td>-0.064095</td>\n",
       "      <td>0.689529</td>\n",
       "      <td>0.625638</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>0.424509</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.634255</td>\n",
       "      <td>0.669435</td>\n",
       "      <td>0.683344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>23.311581</td>\n",
       "      <td>25.515226</td>\n",
       "      <td>0.913634</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.300217</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.026338</td>\n",
       "      <td>0.544243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.142140</td>\n",
       "      <td>0.135760</td>\n",
       "      <td>75.487808</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.465116</td>\n",
       "      <td>6.631782</td>\n",
       "      <td>0.220923</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.292640</td>\n",
       "      <td>0.220905</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.226973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>3.530484</td>\n",
       "      <td>3.609409</td>\n",
       "      <td>44.886791</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>0.290405</td>\n",
       "      <td>0.228209</td>\n",
       "      <td>-0.057530</td>\n",
       "      <td>0.174678</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>28.253962</td>\n",
       "      <td>73.820541</td>\n",
       "      <td>0.382738</td>\n",
       "      <td>0.678922</td>\n",
       "      <td>1.846360</td>\n",
       "      <td>0.367708</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>0.372544</td>\n",
       "      <td>0.650799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>1.734461</td>\n",
       "      <td>2.477821</td>\n",
       "      <td>15.124031</td>\n",
       "      <td>-0.016673</td>\n",
       "      <td>2.003906</td>\n",
       "      <td>1.197476</td>\n",
       "      <td>-0.025932</td>\n",
       "      <td>0.092773</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.779297</td>\n",
       "      <td>1.899707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.068832</td>\n",
       "      <td>3.979035</td>\n",
       "      <td>2.027836</td>\n",
       "      <td>0.094841</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>2.023835</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>2.626806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992202</td>\n",
       "      <td>0.514395</td>\n",
       "      <td>0.502658</td>\n",
       "      <td>0.851724</td>\n",
       "      <td>-0.007349</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>-0.025707</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.062431</td>\n",
       "      <td>39.149841</td>\n",
       "      <td>1.253196</td>\n",
       "      <td>3.066101</td>\n",
       "      <td>2.446855</td>\n",
       "      <td>1.253078</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>6.122201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.202439</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>0.214921</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.668270</td>\n",
       "      <td>0.619246</td>\n",
       "      <td>0.080404</td>\n",
       "      <td>0.433062</td>\n",
       "      <td>0.543789</td>\n",
       "      <td>0.629020</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.662936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>23.813595</td>\n",
       "      <td>26.737455</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.280909</td>\n",
       "      <td>0.314663</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.026851</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.155446</td>\n",
       "      <td>54.636364</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.293457</td>\n",
       "      <td>0.038960</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.153643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.968177</td>\n",
       "      <td>8.135511</td>\n",
       "      <td>0.241924</td>\n",
       "      <td>0.086753</td>\n",
       "      <td>0.358591</td>\n",
       "      <td>0.241927</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.241362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>3.140450</td>\n",
       "      <td>3.317812</td>\n",
       "      <td>50.929825</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.354370</td>\n",
       "      <td>0.272445</td>\n",
       "      <td>-0.053811</td>\n",
       "      <td>0.212280</td>\n",
       "      <td>0.257104</td>\n",
       "      <td>0.273926</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>0.293838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>20.671974</td>\n",
       "      <td>69.679062</td>\n",
       "      <td>0.296674</td>\n",
       "      <td>0.504494</td>\n",
       "      <td>1.735003</td>\n",
       "      <td>0.290774</td>\n",
       "      <td>0.153935</td>\n",
       "      <td>0.388182</td>\n",
       "      <td>0.396555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933343</td>\n",
       "      <td>2.463653</td>\n",
       "      <td>2.931830</td>\n",
       "      <td>14.496063</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>1.884766</td>\n",
       "      <td>1.246964</td>\n",
       "      <td>-0.002507</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>0.274902</td>\n",
       "      <td>1.320312</td>\n",
       "      <td>1.662598</td>\n",
       "      <td>1.762647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.130106</td>\n",
       "      <td>4.244864</td>\n",
       "      <td>1.915281</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>1.916806</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>1.724252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.486104</td>\n",
       "      <td>0.476649</td>\n",
       "      <td>0.833942</td>\n",
       "      <td>-0.005453</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.045858</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>0.055908</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>45.628685</td>\n",
       "      <td>45.220245</td>\n",
       "      <td>1.009032</td>\n",
       "      <td>2.851501</td>\n",
       "      <td>2.826259</td>\n",
       "      <td>1.008931</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>6.639153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.028532</td>\n",
       "      <td>0.187452</td>\n",
       "      <td>0.040812</td>\n",
       "      <td>0.076558</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.081703</td>\n",
       "      <td>0.142737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>24.354338</td>\n",
       "      <td>27.943714</td>\n",
       "      <td>0.871550</td>\n",
       "      <td>0.287277</td>\n",
       "      <td>0.328794</td>\n",
       "      <td>0.873730</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.514052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>0.182811</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>84.157028</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.311035</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.155918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.095639</td>\n",
       "      <td>6.838748</td>\n",
       "      <td>0.306436</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.301488</td>\n",
       "      <td>0.306796</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>0.221986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>2.268730</td>\n",
       "      <td>2.301948</td>\n",
       "      <td>23.118227</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.314453</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.144580</td>\n",
       "      <td>0.195361</td>\n",
       "      <td>0.209229</td>\n",
       "      <td>0.228247</td>\n",
       "      <td>0.241592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>30.609915</td>\n",
       "      <td>63.275879</td>\n",
       "      <td>0.483753</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>1.583948</td>\n",
       "      <td>0.467217</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.312690</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929085</td>\n",
       "      <td>1.196678</td>\n",
       "      <td>1.743547</td>\n",
       "      <td>10.973154</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.876101</td>\n",
       "      <td>-0.007202</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.299805</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.470703</td>\n",
       "      <td>1.602832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.086284</td>\n",
       "      <td>4.431251</td>\n",
       "      <td>1.599161</td>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>1.599199</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>1.593569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>0.385940</td>\n",
       "      <td>0.372567</td>\n",
       "      <td>0.801948</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>-0.005840</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.041260</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.856133</td>\n",
       "      <td>45.227196</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>3.053284</td>\n",
       "      <td>2.826689</td>\n",
       "      <td>1.080163</td>\n",
       "      <td>0.037031</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>4.804199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.226649</td>\n",
       "      <td>0.066821</td>\n",
       "      <td>0.072231</td>\n",
       "      <td>0.160291</td>\n",
       "      <td>0.233623</td>\n",
       "      <td>0.266916</td>\n",
       "      <td>0.272682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>24.984646</td>\n",
       "      <td>29.704109</td>\n",
       "      <td>0.841118</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.349499</td>\n",
       "      <td>0.843272</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.487557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>0.218581</td>\n",
       "      <td>0.218047</td>\n",
       "      <td>55.412373</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.328064</td>\n",
       "      <td>0.059284</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.102937</td>\n",
       "      <td>8.542912</td>\n",
       "      <td>0.363218</td>\n",
       "      <td>0.136737</td>\n",
       "      <td>0.376948</td>\n",
       "      <td>0.362748</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.489043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995580</td>\n",
       "      <td>1.760096</td>\n",
       "      <td>1.922224</td>\n",
       "      <td>55.558140</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.364532</td>\n",
       "      <td>0.240680</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.156885</td>\n",
       "      <td>0.225146</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.254614</td>\n",
       "      <td>0.277622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.525059</td>\n",
       "      <td>69.673721</td>\n",
       "      <td>0.509877</td>\n",
       "      <td>0.861521</td>\n",
       "      <td>1.762080</td>\n",
       "      <td>0.488923</td>\n",
       "      <td>0.281808</td>\n",
       "      <td>0.235603</td>\n",
       "      <td>1.196113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942352</td>\n",
       "      <td>1.072445</td>\n",
       "      <td>1.597363</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>1.742188</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.145898</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.574463</td>\n",
       "      <td>1.685205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.211089</td>\n",
       "      <td>4.750062</td>\n",
       "      <td>1.518104</td>\n",
       "      <td>0.084953</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>1.518587</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>1.432913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994543</td>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.339445</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.029088</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.045491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.167828</td>\n",
       "      <td>45.486034</td>\n",
       "      <td>1.102928</td>\n",
       "      <td>3.135132</td>\n",
       "      <td>2.842865</td>\n",
       "      <td>1.102807</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>5.814858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.094523</td>\n",
       "      <td>0.093153</td>\n",
       "      <td>0.114329</td>\n",
       "      <td>-0.144866</td>\n",
       "      <td>0.364422</td>\n",
       "      <td>0.292698</td>\n",
       "      <td>-0.082924</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.212374</td>\n",
       "      <td>0.305274</td>\n",
       "      <td>0.336874</td>\n",
       "      <td>0.345619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>25.530970</td>\n",
       "      <td>31.090153</td>\n",
       "      <td>0.821191</td>\n",
       "      <td>0.301155</td>\n",
       "      <td>0.365806</td>\n",
       "      <td>0.823263</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.248719</td>\n",
       "      <td>72.025642</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.342896</td>\n",
       "      <td>0.068901</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.165030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.719140</td>\n",
       "      <td>9.508757</td>\n",
       "      <td>0.496294</td>\n",
       "      <td>0.207878</td>\n",
       "      <td>0.419451</td>\n",
       "      <td>0.495595</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>0.657540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994767</td>\n",
       "      <td>1.025271</td>\n",
       "      <td>1.128071</td>\n",
       "      <td>30.849766</td>\n",
       "      <td>-0.023467</td>\n",
       "      <td>0.402832</td>\n",
       "      <td>0.212310</td>\n",
       "      <td>-0.032187</td>\n",
       "      <td>0.130205</td>\n",
       "      <td>0.185107</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>0.231885</td>\n",
       "      <td>0.258467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.125446</td>\n",
       "      <td>82.335564</td>\n",
       "      <td>0.548068</td>\n",
       "      <td>1.115506</td>\n",
       "      <td>2.081787</td>\n",
       "      <td>0.535840</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>0.282257</td>\n",
       "      <td>1.010603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960780</td>\n",
       "      <td>0.907235</td>\n",
       "      <td>1.379985</td>\n",
       "      <td>16.192158</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>2.121094</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.112631</td>\n",
       "      <td>0.190234</td>\n",
       "      <td>0.646484</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>1.742676</td>\n",
       "      <td>1.999658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.457499</td>\n",
       "      <td>4.945893</td>\n",
       "      <td>1.507816</td>\n",
       "      <td>0.087829</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>1.507902</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>1.493226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.348096</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>0.029705</td>\n",
       "      <td>-0.007906</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.447563</td>\n",
       "      <td>45.497261</td>\n",
       "      <td>1.064846</td>\n",
       "      <td>3.027405</td>\n",
       "      <td>2.843565</td>\n",
       "      <td>1.064651</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>6.738204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.063837</td>\n",
       "      <td>0.062355</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>-0.050876</td>\n",
       "      <td>0.351076</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>0.118424</td>\n",
       "      <td>0.195586</td>\n",
       "      <td>0.234049</td>\n",
       "      <td>0.252879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>25.881824</td>\n",
       "      <td>32.060814</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.305291</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>0.809255</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.480492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994920</td>\n",
       "      <td>0.263784</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>103.675552</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.355942</td>\n",
       "      <td>0.075931</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.162432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.022617</td>\n",
       "      <td>9.215854</td>\n",
       "      <td>0.436489</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>0.436201</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.502537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>1.299328</td>\n",
       "      <td>1.383906</td>\n",
       "      <td>28.321587</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>0.392395</td>\n",
       "      <td>0.230217</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.189561</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>0.264658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.342270</td>\n",
       "      <td>76.011490</td>\n",
       "      <td>0.543895</td>\n",
       "      <td>1.010875</td>\n",
       "      <td>1.930578</td>\n",
       "      <td>0.523613</td>\n",
       "      <td>0.301465</td>\n",
       "      <td>0.185537</td>\n",
       "      <td>1.624824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954527</td>\n",
       "      <td>0.932976</td>\n",
       "      <td>1.540862</td>\n",
       "      <td>14.085714</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>1.925781</td>\n",
       "      <td>0.929804</td>\n",
       "      <td>-0.013090</td>\n",
       "      <td>0.191602</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.722168</td>\n",
       "      <td>1.834961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.811490</td>\n",
       "      <td>5.258142</td>\n",
       "      <td>1.485599</td>\n",
       "      <td>0.092014</td>\n",
       "      <td>0.061970</td>\n",
       "      <td>1.484815</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>1.654349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>0.336839</td>\n",
       "      <td>0.324669</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>-0.003871</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.047444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>46.034271</td>\n",
       "      <td>46.470119</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>2.876648</td>\n",
       "      <td>2.904363</td>\n",
       "      <td>0.990457</td>\n",
       "      <td>0.053311</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>5.029110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.104713</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.084456</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>0.116866</td>\n",
       "      <td>0.266807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>26.623869</td>\n",
       "      <td>33.157757</td>\n",
       "      <td>0.802945</td>\n",
       "      <td>0.314048</td>\n",
       "      <td>0.390296</td>\n",
       "      <td>0.804640</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>0.268240</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>75.800003</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.079964</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.604096</td>\n",
       "      <td>11.638908</td>\n",
       "      <td>0.395578</td>\n",
       "      <td>0.202725</td>\n",
       "      <td>0.513562</td>\n",
       "      <td>0.394743</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.604701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>1.536790</td>\n",
       "      <td>1.627915</td>\n",
       "      <td>31.738462</td>\n",
       "      <td>-0.022831</td>\n",
       "      <td>0.503662</td>\n",
       "      <td>0.311572</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.242070</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.338330</td>\n",
       "      <td>0.399863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>39.589603</td>\n",
       "      <td>78.118546</td>\n",
       "      <td>0.506789</td>\n",
       "      <td>0.964149</td>\n",
       "      <td>1.983653</td>\n",
       "      <td>0.486047</td>\n",
       "      <td>0.301361</td>\n",
       "      <td>0.195206</td>\n",
       "      <td>1.543809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>1.068205</td>\n",
       "      <td>1.848875</td>\n",
       "      <td>15.578313</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>2.005859</td>\n",
       "      <td>1.029910</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.308691</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>1.829102</td>\n",
       "      <td>1.911426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.708518</td>\n",
       "      <td>5.781740</td>\n",
       "      <td>1.333252</td>\n",
       "      <td>0.090699</td>\n",
       "      <td>0.068131</td>\n",
       "      <td>1.331242</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>1.709746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993821</td>\n",
       "      <td>0.267856</td>\n",
       "      <td>0.246468</td>\n",
       "      <td>0.789384</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>0.225098</td>\n",
       "      <td>0.022701</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.155056</td>\n",
       "      <td>47.134258</td>\n",
       "      <td>1.064089</td>\n",
       "      <td>3.134216</td>\n",
       "      <td>2.945873</td>\n",
       "      <td>1.063935</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>5.212838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.060893</td>\n",
       "      <td>0.098108</td>\n",
       "      <td>-0.065842</td>\n",
       "      <td>0.314252</td>\n",
       "      <td>0.191410</td>\n",
       "      <td>0.019813</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.107832</td>\n",
       "      <td>0.199382</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>0.260811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.110918</td>\n",
       "      <td>34.026569</td>\n",
       "      <td>0.796757</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.400636</td>\n",
       "      <td>0.798119</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>0.540078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.276547</td>\n",
       "      <td>0.287534</td>\n",
       "      <td>101.193550</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.382935</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>0.166006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.696667</td>\n",
       "      <td>12.212162</td>\n",
       "      <td>0.302704</td>\n",
       "      <td>0.163052</td>\n",
       "      <td>0.538561</td>\n",
       "      <td>0.302754</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.035146</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>2.309118</td>\n",
       "      <td>2.351690</td>\n",
       "      <td>16.982302</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>0.498779</td>\n",
       "      <td>0.376303</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.302285</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.396484</td>\n",
       "      <td>0.410703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.217964</td>\n",
       "      <td>79.873123</td>\n",
       "      <td>0.440924</td>\n",
       "      <td>0.859638</td>\n",
       "      <td>2.026072</td>\n",
       "      <td>0.424288</td>\n",
       "      <td>0.261751</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>1.188613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>1.351828</td>\n",
       "      <td>1.987786</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>2.018555</td>\n",
       "      <td>1.176172</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>0.259570</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.829346</td>\n",
       "      <td>1.941699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.035164</td>\n",
       "      <td>5.331933</td>\n",
       "      <td>1.506989</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>1.507417</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>1.428983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994672</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.335391</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>-0.003691</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>46.787014</td>\n",
       "      <td>50.976673</td>\n",
       "      <td>0.917812</td>\n",
       "      <td>2.923767</td>\n",
       "      <td>3.186023</td>\n",
       "      <td>0.917685</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>4.540858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.091389</td>\n",
       "      <td>0.090030</td>\n",
       "      <td>0.221308</td>\n",
       "      <td>-0.050658</td>\n",
       "      <td>0.577477</td>\n",
       "      <td>0.262256</td>\n",
       "      <td>-0.018378</td>\n",
       "      <td>0.182492</td>\n",
       "      <td>0.201896</td>\n",
       "      <td>0.252864</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.421226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.555099</td>\n",
       "      <td>34.934570</td>\n",
       "      <td>0.788763</td>\n",
       "      <td>0.324967</td>\n",
       "      <td>0.411490</td>\n",
       "      <td>0.789734</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.587316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.295049</td>\n",
       "      <td>68.818184</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.392731</td>\n",
       "      <td>0.089569</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.269969</td>\n",
       "      <td>14.672475</td>\n",
       "      <td>0.427329</td>\n",
       "      <td>0.275982</td>\n",
       "      <td>0.647391</td>\n",
       "      <td>0.426299</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.673809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>1.350135</td>\n",
       "      <td>1.509979</td>\n",
       "      <td>59.300579</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>0.626160</td>\n",
       "      <td>0.372419</td>\n",
       "      <td>-0.031893</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.513584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.063992</td>\n",
       "      <td>70.867645</td>\n",
       "      <td>0.635890</td>\n",
       "      <td>1.096289</td>\n",
       "      <td>1.792945</td>\n",
       "      <td>0.611446</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.234576</td>\n",
       "      <td>1.478360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.709712</td>\n",
       "      <td>1.434338</td>\n",
       "      <td>15.347826</td>\n",
       "      <td>-0.032695</td>\n",
       "      <td>1.844727</td>\n",
       "      <td>0.731556</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>1.651367</td>\n",
       "      <td>1.756787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.911266</td>\n",
       "      <td>5.675344</td>\n",
       "      <td>1.393971</td>\n",
       "      <td>0.093238</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>1.393914</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>1.407177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>0.282055</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.026530</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.651878</td>\n",
       "      <td>48.342358</td>\n",
       "      <td>1.027089</td>\n",
       "      <td>3.102722</td>\n",
       "      <td>3.021368</td>\n",
       "      <td>1.026926</td>\n",
       "      <td>0.056814</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>4.282165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.276863</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.142773</td>\n",
       "      <td>0.182142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.815681</td>\n",
       "      <td>35.910515</td>\n",
       "      <td>0.774583</td>\n",
       "      <td>0.328044</td>\n",
       "      <td>0.423096</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.604075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.308088</td>\n",
       "      <td>0.321079</td>\n",
       "      <td>89.026665</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.407532</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.172197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5.917262</td>\n",
       "      <td>15.048488</td>\n",
       "      <td>0.393213</td>\n",
       "      <td>0.260768</td>\n",
       "      <td>0.664242</td>\n",
       "      <td>0.392581</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.597711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>1.549931</td>\n",
       "      <td>1.716602</td>\n",
       "      <td>53.303032</td>\n",
       "      <td>-0.019552</td>\n",
       "      <td>0.646118</td>\n",
       "      <td>0.404404</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>0.403809</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.468115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>48.664703</td>\n",
       "      <td>70.438400</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>1.224239</td>\n",
       "      <td>1.787476</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>0.207536</td>\n",
       "      <td>0.187394</td>\n",
       "      <td>1.107484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980962</td>\n",
       "      <td>0.505271</td>\n",
       "      <td>0.653128</td>\n",
       "      <td>15.265560</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>1.796387</td>\n",
       "      <td>0.585976</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.166797</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>1.019531</td>\n",
       "      <td>1.628174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.062296</td>\n",
       "      <td>5.988408</td>\n",
       "      <td>1.346317</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>0.070541</td>\n",
       "      <td>1.345101</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>1.554713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>0.274706</td>\n",
       "      <td>0.255667</td>\n",
       "      <td>1.021390</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>56.364899</td>\n",
       "      <td>50.260181</td>\n",
       "      <td>1.121462</td>\n",
       "      <td>3.522339</td>\n",
       "      <td>3.141231</td>\n",
       "      <td>1.121325</td>\n",
       "      <td>0.057383</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>4.124401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.109506</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>0.132267</td>\n",
       "      <td>-0.054424</td>\n",
       "      <td>0.475520</td>\n",
       "      <td>0.381108</td>\n",
       "      <td>-0.061330</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>0.269465</td>\n",
       "      <td>0.394895</td>\n",
       "      <td>0.445713</td>\n",
       "      <td>0.466214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>28.271057</td>\n",
       "      <td>36.425423</td>\n",
       "      <td>0.776135</td>\n",
       "      <td>0.333436</td>\n",
       "      <td>0.429238</td>\n",
       "      <td>0.776811</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>0.614034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>0.304641</td>\n",
       "      <td>0.316340</td>\n",
       "      <td>83.809814</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.416901</td>\n",
       "      <td>0.098415</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.169268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5.506713</td>\n",
       "      <td>13.684910</td>\n",
       "      <td>0.402393</td>\n",
       "      <td>0.242844</td>\n",
       "      <td>0.603910</td>\n",
       "      <td>0.402119</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.487159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996577</td>\n",
       "      <td>1.490848</td>\n",
       "      <td>1.523602</td>\n",
       "      <td>12.505377</td>\n",
       "      <td>0.049619</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>0.361906</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.360840</td>\n",
       "      <td>0.391602</td>\n",
       "      <td>0.435137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>37.772858</td>\n",
       "      <td>72.382622</td>\n",
       "      <td>0.521850</td>\n",
       "      <td>0.920822</td>\n",
       "      <td>1.830573</td>\n",
       "      <td>0.503024</td>\n",
       "      <td>0.284580</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>1.162086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948715</td>\n",
       "      <td>1.017882</td>\n",
       "      <td>1.578896</td>\n",
       "      <td>12.699347</td>\n",
       "      <td>0.044364</td>\n",
       "      <td>1.897461</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>-0.006347</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.633545</td>\n",
       "      <td>1.762695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.897707</td>\n",
       "      <td>6.376474</td>\n",
       "      <td>1.238569</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>1.237419</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>1.476727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994669</td>\n",
       "      <td>0.213796</td>\n",
       "      <td>0.191543</td>\n",
       "      <td>1.158192</td>\n",
       "      <td>-0.003924</td>\n",
       "      <td>0.170410</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>52.797226</td>\n",
       "      <td>57.852005</td>\n",
       "      <td>0.912626</td>\n",
       "      <td>3.299438</td>\n",
       "      <td>3.615731</td>\n",
       "      <td>0.912523</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>4.224644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.097144</td>\n",
       "      <td>0.096132</td>\n",
       "      <td>0.214323</td>\n",
       "      <td>-0.010071</td>\n",
       "      <td>0.636271</td>\n",
       "      <td>0.316292</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>0.223718</td>\n",
       "      <td>0.260260</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.413445</td>\n",
       "      <td>0.521002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>28.926723</td>\n",
       "      <td>37.828533</td>\n",
       "      <td>0.764680</td>\n",
       "      <td>0.341183</td>\n",
       "      <td>0.445842</td>\n",
       "      <td>0.765255</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.617827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.322378</td>\n",
       "      <td>0.331882</td>\n",
       "      <td>65.666664</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.432861</td>\n",
       "      <td>0.107163</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.175117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.051957</td>\n",
       "      <td>16.307974</td>\n",
       "      <td>0.432424</td>\n",
       "      <td>0.310746</td>\n",
       "      <td>0.719584</td>\n",
       "      <td>0.431842</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>1.320503</td>\n",
       "      <td>1.400346</td>\n",
       "      <td>31.715084</td>\n",
       "      <td>-0.010537</td>\n",
       "      <td>0.692993</td>\n",
       "      <td>0.409939</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.272639</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.446191</td>\n",
       "      <td>0.502393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>43.037724</td>\n",
       "      <td>68.926460</td>\n",
       "      <td>0.624401</td>\n",
       "      <td>1.048125</td>\n",
       "      <td>1.746784</td>\n",
       "      <td>0.600031</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>1.603295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.949915</td>\n",
       "      <td>0.722683</td>\n",
       "      <td>1.337174</td>\n",
       "      <td>12.239436</td>\n",
       "      <td>0.055265</td>\n",
       "      <td>1.738281</td>\n",
       "      <td>0.718967</td>\n",
       "      <td>0.057699</td>\n",
       "      <td>0.104297</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>1.570312</td>\n",
       "      <td>1.666650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.889240</td>\n",
       "      <td>5.830320</td>\n",
       "      <td>1.524657</td>\n",
       "      <td>0.104726</td>\n",
       "      <td>0.068708</td>\n",
       "      <td>1.524225</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>1.616956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.342881</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.152832</td>\n",
       "      <td>49.721458</td>\n",
       "      <td>1.008676</td>\n",
       "      <td>3.134155</td>\n",
       "      <td>3.107569</td>\n",
       "      <td>1.008555</td>\n",
       "      <td>0.049873</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>4.247295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.138051</td>\n",
       "      <td>-0.019193</td>\n",
       "      <td>0.377482</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>0.150838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.162882</td>\n",
       "      <td>38.999523</td>\n",
       "      <td>0.747775</td>\n",
       "      <td>0.343978</td>\n",
       "      <td>0.459724</td>\n",
       "      <td>0.748227</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.624090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.350267</td>\n",
       "      <td>0.363007</td>\n",
       "      <td>79.347824</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.445557</td>\n",
       "      <td>0.118019</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.588762</td>\n",
       "      <td>16.664677</td>\n",
       "      <td>0.455380</td>\n",
       "      <td>0.334683</td>\n",
       "      <td>0.735415</td>\n",
       "      <td>0.455094</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.039613</td>\n",
       "      <td>0.545209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>1.202410</td>\n",
       "      <td>1.248351</td>\n",
       "      <td>19.965517</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.706787</td>\n",
       "      <td>0.401917</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.305962</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>0.449004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>44.091393</td>\n",
       "      <td>65.182068</td>\n",
       "      <td>0.676434</td>\n",
       "      <td>1.081811</td>\n",
       "      <td>1.647552</td>\n",
       "      <td>0.656617</td>\n",
       "      <td>0.308776</td>\n",
       "      <td>0.227272</td>\n",
       "      <td>1.358615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951048</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>1.199540</td>\n",
       "      <td>15.615385</td>\n",
       "      <td>-0.040758</td>\n",
       "      <td>1.739746</td>\n",
       "      <td>0.604333</td>\n",
       "      <td>-0.052275</td>\n",
       "      <td>0.091211</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1.486328</td>\n",
       "      <td>1.633936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.963466</td>\n",
       "      <td>5.802093</td>\n",
       "      <td>1.544868</td>\n",
       "      <td>0.105609</td>\n",
       "      <td>0.068305</td>\n",
       "      <td>1.546131</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>1.340201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994311</td>\n",
       "      <td>0.362987</td>\n",
       "      <td>0.352497</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.190430</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.935829</td>\n",
       "      <td>58.862942</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>3.120361</td>\n",
       "      <td>3.678916</td>\n",
       "      <td>0.848174</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>5.539257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.180124</td>\n",
       "      <td>0.179510</td>\n",
       "      <td>0.367820</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.558555</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.474553</td>\n",
       "      <td>0.498315</td>\n",
       "      <td>0.545290</td>\n",
       "      <td>0.684265</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.481527</td>\n",
       "      <td>39.809658</td>\n",
       "      <td>0.740562</td>\n",
       "      <td>0.347760</td>\n",
       "      <td>0.469333</td>\n",
       "      <td>0.740966</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.622939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>0.362237</td>\n",
       "      <td>0.372869</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.457031</td>\n",
       "      <td>0.123706</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.174768</td>\n",
       "      <td>17.283358</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>0.316587</td>\n",
       "      <td>0.762202</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>0.356394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>1.415222</td>\n",
       "      <td>1.472912</td>\n",
       "      <td>31.168421</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>0.722900</td>\n",
       "      <td>0.447776</td>\n",
       "      <td>-0.049150</td>\n",
       "      <td>0.375430</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>47.223068</td>\n",
       "      <td>58.363537</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>1.170833</td>\n",
       "      <td>1.461844</td>\n",
       "      <td>0.800928</td>\n",
       "      <td>0.284580</td>\n",
       "      <td>0.284001</td>\n",
       "      <td>1.002038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>0.411872</td>\n",
       "      <td>0.740873</td>\n",
       "      <td>13.319327</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.638672</td>\n",
       "      <td>0.388416</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>1.461231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.193699</td>\n",
       "      <td>5.759494</td>\n",
       "      <td>1.596268</td>\n",
       "      <td>0.108368</td>\n",
       "      <td>0.067819</td>\n",
       "      <td>1.597897</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>1.305079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.382017</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.040740</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>55.477261</td>\n",
       "      <td>60.892586</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>3.466980</td>\n",
       "      <td>3.805771</td>\n",
       "      <td>0.910980</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>4.446198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.098753</td>\n",
       "      <td>0.097948</td>\n",
       "      <td>0.226229</td>\n",
       "      <td>0.068826</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.338791</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>0.273795</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.415631</td>\n",
       "      <td>0.546960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.845907</td>\n",
       "      <td>40.668385</td>\n",
       "      <td>0.733885</td>\n",
       "      <td>0.352094</td>\n",
       "      <td>0.479449</td>\n",
       "      <td>0.734372</td>\n",
       "      <td>0.017365</td>\n",
       "      <td>0.029415</td>\n",
       "      <td>0.590349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.373947</td>\n",
       "      <td>0.385385</td>\n",
       "      <td>59.279068</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.466736</td>\n",
       "      <td>0.129530</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.188145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.063729</td>\n",
       "      <td>16.081411</td>\n",
       "      <td>0.439248</td>\n",
       "      <td>0.311392</td>\n",
       "      <td>0.709224</td>\n",
       "      <td>0.439060</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.045857</td>\n",
       "      <td>0.482038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995443</td>\n",
       "      <td>1.284720</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>23.446352</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.666870</td>\n",
       "      <td>0.399222</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.271538</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.491778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>47.451469</td>\n",
       "      <td>63.553204</td>\n",
       "      <td>0.746642</td>\n",
       "      <td>1.183826</td>\n",
       "      <td>1.601308</td>\n",
       "      <td>0.739287</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.255691</td>\n",
       "      <td>0.993022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>0.453128</td>\n",
       "      <td>0.693614</td>\n",
       "      <td>14.168000</td>\n",
       "      <td>0.024252</td>\n",
       "      <td>1.729492</td>\n",
       "      <td>0.476263</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>1.531494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.893102</td>\n",
       "      <td>6.090456</td>\n",
       "      <td>1.460170</td>\n",
       "      <td>0.104804</td>\n",
       "      <td>0.071727</td>\n",
       "      <td>1.461141</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>1.283483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>0.326091</td>\n",
       "      <td>0.315790</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>66.110176</td>\n",
       "      <td>59.661243</td>\n",
       "      <td>1.108093</td>\n",
       "      <td>4.131592</td>\n",
       "      <td>3.728813</td>\n",
       "      <td>1.108018</td>\n",
       "      <td>0.049318</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>4.696288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.097354</td>\n",
       "      <td>0.119041</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.498485</td>\n",
       "      <td>0.402779</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.216217</td>\n",
       "      <td>0.305138</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>0.453938</td>\n",
       "      <td>0.467799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>30.291435</td>\n",
       "      <td>41.269196</td>\n",
       "      <td>0.733996</td>\n",
       "      <td>0.357377</td>\n",
       "      <td>0.486644</td>\n",
       "      <td>0.734371</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.609970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997244</td>\n",
       "      <td>0.372622</td>\n",
       "      <td>0.388470</td>\n",
       "      <td>85.732239</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.979453</td>\n",
       "      <td>16.766403</td>\n",
       "      <td>0.416276</td>\n",
       "      <td>0.307707</td>\n",
       "      <td>0.739226</td>\n",
       "      <td>0.416256</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>1.410728</td>\n",
       "      <td>1.470606</td>\n",
       "      <td>27.714285</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.432765</td>\n",
       "      <td>-0.020492</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>46.435028</td>\n",
       "      <td>64.891945</td>\n",
       "      <td>0.715575</td>\n",
       "      <td>1.163125</td>\n",
       "      <td>1.639507</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>0.225664</td>\n",
       "      <td>0.231369</td>\n",
       "      <td>0.975343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>0.486420</td>\n",
       "      <td>0.654955</td>\n",
       "      <td>14.658119</td>\n",
       "      <td>-0.007150</td>\n",
       "      <td>1.674805</td>\n",
       "      <td>0.520839</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>1.047852</td>\n",
       "      <td>1.522217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.348124</td>\n",
       "      <td>6.535086</td>\n",
       "      <td>1.277431</td>\n",
       "      <td>0.098228</td>\n",
       "      <td>0.076935</td>\n",
       "      <td>1.276759</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>1.375659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993009</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>0.217831</td>\n",
       "      <td>1.269430</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.187012</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>62.670074</td>\n",
       "      <td>57.402885</td>\n",
       "      <td>1.091758</td>\n",
       "      <td>3.916321</td>\n",
       "      <td>3.587661</td>\n",
       "      <td>1.091608</td>\n",
       "      <td>0.066166</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>5.568248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.116691</td>\n",
       "      <td>-0.048167</td>\n",
       "      <td>0.459470</td>\n",
       "      <td>0.330236</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.071826</td>\n",
       "      <td>0.192178</td>\n",
       "      <td>0.342865</td>\n",
       "      <td>0.383914</td>\n",
       "      <td>0.411485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>30.874731</td>\n",
       "      <td>42.265732</td>\n",
       "      <td>0.730491</td>\n",
       "      <td>0.364285</td>\n",
       "      <td>0.498457</td>\n",
       "      <td>0.730824</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.611524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>0.378366</td>\n",
       "      <td>0.395466</td>\n",
       "      <td>100.199997</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.489258</td>\n",
       "      <td>0.136063</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.189775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.706844</td>\n",
       "      <td>17.553160</td>\n",
       "      <td>0.382088</td>\n",
       "      <td>0.295533</td>\n",
       "      <td>0.774706</td>\n",
       "      <td>0.381478</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.040184</td>\n",
       "      <td>0.564736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>1.624116</td>\n",
       "      <td>1.719836</td>\n",
       "      <td>30.842365</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>0.764282</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.380391</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.136681</td>\n",
       "      <td>64.073906</td>\n",
       "      <td>0.548377</td>\n",
       "      <td>0.831806</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>0.514073</td>\n",
       "      <td>0.334463</td>\n",
       "      <td>0.233835</td>\n",
       "      <td>1.430339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.985710</td>\n",
       "      <td>1.787897</td>\n",
       "      <td>11.353742</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>1.634766</td>\n",
       "      <td>0.808131</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>1.494629</td>\n",
       "      <td>1.576807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.235064</td>\n",
       "      <td>5.547874</td>\n",
       "      <td>1.664613</td>\n",
       "      <td>0.108670</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>1.666564</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>1.454245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>0.411916</td>\n",
       "      <td>0.399183</td>\n",
       "      <td>1.122642</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.067952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.229416</td>\n",
       "      <td>60.786652</td>\n",
       "      <td>0.974382</td>\n",
       "      <td>3.701599</td>\n",
       "      <td>3.799148</td>\n",
       "      <td>0.974324</td>\n",
       "      <td>0.042101</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>3.609935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>0.366507</td>\n",
       "      <td>0.097597</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.032939</td>\n",
       "      <td>0.053007</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>0.176707</td>\n",
       "      <td>0.262763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>31.662472</td>\n",
       "      <td>42.784061</td>\n",
       "      <td>0.740053</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.504624</td>\n",
       "      <td>0.740369</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.618512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.360320</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.132880</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.105305</td>\n",
       "      <td>20.455339</td>\n",
       "      <td>0.347357</td>\n",
       "      <td>0.313262</td>\n",
       "      <td>0.902194</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>0.379456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>1.885559</td>\n",
       "      <td>1.969272</td>\n",
       "      <td>35.349514</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.888916</td>\n",
       "      <td>0.589781</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.409043</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.645410</td>\n",
       "      <td>0.739805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.166149</td>\n",
       "      <td>53.906418</td>\n",
       "      <td>0.763660</td>\n",
       "      <td>1.018266</td>\n",
       "      <td>1.338238</td>\n",
       "      <td>0.760901</td>\n",
       "      <td>0.257726</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.811025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.794528</td>\n",
       "      <td>12.102880</td>\n",
       "      <td>-0.035162</td>\n",
       "      <td>1.506836</td>\n",
       "      <td>0.443871</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.381323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.054070</td>\n",
       "      <td>5.683800</td>\n",
       "      <td>1.592961</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>1.596553</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>1.135575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>0.383590</td>\n",
       "      <td>0.373968</td>\n",
       "      <td>1.067961</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>54.623924</td>\n",
       "      <td>64.535614</td>\n",
       "      <td>0.846415</td>\n",
       "      <td>3.413574</td>\n",
       "      <td>4.033462</td>\n",
       "      <td>0.846314</td>\n",
       "      <td>0.053611</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>5.132750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.181908</td>\n",
       "      <td>0.318854</td>\n",
       "      <td>-0.060080</td>\n",
       "      <td>0.976490</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>-0.032483</td>\n",
       "      <td>0.543702</td>\n",
       "      <td>0.568990</td>\n",
       "      <td>0.611015</td>\n",
       "      <td>0.709435</td>\n",
       "      <td>0.882136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.022961</td>\n",
       "      <td>44.180645</td>\n",
       "      <td>0.724819</td>\n",
       "      <td>0.377886</td>\n",
       "      <td>0.521095</td>\n",
       "      <td>0.725176</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.585676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.388015</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>93.391060</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.510162</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.750358</td>\n",
       "      <td>26.224215</td>\n",
       "      <td>0.295542</td>\n",
       "      <td>0.341728</td>\n",
       "      <td>1.153692</td>\n",
       "      <td>0.296204</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.211025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>2.392235</td>\n",
       "      <td>2.442798</td>\n",
       "      <td>27.611765</td>\n",
       "      <td>0.117644</td>\n",
       "      <td>1.145996</td>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.023442</td>\n",
       "      <td>0.343477</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.833984</td>\n",
       "      <td>0.886523</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>43.734512</td>\n",
       "      <td>55.419159</td>\n",
       "      <td>0.789159</td>\n",
       "      <td>1.098074</td>\n",
       "      <td>1.376326</td>\n",
       "      <td>0.797830</td>\n",
       "      <td>0.198711</td>\n",
       "      <td>0.324437</td>\n",
       "      <td>0.612478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960291</td>\n",
       "      <td>0.414751</td>\n",
       "      <td>0.516173</td>\n",
       "      <td>12.762712</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>1.478516</td>\n",
       "      <td>0.400002</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>1.256227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.790635</td>\n",
       "      <td>6.803200</td>\n",
       "      <td>1.145143</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>1.145004</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>1.160577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.177642</td>\n",
       "      <td>0.134306</td>\n",
       "      <td>1.680628</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.156738</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.221333</td>\n",
       "      <td>65.443092</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>3.138489</td>\n",
       "      <td>4.090182</td>\n",
       "      <td>0.767322</td>\n",
       "      <td>0.046510</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>4.961665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.303575</td>\n",
       "      <td>0.303537</td>\n",
       "      <td>0.462341</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>1.293111</td>\n",
       "      <td>0.951693</td>\n",
       "      <td>-0.031404</td>\n",
       "      <td>0.893487</td>\n",
       "      <td>0.910342</td>\n",
       "      <td>0.938736</td>\n",
       "      <td>1.030736</td>\n",
       "      <td>1.113242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.510365</td>\n",
       "      <td>45.550747</td>\n",
       "      <td>0.713717</td>\n",
       "      <td>0.383658</td>\n",
       "      <td>0.537274</td>\n",
       "      <td>0.714084</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>0.566285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>0.408862</td>\n",
       "      <td>0.426743</td>\n",
       "      <td>113.614380</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.530487</td>\n",
       "      <td>0.155432</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.257142</td>\n",
       "      <td>28.256945</td>\n",
       "      <td>0.221437</td>\n",
       "      <td>0.275520</td>\n",
       "      <td>1.245100</td>\n",
       "      <td>0.221284</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.095960</td>\n",
       "      <td>0.245937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993192</td>\n",
       "      <td>3.524684</td>\n",
       "      <td>3.634027</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-0.032550</td>\n",
       "      <td>1.256348</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>-0.022374</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>0.982422</td>\n",
       "      <td>1.053613</td>\n",
       "      <td>1.105703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>33.187252</td>\n",
       "      <td>53.744801</td>\n",
       "      <td>0.617497</td>\n",
       "      <td>0.774536</td>\n",
       "      <td>1.358157</td>\n",
       "      <td>0.570284</td>\n",
       "      <td>0.342269</td>\n",
       "      <td>0.189595</td>\n",
       "      <td>1.805263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903270</td>\n",
       "      <td>0.834869</td>\n",
       "      <td>1.575434</td>\n",
       "      <td>8.018182</td>\n",
       "      <td>-0.046865</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>0.615146</td>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>1.280908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.791056</td>\n",
       "      <td>7.212329</td>\n",
       "      <td>1.218893</td>\n",
       "      <td>0.103553</td>\n",
       "      <td>0.084969</td>\n",
       "      <td>1.218713</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>1.253185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.202120</td>\n",
       "      <td>0.181450</td>\n",
       "      <td>1.237624</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.045083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>52.311253</td>\n",
       "      <td>66.598053</td>\n",
       "      <td>0.785477</td>\n",
       "      <td>3.269043</td>\n",
       "      <td>4.162371</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>6.582301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.273723</td>\n",
       "      <td>0.273614</td>\n",
       "      <td>0.426817</td>\n",
       "      <td>-0.134503</td>\n",
       "      <td>1.247106</td>\n",
       "      <td>0.893328</td>\n",
       "      <td>-0.103301</td>\n",
       "      <td>0.827991</td>\n",
       "      <td>0.852250</td>\n",
       "      <td>0.883531</td>\n",
       "      <td>0.972981</td>\n",
       "      <td>1.158377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.877995</td>\n",
       "      <td>46.196896</td>\n",
       "      <td>0.711693</td>\n",
       "      <td>0.388004</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>0.712016</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>0.574693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>0.412462</td>\n",
       "      <td>0.456590</td>\n",
       "      <td>299.286926</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.541161</td>\n",
       "      <td>0.158705</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.158203</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.207676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.163482</td>\n",
       "      <td>20.797432</td>\n",
       "      <td>0.440606</td>\n",
       "      <td>0.404043</td>\n",
       "      <td>0.917130</td>\n",
       "      <td>0.440552</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.060538</td>\n",
       "      <td>0.452929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>1.277488</td>\n",
       "      <td>1.319159</td>\n",
       "      <td>16.657658</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.902832</td>\n",
       "      <td>0.515779</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.583770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.966934</td>\n",
       "      <td>62.618275</td>\n",
       "      <td>0.734082</td>\n",
       "      <td>1.153931</td>\n",
       "      <td>1.579965</td>\n",
       "      <td>0.730353</td>\n",
       "      <td>0.209921</td>\n",
       "      <td>0.237649</td>\n",
       "      <td>0.883324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>0.450313</td>\n",
       "      <td>0.633921</td>\n",
       "      <td>13.569106</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>1.629883</td>\n",
       "      <td>0.473891</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.881714</td>\n",
       "      <td>1.492285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.376526</td>\n",
       "      <td>5.662682</td>\n",
       "      <td>1.655845</td>\n",
       "      <td>0.110416</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>1.658218</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>1.364716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>0.407270</td>\n",
       "      <td>0.396567</td>\n",
       "      <td>1.221198</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.044075</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.397831</td>\n",
       "      <td>76.283791</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>3.086609</td>\n",
       "      <td>4.767734</td>\n",
       "      <td>0.647395</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>12.237870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.544967</td>\n",
       "      <td>0.545467</td>\n",
       "      <td>0.848140</td>\n",
       "      <td>0.040224</td>\n",
       "      <td>2.186612</td>\n",
       "      <td>1.681125</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>1.609587</td>\n",
       "      <td>1.625012</td>\n",
       "      <td>1.661775</td>\n",
       "      <td>1.813412</td>\n",
       "      <td>1.953422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>33.596287</td>\n",
       "      <td>47.076504</td>\n",
       "      <td>0.713653</td>\n",
       "      <td>0.396493</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.713970</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>0.574828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.408431</td>\n",
       "      <td>0.450126</td>\n",
       "      <td>287.507935</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.552765</td>\n",
       "      <td>0.160618</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.331695</td>\n",
       "      <td>25.284454</td>\n",
       "      <td>0.289968</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>1.113093</td>\n",
       "      <td>0.290108</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.098306</td>\n",
       "      <td>0.271452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>2.458431</td>\n",
       "      <td>2.552430</td>\n",
       "      <td>32.361702</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>1.139160</td>\n",
       "      <td>0.792398</td>\n",
       "      <td>0.071805</td>\n",
       "      <td>0.529727</td>\n",
       "      <td>0.700293</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.978301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>39.528179</td>\n",
       "      <td>56.054607</td>\n",
       "      <td>0.705173</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>1.402409</td>\n",
       "      <td>0.693441</td>\n",
       "      <td>0.267403</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.951982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944913</td>\n",
       "      <td>0.575359</td>\n",
       "      <td>1.007315</td>\n",
       "      <td>18.065868</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>1.473145</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>-0.000668</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>1.163086</td>\n",
       "      <td>1.392188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.423832</td>\n",
       "      <td>7.284523</td>\n",
       "      <td>1.293679</td>\n",
       "      <td>0.111039</td>\n",
       "      <td>0.085643</td>\n",
       "      <td>1.296527</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.937994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>0.249481</td>\n",
       "      <td>0.232726</td>\n",
       "      <td>1.471111</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.171387</td>\n",
       "      <td>0.026155</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.055337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>56.244713</td>\n",
       "      <td>76.695351</td>\n",
       "      <td>0.733352</td>\n",
       "      <td>3.514893</td>\n",
       "      <td>4.793457</td>\n",
       "      <td>0.733269</td>\n",
       "      <td>0.053162</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>9.397799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.364031</td>\n",
       "      <td>0.364083</td>\n",
       "      <td>0.504607</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>1.608435</td>\n",
       "      <td>1.278564</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>1.217270</td>\n",
       "      <td>1.231292</td>\n",
       "      <td>1.265685</td>\n",
       "      <td>1.393391</td>\n",
       "      <td>1.484325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>34.101860</td>\n",
       "      <td>48.291222</td>\n",
       "      <td>0.706171</td>\n",
       "      <td>0.402491</td>\n",
       "      <td>0.569678</td>\n",
       "      <td>0.706525</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.422745</td>\n",
       "      <td>0.436344</td>\n",
       "      <td>87.150940</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.563843</td>\n",
       "      <td>0.168954</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.142578</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.728246</td>\n",
       "      <td>28.171011</td>\n",
       "      <td>0.309831</td>\n",
       "      <td>0.384842</td>\n",
       "      <td>1.242149</td>\n",
       "      <td>0.309820</td>\n",
       "      <td>0.026264</td>\n",
       "      <td>0.084122</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>2.234395</td>\n",
       "      <td>2.295405</td>\n",
       "      <td>25.639593</td>\n",
       "      <td>-0.025646</td>\n",
       "      <td>1.233154</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>-0.067910</td>\n",
       "      <td>0.651250</td>\n",
       "      <td>0.802734</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.912988</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.792419</td>\n",
       "      <td>46.897865</td>\n",
       "      <td>0.891137</td>\n",
       "      <td>1.032644</td>\n",
       "      <td>1.182349</td>\n",
       "      <td>0.873383</td>\n",
       "      <td>0.266009</td>\n",
       "      <td>0.184280</td>\n",
       "      <td>1.443500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960473</td>\n",
       "      <td>0.321923</td>\n",
       "      <td>0.506649</td>\n",
       "      <td>11.435643</td>\n",
       "      <td>0.094728</td>\n",
       "      <td>1.172852</td>\n",
       "      <td>0.221990</td>\n",
       "      <td>0.050873</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.905029</td>\n",
       "      <td>1.104297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.488783</td>\n",
       "      <td>7.310069</td>\n",
       "      <td>1.298043</td>\n",
       "      <td>0.111691</td>\n",
       "      <td>0.086062</td>\n",
       "      <td>1.297794</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>1.335782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>0.250837</td>\n",
       "      <td>0.229963</td>\n",
       "      <td>1.378378</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.673882</td>\n",
       "      <td>76.044945</td>\n",
       "      <td>0.666368</td>\n",
       "      <td>3.166626</td>\n",
       "      <td>4.752805</td>\n",
       "      <td>0.666265</td>\n",
       "      <td>0.055802</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>8.428227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.501129</td>\n",
       "      <td>0.501398</td>\n",
       "      <td>0.690929</td>\n",
       "      <td>0.172116</td>\n",
       "      <td>1.943238</td>\n",
       "      <td>1.586179</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>1.530317</td>\n",
       "      <td>1.539507</td>\n",
       "      <td>1.570651</td>\n",
       "      <td>1.661738</td>\n",
       "      <td>1.829590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>34.838112</td>\n",
       "      <td>49.710381</td>\n",
       "      <td>0.700822</td>\n",
       "      <td>0.411179</td>\n",
       "      <td>0.586426</td>\n",
       "      <td>0.701161</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.546113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.433432</td>\n",
       "      <td>0.458498</td>\n",
       "      <td>161.025314</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.177046</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>10.621462</td>\n",
       "      <td>32.936115</td>\n",
       "      <td>0.322487</td>\n",
       "      <td>0.467369</td>\n",
       "      <td>1.450579</td>\n",
       "      <td>0.322195</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.120613</td>\n",
       "      <td>0.362235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993350</td>\n",
       "      <td>2.110694</td>\n",
       "      <td>2.210378</td>\n",
       "      <td>34.619049</td>\n",
       "      <td>0.144624</td>\n",
       "      <td>1.419922</td>\n",
       "      <td>0.984217</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.551191</td>\n",
       "      <td>0.830273</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>1.225508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>38.403057</td>\n",
       "      <td>47.869350</td>\n",
       "      <td>0.802247</td>\n",
       "      <td>0.946365</td>\n",
       "      <td>1.209708</td>\n",
       "      <td>0.782309</td>\n",
       "      <td>0.254058</td>\n",
       "      <td>0.168674</td>\n",
       "      <td>1.506205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956671</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.711866</td>\n",
       "      <td>14.907515</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>1.306641</td>\n",
       "      <td>0.303770</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.959473</td>\n",
       "      <td>1.155273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.154673</td>\n",
       "      <td>5.561210</td>\n",
       "      <td>1.825983</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>1.838875</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.898730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988647</td>\n",
       "      <td>0.465892</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>1.109705</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>0.054975</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>0.083821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.402397</td>\n",
       "      <td>82.002777</td>\n",
       "      <td>0.724395</td>\n",
       "      <td>3.712219</td>\n",
       "      <td>5.125168</td>\n",
       "      <td>0.724312</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>7.696503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.380882</td>\n",
       "      <td>0.380960</td>\n",
       "      <td>0.534119</td>\n",
       "      <td>0.055318</td>\n",
       "      <td>1.785961</td>\n",
       "      <td>1.412949</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>1.361008</td>\n",
       "      <td>1.369412</td>\n",
       "      <td>1.399062</td>\n",
       "      <td>1.494398</td>\n",
       "      <td>1.687996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>35.161789</td>\n",
       "      <td>50.851376</td>\n",
       "      <td>0.691462</td>\n",
       "      <td>0.415019</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>66.506851</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.592651</td>\n",
       "      <td>0.186632</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.954658</td>\n",
       "      <td>25.348925</td>\n",
       "      <td>0.353256</td>\n",
       "      <td>0.394367</td>\n",
       "      <td>1.116485</td>\n",
       "      <td>0.353222</td>\n",
       "      <td>0.032978</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.358190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993002</td>\n",
       "      <td>1.841598</td>\n",
       "      <td>1.952139</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>-0.021749</td>\n",
       "      <td>1.116699</td>\n",
       "      <td>0.724484</td>\n",
       "      <td>-0.010258</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.635840</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.916524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>42.673195</td>\n",
       "      <td>41.494488</td>\n",
       "      <td>1.028406</td>\n",
       "      <td>1.042407</td>\n",
       "      <td>1.007337</td>\n",
       "      <td>1.034815</td>\n",
       "      <td>0.314540</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.965049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913275</td>\n",
       "      <td>0.411610</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>12.960784</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>1.291016</td>\n",
       "      <td>0.322702</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>1.157642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.007144</td>\n",
       "      <td>7.582341</td>\n",
       "      <td>1.187911</td>\n",
       "      <td>0.106024</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>1.189146</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>1.040899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>0.195245</td>\n",
       "      <td>0.164367</td>\n",
       "      <td>1.584906</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.053384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>62.607937</td>\n",
       "      <td>69.010757</td>\n",
       "      <td>0.907220</td>\n",
       "      <td>3.912598</td>\n",
       "      <td>4.313168</td>\n",
       "      <td>0.907129</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>9.018509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.102617</td>\n",
       "      <td>0.202301</td>\n",
       "      <td>-0.019303</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.400570</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.344884</td>\n",
       "      <td>0.353395</td>\n",
       "      <td>0.390495</td>\n",
       "      <td>0.494427</td>\n",
       "      <td>0.701405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>35.825687</td>\n",
       "      <td>51.863037</td>\n",
       "      <td>0.690775</td>\n",
       "      <td>0.422876</td>\n",
       "      <td>0.611889</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>0.526981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>0.453319</td>\n",
       "      <td>0.466282</td>\n",
       "      <td>73.429626</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.190662</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.489024</td>\n",
       "      <td>28.782682</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.504027</td>\n",
       "      <td>1.268909</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.061354</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>0.689369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>1.521227</td>\n",
       "      <td>1.655462</td>\n",
       "      <td>26.803278</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>1.263916</td>\n",
       "      <td>0.767697</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>0.548945</td>\n",
       "      <td>0.681836</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.911035</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>36.703445</td>\n",
       "      <td>51.659477</td>\n",
       "      <td>0.710488</td>\n",
       "      <td>0.911217</td>\n",
       "      <td>1.291001</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.265993</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951792</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.852011</td>\n",
       "      <td>13.660098</td>\n",
       "      <td>-0.025472</td>\n",
       "      <td>1.396973</td>\n",
       "      <td>0.450266</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>1.048462</td>\n",
       "      <td>1.261548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.939654</td>\n",
       "      <td>7.779192</td>\n",
       "      <td>1.277723</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.091431</td>\n",
       "      <td>1.280159</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>1.002010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992180</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>0.221777</td>\n",
       "      <td>1.910638</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.026394</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>78.499130</td>\n",
       "      <td>92.225677</td>\n",
       "      <td>0.851164</td>\n",
       "      <td>4.906006</td>\n",
       "      <td>5.764103</td>\n",
       "      <td>0.851131</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>10.242859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.175124</td>\n",
       "      <td>0.175002</td>\n",
       "      <td>0.263926</td>\n",
       "      <td>-0.010291</td>\n",
       "      <td>1.204165</td>\n",
       "      <td>0.858097</td>\n",
       "      <td>0.058356</td>\n",
       "      <td>0.815276</td>\n",
       "      <td>0.824965</td>\n",
       "      <td>0.856015</td>\n",
       "      <td>0.922965</td>\n",
       "      <td>1.029727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>36.447720</td>\n",
       "      <td>53.549477</td>\n",
       "      <td>0.680636</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.631791</td>\n",
       "      <td>0.680974</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.506673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>0.474578</td>\n",
       "      <td>0.487265</td>\n",
       "      <td>73.057144</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.624268</td>\n",
       "      <td>0.203237</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.718669</td>\n",
       "      <td>36.422890</td>\n",
       "      <td>0.239373</td>\n",
       "      <td>0.382303</td>\n",
       "      <td>1.600676</td>\n",
       "      <td>0.238838</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>0.170018</td>\n",
       "      <td>0.282798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>3.193933</td>\n",
       "      <td>3.426511</td>\n",
       "      <td>34.117950</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>1.697754</td>\n",
       "      <td>1.219758</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>0.674629</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>1.237305</td>\n",
       "      <td>1.426660</td>\n",
       "      <td>1.528652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>32.507000</td>\n",
       "      <td>36.828556</td>\n",
       "      <td>0.882657</td>\n",
       "      <td>0.769394</td>\n",
       "      <td>0.919811</td>\n",
       "      <td>0.836469</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1.611090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.903930</td>\n",
       "      <td>14.661972</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>1.124329</td>\n",
       "      <td>0.298984</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.849976</td>\n",
       "      <td>0.985815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.800538</td>\n",
       "      <td>6.867566</td>\n",
       "      <td>1.281464</td>\n",
       "      <td>0.103454</td>\n",
       "      <td>0.080651</td>\n",
       "      <td>1.282742</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>1.165501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.253847</td>\n",
       "      <td>0.223860</td>\n",
       "      <td>1.354680</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.554260</td>\n",
       "      <td>98.685097</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>4.534424</td>\n",
       "      <td>6.167814</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.044425</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>6.170753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.360342</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>0.463428</td>\n",
       "      <td>-0.063909</td>\n",
       "      <td>1.955085</td>\n",
       "      <td>1.633391</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>1.583734</td>\n",
       "      <td>1.598286</td>\n",
       "      <td>1.633986</td>\n",
       "      <td>1.699435</td>\n",
       "      <td>1.870858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>37.153988</td>\n",
       "      <td>55.376076</td>\n",
       "      <td>0.670939</td>\n",
       "      <td>0.438575</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>0.671269</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.030606</td>\n",
       "      <td>0.498673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.495571</td>\n",
       "      <td>0.511253</td>\n",
       "      <td>90.350426</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.645203</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.165371</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.115090</td>\n",
       "      <td>47.734306</td>\n",
       "      <td>0.149056</td>\n",
       "      <td>0.313553</td>\n",
       "      <td>2.088741</td>\n",
       "      <td>0.150116</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.295770</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>5.724276</td>\n",
       "      <td>5.825323</td>\n",
       "      <td>51.901733</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>2.265869</td>\n",
       "      <td>1.776920</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.399062</td>\n",
       "      <td>1.301172</td>\n",
       "      <td>1.837891</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.140860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.043316</td>\n",
       "      <td>43.275734</td>\n",
       "      <td>0.809768</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>1.084227</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.300994</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>1.439601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>0.483167</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>9.847458</td>\n",
       "      <td>0.050526</td>\n",
       "      <td>1.134766</td>\n",
       "      <td>0.327145</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>1.044531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.160581</td>\n",
       "      <td>6.904369</td>\n",
       "      <td>1.326780</td>\n",
       "      <td>0.107597</td>\n",
       "      <td>0.081167</td>\n",
       "      <td>1.325630</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>1.443225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>0.245112</td>\n",
       "      <td>1.621359</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.073892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>75.652328</td>\n",
       "      <td>128.706833</td>\n",
       "      <td>0.587788</td>\n",
       "      <td>4.728149</td>\n",
       "      <td>8.044176</td>\n",
       "      <td>0.587773</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>7.792107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>0.038708</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>3.316026</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>3.274062</td>\n",
       "      <td>3.288668</td>\n",
       "      <td>3.298522</td>\n",
       "      <td>3.387670</td>\n",
       "      <td>3.451971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>37.708935</td>\n",
       "      <td>56.685688</td>\n",
       "      <td>0.665228</td>\n",
       "      <td>0.445136</td>\n",
       "      <td>0.668839</td>\n",
       "      <td>0.665535</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>0.497328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.508047</td>\n",
       "      <td>0.518542</td>\n",
       "      <td>54.316582</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.659729</td>\n",
       "      <td>0.225288</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.175137</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.248047</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.742046</td>\n",
       "      <td>32.763737</td>\n",
       "      <td>0.205778</td>\n",
       "      <td>0.295794</td>\n",
       "      <td>1.444372</td>\n",
       "      <td>0.204791</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.101958</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>3.871047</td>\n",
       "      <td>4.226618</td>\n",
       "      <td>60.015545</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.149841</td>\n",
       "      <td>0.099979</td>\n",
       "      <td>0.883418</td>\n",
       "      <td>1.064648</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>1.237744</td>\n",
       "      <td>1.301016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>29.981049</td>\n",
       "      <td>38.430950</td>\n",
       "      <td>0.780128</td>\n",
       "      <td>0.686651</td>\n",
       "      <td>0.953880</td>\n",
       "      <td>0.719851</td>\n",
       "      <td>0.337205</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>1.483593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873983</td>\n",
       "      <td>0.634430</td>\n",
       "      <td>1.520104</td>\n",
       "      <td>12.202186</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>1.160309</td>\n",
       "      <td>0.381107</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>1.048486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.295721</td>\n",
       "      <td>7.969981</td>\n",
       "      <td>1.040871</td>\n",
       "      <td>0.097570</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>1.041584</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.965903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990946</td>\n",
       "      <td>0.137616</td>\n",
       "      <td>0.079553</td>\n",
       "      <td>1.872340</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.176270</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.019136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>61.280964</td>\n",
       "      <td>102.592842</td>\n",
       "      <td>0.597322</td>\n",
       "      <td>3.829773</td>\n",
       "      <td>6.412050</td>\n",
       "      <td>0.597277</td>\n",
       "      <td>0.046917</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>8.273088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.674525</td>\n",
       "      <td>0.823806</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>2.896193</td>\n",
       "      <td>2.582277</td>\n",
       "      <td>0.136936</td>\n",
       "      <td>2.538258</td>\n",
       "      <td>2.541200</td>\n",
       "      <td>2.570968</td>\n",
       "      <td>2.644493</td>\n",
       "      <td>2.804333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>38.697121</td>\n",
       "      <td>58.836311</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>0.456815</td>\n",
       "      <td>0.694219</td>\n",
       "      <td>0.658027</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.479692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.525038</td>\n",
       "      <td>0.543178</td>\n",
       "      <td>115.244896</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.689331</td>\n",
       "      <td>0.238976</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.011235</td>\n",
       "      <td>35.228909</td>\n",
       "      <td>0.227405</td>\n",
       "      <td>0.351188</td>\n",
       "      <td>1.553320</td>\n",
       "      <td>0.226089</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>0.105702</td>\n",
       "      <td>0.425028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>3.410647</td>\n",
       "      <td>3.729453</td>\n",
       "      <td>60.825241</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>1.529541</td>\n",
       "      <td>1.203486</td>\n",
       "      <td>0.076847</td>\n",
       "      <td>0.725801</td>\n",
       "      <td>1.131934</td>\n",
       "      <td>1.205078</td>\n",
       "      <td>1.305566</td>\n",
       "      <td>1.431875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>23.515059</td>\n",
       "      <td>45.900337</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>0.551928</td>\n",
       "      <td>1.145307</td>\n",
       "      <td>0.481904</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>0.244770</td>\n",
       "      <td>0.961379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>1.135430</td>\n",
       "      <td>1.877399</td>\n",
       "      <td>9.376812</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>0.624642</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>0.198242</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>1.089844</td>\n",
       "      <td>1.163526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.215260</td>\n",
       "      <td>7.529285</td>\n",
       "      <td>1.356737</td>\n",
       "      <td>0.120324</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>1.360138</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.983629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992116</td>\n",
       "      <td>0.284181</td>\n",
       "      <td>0.267275</td>\n",
       "      <td>1.380567</td>\n",
       "      <td>0.013946</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.017096</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.068032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>81.724022</td>\n",
       "      <td>115.252037</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>5.107544</td>\n",
       "      <td>7.203250</td>\n",
       "      <td>0.709061</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>8.805516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.410436</td>\n",
       "      <td>0.545141</td>\n",
       "      <td>-0.023420</td>\n",
       "      <td>2.538311</td>\n",
       "      <td>2.095706</td>\n",
       "      <td>-0.060634</td>\n",
       "      <td>2.046421</td>\n",
       "      <td>2.061811</td>\n",
       "      <td>2.081560</td>\n",
       "      <td>2.150823</td>\n",
       "      <td>2.299760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>39.805771</td>\n",
       "      <td>60.309048</td>\n",
       "      <td>0.660030</td>\n",
       "      <td>0.469902</td>\n",
       "      <td>0.711620</td>\n",
       "      <td>0.660327</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.490270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.519624</td>\n",
       "      <td>0.539169</td>\n",
       "      <td>122.284210</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.709045</td>\n",
       "      <td>0.243286</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>12.517245</td>\n",
       "      <td>37.646488</td>\n",
       "      <td>0.332494</td>\n",
       "      <td>0.549931</td>\n",
       "      <td>1.656654</td>\n",
       "      <td>0.331953</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.153553</td>\n",
       "      <td>0.390433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988923</td>\n",
       "      <td>2.024096</td>\n",
       "      <td>2.214938</td>\n",
       "      <td>39.608189</td>\n",
       "      <td>-0.094381</td>\n",
       "      <td>1.756836</td>\n",
       "      <td>1.110065</td>\n",
       "      <td>-0.098317</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.879297</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.300781</td>\n",
       "      <td>1.476856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>32.272610</td>\n",
       "      <td>35.608696</td>\n",
       "      <td>0.906313</td>\n",
       "      <td>0.802544</td>\n",
       "      <td>0.886374</td>\n",
       "      <td>0.905423</td>\n",
       "      <td>0.184383</td>\n",
       "      <td>0.199620</td>\n",
       "      <td>0.923668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948857</td>\n",
       "      <td>0.351490</td>\n",
       "      <td>0.522235</td>\n",
       "      <td>14.879700</td>\n",
       "      <td>-0.039399</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>0.206102</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.922681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.227710</td>\n",
       "      <td>6.190627</td>\n",
       "      <td>1.652128</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>0.072577</td>\n",
       "      <td>1.660446</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.945764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.399131</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>65.781540</td>\n",
       "      <td>103.148209</td>\n",
       "      <td>0.637738</td>\n",
       "      <td>4.111206</td>\n",
       "      <td>6.446762</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>6.987781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.568137</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>2.572815</td>\n",
       "      <td>2.335556</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>2.289006</td>\n",
       "      <td>2.307166</td>\n",
       "      <td>2.324615</td>\n",
       "      <td>2.386315</td>\n",
       "      <td>2.463500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>40.384220</td>\n",
       "      <td>61.571194</td>\n",
       "      <td>0.655895</td>\n",
       "      <td>0.476740</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.656223</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.471176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.529138</td>\n",
       "      <td>0.563514</td>\n",
       "      <td>230.145630</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.723419</td>\n",
       "      <td>0.251372</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.200527</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.126939</td>\n",
       "      <td>33.346466</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.358415</td>\n",
       "      <td>1.467971</td>\n",
       "      <td>0.244156</td>\n",
       "      <td>0.023179</td>\n",
       "      <td>0.130038</td>\n",
       "      <td>0.178247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>3.111147</td>\n",
       "      <td>3.176197</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>1.428711</td>\n",
       "      <td>1.111480</td>\n",
       "      <td>-0.017341</td>\n",
       "      <td>0.601738</td>\n",
       "      <td>1.010840</td>\n",
       "      <td>1.130859</td>\n",
       "      <td>1.190332</td>\n",
       "      <td>1.247637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>37.580723</td>\n",
       "      <td>48.322044</td>\n",
       "      <td>0.777714</td>\n",
       "      <td>0.902179</td>\n",
       "      <td>1.196343</td>\n",
       "      <td>0.754114</td>\n",
       "      <td>0.324878</td>\n",
       "      <td>0.298259</td>\n",
       "      <td>1.089246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>0.560993</td>\n",
       "      <td>1.080937</td>\n",
       "      <td>11.131147</td>\n",
       "      <td>-0.043005</td>\n",
       "      <td>1.376953</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>1.131348</td>\n",
       "      <td>1.276367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.311213</td>\n",
       "      <td>7.520018</td>\n",
       "      <td>1.238190</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>1.241025</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.948531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>0.225452</td>\n",
       "      <td>0.199711</td>\n",
       "      <td>1.403756</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.060220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.959496</td>\n",
       "      <td>101.678253</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>4.559570</td>\n",
       "      <td>6.354887</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>9.178478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.394006</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>2.233622</td>\n",
       "      <td>1.795317</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>1.739064</td>\n",
       "      <td>1.757422</td>\n",
       "      <td>1.790122</td>\n",
       "      <td>1.888172</td>\n",
       "      <td>2.087419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>41.616852</td>\n",
       "      <td>63.846737</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>0.491295</td>\n",
       "      <td>0.753357</td>\n",
       "      <td>0.652141</td>\n",
       "      <td>0.015909</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.469553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.538533</td>\n",
       "      <td>0.558187</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.751892</td>\n",
       "      <td>0.263675</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>0.210293</td>\n",
       "      <td>0.237012</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.611343</td>\n",
       "      <td>37.183098</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.422691</td>\n",
       "      <td>1.638337</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.127317</td>\n",
       "      <td>0.329312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>2.878687</td>\n",
       "      <td>3.178475</td>\n",
       "      <td>87.582779</td>\n",
       "      <td>0.056576</td>\n",
       "      <td>1.655762</td>\n",
       "      <td>1.217247</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>0.726074</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.225586</td>\n",
       "      <td>1.322949</td>\n",
       "      <td>1.399531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.930744</td>\n",
       "      <td>36.876457</td>\n",
       "      <td>0.947237</td>\n",
       "      <td>0.849323</td>\n",
       "      <td>0.912941</td>\n",
       "      <td>0.930315</td>\n",
       "      <td>0.270228</td>\n",
       "      <td>0.227754</td>\n",
       "      <td>1.186487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.625477</td>\n",
       "      <td>6.520000</td>\n",
       "      <td>-0.042133</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>-0.040038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.822510</td>\n",
       "      <td>0.978174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.748524</td>\n",
       "      <td>7.695841</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>0.126456</td>\n",
       "      <td>0.090483</td>\n",
       "      <td>1.397565</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>1.295368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.304481</td>\n",
       "      <td>0.283303</td>\n",
       "      <td>1.029851</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.227539</td>\n",
       "      <td>0.036414</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.888145</td>\n",
       "      <td>100.560814</td>\n",
       "      <td>0.595542</td>\n",
       "      <td>3.742798</td>\n",
       "      <td>6.285046</td>\n",
       "      <td>0.595508</td>\n",
       "      <td>0.039760</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>5.273404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.679432</td>\n",
       "      <td>0.804865</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>2.804452</td>\n",
       "      <td>2.542248</td>\n",
       "      <td>0.111989</td>\n",
       "      <td>2.490165</td>\n",
       "      <td>2.503577</td>\n",
       "      <td>2.535627</td>\n",
       "      <td>2.618715</td>\n",
       "      <td>2.694504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>42.831245</td>\n",
       "      <td>66.664520</td>\n",
       "      <td>0.642489</td>\n",
       "      <td>0.505628</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>0.642805</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.035570</td>\n",
       "      <td>0.463301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.560759</td>\n",
       "      <td>0.578697</td>\n",
       "      <td>114.484444</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.786102</td>\n",
       "      <td>0.282584</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.470158</td>\n",
       "      <td>32.872959</td>\n",
       "      <td>0.288084</td>\n",
       "      <td>0.416720</td>\n",
       "      <td>1.447085</td>\n",
       "      <td>0.287972</td>\n",
       "      <td>0.038838</td>\n",
       "      <td>0.128654</td>\n",
       "      <td>0.301876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>2.483415</td>\n",
       "      <td>2.579660</td>\n",
       "      <td>34.108570</td>\n",
       "      <td>-0.058378</td>\n",
       "      <td>1.628906</td>\n",
       "      <td>1.032031</td>\n",
       "      <td>-0.062585</td>\n",
       "      <td>0.580879</td>\n",
       "      <td>0.903613</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>1.219629</td>\n",
       "      <td>1.363066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>24.918390</td>\n",
       "      <td>34.973537</td>\n",
       "      <td>0.712493</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.869858</td>\n",
       "      <td>0.705106</td>\n",
       "      <td>0.167512</td>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.841066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.575936</td>\n",
       "      <td>0.804069</td>\n",
       "      <td>19.296297</td>\n",
       "      <td>-0.008424</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.313290</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.671143</td>\n",
       "      <td>0.873755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.168660</td>\n",
       "      <td>7.409281</td>\n",
       "      <td>1.237456</td>\n",
       "      <td>0.107799</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>1.237447</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>1.238439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990979</td>\n",
       "      <td>0.226719</td>\n",
       "      <td>0.192571</td>\n",
       "      <td>1.757282</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.065591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>100.741928</td>\n",
       "      <td>98.467979</td>\n",
       "      <td>1.023093</td>\n",
       "      <td>6.296143</td>\n",
       "      <td>6.154246</td>\n",
       "      <td>1.023057</td>\n",
       "      <td>0.053555</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>9.993901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.024093</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.076570</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>0.437886</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>-0.060572</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.092114</td>\n",
       "      <td>0.154864</td>\n",
       "      <td>0.187614</td>\n",
       "      <td>0.195273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>43.947289</td>\n",
       "      <td>67.934235</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.518812</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.647256</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>0.452475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.550202</td>\n",
       "      <td>0.566499</td>\n",
       "      <td>106.707314</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.801086</td>\n",
       "      <td>0.284464</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.217461</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.110057</td>\n",
       "      <td>40.890011</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.353097</td>\n",
       "      <td>1.802124</td>\n",
       "      <td>0.195934</td>\n",
       "      <td>0.061525</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>0.459085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>4.062770</td>\n",
       "      <td>4.565912</td>\n",
       "      <td>93.967743</td>\n",
       "      <td>0.060758</td>\n",
       "      <td>1.824951</td>\n",
       "      <td>1.449965</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>0.870840</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>1.455078</td>\n",
       "      <td>1.614013</td>\n",
       "      <td>1.735469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>25.249483</td>\n",
       "      <td>32.930283</td>\n",
       "      <td>0.766756</td>\n",
       "      <td>0.596802</td>\n",
       "      <td>0.801044</td>\n",
       "      <td>0.745031</td>\n",
       "      <td>0.242672</td>\n",
       "      <td>0.253614</td>\n",
       "      <td>0.956855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>0.635460</td>\n",
       "      <td>0.966599</td>\n",
       "      <td>8.742222</td>\n",
       "      <td>-0.021787</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.333666</td>\n",
       "      <td>-0.004649</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.758789</td>\n",
       "      <td>0.898676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.544826</td>\n",
       "      <td>7.688483</td>\n",
       "      <td>1.241445</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.090386</td>\n",
       "      <td>1.240623</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>1.325586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0.232005</td>\n",
       "      <td>0.194837</td>\n",
       "      <td>1.655462</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>0.068521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>71.458214</td>\n",
       "      <td>49.634304</td>\n",
       "      <td>1.439694</td>\n",
       "      <td>4.465942</td>\n",
       "      <td>3.102138</td>\n",
       "      <td>1.439634</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>6.876036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.305513</td>\n",
       "      <td>0.305316</td>\n",
       "      <td>0.320475</td>\n",
       "      <td>-0.010523</td>\n",
       "      <td>1.442139</td>\n",
       "      <td>1.363804</td>\n",
       "      <td>-0.018369</td>\n",
       "      <td>1.222820</td>\n",
       "      <td>1.278892</td>\n",
       "      <td>1.366892</td>\n",
       "      <td>1.402942</td>\n",
       "      <td>1.410501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>45.374569</td>\n",
       "      <td>70.578873</td>\n",
       "      <td>0.642892</td>\n",
       "      <td>0.535663</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>0.643331</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.040710</td>\n",
       "      <td>0.420680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.560207</td>\n",
       "      <td>0.592579</td>\n",
       "      <td>223.780487</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.839996</td>\n",
       "      <td>0.298991</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.315055</td>\n",
       "      <td>43.304157</td>\n",
       "      <td>0.168923</td>\n",
       "      <td>0.315494</td>\n",
       "      <td>1.907967</td>\n",
       "      <td>0.165356</td>\n",
       "      <td>0.070538</td>\n",
       "      <td>0.149193</td>\n",
       "      <td>0.472793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972362</td>\n",
       "      <td>4.953011</td>\n",
       "      <td>5.731565</td>\n",
       "      <td>52.698631</td>\n",
       "      <td>-0.033712</td>\n",
       "      <td>1.899414</td>\n",
       "      <td>1.594395</td>\n",
       "      <td>-0.061291</td>\n",
       "      <td>1.176152</td>\n",
       "      <td>1.445312</td>\n",
       "      <td>1.597656</td>\n",
       "      <td>1.803174</td>\n",
       "      <td>1.869033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>20.395445</td>\n",
       "      <td>38.993725</td>\n",
       "      <td>0.523044</td>\n",
       "      <td>0.461432</td>\n",
       "      <td>0.971314</td>\n",
       "      <td>0.475060</td>\n",
       "      <td>0.240618</td>\n",
       "      <td>0.215558</td>\n",
       "      <td>1.116256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861877</td>\n",
       "      <td>1.166055</td>\n",
       "      <td>2.159798</td>\n",
       "      <td>10.807487</td>\n",
       "      <td>-0.037435</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>0.543181</td>\n",
       "      <td>-0.057100</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.944092</td>\n",
       "      <td>1.021484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.346161</td>\n",
       "      <td>8.306944</td>\n",
       "      <td>1.125102</td>\n",
       "      <td>0.109936</td>\n",
       "      <td>0.097532</td>\n",
       "      <td>1.127175</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.936658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990058</td>\n",
       "      <td>0.173313</td>\n",
       "      <td>0.131827</td>\n",
       "      <td>1.423645</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>75.489738</td>\n",
       "      <td>43.398766</td>\n",
       "      <td>1.739444</td>\n",
       "      <td>4.717896</td>\n",
       "      <td>2.712412</td>\n",
       "      <td>1.739372</td>\n",
       "      <td>0.044829</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>5.947058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.425168</td>\n",
       "      <td>0.425027</td>\n",
       "      <td>0.437876</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>2.079911</td>\n",
       "      <td>2.005483</td>\n",
       "      <td>0.069906</td>\n",
       "      <td>1.745152</td>\n",
       "      <td>1.944964</td>\n",
       "      <td>2.005864</td>\n",
       "      <td>2.042114</td>\n",
       "      <td>2.055563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>46.954895</td>\n",
       "      <td>72.460052</td>\n",
       "      <td>0.648011</td>\n",
       "      <td>0.554308</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.648659</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.047314</td>\n",
       "      <td>0.381947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.548982</td>\n",
       "      <td>0.589416</td>\n",
       "      <td>286.030304</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.864166</td>\n",
       "      <td>0.302922</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.205742</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.712090</td>\n",
       "      <td>35.579922</td>\n",
       "      <td>0.244860</td>\n",
       "      <td>0.382761</td>\n",
       "      <td>1.567657</td>\n",
       "      <td>0.244161</td>\n",
       "      <td>0.041680</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>3.095836</td>\n",
       "      <td>3.300892</td>\n",
       "      <td>38.135136</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>1.507324</td>\n",
       "      <td>1.185812</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>0.794922</td>\n",
       "      <td>1.060547</td>\n",
       "      <td>1.181641</td>\n",
       "      <td>1.345508</td>\n",
       "      <td>1.435244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>26.489454</td>\n",
       "      <td>33.930782</td>\n",
       "      <td>0.780691</td>\n",
       "      <td>0.623040</td>\n",
       "      <td>0.826527</td>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.262014</td>\n",
       "      <td>0.257674</td>\n",
       "      <td>1.016844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.637991</td>\n",
       "      <td>1.015950</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>-0.070283</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.346962</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.290039</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.952783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.111650</td>\n",
       "      <td>5.735451</td>\n",
       "      <td>1.588655</td>\n",
       "      <td>0.107061</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>1.593023</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>1.287539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>0.392105</td>\n",
       "      <td>0.370166</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.040192</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>73.364540</td>\n",
       "      <td>38.575268</td>\n",
       "      <td>1.901854</td>\n",
       "      <td>4.584961</td>\n",
       "      <td>2.410940</td>\n",
       "      <td>1.901732</td>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>6.482912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.474286</td>\n",
       "      <td>0.474084</td>\n",
       "      <td>0.486030</td>\n",
       "      <td>-0.074846</td>\n",
       "      <td>2.247890</td>\n",
       "      <td>2.174021</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>1.922179</td>\n",
       "      <td>2.093942</td>\n",
       "      <td>2.180643</td>\n",
       "      <td>2.223292</td>\n",
       "      <td>2.241890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>48.476753</td>\n",
       "      <td>71.995995</td>\n",
       "      <td>0.673326</td>\n",
       "      <td>0.572268</td>\n",
       "      <td>0.848505</td>\n",
       "      <td>0.674443</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997274</td>\n",
       "      <td>0.493440</td>\n",
       "      <td>0.512047</td>\n",
       "      <td>146.134018</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.279695</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.402333</td>\n",
       "      <td>35.996288</td>\n",
       "      <td>0.261203</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>1.578283</td>\n",
       "      <td>0.251944</td>\n",
       "      <td>0.120610</td>\n",
       "      <td>0.199375</td>\n",
       "      <td>0.604943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948076</td>\n",
       "      <td>2.897871</td>\n",
       "      <td>3.862682</td>\n",
       "      <td>69.468086</td>\n",
       "      <td>-0.036480</td>\n",
       "      <td>1.689453</td>\n",
       "      <td>1.184997</td>\n",
       "      <td>-0.024219</td>\n",
       "      <td>0.420332</td>\n",
       "      <td>0.814160</td>\n",
       "      <td>1.184570</td>\n",
       "      <td>1.494385</td>\n",
       "      <td>1.565547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>19.423687</td>\n",
       "      <td>41.781937</td>\n",
       "      <td>0.464882</td>\n",
       "      <td>0.452640</td>\n",
       "      <td>1.000939</td>\n",
       "      <td>0.452216</td>\n",
       "      <td>0.201845</td>\n",
       "      <td>0.366966</td>\n",
       "      <td>0.550038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>1.395874</td>\n",
       "      <td>2.364907</td>\n",
       "      <td>14.587629</td>\n",
       "      <td>-0.017237</td>\n",
       "      <td>1.425781</td>\n",
       "      <td>0.614956</td>\n",
       "      <td>-0.027108</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>1.151611</td>\n",
       "      <td>1.248047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.886652</td>\n",
       "      <td>6.214496</td>\n",
       "      <td>1.429988</td>\n",
       "      <td>0.104353</td>\n",
       "      <td>0.072141</td>\n",
       "      <td>1.446505</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.834777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977215</td>\n",
       "      <td>0.349691</td>\n",
       "      <td>0.315246</td>\n",
       "      <td>1.020100</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.180908</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>63.740585</td>\n",
       "      <td>37.870277</td>\n",
       "      <td>1.683130</td>\n",
       "      <td>3.983276</td>\n",
       "      <td>2.366880</td>\n",
       "      <td>1.682922</td>\n",
       "      <td>0.063759</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>8.493230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.406058</td>\n",
       "      <td>0.405635</td>\n",
       "      <td>0.418068</td>\n",
       "      <td>0.074904</td>\n",
       "      <td>1.685338</td>\n",
       "      <td>1.616396</td>\n",
       "      <td>0.033294</td>\n",
       "      <td>1.339604</td>\n",
       "      <td>1.502433</td>\n",
       "      <td>1.627490</td>\n",
       "      <td>1.669389</td>\n",
       "      <td>1.677698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>50.561478</td>\n",
       "      <td>69.906929</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.823406</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.394457</td>\n",
       "      <td>0.402549</td>\n",
       "      <td>81.120483</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.821899</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.999374</td>\n",
       "      <td>38.314774</td>\n",
       "      <td>0.234880</td>\n",
       "      <td>0.387518</td>\n",
       "      <td>1.659230</td>\n",
       "      <td>0.233553</td>\n",
       "      <td>0.089502</td>\n",
       "      <td>0.337913</td>\n",
       "      <td>0.264867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952422</td>\n",
       "      <td>3.319094</td>\n",
       "      <td>4.482933</td>\n",
       "      <td>220.176468</td>\n",
       "      <td>-0.051873</td>\n",
       "      <td>1.873291</td>\n",
       "      <td>1.287091</td>\n",
       "      <td>-0.025912</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.455567</td>\n",
       "      <td>1.337891</td>\n",
       "      <td>1.613915</td>\n",
       "      <td>1.713438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>15.078004</td>\n",
       "      <td>29.374578</td>\n",
       "      <td>0.513301</td>\n",
       "      <td>0.340074</td>\n",
       "      <td>0.678578</td>\n",
       "      <td>0.501156</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>0.318267</td>\n",
       "      <td>0.565230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>1.289036</td>\n",
       "      <td>1.963430</td>\n",
       "      <td>16.846153</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>1.390137</td>\n",
       "      <td>0.404566</td>\n",
       "      <td>0.021095</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.358398</td>\n",
       "      <td>0.926270</td>\n",
       "      <td>1.139648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>11.322188</td>\n",
       "      <td>8.784041</td>\n",
       "      <td>1.288950</td>\n",
       "      <td>0.133168</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>1.297055</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.820073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>0.269433</td>\n",
       "      <td>0.238618</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.235840</td>\n",
       "      <td>0.032437</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.812157</td>\n",
       "      <td>35.747231</td>\n",
       "      <td>1.673197</td>\n",
       "      <td>3.737732</td>\n",
       "      <td>2.234153</td>\n",
       "      <td>1.672998</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>4.231378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.402591</td>\n",
       "      <td>0.402085</td>\n",
       "      <td>0.461674</td>\n",
       "      <td>-0.040055</td>\n",
       "      <td>1.738490</td>\n",
       "      <td>1.503579</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>1.215207</td>\n",
       "      <td>1.413174</td>\n",
       "      <td>1.519079</td>\n",
       "      <td>1.551329</td>\n",
       "      <td>1.562970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>53.454762</td>\n",
       "      <td>59.229683</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.630971</td>\n",
       "      <td>0.695732</td>\n",
       "      <td>0.906917</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.307945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993864</td>\n",
       "      <td>0.158960</td>\n",
       "      <td>0.174163</td>\n",
       "      <td>268.473694</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.700516</td>\n",
       "      <td>0.084888</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.440676</td>\n",
       "      <td>41.729496</td>\n",
       "      <td>0.226235</td>\n",
       "      <td>0.414216</td>\n",
       "      <td>1.828960</td>\n",
       "      <td>0.226476</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.211326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>3.440193</td>\n",
       "      <td>3.584890</td>\n",
       "      <td>34.111111</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>1.966309</td>\n",
       "      <td>1.416369</td>\n",
       "      <td>0.029226</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>1.214746</td>\n",
       "      <td>1.443359</td>\n",
       "      <td>1.631738</td>\n",
       "      <td>1.770410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>19.711937</td>\n",
       "      <td>36.543213</td>\n",
       "      <td>0.539414</td>\n",
       "      <td>0.480752</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.147805</td>\n",
       "      <td>0.295889</td>\n",
       "      <td>0.499527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>1.033867</td>\n",
       "      <td>1.288793</td>\n",
       "      <td>16.386667</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>1.200195</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.842529</td>\n",
       "      <td>0.971289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.121619</td>\n",
       "      <td>5.163881</td>\n",
       "      <td>1.766427</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>1.789316</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.856086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.439555</td>\n",
       "      <td>1.000123</td>\n",
       "      <td>-0.006742</td>\n",
       "      <td>0.204346</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.962166</td>\n",
       "      <td>56.208115</td>\n",
       "      <td>1.155744</td>\n",
       "      <td>4.059692</td>\n",
       "      <td>3.512983</td>\n",
       "      <td>1.155625</td>\n",
       "      <td>0.059959</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>4.628320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.135434</td>\n",
       "      <td>0.134477</td>\n",
       "      <td>0.158780</td>\n",
       "      <td>0.183239</td>\n",
       "      <td>0.654969</td>\n",
       "      <td>0.546709</td>\n",
       "      <td>0.107217</td>\n",
       "      <td>0.306801</td>\n",
       "      <td>0.436898</td>\n",
       "      <td>0.553572</td>\n",
       "      <td>0.606183</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>55.236790</td>\n",
       "      <td>35.182590</td>\n",
       "      <td>1.570004</td>\n",
       "      <td>0.651910</td>\n",
       "      <td>0.409948</td>\n",
       "      <td>1.590227</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.380428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>49.218979</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.678223</td>\n",
       "      <td>0.242459</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.628647</td>\n",
       "      <td>33.892223</td>\n",
       "      <td>0.343107</td>\n",
       "      <td>0.511723</td>\n",
       "      <td>1.465570</td>\n",
       "      <td>0.349163</td>\n",
       "      <td>0.047457</td>\n",
       "      <td>0.309232</td>\n",
       "      <td>0.153468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>1.951129</td>\n",
       "      <td>1.937069</td>\n",
       "      <td>14.300971</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>1.035156</td>\n",
       "      <td>1.196191</td>\n",
       "      <td>1.436006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>26.197701</td>\n",
       "      <td>28.950804</td>\n",
       "      <td>0.904904</td>\n",
       "      <td>0.617749</td>\n",
       "      <td>0.643727</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>0.255360</td>\n",
       "      <td>0.362334</td>\n",
       "      <td>0.704765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803287</td>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.897578</td>\n",
       "      <td>12.477477</td>\n",
       "      <td>-0.010974</td>\n",
       "      <td>1.550781</td>\n",
       "      <td>0.362517</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.819580</td>\n",
       "      <td>1.065919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer                                               key    shape   numel  \\\n",
       "0        0             model.layers.0.input_layernorm.weight  (7168,)  7168.0   \n",
       "4        0    model.layers.0.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "5        0    model.layers.0.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "9        0     model.layers.0.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "12       1             model.layers.1.input_layernorm.weight  (7168,)  7168.0   \n",
       "16       1    model.layers.1.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "17       1    model.layers.1.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "21       1     model.layers.1.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "24       2             model.layers.2.input_layernorm.weight  (7168,)  7168.0   \n",
       "28       2    model.layers.2.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "29       2    model.layers.2.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "33       2     model.layers.2.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "36       3             model.layers.3.input_layernorm.weight  (7168,)  7168.0   \n",
       "37       3   model.layers.3.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "42       3    model.layers.3.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "43       3    model.layers.3.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "47       3     model.layers.3.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "50       4             model.layers.4.input_layernorm.weight  (7168,)  7168.0   \n",
       "51       4   model.layers.4.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "56       4    model.layers.4.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "57       4    model.layers.4.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "61       4     model.layers.4.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "64       5             model.layers.5.input_layernorm.weight  (7168,)  7168.0   \n",
       "65       5   model.layers.5.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "70       5    model.layers.5.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "71       5    model.layers.5.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "75       5     model.layers.5.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "78       6             model.layers.6.input_layernorm.weight  (7168,)  7168.0   \n",
       "79       6   model.layers.6.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "84       6    model.layers.6.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "85       6    model.layers.6.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "89       6     model.layers.6.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "92       7             model.layers.7.input_layernorm.weight  (7168,)  7168.0   \n",
       "93       7   model.layers.7.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "98       7    model.layers.7.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "99       7    model.layers.7.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "103      7     model.layers.7.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "106      8             model.layers.8.input_layernorm.weight  (7168,)  7168.0   \n",
       "107      8   model.layers.8.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "112      8    model.layers.8.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "113      8    model.layers.8.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "117      8     model.layers.8.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "120      9             model.layers.9.input_layernorm.weight  (7168,)  7168.0   \n",
       "121      9   model.layers.9.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "126      9    model.layers.9.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "127      9    model.layers.9.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "131      9     model.layers.9.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "134     10            model.layers.10.input_layernorm.weight  (7168,)  7168.0   \n",
       "135     10  model.layers.10.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "140     10   model.layers.10.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "141     10   model.layers.10.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "145     10    model.layers.10.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "148     11            model.layers.11.input_layernorm.weight  (7168,)  7168.0   \n",
       "149     11  model.layers.11.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "154     11   model.layers.11.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "155     11   model.layers.11.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "159     11    model.layers.11.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "162     12            model.layers.12.input_layernorm.weight  (7168,)  7168.0   \n",
       "163     12  model.layers.12.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "168     12   model.layers.12.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "169     12   model.layers.12.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "173     12    model.layers.12.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "176     13            model.layers.13.input_layernorm.weight  (7168,)  7168.0   \n",
       "177     13  model.layers.13.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "182     13   model.layers.13.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "183     13   model.layers.13.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "187     13    model.layers.13.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "190     14            model.layers.14.input_layernorm.weight  (7168,)  7168.0   \n",
       "191     14  model.layers.14.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "196     14   model.layers.14.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "197     14   model.layers.14.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "201     14    model.layers.14.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "204     15            model.layers.15.input_layernorm.weight  (7168,)  7168.0   \n",
       "205     15  model.layers.15.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "210     15   model.layers.15.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "211     15   model.layers.15.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "215     15    model.layers.15.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "218     16            model.layers.16.input_layernorm.weight  (7168,)  7168.0   \n",
       "219     16  model.layers.16.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "224     16   model.layers.16.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "225     16   model.layers.16.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "229     16    model.layers.16.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "232     17            model.layers.17.input_layernorm.weight  (7168,)  7168.0   \n",
       "233     17  model.layers.17.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "238     17   model.layers.17.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "239     17   model.layers.17.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "243     17    model.layers.17.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "246     18            model.layers.18.input_layernorm.weight  (7168,)  7168.0   \n",
       "247     18  model.layers.18.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "252     18   model.layers.18.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "253     18   model.layers.18.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "257     18    model.layers.18.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "260     19            model.layers.19.input_layernorm.weight  (7168,)  7168.0   \n",
       "261     19  model.layers.19.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "266     19   model.layers.19.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "267     19   model.layers.19.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "271     19    model.layers.19.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "274     20            model.layers.20.input_layernorm.weight  (7168,)  7168.0   \n",
       "275     20  model.layers.20.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "280     20   model.layers.20.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "281     20   model.layers.20.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "285     20    model.layers.20.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "288     21            model.layers.21.input_layernorm.weight  (7168,)  7168.0   \n",
       "289     21  model.layers.21.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "294     21   model.layers.21.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "295     21   model.layers.21.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "299     21    model.layers.21.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "302     22            model.layers.22.input_layernorm.weight  (7168,)  7168.0   \n",
       "303     22  model.layers.22.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "308     22   model.layers.22.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "309     22   model.layers.22.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "313     22    model.layers.22.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "316     23            model.layers.23.input_layernorm.weight  (7168,)  7168.0   \n",
       "317     23  model.layers.23.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "322     23   model.layers.23.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "323     23   model.layers.23.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "327     23    model.layers.23.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "330     24            model.layers.24.input_layernorm.weight  (7168,)  7168.0   \n",
       "331     24  model.layers.24.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "336     24   model.layers.24.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "337     24   model.layers.24.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "341     24    model.layers.24.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "344     25            model.layers.25.input_layernorm.weight  (7168,)  7168.0   \n",
       "345     25  model.layers.25.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "350     25   model.layers.25.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "351     25   model.layers.25.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "355     25    model.layers.25.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "358     26            model.layers.26.input_layernorm.weight  (7168,)  7168.0   \n",
       "359     26  model.layers.26.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "364     26   model.layers.26.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "365     26   model.layers.26.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "369     26    model.layers.26.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "372     27            model.layers.27.input_layernorm.weight  (7168,)  7168.0   \n",
       "373     27  model.layers.27.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "378     27   model.layers.27.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "379     27   model.layers.27.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "383     27    model.layers.27.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "386     28            model.layers.28.input_layernorm.weight  (7168,)  7168.0   \n",
       "387     28  model.layers.28.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "392     28   model.layers.28.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "393     28   model.layers.28.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "397     28    model.layers.28.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "400     29            model.layers.29.input_layernorm.weight  (7168,)  7168.0   \n",
       "401     29  model.layers.29.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "406     29   model.layers.29.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "407     29   model.layers.29.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "411     29    model.layers.29.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "414     30            model.layers.30.input_layernorm.weight  (7168,)  7168.0   \n",
       "415     30  model.layers.30.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "420     30   model.layers.30.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "421     30   model.layers.30.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "425     30    model.layers.30.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "428     31            model.layers.31.input_layernorm.weight  (7168,)  7168.0   \n",
       "429     31  model.layers.31.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "434     31   model.layers.31.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "435     31   model.layers.31.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "439     31    model.layers.31.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "442     32            model.layers.32.input_layernorm.weight  (7168,)  7168.0   \n",
       "443     32  model.layers.32.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "448     32   model.layers.32.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "449     32   model.layers.32.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "453     32    model.layers.32.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "456     33            model.layers.33.input_layernorm.weight  (7168,)  7168.0   \n",
       "457     33  model.layers.33.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "462     33   model.layers.33.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "463     33   model.layers.33.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "467     33    model.layers.33.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "470     34            model.layers.34.input_layernorm.weight  (7168,)  7168.0   \n",
       "471     34  model.layers.34.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "476     34   model.layers.34.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "477     34   model.layers.34.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "481     34    model.layers.34.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "484     35            model.layers.35.input_layernorm.weight  (7168,)  7168.0   \n",
       "485     35  model.layers.35.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "490     35   model.layers.35.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "491     35   model.layers.35.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "495     35    model.layers.35.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "498     36            model.layers.36.input_layernorm.weight  (7168,)  7168.0   \n",
       "499     36  model.layers.36.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "504     36   model.layers.36.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "505     36   model.layers.36.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "509     36    model.layers.36.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "512     37            model.layers.37.input_layernorm.weight  (7168,)  7168.0   \n",
       "513     37  model.layers.37.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "518     37   model.layers.37.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "519     37   model.layers.37.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "523     37    model.layers.37.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "526     38            model.layers.38.input_layernorm.weight  (7168,)  7168.0   \n",
       "527     38  model.layers.38.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "532     38   model.layers.38.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "533     38   model.layers.38.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "537     38    model.layers.38.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "540     39            model.layers.39.input_layernorm.weight  (7168,)  7168.0   \n",
       "541     39  model.layers.39.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "546     39   model.layers.39.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "547     39   model.layers.39.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "551     39    model.layers.39.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "554     40            model.layers.40.input_layernorm.weight  (7168,)  7168.0   \n",
       "555     40  model.layers.40.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "560     40   model.layers.40.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "561     40   model.layers.40.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "565     40    model.layers.40.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "568     41            model.layers.41.input_layernorm.weight  (7168,)  7168.0   \n",
       "569     41  model.layers.41.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "574     41   model.layers.41.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "575     41   model.layers.41.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "579     41    model.layers.41.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "582     42            model.layers.42.input_layernorm.weight  (7168,)  7168.0   \n",
       "583     42  model.layers.42.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "588     42   model.layers.42.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "589     42   model.layers.42.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "593     42    model.layers.42.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "596     43            model.layers.43.input_layernorm.weight  (7168,)  7168.0   \n",
       "597     43  model.layers.43.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "602     43   model.layers.43.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "603     43   model.layers.43.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "607     43    model.layers.43.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "610     44            model.layers.44.input_layernorm.weight  (7168,)  7168.0   \n",
       "611     44  model.layers.44.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "616     44   model.layers.44.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "617     44   model.layers.44.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "621     44    model.layers.44.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "624     45            model.layers.45.input_layernorm.weight  (7168,)  7168.0   \n",
       "625     45  model.layers.45.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "630     45   model.layers.45.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "631     45   model.layers.45.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "635     45    model.layers.45.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "638     46            model.layers.46.input_layernorm.weight  (7168,)  7168.0   \n",
       "639     46  model.layers.46.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "644     46   model.layers.46.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "645     46   model.layers.46.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "649     46    model.layers.46.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "652     47            model.layers.47.input_layernorm.weight  (7168,)  7168.0   \n",
       "653     47  model.layers.47.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "658     47   model.layers.47.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "659     47   model.layers.47.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "663     47    model.layers.47.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "666     48            model.layers.48.input_layernorm.weight  (7168,)  7168.0   \n",
       "667     48  model.layers.48.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "672     48   model.layers.48.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "673     48   model.layers.48.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "677     48    model.layers.48.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "680     49            model.layers.49.input_layernorm.weight  (7168,)  7168.0   \n",
       "681     49  model.layers.49.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "686     49   model.layers.49.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "687     49   model.layers.49.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "691     49    model.layers.49.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "694     50            model.layers.50.input_layernorm.weight  (7168,)  7168.0   \n",
       "695     50  model.layers.50.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "700     50   model.layers.50.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "701     50   model.layers.50.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "705     50    model.layers.50.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "708     51            model.layers.51.input_layernorm.weight  (7168,)  7168.0   \n",
       "709     51  model.layers.51.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "714     51   model.layers.51.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "715     51   model.layers.51.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "719     51    model.layers.51.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "722     52            model.layers.52.input_layernorm.weight  (7168,)  7168.0   \n",
       "723     52  model.layers.52.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "728     52   model.layers.52.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "729     52   model.layers.52.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "733     52    model.layers.52.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "736     53            model.layers.53.input_layernorm.weight  (7168,)  7168.0   \n",
       "737     53  model.layers.53.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "742     53   model.layers.53.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "743     53   model.layers.53.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "747     53    model.layers.53.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "750     54            model.layers.54.input_layernorm.weight  (7168,)  7168.0   \n",
       "751     54  model.layers.54.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "756     54   model.layers.54.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "757     54   model.layers.54.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "761     54    model.layers.54.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "764     55            model.layers.55.input_layernorm.weight  (7168,)  7168.0   \n",
       "765     55  model.layers.55.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "770     55   model.layers.55.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "771     55   model.layers.55.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "775     55    model.layers.55.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "778     56            model.layers.56.input_layernorm.weight  (7168,)  7168.0   \n",
       "779     56  model.layers.56.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "784     56   model.layers.56.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "785     56   model.layers.56.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "789     56    model.layers.56.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "792     57            model.layers.57.input_layernorm.weight  (7168,)  7168.0   \n",
       "793     57  model.layers.57.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "798     57   model.layers.57.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "799     57   model.layers.57.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "803     57    model.layers.57.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "806     58            model.layers.58.input_layernorm.weight  (7168,)  7168.0   \n",
       "807     58  model.layers.58.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "812     58   model.layers.58.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "813     58   model.layers.58.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "817     58    model.layers.58.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "820     59            model.layers.59.input_layernorm.weight  (7168,)  7168.0   \n",
       "821     59  model.layers.59.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "826     59   model.layers.59.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "827     59   model.layers.59.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "831     59    model.layers.59.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "834     60            model.layers.60.input_layernorm.weight  (7168,)  7168.0   \n",
       "835     60  model.layers.60.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "840     60   model.layers.60.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "841     60   model.layers.60.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "845     60    model.layers.60.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "\n",
       "         norm_a      norm_b  norm_ratio    mean_a    mean_b  mean_ratio  \\\n",
       "0      5.333566    3.708255    1.438295  0.058730  0.041479    1.415882   \n",
       "4      1.600154    1.976582    0.809556  0.016732  0.016968    0.986042   \n",
       "5      0.152460    0.231502    0.658569  0.005553  0.006916    0.802899   \n",
       "9      8.237963   17.689760    0.465691  0.193372  0.443633    0.435884   \n",
       "12     4.966424    4.025096    1.233865  0.053581  0.044444    1.205580   \n",
       "16     4.805261    5.418404    0.886841  0.045868  0.048390    0.947874   \n",
       "17     0.091417    0.262622    0.348093  0.002844  0.008173    0.348004   \n",
       "21     5.265309   17.526243    0.300424  0.116436  0.419999    0.277228   \n",
       "24     6.698238    5.042212    1.328432  0.074627  0.056358    1.324173   \n",
       "28     5.107561    3.691749    1.383507  0.053593  0.039059    1.372092   \n",
       "29     0.076628    0.277005    0.276632  0.002461  0.009435    0.260855   \n",
       "33     6.045459   18.126390    0.333517  0.147995  0.432889    0.341879   \n",
       "36     8.191147    4.541937    1.803448  0.092289  0.052340    1.763250   \n",
       "37   100.150665   79.248253    1.263759  6.259399  4.953015    1.263755   \n",
       "42     7.430301   10.335238    0.718929  0.080654  0.110154    0.732189   \n",
       "43     0.347525    0.416599    0.834195  0.009611  0.015846    0.606496   \n",
       "47    13.885664   19.065044    0.728331  0.345856  0.456453    0.757705   \n",
       "50     6.282731    3.886504    1.616551  0.071074  0.043553    1.631882   \n",
       "51    94.486427  105.370796    0.896704  5.905396  6.585674    0.896703   \n",
       "56    10.501461   10.436382    1.006236  0.118008  0.108037    1.092297   \n",
       "57     0.145010    1.085993    0.133528  0.005741  0.042525    0.135009   \n",
       "61     8.648572   38.966732    0.221948  0.213636  0.968635    0.220554   \n",
       "64     8.362890    5.834433    1.433368  0.095684  0.066838    1.431584   \n",
       "65   114.025658  120.610062    0.945408  7.126587  7.538128    0.945405   \n",
       "70    11.926690   12.219624    0.976028  0.135137  0.129416    1.044210   \n",
       "71     0.164448    0.613759    0.267936  0.006962  0.026778    0.259980   \n",
       "75    12.083183   29.750238    0.406154  0.297168  0.715038    0.415598   \n",
       "78     7.117170    5.769558    1.233573  0.081482  0.067094    1.214450   \n",
       "79   118.371513   95.961823    1.233527  7.398193  5.997613    1.233523   \n",
       "84    12.566309   13.817199    0.909469  0.143635  0.154706    0.928440   \n",
       "85     0.135344    0.454429    0.297833  0.005504  0.019942    0.275999   \n",
       "89     8.600546   28.650684    0.300186  0.207385  0.687798    0.301520   \n",
       "92     7.519102    5.417134    1.388022  0.087011  0.062993    1.381284   \n",
       "93   106.918343   87.724533    1.218796  6.682373  5.482783    1.218792   \n",
       "98    14.079303   14.198127    0.991631  0.163313  0.160756    1.015910   \n",
       "99     0.426888    0.779261    0.547811  0.018428  0.034266    0.537793   \n",
       "103   13.775208   36.266392    0.379834  0.334484  0.863280    0.387457   \n",
       "106    9.110951    5.380949    1.693187  0.106022  0.062231    1.703697   \n",
       "107   98.215782   86.622200    1.133841  6.138428  5.413887    1.133830   \n",
       "112   15.492817   15.785369    0.981467  0.180642  0.181526    0.995132   \n",
       "113    0.265736    0.534529    0.497139  0.011651  0.023012    0.506322   \n",
       "117   15.508194   24.044184    0.644987  0.380821  0.541633    0.703098   \n",
       "120    8.394691    3.145885    2.668467  0.097636  0.036808    2.652601   \n",
       "121   89.670647   77.074051    1.163435  5.604370  4.817127    1.163426   \n",
       "126   17.782528   16.459641    1.080372  0.208091  0.190776    1.090763   \n",
       "127    0.286094    2.375535    0.120433  0.012511  0.104601    0.119603   \n",
       "131   12.147147   58.573437    0.207383  0.291249  1.428330    0.203909   \n",
       "134    8.541730    3.601893    2.371456  0.099587  0.042321    2.353147   \n",
       "135   78.372345   64.967072    1.206339  4.898193  4.060442    1.206320   \n",
       "140   19.708843   17.559284    1.122417  0.231204  0.204769    1.129095   \n",
       "141    0.359084    1.876313    0.191378  0.015736  0.082707    0.190269   \n",
       "145   14.437043   61.101032    0.236281  0.350926  1.483577    0.236541   \n",
       "148    9.118999    2.988442    3.051423  0.106996  0.034930    3.063137   \n",
       "149   72.608574   60.910301    1.192057  4.537964  3.806892    1.192039   \n",
       "154   20.472179   18.495205    1.106891  0.240605  0.216203    1.112866   \n",
       "155    0.786310    2.485416    0.316369  0.034600  0.109573    0.315769   \n",
       "159   22.092937   53.990604    0.409200  0.538747  1.274603    0.422678   \n",
       "162    9.310952    5.036315    1.848763  0.109255  0.059196    1.845658   \n",
       "163   68.907265   57.200222    1.204668  4.306641  3.575012    1.204651   \n",
       "168   21.192741   19.668037    1.077522  0.249318  0.230472    1.081770   \n",
       "169    0.493276    1.282483    0.384626  0.021726  0.056594    0.383897   \n",
       "173   16.539137   40.300804    0.410392  0.401939  0.947520    0.424202   \n",
       "176    8.637804    4.383891    1.970351  0.101538  0.051574    1.968792   \n",
       "177   60.936588   51.128990    1.191821  3.808472  3.195559    1.191802   \n",
       "182   21.127401   20.101664    1.051028  0.248703  0.235769    1.054858   \n",
       "183    0.791774    1.809377    0.437595  0.034928  0.079847    0.437437   \n",
       "187   22.933607   53.314022    0.430161  0.557188  1.237014    0.450430   \n",
       "190    7.447861    4.184812    1.779736  0.087525  0.049242    1.777459   \n",
       "191   59.117859   50.622261    1.167823  3.694763  3.163889    1.167792   \n",
       "196   21.704342   20.226292    1.073076  0.255670  0.237395    1.076981   \n",
       "197    1.311881    2.227962    0.588826  0.057807  0.098248    0.588375   \n",
       "201   28.781591   62.755371    0.458632  0.704034  1.500387    0.469235   \n",
       "204    6.517498    3.358935    1.940346  0.076545  0.039542    1.935784   \n",
       "205   57.500515   50.311974    1.142879  3.593689  3.144496    1.142851   \n",
       "210   21.481438   20.713083    1.037095  0.253141  0.243359    1.040197   \n",
       "211    2.776436    3.292956    0.843144  0.122195  0.145305    0.840955   \n",
       "215   34.155495   73.755165    0.463093  0.837078  1.792213    0.467064   \n",
       "218    7.493422    3.122280    2.399984  0.088161  0.036642    2.405991   \n",
       "219   63.492413   47.654469    1.332350  3.968140  2.978401    1.332306   \n",
       "224   21.855965   21.130243    1.034345  0.257655  0.248375    1.037365   \n",
       "225    1.641315    3.123290    0.525508  0.072362  0.137754    0.525302   \n",
       "229   31.587980   59.614555    0.529870  0.757899  1.457768    0.519904   \n",
       "232    7.470176    2.893547    2.581667  0.087969  0.033970    2.589619   \n",
       "233   64.110390   43.221100    1.483312  4.006653  2.701313    1.483224   \n",
       "238   21.914175   21.914501    0.999985  0.258373  0.257723    1.002524   \n",
       "239    2.020492    4.783579    0.422381  0.089113  0.210982    0.422375   \n",
       "243   34.808437   71.422585    0.487359  0.841668  1.722112    0.488742   \n",
       "246    8.183807    3.338204    2.451560  0.096202  0.039203    2.453969   \n",
       "247   61.606770   41.250099    1.493494  3.850281  2.578124    1.493443   \n",
       "252   22.301815   22.705572    0.982218  0.262995  0.267114    0.984580   \n",
       "253    1.790116    3.660754    0.489002  0.078828  0.161438    0.488288   \n",
       "257   22.928190   56.085789    0.408806  0.555045  1.375809    0.403432   \n",
       "260    7.698030    3.559573    2.162627  0.090643  0.041870    2.164872   \n",
       "261   48.838367   42.235420    1.156337  3.052063  2.639706    1.156213   \n",
       "266   22.808533   24.000456    0.950337  0.269003  0.282359    0.952699   \n",
       "267    2.007612    6.082238    0.330078  0.088538  0.268124    0.330212   \n",
       "271   35.754414   62.438587    0.572633  0.869946  1.537322    0.565884   \n",
       "274    8.941700    3.825140    2.337614  0.105286  0.045020    2.338668   \n",
       "275   51.349850   41.333645    1.242326  3.208984  2.583346    1.242181   \n",
       "280   23.311581   25.515226    0.913634  0.274969  0.300217    0.915900   \n",
       "281    1.465116    6.631782    0.220923  0.064646  0.292640    0.220905   \n",
       "285   28.253962   73.820541    0.382738  0.678922  1.846360    0.367708   \n",
       "288    8.068832    3.979035    2.027836  0.094841  0.046862    2.023835   \n",
       "289   49.062431   39.149841    1.253196  3.066101  2.446855    1.253078   \n",
       "294   23.813595   26.737455    0.890646  0.280909  0.314663    0.892731   \n",
       "295    1.968177    8.135511    0.241924  0.086753  0.358591    0.241927   \n",
       "299   20.671974   69.679062    0.296674  0.504494  1.735003    0.290774   \n",
       "302    8.130106    4.244864    1.915281  0.095703  0.049928    1.916806   \n",
       "303   45.628685   45.220245    1.009032  2.851501  2.826259    1.008931   \n",
       "308   24.354338   27.943714    0.871550  0.287277  0.328794    0.873730   \n",
       "309    2.095639    6.838748    0.306436  0.092495  0.301488    0.306796   \n",
       "313   30.609915   63.275879    0.483753  0.740047  1.583948    0.467217   \n",
       "316    7.086284    4.431251    1.599161  0.083416  0.052161    1.599199   \n",
       "317   48.856133   45.227196    1.080238  3.053284  2.826689    1.080163   \n",
       "322   24.984646   29.704109    0.841118  0.294723  0.349499    0.843272   \n",
       "323    3.102937    8.542912    0.363218  0.136737  0.376948    0.362748   \n",
       "327   35.525059   69.673721    0.509877  0.861521  1.762080    0.488923   \n",
       "330    7.211089    4.750062    1.518104  0.084953  0.055942    1.518587   \n",
       "331   50.167828   45.486034    1.102928  3.135132  2.842865    1.102807   \n",
       "336   25.530970   31.090153    0.821191  0.301155  0.365806    0.823263   \n",
       "337    4.719140    9.508757    0.496294  0.207878  0.419451    0.495595   \n",
       "341   45.125446   82.335564    0.548068  1.115506  2.081787    0.535840   \n",
       "344    7.457499    4.945893    1.507816  0.087829  0.058246    1.507902   \n",
       "345   48.447563   45.497261    1.064846  3.027405  2.843565    1.064651   \n",
       "350   25.881824   32.060814    0.807273  0.305291  0.377249    0.809255   \n",
       "351    4.022617    9.215854    0.436489  0.177301  0.406466    0.436201   \n",
       "355   41.342270   76.011490    0.543895  1.010875  1.930578    0.523613   \n",
       "358    7.811490    5.258142    1.485599  0.092014  0.061970    1.484815   \n",
       "359   46.034271   46.470119    0.990621  2.876648  2.904363    0.990457   \n",
       "364   26.623869   33.157757    0.802945  0.314048  0.390296    0.804640   \n",
       "365    4.604096   11.638908    0.395578  0.202725  0.513562    0.394743   \n",
       "369   39.589603   78.118546    0.506789  0.964149  1.983653    0.486047   \n",
       "372    7.708518    5.781740    1.333252  0.090699  0.068131    1.331242   \n",
       "373   50.155056   47.134258    1.064089  3.134216  2.945873    1.063935   \n",
       "378   27.110918   34.026569    0.796757  0.319755  0.400636    0.798119   \n",
       "379    3.696667   12.212162    0.302704  0.163052  0.538561    0.302754   \n",
       "383   35.217964   79.873123    0.440924  0.859638  2.026072    0.424288   \n",
       "386    8.035164    5.331933    1.506989  0.094667  0.062801    1.507417   \n",
       "387   46.787014   50.976673    0.917812  2.923767  3.186023    0.917685   \n",
       "392   27.555099   34.934570    0.788763  0.324967  0.411490    0.789734   \n",
       "393    6.269969   14.672475    0.427329  0.275982  0.647391    0.426299   \n",
       "397   45.063992   70.867645    0.635890  1.096289  1.792945    0.611446   \n",
       "400    7.911266    5.675344    1.393971  0.093238  0.066889    1.393914   \n",
       "401   49.651878   48.342358    1.027089  3.102722  3.021368    1.026926   \n",
       "406   27.815681   35.910515    0.774583  0.328044  0.423096    0.775342   \n",
       "407    5.917262   15.048488    0.393213  0.260768  0.664242    0.392581   \n",
       "411   48.664703   70.438400    0.690883  1.224239  1.787476    0.684898   \n",
       "414    8.062296    5.988408    1.346317  0.094885  0.070541    1.345101   \n",
       "415   56.364899   50.260181    1.121462  3.522339  3.141231    1.121325   \n",
       "420   28.271057   36.425423    0.776135  0.333436  0.429238    0.776811   \n",
       "421    5.506713   13.684910    0.402393  0.242844  0.603910    0.402119   \n",
       "425   37.772858   72.382622    0.521850  0.920822  1.830573    0.503024   \n",
       "428    7.897707    6.376474    1.238569  0.092992  0.075150    1.237419   \n",
       "429   52.797226   57.852005    0.912626  3.299438  3.615731    0.912523   \n",
       "434   28.926723   37.828533    0.764680  0.341183  0.445842    0.765255   \n",
       "435    7.051957   16.307974    0.432424  0.310746  0.719584    0.431842   \n",
       "439   43.037724   68.926460    0.624401  1.048125  1.746784    0.600031   \n",
       "442    8.889240    5.830320    1.524657  0.104726  0.068708    1.524225   \n",
       "443   50.152832   49.721458    1.008676  3.134155  3.107569    1.008555   \n",
       "448   29.162882   38.999523    0.747775  0.343978  0.459724    0.748227   \n",
       "449    7.588762   16.664677    0.455380  0.334683  0.735415    0.455094   \n",
       "453   44.091393   65.182068    0.676434  1.081811  1.647552    0.656617   \n",
       "456    8.963466    5.802093    1.544868  0.105609  0.068305    1.546131   \n",
       "457   49.935829   58.862942    0.848341  3.120361  3.678916    0.848174   \n",
       "462   29.481527   39.809658    0.740562  0.347760  0.469333    0.740966   \n",
       "463    7.174768   17.283358    0.415126  0.316587  0.762202    0.415358   \n",
       "467   47.223068   58.363537    0.809119  1.170833  1.461844    0.800928   \n",
       "470    9.193699    5.759494    1.596268  0.108368  0.067819    1.597897   \n",
       "471   55.477261   60.892586    0.911068  3.466980  3.805771    0.910980   \n",
       "476   29.845907   40.668385    0.733885  0.352094  0.479449    0.734372   \n",
       "477    7.063729   16.081411    0.439248  0.311392  0.709224    0.439060   \n",
       "481   47.451469   63.553204    0.746642  1.183826  1.601308    0.739287   \n",
       "484    8.893102    6.090456    1.460170  0.104804  0.071727    1.461141   \n",
       "485   66.110176   59.661243    1.108093  4.131592  3.728813    1.108018   \n",
       "490   30.291435   41.269196    0.733996  0.357377  0.486644    0.734371   \n",
       "491    6.979453   16.766403    0.416276  0.307707  0.739226    0.416256   \n",
       "495   46.435028   64.891945    0.715575  1.163125  1.639507    0.709436   \n",
       "498    8.348124    6.535086    1.277431  0.098228  0.076935    1.276759   \n",
       "499   62.670074   57.402885    1.091758  3.916321  3.587661    1.091608   \n",
       "504   30.874731   42.265732    0.730491  0.364285  0.498457    0.730824   \n",
       "505    6.706844   17.553160    0.382088  0.295533  0.774706    0.381478   \n",
       "509   35.136681   64.073906    0.548377  0.831806  1.618070    0.514073   \n",
       "512    9.235064    5.547874    1.664613  0.108670  0.065206    1.666564   \n",
       "513   59.229416   60.786652    0.974382  3.701599  3.799148    0.974324   \n",
       "518   31.662472   42.784061    0.740053  0.373608  0.504624    0.740369   \n",
       "519    7.105305   20.455339    0.347357  0.313262  0.902194    0.347222   \n",
       "523   41.166149   53.906418    0.763660  1.018266  1.338238    0.760901   \n",
       "526    9.054070    5.683800    1.592961  0.106694  0.066828    1.596553   \n",
       "527   54.623924   64.535614    0.846415  3.413574  4.033462    0.846314   \n",
       "532   32.022961   44.180645    0.724819  0.377886  0.521095    0.725176   \n",
       "533    7.750358   26.224215    0.295542  0.341728  1.153692    0.296204   \n",
       "537   43.734512   55.419159    0.789159  1.098074  1.376326    0.797830   \n",
       "540    7.790635    6.803200    1.145143  0.091599  0.079999    1.145004   \n",
       "541   50.221333   65.443092    0.767405  3.138489  4.090182    0.767322   \n",
       "546   32.510365   45.550747    0.713717  0.383658  0.537274    0.714084   \n",
       "547    6.257142   28.256945    0.221437  0.275520  1.245100    0.221284   \n",
       "551   33.187252   53.744801    0.617497  0.774536  1.358157    0.570284   \n",
       "554    8.791056    7.212329    1.218893  0.103553  0.084969    1.218713   \n",
       "555   52.311253   66.598053    0.785477  3.269043  4.162371    0.785380   \n",
       "560   32.877995   46.196896    0.711693  0.388004  0.544937    0.712016   \n",
       "561    9.163482   20.797432    0.440606  0.404043  0.917130    0.440552   \n",
       "565   45.966934   62.618275    0.734082  1.153931  1.579965    0.730353   \n",
       "568    9.376526    5.662682    1.655845  0.110416  0.066587    1.658218   \n",
       "569   49.397831   76.283791    0.647553  3.086609  4.767734    0.647395   \n",
       "574   33.596287   47.076504    0.713653  0.396493  0.555336    0.713970   \n",
       "575    7.331695   25.284454    0.289968  0.322917  1.113093    0.290108   \n",
       "579   39.528179   56.054607    0.705173  0.972488  1.402409    0.693441   \n",
       "582    9.423832    7.284523    1.293679  0.111039  0.085643    1.296527   \n",
       "583   56.244713   76.695351    0.733352  3.514893  4.793457    0.733269   \n",
       "588   34.101860   48.291222    0.706171  0.402491  0.569678    0.706525   \n",
       "589    8.728246   28.171011    0.309831  0.384842  1.242149    0.309820   \n",
       "593   41.792419   46.897865    0.891137  1.032644  1.182349    0.873383   \n",
       "596    9.488783    7.310069    1.298043  0.111691  0.086062    1.297794   \n",
       "597   50.673882   76.044945    0.666368  3.166626  4.752805    0.666265   \n",
       "602   34.838112   49.710381    0.700822  0.411179  0.586426    0.701161   \n",
       "603   10.621462   32.936115    0.322487  0.467369  1.450579    0.322195   \n",
       "607   38.403057   47.869350    0.802247  0.946365  1.209708    0.782309   \n",
       "610   10.154673    5.561210    1.825983  0.119674  0.065080    1.838875   \n",
       "611   59.402397   82.002777    0.724395  3.712219  5.125168    0.724312   \n",
       "616   35.161789   50.851376    0.691462  0.415019  0.599913    0.691798   \n",
       "617    8.954658   25.348925    0.353256  0.394367  1.116485    0.353222   \n",
       "621   42.673195   41.494488    1.028406  1.042407  1.007337    1.034815   \n",
       "624    9.007144    7.582341    1.187911  0.106024  0.089159    1.189146   \n",
       "625   62.607937   69.010757    0.907220  3.912598  4.313168    0.907129   \n",
       "630   35.825687   51.863037    0.690775  0.422876  0.611889    0.691099   \n",
       "631   11.489024   28.782682    0.399164  0.504027  1.268909    0.397213   \n",
       "635   36.703445   51.659477    0.710488  0.911217  1.291001    0.705822   \n",
       "638    9.939654    7.779192    1.277723  0.117046  0.091431    1.280159   \n",
       "639   78.499130   92.225677    0.851164  4.906006  5.764103    0.851131   \n",
       "644   36.447720   53.549477    0.680636  0.430233  0.631791    0.680974   \n",
       "645    8.718669   36.422890    0.239373  0.382303  1.600676    0.238838   \n",
       "649   32.507000   36.828556    0.882657  0.769394  0.919811    0.836469   \n",
       "652    8.800538    6.867566    1.281464  0.103454  0.080651    1.282742   \n",
       "653   72.554260   98.685097    0.735210  4.534424  6.167814    0.735175   \n",
       "658   37.153988   55.376076    0.670939  0.438575  0.653352    0.671269   \n",
       "659    7.115090   47.734306    0.149056  0.313553  2.088741    0.150116   \n",
       "663   35.043316   43.275734    0.809768  0.841964  1.084227    0.776557   \n",
       "666    9.160581    6.904369    1.326780  0.107597  0.081167    1.325630   \n",
       "667   75.652328  128.706833    0.587788  4.728149  8.044176    0.587773   \n",
       "672   37.708935   56.685688    0.665228  0.445136  0.668839    0.665535   \n",
       "673    6.742046   32.763737    0.205778  0.295794  1.444372    0.204791   \n",
       "677   29.981049   38.430950    0.780128  0.686651  0.953880    0.719851   \n",
       "680    8.295721    7.969981    1.040871  0.097570  0.093675    1.041584   \n",
       "681   61.280964  102.592842    0.597322  3.829773  6.412050    0.597277   \n",
       "686   38.697121   58.836311    0.657708  0.456815  0.694219    0.658027   \n",
       "687    8.011235   35.228909    0.227405  0.351188  1.553320    0.226089   \n",
       "691   23.515059   45.900337    0.512307  0.551928  1.145307    0.481904   \n",
       "694   10.215260    7.529285    1.356737  0.120324  0.088465    1.360138   \n",
       "695   81.724022  115.252037    0.709090  5.107544  7.203250    0.709061   \n",
       "700   39.805771   60.309048    0.660030  0.469902  0.711620    0.660327   \n",
       "701   12.517245   37.646488    0.332494  0.549931  1.656654    0.331953   \n",
       "705   32.272610   35.608696    0.906313  0.802544  0.886374    0.905423   \n",
       "708   10.227710    6.190627    1.652128  0.120510  0.072577    1.660446   \n",
       "709   65.781540  103.148209    0.637738  4.111206  6.446762    0.637716   \n",
       "714   40.384220   61.571194    0.655895  0.476740  0.726491    0.656223   \n",
       "715    8.126939   33.346466    0.243712  0.358415  1.467971    0.244156   \n",
       "719   37.580723   48.322044    0.777714  0.902179  1.196343    0.754114   \n",
       "722    9.311213    7.520018    1.238190  0.109624  0.088333    1.241025   \n",
       "723   72.959496  101.678253    0.717553  4.559570  6.354887    0.717490   \n",
       "728   41.616852   63.846737    0.651824  0.491295  0.753357    0.652141   \n",
       "729    9.611343   37.183098    0.258487  0.422691  1.638337    0.258000   \n",
       "733   34.930744   36.876457    0.947237  0.849323  0.912941    0.930315   \n",
       "736   10.748524    7.695841    1.396667  0.126456  0.090483    1.397565   \n",
       "737   59.888145  100.560814    0.595542  3.742798  6.285046    0.595508   \n",
       "742   42.831245   66.664520    0.642489  0.505628  0.786597    0.642805   \n",
       "743    9.470158   32.872959    0.288084  0.416720  1.447085    0.287972   \n",
       "747   24.918390   34.973537    0.712493  0.613342  0.869858    0.705106   \n",
       "750    9.168660    7.409281    1.237456  0.107799  0.087114    1.237447   \n",
       "751  100.741928   98.467979    1.023093  6.296143  6.154246    1.023057   \n",
       "756   43.947289   67.934235    0.646909  0.518812  0.801556    0.647256   \n",
       "757    8.110057   40.890011    0.198338  0.353097  1.802124    0.195934   \n",
       "761   25.249483   32.930283    0.766756  0.596802  0.801044    0.745031   \n",
       "764    9.544826    7.688483    1.241445  0.112135  0.090386    1.240623   \n",
       "765   71.458214   49.634304    1.439694  4.465942  3.102138    1.439634   \n",
       "770   45.374569   70.578873    0.642892  0.535663  0.832640    0.643331   \n",
       "771    7.315055   43.304157    0.168923  0.315494  1.907967    0.165356   \n",
       "775   20.395445   38.993725    0.523044  0.461432  0.971314    0.475060   \n",
       "778    9.346161    8.306944    1.125102  0.109936  0.097532    1.127175   \n",
       "779   75.489738   43.398766    1.739444  4.717896  2.712412    1.739372   \n",
       "784   46.954895   72.460052    0.648011  0.554308  0.854545    0.648659   \n",
       "785    8.712090   35.579922    0.244860  0.382761  1.567657    0.244161   \n",
       "789   26.489454   33.930782    0.780691  0.623040  0.826527    0.753805   \n",
       "792    9.111650    5.735451    1.588655  0.107061  0.067206    1.593023   \n",
       "793   73.364540   38.575268    1.901854  4.584961  2.410940    1.901732   \n",
       "798   48.476753   71.995995    0.673326  0.572268  0.848505    0.674443   \n",
       "799    9.402333   35.996288    0.261203  0.397639  1.578283    0.251944   \n",
       "803   19.423687   41.781937    0.464882  0.452640  1.000939    0.452216   \n",
       "806    8.886652    6.214496    1.429988  0.104353  0.072141    1.446505   \n",
       "807   63.740585   37.870277    1.683130  3.983276  2.366880    1.682922   \n",
       "812   50.561478   69.906929    0.723268  0.596867  0.823406    0.724877   \n",
       "813    8.999374   38.314774    0.234880  0.387518  1.659230    0.233553   \n",
       "817   15.078004   29.374578    0.513301  0.340074  0.678578    0.501156   \n",
       "820   11.322188    8.784041    1.288950  0.133168  0.102669    1.297055   \n",
       "821   59.812157   35.747231    1.673197  3.737732  2.234153    1.672998   \n",
       "826   53.454762   59.229683    0.902500  0.630971  0.695732    0.906917   \n",
       "827    9.440676   41.729496    0.226235  0.414216  1.828960    0.226476   \n",
       "831   19.711937   36.543213    0.539414  0.480752  0.884226    0.543699   \n",
       "834    9.121619    5.163881    1.766427  0.107321  0.059979    1.789316   \n",
       "835   64.962166   56.208115    1.155744  4.059692  3.512983    1.155625   \n",
       "840   55.236790   35.182590    1.570004  0.651910  0.409948    1.590227   \n",
       "841   11.628647   33.892223    0.343107  0.511723  1.465570    0.349163   \n",
       "845   26.197701   28.950804    0.904904  0.617749  0.643727    0.959645   \n",
       "\n",
       "        std_a     std_b  std_ratio  zero_frac_a  zero_frac_b   cos_sim  \\\n",
       "0    0.022791  0.014067   1.620160          0.0          0.0  0.883294   \n",
       "4    0.008790  0.016035   0.548183          0.0          0.0  0.645940   \n",
       "5    0.003816  0.007539   0.506165          0.0          0.0  0.550863   \n",
       "9    0.082398  0.083180   0.990599          0.0          0.0  0.905126   \n",
       "12   0.023877  0.016881   1.414466          0.0          0.0  0.853763   \n",
       "16   0.033429  0.041884   0.798134          0.0          0.0  0.607914   \n",
       "17   0.002869  0.008241   0.348181          0.0          0.0  0.498078   \n",
       "21   0.067022  0.153560   0.436454          0.0          0.0  0.813170   \n",
       "24   0.026269  0.019253   1.364385          0.0          0.0  0.894958   \n",
       "28   0.027699  0.019384   1.428917          0.0          0.0  0.798047   \n",
       "29   0.002326  0.007801   0.298212          0.0          0.0  0.556629   \n",
       "33   0.043489  0.162842   0.267065          0.0          0.0  0.897100   \n",
       "36   0.029036  0.011767   2.467632          0.0          0.0  0.930285   \n",
       "37   0.014595  0.002173   6.715944          0.0          0.0  0.999997   \n",
       "42   0.034600  0.052612   0.657652          0.0          0.0  0.825780   \n",
       "43   0.011980  0.009374   1.278002          0.0          0.0  0.506418   \n",
       "47   0.076888  0.168193   0.457143          0.0          0.0  0.916142   \n",
       "50   0.021338  0.014504   1.471112          0.0          0.0  0.909860   \n",
       "51   0.008470  0.001803   4.698055          0.0          0.0  0.999999   \n",
       "56   0.038199  0.059355   0.643564          0.0          0.0  0.829575   \n",
       "57   0.002847  0.022251   0.127971          0.0          0.0  0.798677   \n",
       "61   0.055281  0.224259   0.246504          0.0          0.0  0.941680   \n",
       "64   0.024525  0.016782   1.461375          0.0          0.0  0.939693   \n",
       "65   0.015421  0.001900   8.115402          0.0          0.0  0.999998   \n",
       "70   0.039780  0.063898   0.622563          0.0          0.0  0.857210   \n",
       "71   0.002086  0.004320   0.482850          0.0          0.0  0.942494   \n",
       "75   0.082129  0.254837   0.322280          0.0          0.0  0.904794   \n",
       "78   0.020674  0.011933   1.732541          0.0          0.0  0.954217   \n",
       "79   0.019627  0.002006   9.784381          0.0          0.0  0.999996   \n",
       "84   0.037405  0.051966   0.719793          0.0          0.0  0.915626   \n",
       "85   0.002342  0.002376   0.985429          0.0          0.0  0.911585   \n",
       "89   0.071755  0.247687   0.289699          0.0          0.0  0.888783   \n",
       "92   0.017790  0.011218   1.585890          0.0          0.0  0.965007   \n",
       "93   0.017590  0.002712   6.487113          0.0          0.0  0.999997   \n",
       "98   0.031355  0.047757   0.656547          0.0          0.0  0.940211   \n",
       "99   0.004040  0.003441   1.174130          0.0          0.0  0.970948   \n",
       "103  0.107981  0.333213   0.324059          0.0          0.0  0.892380   \n",
       "106  0.018435  0.012914   1.427530          0.0          0.0  0.964222   \n",
       "107  0.026832  0.002409  11.140157          0.0          0.0  0.999990   \n",
       "112  0.029228  0.042554   0.686859          0.0          0.0  0.960529   \n",
       "113  0.001471  0.005339   0.275604          0.0          0.0  0.965048   \n",
       "117  0.107487  0.288125   0.373056          0.0          0.0  0.847762   \n",
       "120  0.017277  0.005085   3.397628          0.0          0.0  0.975138   \n",
       "121  0.022561  0.002918   7.730451          0.0          0.0  0.999992   \n",
       "126  0.028520  0.037421   0.762141          0.0          0.0  0.971939   \n",
       "127  0.001830  0.008966   0.204072          0.0          0.0  0.985790   \n",
       "131  0.106005  0.439884   0.240985          0.0          0.0  0.897370   \n",
       "134  0.016160  0.004346   3.718390          0.0          0.0  0.981753   \n",
       "135  0.027689  0.002476  11.181231          0.0          0.0  0.999984   \n",
       "140  0.027121  0.032928   0.823633          0.0          0.0  0.980439   \n",
       "141  0.002050  0.005975   0.343094          0.0          0.0  0.989113   \n",
       "145  0.112010  0.479122   0.233783          0.0          0.0  0.904946   \n",
       "148  0.012362  0.005079   2.433828          0.0          0.0  0.983285   \n",
       "149  0.025554  0.003380   7.560077          0.0          0.0  0.999984   \n",
       "154  0.024059  0.031279   0.769164          0.0          0.0  0.984686   \n",
       "155  0.003232  0.007670   0.421386          0.0          0.0  0.993276   \n",
       "159  0.165902  0.522651   0.317425          0.0          0.0  0.881890   \n",
       "162  0.012566  0.005869   2.141295          0.0          0.0  0.988693   \n",
       "163  0.023356  0.003359   6.953601          0.0          0.0  0.999985   \n",
       "168  0.022324  0.029136   0.766179          0.0          0.0  0.988117   \n",
       "169  0.001791  0.003091   0.579381          0.0          0.0  0.994731   \n",
       "173  0.128579  0.399498   0.321853          0.0          0.0  0.878062   \n",
       "176  0.009948  0.004613   2.156290          0.0          0.0  0.991157   \n",
       "177  0.022247  0.004548   4.891450          0.0          0.0  0.999981   \n",
       "182  0.020467  0.028020   0.730448          0.0          0.0  0.989647   \n",
       "183  0.002114  0.004331   0.488275          0.0          0.0  0.996613   \n",
       "187  0.178766  0.565957   0.315864          0.0          0.0  0.862326   \n",
       "190  0.008832  0.004293   2.057549          0.0          0.0  0.991078   \n",
       "191  0.027581  0.003806   7.246110          0.0          0.0  0.999971   \n",
       "196  0.018778  0.026780   0.701217          0.0          0.0  0.991036   \n",
       "197  0.004447  0.006502   0.683947          0.0          0.0  0.994724   \n",
       "201  0.208918  0.559280   0.373548          0.0          0.0  0.894577   \n",
       "204  0.008178  0.003228   2.533557          0.0          0.0  0.991017   \n",
       "205  0.025893  0.003951   6.552856          0.0          0.0  0.999974   \n",
       "210  0.017214  0.025106   0.685666          0.0          0.0  0.992444   \n",
       "211  0.011143  0.008074   1.380246          0.0          0.0  0.994207   \n",
       "215  0.242495  0.574041   0.422434          0.0          0.0  0.915188   \n",
       "218  0.007829  0.004168   1.878375          0.0          0.0  0.989703   \n",
       "219  0.032880  0.004409   7.457530          0.0          0.0  0.999965   \n",
       "224  0.015965  0.024475   0.652296          0.0          0.0  0.993296   \n",
       "225  0.005022  0.008743   0.574459          0.0          0.0  0.995508   \n",
       "229  0.274224  0.434334   0.631367          0.0          0.0  0.903922   \n",
       "232  0.006826  0.003756   1.817235          0.0          0.0  0.991019   \n",
       "233  0.044437  0.005491   8.092406          0.0          0.0  0.999936   \n",
       "238  0.015482  0.024030   0.644272          0.0          0.0  0.993903   \n",
       "239  0.005676  0.013395   0.423756          0.0          0.0  0.995916   \n",
       "243  0.283576  0.596166   0.475666          0.0          0.0  0.903039   \n",
       "246  0.009420  0.004217   2.233580          0.0          0.0  0.989407   \n",
       "247  0.033121  0.006175   5.364066          0.0          0.0  0.999960   \n",
       "252  0.014873  0.023937   0.621356          0.0          0.0  0.994430   \n",
       "253  0.006702  0.010574   0.633824          0.0          0.0  0.994356   \n",
       "257  0.184876  0.393799   0.469468          0.0          0.0  0.911530   \n",
       "260  0.007147  0.003816   1.872844          0.0          0.0  0.992685   \n",
       "261  0.045226  0.006380   7.089037          0.0          0.0  0.999887   \n",
       "266  0.014632  0.025175   0.581225          0.0          0.0  0.994609   \n",
       "267  0.005758  0.019046   0.302330          0.0          0.0  0.995424   \n",
       "271  0.274722  0.418063   0.657131          0.0          0.0  0.916838   \n",
       "274  0.008313  0.003805   2.184911          0.0          0.0  0.993408   \n",
       "275  0.049468  0.005968   8.288301          0.0          0.0  0.999876   \n",
       "280  0.014334  0.026338   0.544243          0.0          0.0  0.994853   \n",
       "281  0.003669  0.016166   0.226973          0.0          0.0  0.996860   \n",
       "285  0.242451  0.372544   0.650799          0.0          0.0  0.922038   \n",
       "288  0.009387  0.003573   2.626806          0.0          0.0  0.992202   \n",
       "289  0.042962  0.007017   6.122201          0.0          0.0  0.999899   \n",
       "294  0.014269  0.026851   0.531409          0.0          0.0  0.995125   \n",
       "295  0.006310  0.026143   0.241362          0.0          0.0  0.994746   \n",
       "299  0.153935  0.388182   0.396555          0.0          0.0  0.933343   \n",
       "302  0.007894  0.004578   1.724252          0.0          0.0  0.992411   \n",
       "303  0.040759  0.006139   6.639153          0.0          0.0  0.999896   \n",
       "308  0.014813  0.028817   0.514052          0.0          0.0  0.994902   \n",
       "309  0.004707  0.021204   0.221986          0.0          0.0  0.996246   \n",
       "313  0.249668  0.312690   0.798453          0.0          0.0  0.929085   \n",
       "316  0.006879  0.004317   1.593569          0.0          0.0  0.993147   \n",
       "317  0.037031  0.007708   4.804199          0.0          0.0  0.999925   \n",
       "322  0.014977  0.030719   0.487557          0.0          0.0  0.994913   \n",
       "323  0.010400  0.021266   0.489043          0.0          0.0  0.995580   \n",
       "327  0.281808  0.235603   1.196113          0.0          0.0  0.942352   \n",
       "330  0.006124  0.004274   1.432913          0.0          0.0  0.994543   \n",
       "331  0.047344  0.008142   5.814858          0.0          0.0  0.999876   \n",
       "336  0.015559  0.032169   0.483660          0.0          0.0  0.994878   \n",
       "337  0.016840  0.025611   0.657540          0.0          0.0  0.994767   \n",
       "341  0.285250  0.282257   1.010603          0.0          0.0  0.960780   \n",
       "344  0.006686  0.004477   1.493226          0.0          0.0  0.994162   \n",
       "345  0.058638  0.008702   6.738204          0.0          0.0  0.999805   \n",
       "350  0.015817  0.032919   0.480492          0.0          0.0  0.994920   \n",
       "351  0.012989  0.025848   0.502537          0.0          0.0  0.995297   \n",
       "355  0.301465  0.185537   1.624824          0.0          0.0  0.954527   \n",
       "358  0.006798  0.004109   1.654349          0.0          0.0  0.995086   \n",
       "359  0.053311  0.010601   5.029110          0.0          0.0  0.999824   \n",
       "364  0.016193  0.032409   0.499652          0.0          0.0  0.995293   \n",
       "365  0.017446  0.028851   0.604701          0.0          0.0  0.994639   \n",
       "369  0.301361  0.195206   1.543809          0.0          0.0  0.950860   \n",
       "372  0.007964  0.004658   1.709746          0.0          0.0  0.993821   \n",
       "373  0.054547  0.010464   5.212838          0.0          0.0  0.999838   \n",
       "378  0.017211  0.031868   0.540078          0.0          0.0  0.995455   \n",
       "379  0.010213  0.035146   0.290581          0.0          0.0  0.996120   \n",
       "383  0.261751  0.220215   1.188613          0.0          0.0  0.951564   \n",
       "386  0.006739  0.004716   1.428983          0.0          0.0  0.994672   \n",
       "387  0.049634  0.010931   4.540858          0.0          0.0  0.999847   \n",
       "392  0.017971  0.030599   0.587316          0.0          0.0  0.995759   \n",
       "393  0.024823  0.036839   0.673809          0.0          0.0  0.994243   \n",
       "397  0.346788  0.234576   1.478360          0.0          0.0  0.944099   \n",
       "400  0.006193  0.004401   1.407177          0.0          0.0  0.995635   \n",
       "401  0.056814  0.013268   4.282165          0.0          0.0  0.999829   \n",
       "406  0.018078  0.029927   0.604075          0.0          0.0  0.996039   \n",
       "407  0.019661  0.032893   0.597711          0.0          0.0  0.995877   \n",
       "411  0.207536  0.187394   1.107484          0.0          0.0  0.980962   \n",
       "414  0.008068  0.005189   1.554713          0.0          0.0  0.993743   \n",
       "415  0.057383  0.013913   4.124401          0.0          0.0  0.999854   \n",
       "420  0.017977  0.029278   0.614034          0.0          0.0  0.996270   \n",
       "421  0.015916  0.032671   0.487159          0.0          0.0  0.996577   \n",
       "425  0.284580  0.244887   1.162086          0.0          0.0  0.948715   \n",
       "428  0.007365  0.004987   1.476727          0.0          0.0  0.994669   \n",
       "429  0.050604  0.011978   4.224644          0.0          0.0  0.999876   \n",
       "434  0.018136  0.029355   0.617827          0.0          0.0  0.996473   \n",
       "435  0.023786  0.040404   0.588696          0.0          0.0  0.995470   \n",
       "439  0.327602  0.204331   1.603295          0.0          0.0  0.949915   \n",
       "442  0.007496  0.004636   1.616956          0.0          0.0  0.995147   \n",
       "443  0.049873  0.011742   4.247295          0.0          0.0  0.999865   \n",
       "448  0.018111  0.029019   0.624090          0.0          0.0  0.996667   \n",
       "449  0.021598  0.039613   0.545209          0.0          0.0  0.996482   \n",
       "453  0.308776  0.227272   1.358615          0.0          0.0  0.951048   \n",
       "456  0.007443  0.005554   1.340201          0.0          0.0  0.994311   \n",
       "457  0.062602  0.011302   5.539257          0.0          0.0  0.999794   \n",
       "462  0.017858  0.028667   0.622939          0.0          0.0  0.996857   \n",
       "463  0.017728  0.049744   0.356394          0.0          0.0  0.996299   \n",
       "467  0.284580  0.284001   1.002038          0.0          0.0  0.953887   \n",
       "470  0.006946  0.005322   1.305079          0.0          0.0  0.994887   \n",
       "471  0.049176  0.011060   4.446198          0.0          0.0  0.999898   \n",
       "476  0.017365  0.029415   0.590349          0.0          0.0  0.996936   \n",
       "477  0.022105  0.045857   0.482038          0.0          0.0  0.995443   \n",
       "481  0.253906  0.255691   0.993022          0.0          0.0  0.966334   \n",
       "484  0.007042  0.005487   1.283483          0.0          0.0  0.994877   \n",
       "485  0.049318  0.010502   4.696288          0.0          0.0  0.999925   \n",
       "490  0.017059  0.027967   0.609970          0.0          0.0  0.997244   \n",
       "491  0.021415  0.050917   0.420588          0.0          0.0  0.995037   \n",
       "495  0.225664  0.231369   0.975343          0.0          0.0  0.971872   \n",
       "498  0.008589  0.006244   1.375659          0.0          0.0  0.993009   \n",
       "499  0.066166  0.011883   5.568248          0.0          0.0  0.999849   \n",
       "504  0.016837  0.027533   0.611524          0.0          0.0  0.997428   \n",
       "505  0.022693  0.040184   0.564736          0.0          0.0  0.995718   \n",
       "509  0.334463  0.233835   1.430339          0.0          0.0  0.919561   \n",
       "512  0.009438  0.006490   1.454245          0.0          0.0  0.991455   \n",
       "513  0.042101  0.011662   3.609935          0.0          0.0  0.999931   \n",
       "518  0.016627  0.026882   0.618512          0.0          0.0  0.997613   \n",
       "519  0.021713  0.057221   0.379456          0.0          0.0  0.995635   \n",
       "523  0.257726  0.317778   0.811025          0.0          0.0  0.941210   \n",
       "526  0.007271  0.006403   1.135575          0.0          0.0  0.993166   \n",
       "527  0.053611  0.010445   5.132750          0.0          0.0  0.999871   \n",
       "532  0.016271  0.027781   0.585676          0.0          0.0  0.997674   \n",
       "533  0.023286  0.110348   0.211025          0.0          0.0  0.993915   \n",
       "537  0.198711  0.324437   0.612478          0.0          0.0  0.960291   \n",
       "540  0.008773  0.007559   1.160577          0.0          0.0  0.991130   \n",
       "541  0.046510  0.009374   4.961665          0.0          0.0  0.999888   \n",
       "546  0.016016  0.028283   0.566285          0.0          0.0  0.997761   \n",
       "547  0.023600  0.095960   0.245937          0.0          0.0  0.993192   \n",
       "551  0.342269  0.189595   1.805263          0.0          0.0  0.903270   \n",
       "554  0.007645  0.006101   1.253185          0.0          0.0  0.994757   \n",
       "555  0.051802  0.007870   6.582301          0.0          0.0  0.999869   \n",
       "560  0.016016  0.027869   0.574693          0.0          0.0  0.997859   \n",
       "561  0.027419  0.060538   0.452929          0.0          0.0  0.995574   \n",
       "565  0.209921  0.237649   0.883324          0.0          0.0  0.973735   \n",
       "568  0.008593  0.006297   1.364716          0.0          0.0  0.992557   \n",
       "569  0.068300  0.005581  12.237870          0.0          0.0  0.999756   \n",
       "574  0.016069  0.027954   0.574828          0.0          0.0  0.997923   \n",
       "575  0.026685  0.098306   0.271452          0.0          0.0  0.993042   \n",
       "579  0.267403  0.280891   0.951982          0.0          0.0  0.944913   \n",
       "582  0.007744  0.008256   0.937994          0.0          0.0  0.993074   \n",
       "583  0.053162  0.005657   9.397799          0.0          0.0  0.999885   \n",
       "588  0.015515  0.028427   0.545773          0.0          0.0  0.998028   \n",
       "589  0.026264  0.084122   0.312219          0.0          0.0  0.995281   \n",
       "593  0.266009  0.184280   1.443500          0.0          0.0  0.960473   \n",
       "596  0.009275  0.006944   1.335782          0.0          0.0  0.993381   \n",
       "597  0.055802  0.006621   8.428227          0.0          0.0  0.999848   \n",
       "602  0.015907  0.029127   0.546113          0.0          0.0  0.998030   \n",
       "603  0.043690  0.120613   0.362235          0.0          0.0  0.993350   \n",
       "607  0.254058  0.168674   1.506205          0.0          0.0  0.956671   \n",
       "610  0.007999  0.008900   0.898730          0.0          0.0  0.988647   \n",
       "611  0.056542  0.007346   7.696503          0.0          0.0  0.999884   \n",
       "616  0.015536  0.029243   0.531268          0.0          0.0  0.998119   \n",
       "617  0.032978  0.092069   0.358190          0.0          0.0  0.993002   \n",
       "621  0.314540  0.325932   0.965049          0.0          0.0  0.913275   \n",
       "624  0.008785  0.008439   1.040899          0.0          0.0  0.992221   \n",
       "625  0.055842  0.006192   9.018509          0.0          0.0  0.999897   \n",
       "630  0.015270  0.028975   0.526981          0.0          0.0  0.998236   \n",
       "631  0.061354  0.089001   0.689369          0.0          0.0  0.990339   \n",
       "635  0.216169  0.265993   0.812687          0.0          0.0  0.951792   \n",
       "638  0.009121  0.009103   1.002010          0.0          0.0  0.992180   \n",
       "639  0.043145  0.004212  10.242859          0.0          0.0  0.999961   \n",
       "644  0.015107  0.029817   0.506673          0.0          0.0  0.998277   \n",
       "645  0.048081  0.170018   0.282798          0.0          0.0  0.987526   \n",
       "649  0.309826  0.192308   1.611090          0.0          0.0  0.909879   \n",
       "652  0.010104  0.008669   1.165501          0.0          0.0  0.989623   \n",
       "653  0.044425  0.007199   6.170753          0.0          0.0  0.999951   \n",
       "658  0.015262  0.030606   0.498673          0.0          0.0  0.998305   \n",
       "659  0.023677  0.295770   0.080051          0.0          0.0  0.986884   \n",
       "663  0.300994  0.209081   1.439601          0.0          0.0  0.927824   \n",
       "666  0.011395  0.007895   1.443225          0.0          0.0  0.989851   \n",
       "667  0.033820  0.004340   7.792107          0.0          0.0  0.999974   \n",
       "672  0.015196  0.030555   0.497328          0.0          0.0  0.998384   \n",
       "673  0.035853  0.101958   0.351643          0.0          0.0  0.990906   \n",
       "677  0.337205  0.227290   1.483593          0.0          0.0  0.873983   \n",
       "680  0.008992  0.009310   0.965903          0.0          0.0  0.990946   \n",
       "681  0.046917  0.005671   8.273088          0.0          0.0  0.999925   \n",
       "686  0.015166  0.031615   0.479692          0.0          0.0  0.998416   \n",
       "687  0.044926  0.105702   0.425028          0.0          0.0  0.989774   \n",
       "691  0.235317  0.244770   0.961379          0.0          0.0  0.901897   \n",
       "694  0.008951  0.009100   0.983629          0.0          0.0  0.992116   \n",
       "695  0.046018  0.005226   8.805516          0.0          0.0  0.999959   \n",
       "700  0.015629  0.031877   0.490270          0.0          0.0  0.998449   \n",
       "701  0.059952  0.153553   0.390433          0.0          0.0  0.988923   \n",
       "705  0.184383  0.199620   0.923668          0.0          0.0  0.948857   \n",
       "708  0.008411  0.008893   0.945764          0.0          0.0  0.990221   \n",
       "709  0.033977  0.004862   6.987781          0.0          0.0  0.999966   \n",
       "714  0.015557  0.033018   0.471176          0.0          0.0  0.998444   \n",
       "715  0.023179  0.130038   0.178247          0.0          0.0  0.993983   \n",
       "719  0.324878  0.298259   1.089246          0.0          0.0  0.909388   \n",
       "722  0.008825  0.009304   0.948531          0.0          0.0  0.991443   \n",
       "723  0.060255  0.006565   9.178478          0.0          0.0  0.999912   \n",
       "728  0.015909  0.033881   0.469553          0.0          0.0  0.998470   \n",
       "729  0.041927  0.127317   0.329312          0.0          0.0  0.992558   \n",
       "733  0.270228  0.227754   1.186487          0.0          0.0  0.921500   \n",
       "736  0.011248  0.008683   1.295368          0.0          0.0  0.991587   \n",
       "737  0.039760  0.007540   5.273404          0.0          0.0  0.999943   \n",
       "742  0.016480  0.035570   0.463301          0.0          0.0  0.998452   \n",
       "743  0.038838  0.128654   0.301876          0.0          0.0  0.991293   \n",
       "747  0.167512  0.199167   0.841066          0.0          0.0  0.939840   \n",
       "750  0.010353  0.008360   1.238439          0.0          0.0  0.990979   \n",
       "751  0.053555  0.005359   9.993901          0.0          0.0  0.999964   \n",
       "756  0.016625  0.036743   0.452475          0.0          0.0  0.998444   \n",
       "757  0.061525  0.134016   0.459085          0.0          0.0  0.983217   \n",
       "761  0.242672  0.253614   0.956855          0.0          0.0  0.880664   \n",
       "764  0.011644  0.008784   1.325586          0.0          0.0  0.990068   \n",
       "765  0.041841  0.006085   6.876036          0.0          0.0  0.999954   \n",
       "770  0.017126  0.040710   0.420680          0.0          0.0  0.998302   \n",
       "771  0.070538  0.149193   0.472793          0.0          0.0  0.972362   \n",
       "775  0.240618  0.215558   1.116256          0.0          0.0  0.861877   \n",
       "778  0.010014  0.010692   0.936658          0.0          0.0  0.990058   \n",
       "779  0.044829  0.007538   5.947058          0.0          0.0  0.999953   \n",
       "784  0.018072  0.047314   0.381947          0.0          0.0  0.997948   \n",
       "785  0.041680  0.122358   0.340643          0.0          0.0  0.991023   \n",
       "789  0.262014  0.257674   1.016844          0.0          0.0  0.871921   \n",
       "792  0.010963  0.008514   1.287539          0.0          0.0  0.986934   \n",
       "793  0.054399  0.008391   6.482912          0.0          0.0  0.999920   \n",
       "798  0.018818  0.056335   0.334038          0.0          0.0  0.997274   \n",
       "799  0.120610  0.199375   0.604943          0.0          0.0  0.948076   \n",
       "803  0.201845  0.366966   0.550038          0.0          0.0  0.855079   \n",
       "806  0.011306  0.013544   0.834777          0.0          0.0  0.977215   \n",
       "807  0.063759  0.007507   8.493230          0.0          0.0  0.999871   \n",
       "812  0.019971  0.061486   0.324797          0.0          0.0  0.996672   \n",
       "813  0.089502  0.337913   0.264867          0.0          0.0  0.952422   \n",
       "817  0.179894  0.318267   0.565230          0.0          0.0  0.804283   \n",
       "820  0.012258  0.014947   0.820073          0.0          0.0  0.985603   \n",
       "821  0.062813  0.014845   4.231378          0.0          0.0  0.999832   \n",
       "826  0.022578  0.073319   0.307945          0.0          0.0  0.993864   \n",
       "827  0.050000  0.236600   0.211326          0.0          0.0  0.984470   \n",
       "831  0.147805  0.295889   0.499527          0.0          0.0  0.908353   \n",
       "834  0.009481  0.011074   0.856086          0.0          0.0  0.979456   \n",
       "835  0.059959  0.012955   4.628320          0.0          0.0  0.999894   \n",
       "840  0.025884  0.068038   0.380428          0.0          0.0  0.985737   \n",
       "841  0.047457  0.309232   0.153468          0.0          0.0  0.975739   \n",
       "845  0.255360  0.362334   0.704765          0.0          0.0  0.803287   \n",
       "\n",
       "     rel_l2_err  mean_rel_diff  max_rel_diff   pearson  max_abs_diff  \\\n",
       "0      0.505120       0.325193      5.045249  0.003609      0.272217   \n",
       "4      0.964386       1.760695   4720.670898  0.007855      0.676208   \n",
       "5      1.277797       2.887821     84.512604 -0.015007      0.068909   \n",
       "9      1.312957       1.929219     23.032129  0.012730      1.400146   \n",
       "12     0.522459       0.437025     12.734513 -0.000896      0.185303   \n",
       "16     0.948953       1.461620    755.537292 -0.008112      0.530029   \n",
       "17     2.528081      19.070650   1066.807495  0.004631      0.041565   \n",
       "21     2.581912       5.037098    172.381821 -0.004717      0.845947   \n",
       "24     0.468261       0.384318     10.901235  0.021790      0.197266   \n",
       "28     0.607275       0.457887     44.881279  0.011214      0.599915   \n",
       "29     3.169114      14.854513   1442.955078 -0.007952      0.031369   \n",
       "33     2.147197       2.239266     25.785185 -0.009041      0.907227   \n",
       "36     0.525156       0.416418      3.993939 -0.005894      0.352295   \n",
       "37     0.208720       0.208703      0.211952  0.077591      1.331326   \n",
       "42     0.798445       2.027711    500.894745 -0.020555      0.302460   \n",
       "43     1.105839      18.509750   2520.660645 -0.080960      0.044434   \n",
       "47     0.607787       0.518893      4.371428  0.002373      0.888672   \n",
       "50     0.506939       0.391246      3.827586  0.012733      0.244629   \n",
       "51     0.115205       0.115199      0.121158  0.032667      0.711805   \n",
       "56     0.582046       0.915274    263.826660 -0.028770      0.319336   \n",
       "57     6.717411      16.174299   2135.943359  0.023826      0.120544   \n",
       "61     3.579740       3.865564     11.202021 -0.026300      1.583984   \n",
       "64     0.418997       0.326038     11.643903  0.002794      0.348633   \n",
       "65     0.057788       0.057752      0.072176  0.069558      0.507486   \n",
       "70     0.541476       0.719009     83.879433 -0.023657      0.298401   \n",
       "71     2.809685       5.259251    399.822845 -0.069843      0.033981   \n",
       "75     1.614500       1.662392     10.543379 -0.035047      1.167969   \n",
       "78     0.331784       0.236818      3.896552 -0.002211      0.307129   \n",
       "79     0.189332       0.189308      0.193728  0.002269      1.440852   \n",
       "84     0.442103       0.496128     21.127659 -0.021555      0.230469   \n",
       "85     2.480313       4.264627    114.911110 -0.046069      0.031281   \n",
       "89     2.485110       2.776003     11.489796 -0.003180      1.109375   \n",
       "92     0.358566       0.270462      3.243094  0.012820      0.479004   \n",
       "93     0.179534       0.179510      0.184538  0.088802      1.239864   \n",
       "98     0.347361       0.387639     73.884354 -0.022177      0.218628   \n",
       "99     0.887372       4.830700   1430.934937 -0.045017      0.041963   \n",
       "103    1.797909       1.925852     10.154929  0.041392      1.418945   \n",
       "106    0.458113       0.407056      2.447005 -0.012705      0.354492   \n",
       "107    0.118114       0.118017      0.122048 -0.016731      0.751359   \n",
       "112    0.284235       0.283835     35.402115 -0.015849      0.222778   \n",
       "113    1.078778       3.367396    935.087830 -0.049529      0.074402   \n",
       "117    0.880355       0.853385      6.896774 -0.014892      1.043945   \n",
       "120    0.639980       0.614214      0.945423 -0.012499      0.524414   \n",
       "121    0.140528       0.140455      0.146678 -0.078326      0.825065   \n",
       "126    0.239751       0.204379     13.511628 -0.010411      0.227295   \n",
       "127    7.319476      12.125095   2353.144287 -0.005494      0.122070   \n",
       "131    3.949352       4.783004     18.106796 -0.006946      1.940430   \n",
       "134    0.591474       0.566980      0.921033 -0.010487      0.308838   \n",
       "135    0.171124       0.171006      0.178169 -0.000522      0.879712   \n",
       "140    0.216220       0.181954     12.239436 -0.008339      0.254173   \n",
       "141    4.238711       4.865345    129.909088  0.007506      0.087219   \n",
       "145    3.354393       3.807660     17.690266 -0.017125      1.956055   \n",
       "148    0.680383       0.670312      0.881579  0.014008      0.269775   \n",
       "149    0.161199       0.161074      0.171046  0.000102      0.785744   \n",
       "154    0.192343       0.162446     20.810057 -0.006962      0.258667   \n",
       "155    2.170675      24.702936  10239.000000  0.006425      0.109955   \n",
       "159    1.631507       1.854414      9.926829 -0.021215      1.792969   \n",
       "162    0.472232       0.452887      0.791096  0.007894      0.225586   \n",
       "163    0.169968       0.169859      0.178630  0.067644      0.775926   \n",
       "168    0.165023       0.129539     28.014925 -0.003010      0.266907   \n",
       "169    1.608467       1.686309     33.133335 -0.090782      0.053085   \n",
       "173    1.630441       1.754232      8.842424  0.003612      1.446289   \n",
       "176    0.501507       0.488571      0.851240 -0.013793      0.218506   \n",
       "177    0.161045       0.160905      0.173687 -0.077375      0.670324   \n",
       "182    0.148516       0.109167     32.947826 -0.001963      0.260788   \n",
       "183    1.291228       1.392268     52.439999 -0.029082      0.080017   \n",
       "187    1.547568       1.756489     12.333333 -0.027902      1.943359   \n",
       "190    0.449416       0.433584      0.809586 -0.012653      0.199707   \n",
       "191    0.143878       0.143632      0.153526 -0.037131      0.573322   \n",
       "196    0.146101       0.114674     47.490799  0.000908      0.268997   \n",
       "197    0.711010       0.852622     52.106384 -0.030337      0.097137   \n",
       "201    1.361276       1.660806     12.402597 -0.037486      2.171875   \n",
       "204    0.494089       0.478963      0.827801 -0.003161      0.194824   \n",
       "205    0.125200       0.124949      0.134385  0.056575      0.487145   \n",
       "210    0.125898       0.096949     87.480873  0.002217      0.264160   \n",
       "211    0.219886      10.727682   5254.940918 -0.025096      0.148466   \n",
       "215    1.307852       1.871016     19.912281  0.005372      2.329102   \n",
       "218    0.590640       0.582067      0.862103  0.000401      0.212158   \n",
       "219    0.249551       0.249369      0.257533  0.044686      1.030133   \n",
       "224    0.118595       0.081640     43.869564  0.003536      0.266983   \n",
       "225    0.912338       0.957306     23.373056 -0.020380      0.137665   \n",
       "229    1.072320       1.502367     10.138122  0.028108      1.860352   \n",
       "232    0.618305       0.611855      0.858696  0.006729      0.197266   \n",
       "233    0.325965       0.325706      0.337825 -0.015730      1.372413   \n",
       "238    0.110431       0.084935     88.872337  0.000697      0.266068   \n",
       "239    1.374585       1.434541     30.716814 -0.014020      0.211853   \n",
       "243    1.226518       1.678248     12.224490  0.072027      2.339844   \n",
       "246    0.599349       0.589859      0.857021 -0.011786      0.244385   \n",
       "247    0.330511       0.330355      0.339464 -0.022923      1.320729   \n",
       "252    0.108024       0.080463     60.730495  0.002052      0.266006   \n",
       "253    1.055969       9.782271   4412.109863  0.014655      0.163049   \n",
       "257    1.588764       1.934185      8.409327 -0.006847      1.609375   \n",
       "260    0.543855       0.536279      0.844444 -0.014924      0.222656   \n",
       "261    0.135924       0.135136      0.157368 -0.021378      0.486856   \n",
       "266    0.118641       0.105258     90.151512  0.006361      0.272369   \n",
       "267    2.036408       2.119742     31.705883  0.008759      0.340820   \n",
       "271    0.920567       1.348303     12.226666 -0.042092      1.803711   \n",
       "274    0.577120       0.570422      0.843960  0.007729      0.245605   \n",
       "275    0.195568       0.194755      0.211148 -0.064095      0.689529   \n",
       "280    0.142140       0.135760     75.487808  0.006562      0.284912   \n",
       "281    3.530484       3.609409     44.886791 -0.004160      0.290405   \n",
       "285    1.734461       2.477821     15.124031 -0.016673      2.003906   \n",
       "288    0.514395       0.502658      0.851724 -0.007349      0.244141   \n",
       "289    0.202439       0.201801      0.214921  0.030802      0.668270   \n",
       "294    0.161315       0.155446     54.636364  0.006748      0.293457   \n",
       "295    3.140450       3.317812     50.929825  0.003966      0.354370   \n",
       "299    2.463653       2.931830     14.496063 -0.000725      1.884766   \n",
       "302    0.486104       0.476649      0.833942 -0.005453      0.238281   \n",
       "303    0.016897       0.014361      0.070988  0.028532      0.187452   \n",
       "308    0.182811       0.183822     84.157028  0.009452      0.311035   \n",
       "309    2.268730       2.301948     23.118227 -0.000173      0.314453   \n",
       "313    1.196678       1.743547     10.973154 -0.008150      1.666016   \n",
       "316    0.385940       0.372567      0.801948 -0.010969      0.185791   \n",
       "317    0.075211       0.074094      0.088847  0.058065      0.274872   \n",
       "322    0.218581       0.218047     55.412373  0.008312      0.328064   \n",
       "323    1.760096       1.922224     55.558140  0.010141      0.364532   \n",
       "327    1.072445       1.597363      9.880000  0.007066      1.742188   \n",
       "330    0.351658       0.339445      0.753247  0.005403      0.169922   \n",
       "331    0.094523       0.093153      0.114329 -0.144866      0.364422   \n",
       "336    0.244720       0.248719     72.025642  0.010766      0.342896   \n",
       "337    1.025271       1.128071     30.849766 -0.023467      0.402832   \n",
       "341    0.907235       1.379985     16.192158  0.022165      2.121094   \n",
       "344    0.348096       0.335123      0.807910 -0.003455      0.185791   \n",
       "345    0.063837       0.062355      0.140430 -0.050876      0.351076   \n",
       "350    0.263784       0.272826    103.675552  0.008870      0.355942   \n",
       "351    1.299328       1.383906     28.321587 -0.004202      0.392395   \n",
       "355    0.932976       1.540862     14.085714  0.022983      1.925781   \n",
       "358    0.336839       0.324669      0.763889 -0.002376      0.174561   \n",
       "359    0.021082       0.012783      0.104713  0.038309      0.274872   \n",
       "364    0.268240       0.273705     75.800003  0.010594      0.370117   \n",
       "365    1.536790       1.627915     31.738462 -0.022831      0.503662   \n",
       "369    1.068205       1.848875     15.578313  0.033766      2.005859   \n",
       "372    0.267856       0.246468      0.789384 -0.004425      0.225098   \n",
       "373    0.062703       0.060893      0.098108 -0.065842      0.314252   \n",
       "378    0.276547       0.287534    101.193550  0.010490      0.382935   \n",
       "379    2.309118       2.351690     16.982302  0.047744      0.498779   \n",
       "383    1.351828       1.987786     14.111111  0.016806      2.018555   \n",
       "386    0.346776       0.335391      0.752809 -0.000667      0.155762   \n",
       "387    0.091389       0.090030      0.221308 -0.050658      0.577477   \n",
       "392    0.287182       0.295049     68.818184  0.008367      0.392731   \n",
       "393    1.350135       1.509979     59.300579 -0.025200      0.626160   \n",
       "397    0.709712       1.434338     15.347826 -0.032695      1.844727   \n",
       "400    0.293495       0.282055      0.849462 -0.003073      0.172363   \n",
       "401    0.032059       0.030071      0.100677  0.082732      0.276863   \n",
       "406    0.308088       0.321079     89.026665  0.010956      0.407532   \n",
       "407    1.549931       1.716602     53.303032 -0.019552      0.646118   \n",
       "411    0.505271       0.653128     15.265560  0.023098      1.796387   \n",
       "414    0.274706       0.255667      1.021390  0.003842      0.197266   \n",
       "415    0.109506       0.107946      0.132267 -0.054424      0.475520   \n",
       "420    0.304641       0.316340     83.809814  0.009613      0.416901   \n",
       "421    1.490848       1.523602     12.505377  0.049619      0.567871   \n",
       "425    1.017882       1.578896     12.699347  0.044364      1.897461   \n",
       "428    0.213796       0.191543      1.158192 -0.003924      0.170410   \n",
       "429    0.097144       0.096132      0.214323 -0.010071      0.636271   \n",
       "434    0.322378       0.331882     65.666664  0.011437      0.432861   \n",
       "435    1.320503       1.400346     31.715084 -0.010537      0.692993   \n",
       "439    0.722683       1.337174     12.239436  0.055265      1.738281   \n",
       "442    0.353244       0.342881      0.887755 -0.008110      0.158691   \n",
       "443    0.018477       0.014545      0.138051 -0.019193      0.377482   \n",
       "448    0.350267       0.363007     79.347824  0.010090      0.445557   \n",
       "449    1.202410       1.248351     19.965517  0.000548      0.706787   \n",
       "453    0.611182       1.199540     15.615385 -0.040758      1.739746   \n",
       "456    0.362987       0.352497      0.722222  0.011641      0.190430   \n",
       "457    0.180124       0.179510      0.367820  0.001369      0.988516   \n",
       "462    0.362237       0.372869     58.500000  0.009848      0.457031   \n",
       "463    1.415222       1.472912     31.168421 -0.004706      0.722900   \n",
       "467    0.411872       0.740873     13.319327  0.000266      1.638672   \n",
       "470    0.382017       0.373733      0.867299 -0.001236      0.161133   \n",
       "471    0.098753       0.097948      0.226229  0.068826      0.703431   \n",
       "476    0.373947       0.385385     59.279068  0.008171      0.466736   \n",
       "477    1.284720       1.352967     23.446352  0.006831      0.666870   \n",
       "481    0.453128       0.693614     14.168000  0.024252      1.729492   \n",
       "484    0.326091       0.315790      0.866029  0.006509      0.170898   \n",
       "485    0.098237       0.097354      0.119041  0.014319      0.498485   \n",
       "490    0.372622       0.388470     85.732239  0.009691      0.478790   \n",
       "491    1.410728       1.470606     27.714285 -0.040188      0.757812   \n",
       "495    0.486420       0.654955     14.658119 -0.007150      1.674805   \n",
       "498    0.241066       0.217831      1.269430  0.010566      0.187012   \n",
       "499    0.085675       0.084091      0.116691 -0.048167      0.459470   \n",
       "504    0.378366       0.395466    100.199997  0.005834      0.489258   \n",
       "505    1.624116       1.719836     30.842365 -0.002109      0.764282   \n",
       "509    0.985710       1.787897     11.353742  0.024264      1.634766   \n",
       "512    0.411916       0.399183      1.122642  0.011990      0.252930   \n",
       "513    0.028846       0.026502      0.106620  0.022289      0.366507   \n",
       "518    0.360320       0.380645    128.000000  0.006866      0.500000   \n",
       "519    1.885559       1.969272     35.349514  0.006627      0.888916   \n",
       "523    0.499750       0.794528     12.102880 -0.035162      1.506836   \n",
       "526    0.383590       0.373968      1.067961  0.004405      0.206055   \n",
       "527    0.182292       0.181908      0.318854 -0.060080      0.976490   \n",
       "532    0.388015       0.404199     93.391060  0.007262      0.510162   \n",
       "533    2.392235       2.442798     27.611765  0.117644      1.145996   \n",
       "537    0.414751       0.516173     12.762712  0.061763      1.478516   \n",
       "540    0.177642       0.134306      1.680628  0.011072      0.156738   \n",
       "541    0.303575       0.303537      0.462341  0.007456      1.293111   \n",
       "546    0.408862       0.426743    113.614380  0.005679      0.530487   \n",
       "547    3.524684       3.634027     31.000000 -0.032550      1.256348   \n",
       "551    0.834869       1.575434      8.018182 -0.046865      1.359375   \n",
       "554    0.202120       0.181450      1.237624  0.006113      0.173828   \n",
       "555    0.273723       0.273614      0.426817 -0.134503      1.247106   \n",
       "560    0.412462       0.456590    299.286926  0.006396      0.541161   \n",
       "561    1.277488       1.319159     16.657658  0.007819      0.902832   \n",
       "565    0.450313       0.633921     13.569106  0.031042      1.629883   \n",
       "568    0.407270       0.396567      1.221198 -0.000108      0.209473   \n",
       "569    0.544967       0.545467      0.848140  0.040224      2.186612   \n",
       "574    0.408431       0.450126    287.507935  0.003183      0.552765   \n",
       "575    2.458431       2.552430     32.361702  0.041823      1.139160   \n",
       "579    0.575359       1.007315     18.065868 -0.010039      1.473145   \n",
       "582    0.249481       0.232726      1.471111  0.015132      0.171387   \n",
       "583    0.364031       0.364083      0.504607  0.017667      1.608435   \n",
       "588    0.422745       0.436344     87.150940  0.006284      0.563843   \n",
       "589    2.234395       2.295405     25.639593 -0.025646      1.233154   \n",
       "593    0.321923       0.506649     11.435643  0.094728      1.172852   \n",
       "596    0.250837       0.229963      1.378378  0.005820      0.169434   \n",
       "597    0.501129       0.501398      0.690929  0.172116      1.943238   \n",
       "602    0.433432       0.458498    161.025314  0.003851      0.582321   \n",
       "603    2.110694       2.210378     34.619049  0.144624      1.419922   \n",
       "607    0.410828       0.711866     14.907515  0.003402      1.306641   \n",
       "610    0.465892       0.457493      1.109705  0.008152      0.188477   \n",
       "611    0.380882       0.380960      0.534119  0.055318      1.785961   \n",
       "616    0.452267       0.464636     66.506851  0.002084      0.592651   \n",
       "617    1.841598       1.952139     24.600000 -0.021749      1.116699   \n",
       "621    0.411610       0.694963     12.960784  0.027011      1.291016   \n",
       "624    0.195245       0.164367      1.584906  0.009037      0.196777   \n",
       "625    0.103375       0.102617      0.202301 -0.019303      0.727019   \n",
       "630    0.453319       0.466282     73.429626  0.003238      0.605042   \n",
       "631    1.521227       1.655462     26.803278  0.011804      1.263916   \n",
       "635    0.549315       0.852011     13.660098 -0.025472      1.396973   \n",
       "638    0.243896       0.221777      1.910638  0.013917      0.219238   \n",
       "639    0.175124       0.175002      0.263926 -0.010291      1.204165   \n",
       "644    0.474578       0.487265     73.057144  0.002472      0.624268   \n",
       "645    3.193933       3.426511     34.117950  0.067643      1.697754   \n",
       "649    0.471038       0.903930     14.661972  0.024819      1.124329   \n",
       "652    0.253847       0.223860      1.354680  0.005577      0.193359   \n",
       "653    0.360342       0.360357      0.463428 -0.063909      1.955085   \n",
       "658    0.495571       0.511253     90.350426  0.003091      0.645203   \n",
       "659    5.724276       5.825323     51.901733 -0.040571      2.265869   \n",
       "663    0.483167       0.852029      9.847458  0.050526      1.134766   \n",
       "666    0.275609       0.245112      1.621359  0.008213      0.203125   \n",
       "667    0.701356       0.701425      0.775342  0.038708      3.513270   \n",
       "672    0.508047       0.518542     54.316582  0.004841      0.659729   \n",
       "673    3.871047       4.226618     60.015545  0.075019      1.437500   \n",
       "677    0.634430       1.520104     12.202186  0.008066      1.160309   \n",
       "680    0.137616       0.079553      1.872340  0.005296      0.176270   \n",
       "681    0.674324       0.674525      0.823806  0.064486      2.896193   \n",
       "686    0.525038       0.543178    115.244896  0.001010      0.689331   \n",
       "687    3.410647       3.729453     60.825241  0.017024      1.529541   \n",
       "691    1.135430       1.877399      9.376812  0.028421      1.280273   \n",
       "694    0.284181       0.267275      1.380567  0.013946      0.177734   \n",
       "695    0.410400       0.410436      0.545141 -0.023420      2.538311   \n",
       "700    0.519624       0.539169    122.284210  0.002202      0.709045   \n",
       "701    2.024096       2.214938     39.608189 -0.094381      1.756836   \n",
       "705    0.351490       0.522235     14.879700 -0.039399      0.988770   \n",
       "708    0.409441       0.399131      0.905172  0.006340      0.255859   \n",
       "709    0.568137       0.568205      0.663952  0.011457      2.572815   \n",
       "714    0.529138       0.563514    230.145630  0.004467      0.723419   \n",
       "715    3.111147       3.176197     29.857143 -0.007052      1.428711   \n",
       "719    0.560993       1.080937     11.131147 -0.043005      1.376953   \n",
       "722    0.225452       0.199711      1.403756  0.018017      0.166992   \n",
       "723    0.393939       0.394006      0.541484 -0.031236      2.233622   \n",
       "728    0.538533       0.558187    127.000000  0.001977      0.751892   \n",
       "729    2.878687       3.178475     87.582779  0.056576      1.655762   \n",
       "733    0.410912       0.625477      6.520000 -0.042133      1.117188   \n",
       "736    0.304481       0.283303      1.029851  0.008745      0.227539   \n",
       "737    0.679284       0.679432      0.804865  0.029237      2.804452   \n",
       "742    0.560759       0.578697    114.484444  0.002156      0.786102   \n",
       "743    2.483415       2.579660     34.108570 -0.058378      1.628906   \n",
       "747    0.575936       0.804069     19.296297 -0.008424      1.125000   \n",
       "750    0.226719       0.192571      1.757282  0.012264      0.176758   \n",
       "751    0.024093       0.023460      0.076570  0.034095      0.437886   \n",
       "756    0.550202       0.566499    106.707314  0.003396      0.801086   \n",
       "757    4.062770       4.565912     93.967743  0.060758      1.824951   \n",
       "761    0.635460       0.966599      8.742222 -0.021787      1.117188   \n",
       "764    0.232005       0.194837      1.655462  0.007968      0.192383   \n",
       "765    0.305513       0.305316      0.320475 -0.010523      1.442139   \n",
       "770    0.560207       0.592579    223.780487  0.003294      0.839996   \n",
       "771    4.953011       5.731565     52.698631 -0.033712      1.899414   \n",
       "775    1.166055       2.159798     10.807487 -0.037435      1.101562   \n",
       "778    0.173313       0.131827      1.423645  0.011275      0.216309   \n",
       "779    0.425168       0.425027      0.437876  0.056959      2.079911   \n",
       "784    0.548982       0.589416    286.030304  0.004287      0.864166   \n",
       "785    3.095836       3.300892     38.135136 -0.010246      1.507324   \n",
       "789    0.637991       1.015950      8.636364 -0.070283      1.142578   \n",
       "792    0.392105       0.370166      0.910448  0.001901      0.187500   \n",
       "793    0.474286       0.474084      0.486030 -0.074846      2.247890   \n",
       "798    0.493440       0.512047    146.134018  0.004379      0.865173   \n",
       "799    2.897871       3.862682     69.468086 -0.036480      1.689453   \n",
       "803    1.395874       2.364907     14.587629 -0.017237      1.425781   \n",
       "806    0.349691       0.315246      1.020100  0.005220      0.180908   \n",
       "807    0.406058       0.405635      0.418068  0.074904      1.685338   \n",
       "812    0.394457       0.402549     81.120483  0.002309      0.821899   \n",
       "813    3.319094       4.482933    220.176468 -0.051873      1.873291   \n",
       "817    1.289036       1.963430     16.846153  0.020104      1.390137   \n",
       "820    0.269433       0.238618      1.045455  0.015175      0.235840   \n",
       "821    0.402591       0.402085      0.461674 -0.040055      1.738490   \n",
       "826    0.158960       0.174163    268.473694  0.002003      0.700516   \n",
       "827    3.440193       3.584890     34.111111 -0.007737      1.966309   \n",
       "831    1.033867       1.288793     16.386667  0.020504      1.200195   \n",
       "834    0.459910       0.439555      1.000123 -0.006742      0.204346   \n",
       "835    0.135434       0.134477      0.158780  0.183239      0.654969   \n",
       "840    0.387273       0.378300     49.218979  0.001302      0.678223   \n",
       "841    1.951129       1.937069     14.300971  0.076730      1.769531   \n",
       "845    0.667694       0.897578     12.477477 -0.010974      1.550781   \n",
       "\n",
       "     mean_abs_diff  spearman  q01_abs_diff  q05_abs_diff  q50_abs_diff  \\\n",
       "0         0.021565 -0.007118      0.000244      0.001709      0.016113   \n",
       "4         0.009883  0.009918      0.000122      0.000732      0.007568   \n",
       "5         0.006171 -0.009046      0.000122      0.000535      0.004852   \n",
       "9         0.252936  0.021972      0.013672      0.058105      0.260742   \n",
       "12        0.022439 -0.002995      0.000244      0.001465      0.016632   \n",
       "16        0.031187 -0.004826      0.000285      0.001953      0.020996   \n",
       "17        0.007834 -0.010430      0.000132      0.000500      0.005886   \n",
       "21        0.306409  0.003983      0.009131      0.055420      0.300781   \n",
       "24        0.028536  0.022656      0.000488      0.002197      0.022949   \n",
       "28        0.024096  0.028088      0.000244      0.001709      0.018066   \n",
       "29        0.008506  0.000496      0.000185      0.000719      0.006996   \n",
       "33        0.285435 -0.010404      0.007178      0.047852      0.257812   \n",
       "36        0.041516 -0.007745      0.000977      0.005127      0.037842   \n",
       "37        1.306384  0.044163      1.291267      1.293877      1.298276   \n",
       "42        0.056521 -0.019346      0.000977      0.004395      0.049072   \n",
       "43        0.014174 -0.080748      0.000271      0.001410      0.012455   \n",
       "47        0.165950  0.018760      0.001953      0.009766      0.128906   \n",
       "50        0.030028  0.015564      0.000488      0.002930      0.025879   \n",
       "51        0.680279  0.132161      0.648305      0.675556      0.679355   \n",
       "56        0.058462 -0.025815      0.000977      0.004883      0.050781   \n",
       "57        0.037131  0.027201      0.000725      0.002431      0.037491   \n",
       "61        0.755728 -0.028483      0.042334      0.369385      0.760742   \n",
       "64        0.032749  0.014042      0.000488      0.002930      0.028809   \n",
       "65        0.411542  0.052694      0.379396      0.382086      0.413536   \n",
       "70        0.061895 -0.020848      0.000977      0.004883      0.053711   \n",
       "71        0.019957  0.002694      0.009033      0.012682      0.020142   \n",
       "75        0.429652 -0.041957      0.009131      0.037109      0.437500   \n",
       "78        0.020602 -0.003152      0.000488      0.001465      0.016113   \n",
       "79        1.400580  0.085245      1.314402      1.347102      1.408402   \n",
       "84        0.052470 -0.019529      0.000977      0.003906      0.043945   \n",
       "85        0.014492 -0.008604      0.006639      0.009416      0.014618   \n",
       "89        0.483756 -0.004213      0.018896      0.073242      0.487305   \n",
       "92        0.024924  0.007116      0.000977      0.003418      0.022461   \n",
       "93        1.199590  0.094040      1.140775      1.171515      1.203815   \n",
       "98        0.044104 -0.026056      0.000977      0.002930      0.034180   \n",
       "99        0.016000  0.007064      0.004896      0.008246      0.015747   \n",
       "103       0.543642  0.042698      0.011719      0.044922      0.550781   \n",
       "106       0.044589 -0.006039      0.004883      0.015137      0.043457   \n",
       "107       0.724541  0.038277      0.633897      0.679010      0.740360   \n",
       "112       0.037543 -0.019328      0.000977      0.001953      0.027344   \n",
       "113       0.011405 -0.045209      0.003181      0.005771      0.011169   \n",
       "117       0.282334 -0.012600      0.003906      0.021484      0.250000   \n",
       "120       0.060864 -0.002786      0.030273      0.038818      0.059082   \n",
       "121       0.787243 -0.141759      0.713427      0.744767      0.779016   \n",
       "126       0.034986 -0.014315      0.000000      0.001953      0.023438   \n",
       "127       0.092130 -0.033861      0.048609      0.082898      0.093323   \n",
       "131       1.141272 -0.015383      0.031250      0.132568      1.252441   \n",
       "134       0.057278 -0.005885      0.030681      0.038086      0.055420   \n",
       "135       0.837752  0.052533      0.705659      0.812012      0.845262   \n",
       "140       0.035862 -0.018406      0.000977      0.002930      0.027344   \n",
       "141       0.067032  0.034911      0.052185      0.059760      0.067444   \n",
       "145       1.142103  0.009171      0.025391      0.119141      1.288086   \n",
       "148       0.072066  0.002092      0.047527      0.055908      0.071289   \n",
       "149       0.731071  0.005372      0.647481      0.691194      0.725244   \n",
       "154       0.031763 -0.018691      0.000977      0.002930      0.023438   \n",
       "155       0.075135  0.027464      0.059243      0.066296      0.075439   \n",
       "159       0.816552 -0.028128      0.020215      0.089600      0.877930   \n",
       "162       0.050131 -0.002101      0.022949      0.031738      0.049561   \n",
       "163       0.731628  0.060866      0.659254      0.703027      0.736477   \n",
       "168       0.026266 -0.011222      0.000000      0.001953      0.018555   \n",
       "169       0.034972  0.001520      0.028956      0.032349      0.035034   \n",
       "173       0.589704 -0.001843      0.009766      0.044678      0.613770   \n",
       "176       0.050000 -0.018795      0.029216      0.036133      0.049561   \n",
       "177       0.612913 -0.026785      0.513128      0.576743      0.615649   \n",
       "182       0.021546 -0.015994      0.000000      0.001953      0.013672   \n",
       "183       0.045048 -0.056886      0.038438      0.041504      0.045166   \n",
       "187       0.780742 -0.032075      0.015625      0.074219      0.800781   \n",
       "190       0.038317  0.000484      0.021729      0.026855      0.037598   \n",
       "191       0.530874 -0.006490      0.441612      0.496697      0.537072   \n",
       "196       0.023547 -0.009827      0.000000      0.001953      0.016602   \n",
       "197       0.040883 -0.078225      0.029893      0.035645      0.040527   \n",
       "201       0.898635 -0.035233      0.031250      0.131836      0.937500   \n",
       "204       0.037017 -0.013470      0.021079      0.026367      0.036377   \n",
       "205       0.449193  0.003710      0.326014      0.402821      0.451695   \n",
       "210       0.017484 -0.003408      0.000000      0.000977      0.010742   \n",
       "211       0.023877  0.011452      0.008896      0.012695      0.022461   \n",
       "215       1.042509  0.010510      0.036523      0.203125      1.115234   \n",
       "218       0.051553 -0.005634      0.033936      0.039795      0.051270   \n",
       "219       0.989739  0.137209      0.862356      0.931333      0.996683   \n",
       "224       0.016438 -0.000843      0.000000      0.000977      0.009766   \n",
       "225       0.065671 -0.049760      0.039819      0.053223      0.066162   \n",
       "229       0.775614  0.026777      0.031250      0.121094      0.769531   \n",
       "232       0.053999  0.000763      0.035076      0.042969      0.053955   \n",
       "233       1.305340 -0.025474      1.095804      1.236563      1.323164   \n",
       "238       0.014603 -0.003193      0.000000      0.000000      0.009766   \n",
       "239       0.122173 -0.065574      0.092500      0.106445      0.122559   \n",
       "243       0.991634  0.047350      0.029980      0.187500      0.992188   \n",
       "246       0.057040 -0.023784      0.037517      0.044678      0.056641   \n",
       "247       1.272157 -0.058165      1.106757      1.217929      1.279280   \n",
       "252       0.015692  0.001305      0.000000      0.001953      0.010742   \n",
       "253       0.083081  0.034519      0.060327      0.073730      0.083496   \n",
       "257       0.859472 -0.024700      0.023438      0.152344      0.898438   \n",
       "260       0.048805 -0.019072      0.032471      0.039062      0.048584   \n",
       "261       0.412969 -0.032225      0.279165      0.346234      0.420409   \n",
       "266       0.021534  0.004546      0.000000      0.001953      0.017578   \n",
       "267       0.179885 -0.008222      0.139214      0.160156      0.179688   \n",
       "271       0.762092 -0.032200      0.023438      0.163086      0.742676   \n",
       "274       0.060274 -0.002326      0.042969      0.049561      0.059814   \n",
       "275       0.625638 -0.029374      0.424509      0.554480      0.634255   \n",
       "280       0.031288  0.008372      0.001953      0.005859      0.029297   \n",
       "281       0.228209 -0.057530      0.174678      0.220215      0.229492   \n",
       "285       1.197476 -0.025932      0.092773      0.464844      1.207031   \n",
       "288       0.047998 -0.025707      0.029785      0.036377      0.047607   \n",
       "289       0.619246  0.080404      0.433062      0.543789      0.629020   \n",
       "294       0.038960  0.007186      0.001953      0.009766      0.037109   \n",
       "295       0.272445 -0.053811      0.212280      0.257104      0.273926   \n",
       "299       1.246964 -0.002507      0.053516      0.274902      1.320312   \n",
       "302       0.045858 -0.007657      0.029785      0.036133      0.045410   \n",
       "303       0.040812  0.076558      0.001915      0.004952      0.037497   \n",
       "308       0.046512  0.011066      0.003906      0.013672      0.044922   \n",
       "309       0.209300  0.005923      0.144580      0.195361      0.209229   \n",
       "313       0.876101 -0.007202      0.050781      0.299805      0.859375   \n",
       "316       0.031354 -0.005840      0.016113      0.021240      0.031250   \n",
       "317       0.226649  0.066821      0.072231      0.160291      0.233623   \n",
       "322       0.059284  0.010663      0.005859      0.023438      0.058594   \n",
       "323       0.240680  0.018023      0.156885      0.225146      0.242188   \n",
       "327       0.918397  0.011998      0.145898      0.492188      0.859375   \n",
       "330       0.029088  0.001793      0.012695      0.018799      0.029053   \n",
       "331       0.292698 -0.082924      0.080933      0.212374      0.305274   \n",
       "336       0.068901  0.011776      0.007812      0.029297      0.068359   \n",
       "337       0.212310 -0.032187      0.130205      0.185107      0.213867   \n",
       "341       0.995629  0.112631      0.190234      0.646484      0.929688   \n",
       "344       0.029705 -0.007906      0.013184      0.019287      0.029541   \n",
       "345       0.189076  0.020717      0.031174      0.118424      0.195586   \n",
       "350       0.075931  0.008284      0.009766      0.035156      0.076172   \n",
       "351       0.230217  0.003202      0.189561      0.211914      0.230469   \n",
       "355       0.929804 -0.013090      0.191602      0.601562      0.843750   \n",
       "358       0.030131 -0.003871      0.015625      0.020996      0.029785   \n",
       "359       0.035849  0.084456      0.000512      0.002011      0.020446   \n",
       "364       0.079964  0.012719      0.013672      0.039062      0.080078   \n",
       "365       0.311572  0.005374      0.242070      0.280273      0.311523   \n",
       "369       1.029910  0.020146      0.308691      0.664062      0.960938   \n",
       "372       0.022701 -0.000960      0.008301      0.012695      0.021973   \n",
       "373       0.191410  0.019813      0.025485      0.107832      0.199382   \n",
       "378       0.084337  0.013384      0.017578      0.044922      0.083984   \n",
       "379       0.376303  0.001637      0.302285      0.355469      0.377930   \n",
       "383       1.176172  0.023768      0.259570      0.823242      1.125000   \n",
       "386       0.032009 -0.003691      0.017578      0.022461      0.031250   \n",
       "387       0.262256 -0.018378      0.182492      0.201896      0.252864   \n",
       "392       0.089569  0.008641      0.021484      0.050781      0.089844   \n",
       "393       0.372419 -0.031893      0.281250      0.339844      0.371094   \n",
       "397       0.731556  0.004577      0.109375      0.296875      0.648438   \n",
       "400       0.026530  0.000234      0.011719      0.017090      0.026367   \n",
       "401       0.093348  0.070377      0.010477      0.032987      0.094937   \n",
       "406       0.097800  0.010594      0.031250      0.060547      0.097656   \n",
       "407       0.404404  0.003923      0.331797      0.376953      0.403809   \n",
       "411       0.585976  0.012139      0.166797      0.351562      0.539062   \n",
       "414       0.024636 -0.004665      0.008301      0.014160      0.024414   \n",
       "415       0.381108 -0.061330      0.150956      0.269465      0.394895   \n",
       "420       0.098415  0.012467      0.033203      0.062500      0.097656   \n",
       "421       0.361906  0.015911      0.328125      0.339844      0.360840   \n",
       "425       0.928839 -0.006347      0.192969      0.531250      0.859375   \n",
       "428       0.018159  0.002101      0.003906      0.008301      0.017578   \n",
       "429       0.316292  0.030103      0.223718      0.260260      0.308420   \n",
       "434       0.107163  0.010866      0.042969      0.072266      0.107422   \n",
       "435       0.409939  0.071475      0.272639      0.375000      0.410156   \n",
       "439       0.718967  0.057699      0.104297      0.375000      0.609375   \n",
       "442       0.036177  0.008528      0.021973      0.027832      0.035156   \n",
       "443       0.045346  0.000217      0.002608      0.006397      0.041293   \n",
       "448       0.118019  0.011936      0.052734      0.084668      0.119141   \n",
       "449       0.401917 -0.012065      0.305962      0.371094      0.402344   \n",
       "453       0.604333 -0.052275      0.091211      0.242188      0.531250   \n",
       "456       0.037489  0.004408      0.016929      0.026855      0.037598   \n",
       "457       0.558555  0.015097      0.474553      0.498315      0.545290   \n",
       "462       0.123706  0.011032      0.060547      0.091797      0.123047   \n",
       "463       0.447776 -0.049150      0.375430      0.410156      0.447266   \n",
       "467       0.388416 -0.002302      0.010547      0.070312      0.304688   \n",
       "470       0.040740  0.001698      0.023276      0.029785      0.041016   \n",
       "471       0.338791  0.035737      0.273795      0.289995      0.327531   \n",
       "476       0.129530  0.008072      0.066406      0.097656      0.130859   \n",
       "477       0.399222 -0.004605      0.271538      0.365234      0.400391   \n",
       "481       0.476263 -0.000888      0.031250      0.164062      0.414062   \n",
       "484       0.033331  0.015238      0.018555      0.024414      0.033203   \n",
       "485       0.402779  0.005717      0.216217      0.305138      0.419812   \n",
       "490       0.131238  0.013318      0.070312      0.101562      0.130859   \n",
       "491       0.432765 -0.020492      0.251296      0.392578      0.435547   \n",
       "495       0.520839 -0.023757      0.078125      0.252930      0.460938   \n",
       "498       0.021796 -0.005020      0.006348      0.011719      0.020996   \n",
       "499       0.330236  0.004953      0.071826      0.192178      0.342865   \n",
       "504       0.136063  0.013454      0.076172      0.109375      0.136719   \n",
       "505       0.480046  0.001031      0.380391      0.451172      0.476562   \n",
       "509       0.808131  0.004440      0.089941      0.333984      0.718750   \n",
       "512       0.043697  0.006489      0.021812      0.032227      0.043457   \n",
       "513       0.097597  0.039227      0.032939      0.053007      0.088256   \n",
       "518       0.132880  0.007947      0.078125      0.107422      0.132812   \n",
       "519       0.589781  0.002880      0.409043      0.542969      0.589844   \n",
       "523       0.443871 -0.003178      0.018359      0.101562      0.382812   \n",
       "526       0.040120 -0.002264      0.020020      0.029785      0.040039   \n",
       "527       0.619888 -0.032483      0.543702      0.568990      0.611015   \n",
       "532       0.145065  0.011075      0.091797      0.119141      0.144531   \n",
       "533       0.813959  0.023442      0.343477      0.679004      0.833984   \n",
       "537       0.400002  0.026639      0.031250      0.105469      0.351562   \n",
       "540       0.012805  0.005889      0.000488      0.002441      0.011230   \n",
       "541       0.951693 -0.031404      0.893487      0.910342      0.938736   \n",
       "546       0.155432  0.006220      0.101562      0.128906      0.156250   \n",
       "547       0.970430 -0.022374      0.543379      0.873047      0.982422   \n",
       "551       0.615146 -0.019253      0.031250      0.148438      0.539062   \n",
       "554       0.019097  0.003274      0.005371      0.009277      0.018555   \n",
       "555       0.893328 -0.103301      0.827991      0.852250      0.883531   \n",
       "560       0.158705  0.012571      0.107422      0.132812      0.158203   \n",
       "561       0.515779  0.072171      0.458984      0.480469      0.513672   \n",
       "565       0.473891  0.012643      0.078125      0.203125      0.437500   \n",
       "568       0.044075  0.007417      0.025879      0.034180      0.043457   \n",
       "569       1.681125 -0.014194      1.609587      1.625012      1.661775   \n",
       "574       0.160618  0.008953      0.111328      0.134766      0.160156   \n",
       "575       0.792398  0.071805      0.529727      0.700293      0.791016   \n",
       "579       0.503260 -0.000668      0.018359      0.117188      0.453125   \n",
       "582       0.026155  0.018294      0.008301      0.015625      0.025391   \n",
       "583       1.278564  0.112266      1.217270      1.231292      1.265685   \n",
       "588       0.168954  0.006902      0.119141      0.142578      0.169922   \n",
       "589       0.859100 -0.067910      0.651250      0.802734      0.863281   \n",
       "593       0.221990  0.050873      0.007812      0.015625      0.117188   \n",
       "596       0.026141  0.013375      0.008789      0.014648      0.024902   \n",
       "597       1.586179  0.018699      1.530317      1.539507      1.570651   \n",
       "602       0.177046  0.008583      0.125000      0.152344      0.177734   \n",
       "603       0.984217  0.006356      0.551191      0.830273      0.999023   \n",
       "607       0.303770  0.028162      0.007812      0.031250      0.226562   \n",
       "610       0.054975  0.012954      0.026855      0.042480      0.054932   \n",
       "611       1.412949  0.031417      1.361008      1.369412      1.399062   \n",
       "616       0.186632  0.002831      0.136719      0.162109      0.187500   \n",
       "617       0.724484 -0.010258      0.415385      0.635840      0.730469   \n",
       "621       0.322702  0.040585      0.000000      0.015625      0.199219   \n",
       "624       0.017853  0.010440      0.001465      0.004883      0.017090   \n",
       "625       0.400570 -0.016101      0.344884      0.353395      0.390495   \n",
       "630       0.190662  0.003574      0.138672      0.166016      0.191406   \n",
       "631       0.767697 -0.001633      0.548945      0.681836      0.761719   \n",
       "635       0.450266 -0.002157      0.039062      0.148438      0.394531   \n",
       "638       0.026394  0.015804      0.003906      0.011890      0.025879   \n",
       "639       0.858097  0.058356      0.815276      0.824965      0.856015   \n",
       "644       0.203237  0.002284      0.154297      0.177734      0.203125   \n",
       "645       1.219758  0.066391      0.674629      0.978027      1.237305   \n",
       "649       0.298984  0.012592      0.007812      0.019531      0.222656   \n",
       "652       0.023712  0.018169      0.003906      0.010254      0.022461   \n",
       "653       1.633391  0.030082      1.583734      1.598286      1.633986   \n",
       "658       0.216439  0.006513      0.165371      0.191406      0.216797   \n",
       "659       1.776920  0.034714      0.399062      1.301172      1.837891   \n",
       "663       0.327145  0.041186      0.000000      0.015625      0.238281   \n",
       "666       0.027048  0.008264      0.005859      0.012695      0.025391   \n",
       "667       3.316026  0.096552      3.274062      3.288668      3.298522   \n",
       "672       0.225288  0.005034      0.175137      0.201172      0.226562   \n",
       "673       1.149841  0.099979      0.883418      1.064648      1.156250   \n",
       "677       0.381107  0.013044      0.001367      0.023438      0.293945   \n",
       "680       0.008143  0.019136      0.000000      0.000488      0.005859   \n",
       "681       2.582277  0.136936      2.538258      2.541200      2.570968   \n",
       "686       0.238976  0.001001      0.187500      0.214844      0.240234   \n",
       "687       1.203486  0.076847      0.725801      1.131934      1.205078   \n",
       "691       0.624642 -0.016700      0.038745      0.198242      0.589844   \n",
       "694       0.032552  0.017096      0.010581      0.019043      0.031738   \n",
       "695       2.095706 -0.060634      2.046421      2.061811      2.081560   \n",
       "700       0.243286  0.005061      0.193359      0.218750      0.244141   \n",
       "701       1.110065 -0.098317      0.535117      0.879297      1.125000   \n",
       "705       0.206102 -0.067031      0.000000      0.011719      0.144531   \n",
       "708       0.048355  0.011620      0.021484      0.034668      0.048340   \n",
       "709       2.335556  0.009163      2.289006      2.307166      2.324615   \n",
       "714       0.251372  0.002493      0.200527      0.224609      0.251953   \n",
       "715       1.111480 -0.017341      0.601738      1.010840      1.130859   \n",
       "719       0.425486 -0.036488      0.007812      0.034180      0.335938   \n",
       "722       0.022345  0.013347      0.002930      0.008301      0.021484   \n",
       "723       1.795317  0.044818      1.739064      1.757422      1.790122   \n",
       "728       0.263675 -0.001037      0.210293      0.237012      0.263672   \n",
       "729       1.217247 -0.030813      0.726074      1.125000      1.225586   \n",
       "733       0.263855 -0.040038      0.000000      0.015625      0.167969   \n",
       "736       0.036414  0.016478      0.007812      0.019043      0.035156   \n",
       "737       2.542248  0.111989      2.490165      2.503577      2.535627   \n",
       "742       0.282584  0.001183      0.218750      0.253906      0.285156   \n",
       "743       1.032031 -0.062585      0.580879      0.903613      1.023438   \n",
       "747       0.313290  0.013763      0.007812      0.046875      0.295898   \n",
       "750       0.021395  0.021453      0.001953      0.006348      0.020020   \n",
       "751       0.147727 -0.060572      0.025366      0.092114      0.154864   \n",
       "756       0.284464  0.002218      0.217461      0.253906      0.285156   \n",
       "757       1.449965  0.051553      0.870840      1.345703      1.455078   \n",
       "761       0.333666 -0.004649      0.007812      0.026367      0.288086   \n",
       "764       0.022602  0.021099      0.001465      0.006348      0.020996   \n",
       "765       1.363804 -0.018369      1.222820      1.278892      1.366892   \n",
       "770       0.298991  0.001966      0.218750      0.265625      0.300781   \n",
       "771       1.594395 -0.061291      1.176152      1.445312      1.597656   \n",
       "775       0.543181 -0.057100      0.032617      0.101562      0.539062   \n",
       "778       0.015029 -0.004281      0.000488      0.001953      0.013184   \n",
       "779       2.005483  0.069906      1.745152      1.944964      2.005864   \n",
       "784       0.302922  0.000005      0.205742      0.261719      0.304688   \n",
       "785       1.185812 -0.011821      0.794922      1.060547      1.181641   \n",
       "789       0.346962 -0.051287      0.007812      0.023438      0.290039   \n",
       "792       0.040192 -0.002031      0.010742      0.021973      0.039062   \n",
       "793       2.174021  0.005330      1.922179      2.093942      2.180643   \n",
       "798       0.279695 -0.006942      0.132812      0.210938      0.285156   \n",
       "799       1.184997 -0.024219      0.420332      0.814160      1.184570   \n",
       "803       0.614956 -0.027108      0.023438      0.089844      0.617188   \n",
       "806       0.033523  0.006793      0.001465      0.008301      0.033325   \n",
       "807       1.616396  0.033294      1.339604      1.502433      1.627490   \n",
       "812       0.232021 -0.007180      0.074219      0.171875      0.238281   \n",
       "813       1.287091 -0.025912      0.199434      0.455567      1.337891   \n",
       "817       0.404566  0.021095      0.006543      0.031250      0.358398   \n",
       "820       0.032437  0.005523      0.001953      0.007812      0.031738   \n",
       "821       1.503579 -0.005725      1.215207      1.413174      1.519079   \n",
       "826       0.084888 -0.002407      0.003906      0.023438      0.082031   \n",
       "827       1.416369  0.029226      0.235859      1.214746      1.443359   \n",
       "831       0.472467  0.003687      0.015625      0.100586      0.472656   \n",
       "834       0.047568 -0.004929      0.009766      0.024414      0.048096   \n",
       "835       0.546709  0.107217      0.306801      0.436898      0.553572   \n",
       "840       0.242459  0.000591      0.144531      0.175781      0.224609   \n",
       "841       0.963114  0.041732      0.027344      0.182324      1.035156   \n",
       "845       0.362517 -0.009205      0.006543      0.027344      0.322266   \n",
       "\n",
       "     q95_abs_diff  q99_abs_diff shape_a shape_b note  \n",
       "0        0.060791      0.127278     NaN     NaN  NaN  \n",
       "4        0.023434      0.040568     NaN     NaN  NaN  \n",
       "5        0.015239      0.021301     NaN     NaN  NaN  \n",
       "9        0.419006      0.477258     NaN     NaN  NaN  \n",
       "12       0.064941      0.096353     NaN     NaN  NaN  \n",
       "16       0.080315      0.259021     NaN     NaN  NaN  \n",
       "17       0.020419      0.025437     NaN     NaN  NaN  \n",
       "21       0.593750      0.704395     NaN     NaN  NaN  \n",
       "24       0.073160      0.113362     NaN     NaN  NaN  \n",
       "28       0.063089      0.121575     NaN     NaN  NaN  \n",
       "29       0.021604      0.027104     NaN     NaN  NaN  \n",
       "33       0.591309      0.731934     NaN     NaN  NaN  \n",
       "36       0.089111      0.139402     NaN     NaN  NaN  \n",
       "37       1.330326      1.331326     NaN     NaN  NaN  \n",
       "42       0.134277      0.176633     NaN     NaN  NaN  \n",
       "43       0.030662      0.038589     NaN     NaN  NaN  \n",
       "47       0.441406      0.577344     NaN     NaN  NaN  \n",
       "50       0.071045      0.103352     NaN     NaN  NaN  \n",
       "51       0.691467      0.711695     NaN     NaN  NaN  \n",
       "56       0.134967      0.180012     NaN     NaN  NaN  \n",
       "57       0.069806      0.081073     NaN     NaN  NaN  \n",
       "61       1.133057      1.293262     NaN     NaN  NaN  \n",
       "64       0.073932      0.113198     NaN     NaN  NaN  \n",
       "65       0.418936      0.472687     NaN     NaN  NaN  \n",
       "70       0.144775      0.184062     NaN     NaN  NaN  \n",
       "71       0.026879      0.031139     NaN     NaN  NaN  \n",
       "75       0.842041      0.963525     NaN     NaN  NaN  \n",
       "78       0.053955      0.082681     NaN     NaN  NaN  \n",
       "79       1.411452      1.415401     NaN     NaN  NaN  \n",
       "84       0.130371      0.166016     NaN     NaN  NaN  \n",
       "85       0.019324      0.021444     NaN     NaN  NaN  \n",
       "89       0.884766      1.000293     NaN     NaN  NaN  \n",
       "92       0.050537      0.076248     NaN     NaN  NaN  \n",
       "93       1.212064      1.237065     NaN     NaN  NaN  \n",
       "98       0.122314      0.161133     NaN     NaN  NaN  \n",
       "99       0.023676      0.028769     NaN     NaN  NaN  \n",
       "103      1.052002      1.183545     NaN     NaN  NaN  \n",
       "106      0.074463      0.099202     NaN     NaN  NaN  \n",
       "107      0.746760      0.749559     NaN     NaN  NaN  \n",
       "112      0.115723      0.167114     NaN     NaN  NaN  \n",
       "113      0.015741      0.024855     NaN     NaN  NaN  \n",
       "117      0.675781      0.839795     NaN     NaN  NaN  \n",
       "120      0.088379      0.118001     NaN     NaN  NaN  \n",
       "121      0.811116      0.817516     NaN     NaN  NaN  \n",
       "126      0.112305      0.179524     NaN     NaN  NaN  \n",
       "127      0.100098      0.102899     NaN     NaN  NaN  \n",
       "131      1.673828      1.804297     NaN     NaN  NaN  \n",
       "134      0.080078      0.119707     NaN     NaN  NaN  \n",
       "135      0.850311      0.877712     NaN     NaN  NaN  \n",
       "140      0.103516      0.190022     NaN     NaN  NaN  \n",
       "141      0.073203      0.076209     NaN     NaN  NaN  \n",
       "145      1.699219      1.824756     NaN     NaN  NaN  \n",
       "148      0.089191      0.113770     NaN     NaN  NaN  \n",
       "149      0.758743      0.766583     NaN     NaN  NaN  \n",
       "154      0.090820      0.197263     NaN     NaN  NaN  \n",
       "155      0.082764      0.087783     NaN     NaN  NaN  \n",
       "159      1.428955      1.593652     NaN     NaN  NaN  \n",
       "162      0.069092      0.089436     NaN     NaN  NaN  \n",
       "163      0.744476      0.767717     NaN     NaN  NaN  \n",
       "168      0.074219      0.194417     NaN     NaN  NaN  \n",
       "169      0.037964      0.040745     NaN     NaN  NaN  \n",
       "173      1.129150      1.292969     NaN     NaN  NaN  \n",
       "176      0.063721      0.077717     NaN     NaN  NaN  \n",
       "177      0.637124      0.648905     NaN     NaN  NaN  \n",
       "182      0.064453      0.186685     NaN     NaN  NaN  \n",
       "183      0.048340      0.050022     NaN     NaN  NaN  \n",
       "187      1.523438      1.669580     NaN     NaN  NaN  \n",
       "190      0.050293      0.065510     NaN     NaN  NaN  \n",
       "191      0.555897      0.569222     NaN     NaN  NaN  \n",
       "196      0.063477      0.185215     NaN     NaN  NaN  \n",
       "197      0.046631      0.055884     NaN     NaN  NaN  \n",
       "201      1.583984      1.846289     NaN     NaN  NaN  \n",
       "204      0.048584      0.065183     NaN     NaN  NaN  \n",
       "205      0.476476      0.481145     NaN     NaN  NaN  \n",
       "210      0.050781      0.172524     NaN     NaN  NaN  \n",
       "211      0.035156      0.067779     NaN     NaN  NaN  \n",
       "215      1.775879      2.092383     NaN     NaN  NaN  \n",
       "218      0.062988      0.073242     NaN     NaN  NaN  \n",
       "219      1.019134      1.023662     NaN     NaN  NaN  \n",
       "224      0.046875      0.170083     NaN     NaN  NaN  \n",
       "225      0.074707      0.078125     NaN     NaN  NaN  \n",
       "229      1.458008      1.629541     NaN     NaN  NaN  \n",
       "232      0.064209      0.072021     NaN     NaN  NaN  \n",
       "233      1.338463      1.357954     NaN     NaN  NaN  \n",
       "238      0.039062      0.161284     NaN     NaN  NaN  \n",
       "239      0.135742      0.141548     NaN     NaN  NaN  \n",
       "243      1.771729      1.987158     NaN     NaN  NaN  \n",
       "246      0.069092      0.084795     NaN     NaN  NaN  \n",
       "247      1.304197      1.314295     NaN     NaN  NaN  \n",
       "252      0.038086      0.156084     NaN     NaN  NaN  \n",
       "253      0.090820      0.095649     NaN     NaN  NaN  \n",
       "257      1.378906      1.497022     NaN     NaN  NaN  \n",
       "260      0.058105      0.066243     NaN     NaN  NaN  \n",
       "261      0.451003      0.459749     NaN     NaN  NaN  \n",
       "266      0.043945      0.156250     NaN     NaN  NaN  \n",
       "267      0.199707      0.235523     NaN     NaN  NaN  \n",
       "271      1.430420      1.642481     NaN     NaN  NaN  \n",
       "274      0.071533      0.083496     NaN     NaN  NaN  \n",
       "275      0.669435      0.683344     NaN     NaN  NaN  \n",
       "280      0.052734      0.156899     NaN     NaN  NaN  \n",
       "281      0.236816      0.238770     NaN     NaN  NaN  \n",
       "285      1.779297      1.899707     NaN     NaN  NaN  \n",
       "288      0.059082      0.072100     NaN     NaN  NaN  \n",
       "289      0.655271      0.662936     NaN     NaN  NaN  \n",
       "294      0.062500      0.153643     NaN     NaN  NaN  \n",
       "295      0.287109      0.293838     NaN     NaN  NaN  \n",
       "299      1.662598      1.762647     NaN     NaN  NaN  \n",
       "302      0.055908      0.066243     NaN     NaN  NaN  \n",
       "303      0.081703      0.142737     NaN     NaN  NaN  \n",
       "308      0.072266      0.155918     NaN     NaN  NaN  \n",
       "309      0.228247      0.241592     NaN     NaN  NaN  \n",
       "313      1.470703      1.602832     NaN     NaN  NaN  \n",
       "316      0.041260      0.049153     NaN     NaN  NaN  \n",
       "317      0.266916      0.272682     NaN     NaN  NaN  \n",
       "322      0.087891      0.160156     NaN     NaN  NaN  \n",
       "323      0.254614      0.277622     NaN     NaN  NaN  \n",
       "327      1.574463      1.685205     NaN     NaN  NaN  \n",
       "330      0.039062      0.045491     NaN     NaN  NaN  \n",
       "331      0.336874      0.345619     NaN     NaN  NaN  \n",
       "336      0.099609      0.165030     NaN     NaN  NaN  \n",
       "337      0.231885      0.258467     NaN     NaN  NaN  \n",
       "341      1.742676      1.999658     NaN     NaN  NaN  \n",
       "344      0.039307      0.045410     NaN     NaN  NaN  \n",
       "345      0.234049      0.252879     NaN     NaN  NaN  \n",
       "350      0.107422      0.162432     NaN     NaN  NaN  \n",
       "351      0.245117      0.264658     NaN     NaN  NaN  \n",
       "355      1.722168      1.834961     NaN     NaN  NaN  \n",
       "358      0.040039      0.047444     NaN     NaN  NaN  \n",
       "359      0.116866      0.266807     NaN     NaN  NaN  \n",
       "364      0.111328      0.162100     NaN     NaN  NaN  \n",
       "365      0.338330      0.399863     NaN     NaN  NaN  \n",
       "369      1.829102      1.911426     NaN     NaN  NaN  \n",
       "372      0.033691      0.042480     NaN     NaN  NaN  \n",
       "373      0.246731      0.260811     NaN     NaN  NaN  \n",
       "378      0.115234      0.166006     NaN     NaN  NaN  \n",
       "379      0.396484      0.410703     NaN     NaN  NaN  \n",
       "383      1.829346      1.941699     NaN     NaN  NaN  \n",
       "386      0.042480      0.055989     NaN     NaN  NaN  \n",
       "387      0.363133      0.421226     NaN     NaN  NaN  \n",
       "392      0.121094      0.167969     NaN     NaN  NaN  \n",
       "393      0.410156      0.513584     NaN     NaN  NaN  \n",
       "397      1.651367      1.756787     NaN     NaN  NaN  \n",
       "400      0.034668      0.040120     NaN     NaN  NaN  \n",
       "401      0.142773      0.182142     NaN     NaN  NaN  \n",
       "406      0.128906      0.172197     NaN     NaN  NaN  \n",
       "407      0.435547      0.468115     NaN     NaN  NaN  \n",
       "411      1.019531      1.628174     NaN     NaN  NaN  \n",
       "414      0.034668      0.047688     NaN     NaN  NaN  \n",
       "415      0.445713      0.466214     NaN     NaN  NaN  \n",
       "420      0.128906      0.169268     NaN     NaN  NaN  \n",
       "421      0.391602      0.435137     NaN     NaN  NaN  \n",
       "425      1.633545      1.762695     NaN     NaN  NaN  \n",
       "428      0.028320      0.038574     NaN     NaN  NaN  \n",
       "429      0.413445      0.521002     NaN     NaN  NaN  \n",
       "434      0.136719      0.175117     NaN     NaN  NaN  \n",
       "435      0.446191      0.502393     NaN     NaN  NaN  \n",
       "439      1.570312      1.666650     NaN     NaN  NaN  \n",
       "442      0.045898      0.064941     NaN     NaN  NaN  \n",
       "443      0.094535      0.150838     NaN     NaN  NaN  \n",
       "448      0.146484      0.181641     NaN     NaN  NaN  \n",
       "449      0.431641      0.449004     NaN     NaN  NaN  \n",
       "453      1.486328      1.633936     NaN     NaN  NaN  \n",
       "456      0.046875      0.058594     NaN     NaN  NaN  \n",
       "457      0.684265      0.818746     NaN     NaN  NaN  \n",
       "462      0.152344      0.183594     NaN     NaN  NaN  \n",
       "463      0.484375      0.511289     NaN     NaN  NaN  \n",
       "467      1.127930      1.461231     NaN     NaN  NaN  \n",
       "470      0.050537      0.055664     NaN     NaN  NaN  \n",
       "471      0.415631      0.546960     NaN     NaN  NaN  \n",
       "476      0.156250      0.188145     NaN     NaN  NaN  \n",
       "477      0.433594      0.491778     NaN     NaN  NaN  \n",
       "481      1.071289      1.531494     NaN     NaN  NaN  \n",
       "484      0.042480      0.053711     NaN     NaN  NaN  \n",
       "485      0.453938      0.467799     NaN     NaN  NaN  \n",
       "490      0.156250      0.185547     NaN     NaN  NaN  \n",
       "491      0.468750      0.525303     NaN     NaN  NaN  \n",
       "495      1.047852      1.522217     NaN     NaN  NaN  \n",
       "498      0.031738      0.053223     NaN     NaN  NaN  \n",
       "499      0.383914      0.411485     NaN     NaN  NaN  \n",
       "504      0.160156      0.189775     NaN     NaN  NaN  \n",
       "505      0.521484      0.589414     NaN     NaN  NaN  \n",
       "509      1.494629      1.576807     NaN     NaN  NaN  \n",
       "512      0.054443      0.067952     NaN     NaN  NaN  \n",
       "513      0.176707      0.262763     NaN     NaN  NaN  \n",
       "518      0.156250      0.183594     NaN     NaN  NaN  \n",
       "519      0.645410      0.739805     NaN     NaN  NaN  \n",
       "523      1.062500      1.381323     NaN     NaN  NaN  \n",
       "526      0.049316      0.057617     NaN     NaN  NaN  \n",
       "527      0.709435      0.882136     NaN     NaN  NaN  \n",
       "532      0.167969      0.193359     NaN     NaN  NaN  \n",
       "533      0.886523      0.921875     NaN     NaN  NaN  \n",
       "537      0.898438      1.256227     NaN     NaN  NaN  \n",
       "540      0.025879      0.049478     NaN     NaN  NaN  \n",
       "541      1.030736      1.113242     NaN     NaN  NaN  \n",
       "546      0.179688      0.203125     NaN     NaN  NaN  \n",
       "547      1.053613      1.105703     NaN     NaN  NaN  \n",
       "551      1.216064      1.280908     NaN     NaN  NaN  \n",
       "554      0.028320      0.045083     NaN     NaN  NaN  \n",
       "555      0.972981      1.158377     NaN     NaN  NaN  \n",
       "560      0.181641      0.207676     NaN     NaN  NaN  \n",
       "561      0.554688      0.583770     NaN     NaN  NaN  \n",
       "565      0.881714      1.492285     NaN     NaN  NaN  \n",
       "568      0.055664      0.072266     NaN     NaN  NaN  \n",
       "569      1.813412      1.953422     NaN     NaN  NaN  \n",
       "574      0.185547      0.210938     NaN     NaN  NaN  \n",
       "575      0.901269      0.978301     NaN     NaN  NaN  \n",
       "579      1.163086      1.392188     NaN     NaN  NaN  \n",
       "582      0.037598      0.055337     NaN     NaN  NaN  \n",
       "583      1.393391      1.484325     NaN     NaN  NaN  \n",
       "588      0.191406      0.216797     NaN     NaN  NaN  \n",
       "589      0.912988      0.982891     NaN     NaN  NaN  \n",
       "593      0.905029      1.104297     NaN     NaN  NaN  \n",
       "596      0.040527      0.065264     NaN     NaN  NaN  \n",
       "597      1.661738      1.829590     NaN     NaN  NaN  \n",
       "602      0.201172      0.224609     NaN     NaN  NaN  \n",
       "603      1.093750      1.225508     NaN     NaN  NaN  \n",
       "607      0.959473      1.155273     NaN     NaN  NaN  \n",
       "610      0.067139      0.083821     NaN     NaN  NaN  \n",
       "611      1.494398      1.687996     NaN     NaN  NaN  \n",
       "616      0.208984      0.232422     NaN     NaN  NaN  \n",
       "617      0.791016      0.916524     NaN     NaN  NaN  \n",
       "621      0.980957      1.157642     NaN     NaN  NaN  \n",
       "624      0.032227      0.053384     NaN     NaN  NaN  \n",
       "625      0.494427      0.701405     NaN     NaN  NaN  \n",
       "630      0.212891      0.234375     NaN     NaN  NaN  \n",
       "631      0.911035      0.994141     NaN     NaN  NaN  \n",
       "635      1.048462      1.261548     NaN     NaN  NaN  \n",
       "638      0.041504      0.065918     NaN     NaN  NaN  \n",
       "639      0.922965      1.029727     NaN     NaN  NaN  \n",
       "644      0.226562      0.246094     NaN     NaN  NaN  \n",
       "645      1.426660      1.528652     NaN     NaN  NaN  \n",
       "649      0.849976      0.985815     NaN     NaN  NaN  \n",
       "652      0.039551      0.062988     NaN     NaN  NaN  \n",
       "653      1.699435      1.870858     NaN     NaN  NaN  \n",
       "658      0.240234      0.257812     NaN     NaN  NaN  \n",
       "659      2.062500      2.140860     NaN     NaN  NaN  \n",
       "663      0.945801      1.044531     NaN     NaN  NaN  \n",
       "666      0.046875      0.073892     NaN     NaN  NaN  \n",
       "667      3.387670      3.451971     NaN     NaN  NaN  \n",
       "672      0.248047      0.265625     NaN     NaN  NaN  \n",
       "673      1.237744      1.301016     NaN     NaN  NaN  \n",
       "677      0.948853      1.048486     NaN     NaN  NaN  \n",
       "680      0.021973      0.054199     NaN     NaN  NaN  \n",
       "681      2.644493      2.804333     NaN     NaN  NaN  \n",
       "686      0.261719      0.279297     NaN     NaN  NaN  \n",
       "687      1.305566      1.431875     NaN     NaN  NaN  \n",
       "691      1.089844      1.163526     NaN     NaN  NaN  \n",
       "694      0.048340      0.068032     NaN     NaN  NaN  \n",
       "695      2.150823      2.299760     NaN     NaN  NaN  \n",
       "700      0.267578      0.283203     NaN     NaN  NaN  \n",
       "701      1.300781      1.476856     NaN     NaN  NaN  \n",
       "705      0.673096      0.922681     NaN     NaN  NaN  \n",
       "708      0.062012      0.073242     NaN     NaN  NaN  \n",
       "709      2.386315      2.463500     NaN     NaN  NaN  \n",
       "714      0.275391      0.291016     NaN     NaN  NaN  \n",
       "715      1.190332      1.247637     NaN     NaN  NaN  \n",
       "719      1.131348      1.276367     NaN     NaN  NaN  \n",
       "722      0.037598      0.060220     NaN     NaN  NaN  \n",
       "723      1.888172      2.087419     NaN     NaN  NaN  \n",
       "728      0.289062      0.304688     NaN     NaN  NaN  \n",
       "729      1.322949      1.399531     NaN     NaN  NaN  \n",
       "733      0.822510      0.978174     NaN     NaN  NaN  \n",
       "736      0.057617      0.075195     NaN     NaN  NaN  \n",
       "737      2.618715      2.694504     NaN     NaN  NaN  \n",
       "742      0.308594      0.326172     NaN     NaN  NaN  \n",
       "743      1.219629      1.363066     NaN     NaN  NaN  \n",
       "747      0.671143      0.873755     NaN     NaN  NaN  \n",
       "750      0.040527      0.065591     NaN     NaN  NaN  \n",
       "751      0.187614      0.195273     NaN     NaN  NaN  \n",
       "756      0.312500      0.328125     NaN     NaN  NaN  \n",
       "757      1.614013      1.735469     NaN     NaN  NaN  \n",
       "761      0.758789      0.898676     NaN     NaN  NaN  \n",
       "764      0.043774      0.068521     NaN     NaN  NaN  \n",
       "765      1.402942      1.410501     NaN     NaN  NaN  \n",
       "770      0.328125      0.343750     NaN     NaN  NaN  \n",
       "771      1.803174      1.869033     NaN     NaN  NaN  \n",
       "775      0.944092      1.021484     NaN     NaN  NaN  \n",
       "778      0.032715      0.055010     NaN     NaN  NaN  \n",
       "779      2.042114      2.055563     NaN     NaN  NaN  \n",
       "784      0.335938      0.353516     NaN     NaN  NaN  \n",
       "785      1.345508      1.435244     NaN     NaN  NaN  \n",
       "789      0.809082      0.952783     NaN     NaN  NaN  \n",
       "792      0.061035      0.083008     NaN     NaN  NaN  \n",
       "793      2.223292      2.241890     NaN     NaN  NaN  \n",
       "798      0.320312      0.339844     NaN     NaN  NaN  \n",
       "799      1.494385      1.565547     NaN     NaN  NaN  \n",
       "803      1.151611      1.248047     NaN     NaN  NaN  \n",
       "806      0.057532      0.076660     NaN     NaN  NaN  \n",
       "807      1.669389      1.677698     NaN     NaN  NaN  \n",
       "812      0.273438      0.304688     NaN     NaN  NaN  \n",
       "813      1.613915      1.713438     NaN     NaN  NaN  \n",
       "817      0.926270      1.139648     NaN     NaN  NaN  \n",
       "820      0.058105      0.080078     NaN     NaN  NaN  \n",
       "821      1.551329      1.562970     NaN     NaN  NaN  \n",
       "826      0.132812      0.363281     NaN     NaN  NaN  \n",
       "827      1.631738      1.770410     NaN     NaN  NaN  \n",
       "831      0.842529      0.971289     NaN     NaN  NaN  \n",
       "834      0.067627      0.083496     NaN     NaN  NaN  \n",
       "835      0.606183      0.620658     NaN     NaN  NaN  \n",
       "840      0.394531      0.530435     NaN     NaN  NaN  \n",
       "841      1.196191      1.436006     NaN     NaN  NaN  \n",
       "845      0.819580      1.065919     NaN     NaN  NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8497a507-d473-4578-a227-3bbf455effdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RESULT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e93a2-b030-4b56-acd7-0dc94ca90462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868647d3-a447-49bb-9035-5f48b3882e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751e1ea-8f9a-4fd8-8740-887fff124078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80be940-4c1c-46f0-9bae-fc2d9ba44492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739f144-414b-4c26-bfd2-4ce3b1304fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826dcbb-7a52-465a-9019-52cbaa637432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed9e25-9329-4fac-824c-5bf956272547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a31af2-fd52-4614-b10a-8b55da75a30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d5f18-367d-4d66-b89d-a0460cec2ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59d0bf-db74-48c8-99dd-a46b2d3c4e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1199fe6-ece3-456d-9864-382505306f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa165d4-203e-42cd-97d8-816252103c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81369-33c7-4a8e-a482-fd982b864f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-vmamedov-tmp]",
   "language": "python",
   "name": "conda-env-.mlspace-vmamedov-tmp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
