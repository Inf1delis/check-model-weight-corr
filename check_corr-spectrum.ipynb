{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc8a6f0-7083-46cf-b860-987c1a9b94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GIGACHAT_DIR = \"...\"\n",
    "DEEPSEEK_DIR = \"...\"\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "NUM_LAYERS = 61\n",
    "\n",
    "RESULT_CSV_PATH = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ee1f3e7-b21a-4c71-afe3-12d0704cd352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:49:11] layer 0 (12 common tensors)\n",
      "[08:49:11] processed 1 tensors (138.9/s, layer 0 1/12 in 0.0s)\n",
      "[08:49:53] processed 5 tensors (0.1/s, layer 0 5/12 in 41.8s)\n",
      "[08:49:53] processed 10 tensors (0.2/s, layer 0 10/12 in 41.9s)\n",
      "[08:49:54] layer 1 (12 common tensors)\n",
      "[08:50:21] processed 15 tensors (0.2/s, layer 1 3/12 in 27.5s)\n",
      "[08:50:36] layer 2 (12 common tensors)\n",
      "[08:50:36] processed 25 tensors (0.3/s, layer 2 1/12 in 0.0s)\n",
      "[08:51:17] processed 30 tensors (0.2/s, layer 2 6/12 in 41.3s)\n",
      "[08:51:17] processed 35 tensors (0.3/s, layer 2 11/12 in 41.6s)\n",
      "[08:51:17] layer 3 (14 common tensors)\n",
      "[08:51:18] processed 40 tensors (0.3/s, layer 3 4/14 in 0.6s)\n",
      "[08:51:19] processed 45 tensors (0.4/s, layer 3 9/14 in 1.7s)\n",
      "[08:51:19] layer 4 (14 common tensors)\n",
      "[08:51:21] processed 55 tensors (0.4/s, layer 4 5/14 in 1.1s)\n",
      "[08:51:21] layer 5 (14 common tensors)\n",
      "[08:51:21] processed 65 tensors (0.5/s, layer 5 1/14 in 0.0s)\n",
      "[08:51:23] processed 70 tensors (0.5/s, layer 5 6/14 in 1.6s)\n",
      "[08:51:23] layer 6 (14 common tensors)\n",
      "[08:51:23] processed 80 tensors (0.6/s, layer 6 2/14 in 0.0s)\n",
      "[08:51:25] processed 85 tensors (0.6/s, layer 6 7/14 in 1.6s)\n",
      "[08:51:25] processed 90 tensors (0.7/s, layer 6 12/14 in 1.7s)\n",
      "[08:51:25] layer 7 (14 common tensors)\n",
      "[08:51:26] processed 95 tensors (0.7/s, layer 7 3/14 in 0.0s)\n",
      "[08:51:27] processed 100 tensors (0.7/s, layer 7 8/14 in 1.5s)\n",
      "[08:51:27] processed 105 tensors (0.8/s, layer 7 13/14 in 1.9s)\n",
      "[08:51:27] layer 8 (14 common tensors)\n",
      "[08:51:28] processed 110 tensors (0.8/s, layer 8 4/14 in 0.6s)\n",
      "[08:51:29] processed 115 tensors (0.8/s, layer 8 9/14 in 1.6s)\n",
      "[08:51:29] layer 9 (14 common tensors)\n",
      "[08:51:30] processed 125 tensors (0.9/s, layer 9 5/14 in 1.0s)\n",
      "[08:51:31] layer 10 (14 common tensors)\n",
      "[08:51:31] processed 135 tensors (1.0/s, layer 10 1/14 in 0.1s)\n",
      "[08:51:33] processed 140 tensors (1.0/s, layer 10 6/14 in 1.6s)\n",
      "[08:51:33] layer 11 (14 common tensors)\n",
      "[08:51:33] processed 150 tensors (1.1/s, layer 11 2/14 in 0.0s)\n",
      "[08:51:35] processed 155 tensors (1.1/s, layer 11 7/14 in 1.5s)\n",
      "[08:51:35] processed 160 tensors (1.1/s, layer 11 12/14 in 1.6s)\n",
      "[08:51:35] layer 12 (14 common tensors)\n",
      "[08:51:35] processed 165 tensors (1.1/s, layer 12 3/14 in 0.0s)\n",
      "[08:51:37] processed 170 tensors (1.2/s, layer 12 8/14 in 1.5s)\n",
      "[08:51:37] processed 175 tensors (1.2/s, layer 12 13/14 in 1.9s)\n",
      "[08:51:37] layer 13 (14 common tensors)\n",
      "[08:51:38] processed 180 tensors (1.2/s, layer 13 4/14 in 0.5s)\n",
      "[08:51:39] processed 185 tensors (1.3/s, layer 13 9/14 in 1.6s)\n",
      "[08:51:39] layer 14 (14 common tensors)\n",
      "[08:51:40] processed 195 tensors (1.3/s, layer 14 5/14 in 1.0s)\n",
      "[08:51:41] layer 15 (14 common tensors)\n",
      "[08:51:41] processed 205 tensors (1.4/s, layer 15 1/14 in 0.0s)\n",
      "[08:51:43] processed 210 tensors (1.4/s, layer 15 6/14 in 1.5s)\n",
      "[08:51:43] layer 16 (14 common tensors)\n",
      "[08:51:43] processed 220 tensors (1.5/s, layer 16 2/14 in 0.0s)\n",
      "[08:51:45] processed 225 tensors (1.5/s, layer 16 7/14 in 1.5s)\n",
      "[08:51:45] processed 230 tensors (1.5/s, layer 16 12/14 in 1.7s)\n",
      "[08:51:45] layer 17 (14 common tensors)\n",
      "[08:51:45] processed 235 tensors (1.5/s, layer 17 3/14 in 0.0s)\n",
      "[08:51:47] processed 240 tensors (1.5/s, layer 17 8/14 in 1.5s)\n",
      "[08:51:47] processed 245 tensors (1.6/s, layer 17 13/14 in 1.9s)\n",
      "[08:51:47] layer 18 (14 common tensors)\n",
      "[08:51:48] processed 250 tensors (1.6/s, layer 18 4/14 in 0.5s)\n",
      "[08:51:49] processed 255 tensors (1.6/s, layer 18 9/14 in 1.6s)\n",
      "[08:51:49] layer 19 (14 common tensors)\n",
      "[08:51:50] processed 265 tensors (1.7/s, layer 19 5/14 in 1.0s)\n",
      "[08:51:51] layer 20 (14 common tensors)\n",
      "[08:51:51] processed 275 tensors (1.7/s, layer 20 1/14 in 0.0s)\n",
      "[08:51:52] processed 280 tensors (1.7/s, layer 20 6/14 in 1.5s)\n",
      "[08:51:53] layer 21 (14 common tensors)\n",
      "[08:51:53] processed 290 tensors (1.8/s, layer 21 2/14 in 0.0s)\n",
      "[08:51:54] processed 295 tensors (1.8/s, layer 21 7/14 in 1.5s)\n",
      "[08:51:54] processed 300 tensors (1.8/s, layer 21 12/14 in 1.6s)\n",
      "[08:51:55] layer 22 (14 common tensors)\n",
      "[08:51:55] processed 305 tensors (1.9/s, layer 22 3/14 in 0.0s)\n",
      "[08:51:56] processed 310 tensors (1.9/s, layer 22 8/14 in 1.5s)\n",
      "[08:51:57] processed 315 tensors (1.9/s, layer 22 13/14 in 1.9s)\n",
      "[08:51:57] layer 23 (14 common tensors)\n",
      "[08:51:57] processed 320 tensors (1.9/s, layer 23 4/14 in 0.5s)\n",
      "[08:51:58] processed 325 tensors (1.9/s, layer 23 9/14 in 1.6s)\n",
      "[08:51:59] layer 24 (14 common tensors)\n",
      "[08:52:00] processed 335 tensors (2.0/s, layer 24 5/14 in 1.0s)\n",
      "[08:52:01] layer 25 (14 common tensors)\n",
      "[08:52:01] processed 345 tensors (2.0/s, layer 25 1/14 in 0.0s)\n",
      "[08:52:02] processed 350 tensors (2.1/s, layer 25 6/14 in 1.6s)\n",
      "[08:52:03] layer 26 (14 common tensors)\n",
      "[08:52:03] processed 360 tensors (2.1/s, layer 26 2/14 in 0.0s)\n",
      "[08:52:04] processed 365 tensors (2.1/s, layer 26 7/14 in 1.5s)\n",
      "[08:52:04] processed 370 tensors (2.1/s, layer 26 12/14 in 1.7s)\n",
      "[08:52:05] layer 27 (14 common tensors)\n",
      "[08:52:05] processed 375 tensors (2.2/s, layer 27 3/14 in 0.0s)\n",
      "[08:52:06] processed 380 tensors (2.2/s, layer 27 8/14 in 1.6s)\n",
      "[08:52:06] processed 385 tensors (2.2/s, layer 27 13/14 in 1.9s)\n",
      "[08:52:06] layer 28 (14 common tensors)\n",
      "[08:52:07] processed 390 tensors (2.2/s, layer 28 4/14 in 0.5s)\n",
      "[08:52:08] processed 395 tensors (2.2/s, layer 28 9/14 in 1.6s)\n",
      "[08:52:08] layer 29 (14 common tensors)\n",
      "[08:52:10] processed 405 tensors (2.3/s, layer 29 5/14 in 1.1s)\n",
      "[08:52:10] layer 30 (14 common tensors)\n",
      "[08:52:10] processed 415 tensors (2.3/s, layer 30 1/14 in 0.0s)\n",
      "[08:52:12] processed 420 tensors (2.3/s, layer 30 6/14 in 1.6s)\n",
      "[08:52:12] layer 31 (14 common tensors)\n",
      "[08:52:12] processed 430 tensors (2.4/s, layer 31 2/14 in 0.0s)\n",
      "[08:52:14] processed 435 tensors (2.4/s, layer 31 7/14 in 1.5s)\n",
      "[08:52:14] processed 440 tensors (2.4/s, layer 31 12/14 in 1.7s)\n",
      "[08:52:14] layer 32 (14 common tensors)\n",
      "[08:52:14] processed 445 tensors (2.4/s, layer 32 3/14 in 0.0s)\n",
      "[08:52:16] processed 450 tensors (2.4/s, layer 32 8/14 in 1.6s)\n",
      "[08:52:16] processed 455 tensors (2.5/s, layer 32 13/14 in 1.9s)\n",
      "[08:52:16] layer 33 (14 common tensors)\n",
      "[08:52:17] processed 460 tensors (2.5/s, layer 33 4/14 in 0.6s)\n",
      "[08:52:18] processed 465 tensors (2.5/s, layer 33 9/14 in 1.6s)\n",
      "[08:52:18] layer 34 (14 common tensors)\n",
      "[08:52:19] processed 475 tensors (2.5/s, layer 34 5/14 in 1.0s)\n",
      "[08:52:20] layer 35 (14 common tensors)\n",
      "[08:52:20] processed 485 tensors (2.6/s, layer 35 1/14 in 0.0s)\n",
      "[08:52:22] processed 490 tensors (2.6/s, layer 35 6/14 in 1.5s)\n",
      "[08:52:22] layer 36 (14 common tensors)\n",
      "[08:52:22] processed 500 tensors (2.6/s, layer 36 2/14 in 0.0s)\n",
      "[08:52:24] processed 505 tensors (2.6/s, layer 36 7/14 in 1.6s)\n",
      "[08:52:24] processed 510 tensors (2.7/s, layer 36 12/14 in 1.7s)\n",
      "[08:52:24] layer 37 (14 common tensors)\n",
      "[08:52:24] processed 515 tensors (2.7/s, layer 37 3/14 in 0.1s)\n",
      "[08:52:26] processed 520 tensors (2.7/s, layer 37 8/14 in 1.6s)\n",
      "[08:52:26] processed 525 tensors (2.7/s, layer 37 13/14 in 1.9s)\n",
      "[08:52:26] layer 38 (14 common tensors)\n",
      "[08:52:27] processed 530 tensors (2.7/s, layer 38 4/14 in 0.6s)\n",
      "[08:52:28] processed 535 tensors (2.7/s, layer 38 9/14 in 1.6s)\n",
      "[08:52:28] layer 39 (14 common tensors)\n",
      "[08:52:29] processed 545 tensors (2.8/s, layer 39 5/14 in 1.1s)\n",
      "[08:52:30] layer 40 (14 common tensors)\n",
      "[08:52:30] processed 555 tensors (2.8/s, layer 40 1/14 in 0.0s)\n",
      "[08:52:31] processed 560 tensors (2.8/s, layer 40 6/14 in 1.6s)\n",
      "[08:52:32] layer 41 (14 common tensors)\n",
      "[08:52:32] processed 570 tensors (2.8/s, layer 41 2/14 in 0.0s)\n",
      "[08:52:33] processed 575 tensors (2.8/s, layer 41 7/14 in 1.6s)\n",
      "[08:52:34] processed 580 tensors (2.9/s, layer 41 12/14 in 1.7s)\n",
      "[08:52:34] layer 42 (14 common tensors)\n",
      "[08:52:34] processed 585 tensors (2.9/s, layer 42 3/14 in 0.0s)\n",
      "[08:52:35] processed 590 tensors (2.9/s, layer 42 8/14 in 1.6s)\n",
      "[08:52:36] processed 595 tensors (2.9/s, layer 42 13/14 in 1.9s)\n",
      "[08:52:36] layer 43 (14 common tensors)\n",
      "[08:52:36] processed 600 tensors (2.9/s, layer 43 4/14 in 0.6s)\n",
      "[08:52:37] processed 605 tensors (2.9/s, layer 43 9/14 in 1.6s)\n",
      "[08:52:38] layer 44 (14 common tensors)\n",
      "[08:52:39] processed 615 tensors (3.0/s, layer 44 5/14 in 1.0s)\n",
      "[08:52:40] layer 45 (14 common tensors)\n",
      "[08:52:40] processed 625 tensors (3.0/s, layer 45 1/14 in 0.0s)\n",
      "[08:52:41] processed 630 tensors (3.0/s, layer 45 6/14 in 1.5s)\n",
      "[08:52:42] layer 46 (14 common tensors)\n",
      "[08:52:42] processed 640 tensors (3.0/s, layer 46 2/14 in 0.0s)\n",
      "[08:52:43] processed 645 tensors (3.0/s, layer 46 7/14 in 1.6s)\n",
      "[08:52:43] processed 650 tensors (3.1/s, layer 46 12/14 in 1.7s)\n",
      "[08:52:44] layer 47 (14 common tensors)\n",
      "[08:52:44] processed 655 tensors (3.1/s, layer 47 3/14 in 0.1s)\n",
      "[08:52:45] processed 660 tensors (3.1/s, layer 47 8/14 in 1.6s)\n",
      "[08:52:45] processed 665 tensors (3.1/s, layer 47 13/14 in 1.9s)\n",
      "[08:52:45] layer 48 (14 common tensors)\n",
      "[08:52:46] processed 670 tensors (3.1/s, layer 48 4/14 in 0.5s)\n",
      "[08:52:47] processed 675 tensors (3.1/s, layer 48 9/14 in 1.6s)\n",
      "[08:52:47] layer 49 (14 common tensors)\n",
      "[08:52:48] processed 685 tensors (3.2/s, layer 49 5/14 in 1.0s)\n",
      "[08:52:49] layer 50 (14 common tensors)\n",
      "[08:52:49] processed 695 tensors (3.2/s, layer 50 1/14 in 0.0s)\n",
      "[08:52:51] processed 700 tensors (3.2/s, layer 50 6/14 in 1.5s)\n",
      "[08:52:51] layer 51 (14 common tensors)\n",
      "[08:52:51] processed 710 tensors (3.2/s, layer 51 2/14 in 0.0s)\n",
      "[08:52:53] processed 715 tensors (3.2/s, layer 51 7/14 in 1.6s)\n",
      "[08:52:53] processed 720 tensors (3.3/s, layer 51 12/14 in 1.7s)\n",
      "[08:52:53] layer 52 (14 common tensors)\n",
      "[08:52:53] processed 725 tensors (3.3/s, layer 52 3/14 in 0.0s)\n",
      "[08:52:55] processed 730 tensors (3.3/s, layer 52 8/14 in 1.5s)\n",
      "[08:52:55] processed 735 tensors (3.3/s, layer 52 13/14 in 1.9s)\n",
      "[08:52:55] layer 53 (14 common tensors)\n",
      "[08:52:56] processed 740 tensors (3.3/s, layer 53 4/14 in 0.6s)\n",
      "[08:52:57] processed 745 tensors (3.3/s, layer 53 9/14 in 1.6s)\n",
      "[08:52:57] layer 54 (14 common tensors)\n",
      "[08:52:58] processed 755 tensors (3.3/s, layer 54 5/14 in 1.0s)\n",
      "[08:52:59] layer 55 (14 common tensors)\n",
      "[08:52:59] processed 765 tensors (3.4/s, layer 55 1/14 in 0.0s)\n",
      "[08:53:01] processed 770 tensors (3.4/s, layer 55 6/14 in 1.5s)\n",
      "[08:53:01] layer 56 (14 common tensors)\n",
      "[08:53:01] processed 780 tensors (3.4/s, layer 56 2/14 in 0.0s)\n",
      "[08:53:03] processed 785 tensors (3.4/s, layer 56 7/14 in 1.5s)\n",
      "[08:53:03] processed 790 tensors (3.4/s, layer 56 12/14 in 1.6s)\n",
      "[08:53:03] layer 57 (14 common tensors)\n",
      "[08:53:03] processed 795 tensors (3.4/s, layer 57 3/14 in 0.1s)\n",
      "[08:53:05] processed 800 tensors (3.4/s, layer 57 8/14 in 1.6s)\n",
      "[08:53:05] processed 805 tensors (3.4/s, layer 57 13/14 in 1.9s)\n",
      "[08:53:05] layer 58 (14 common tensors)\n",
      "[08:53:06] processed 810 tensors (3.5/s, layer 58 4/14 in 0.6s)\n",
      "[08:53:07] processed 815 tensors (3.5/s, layer 58 9/14 in 1.6s)\n",
      "[08:53:07] layer 59 (14 common tensors)\n",
      "[08:53:08] processed 825 tensors (3.5/s, layer 59 5/14 in 1.0s)\n",
      "[08:53:09] layer 60 (14 common tensors)\n",
      "[08:53:09] processed 835 tensors (3.5/s, layer 60 1/14 in 0.0s)\n",
      "[08:53:10] processed 840 tensors (3.5/s, layer 60 6/14 in 1.5s)\n",
      "[08:53:11] finished: 848 tensors in 239.3s (3.5/s)\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from contextlib import ExitStack\n",
    "from typing import Optional, Sequence\n",
    "from safetensors import safe_open\n",
    "\n",
    "# ---------- regex setup ----------\n",
    "DEFAULT_PREFIXES = (\n",
    "    r\"model\\.layers\\.(\\d+)\\.\",       # llama/qwen/deepseek-style\n",
    ")\n",
    "\n",
    "# --- skip patterns (ignore at indexing/load stage) ---\n",
    "DEFAULT_SKIP_REGEXES = (\n",
    "    r\"\\.experts\\.\",   # ignore MoE experts tensors\n",
    ")\n",
    "\n",
    "def iter_safetensors_files(model_dir):\n",
    "    files = sorted(glob.glob(os.path.join(model_dir, \"*.safetensors\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .safetensors files in {model_dir}\")\n",
    "    return files\n",
    "\n",
    "def compile_regexes(patterns):\n",
    "    if not patterns:\n",
    "        return []\n",
    "    return [re.compile(p) for p in patterns]\n",
    "\n",
    "def compile_prefixes(prefixes):\n",
    "    return compile_regexes(prefixes)\n",
    "\n",
    "def _should_skip_key(key, regs):\n",
    "    for rgx in regs:\n",
    "        if rgx.search(key):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_layer_id(key, regs):\n",
    "    for rgx in regs:\n",
    "        m = rgx.search(key)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "# ---------- 1) lightweight index: layer -> {key: filepath} ----------\n",
    "def build_layer_index(\n",
    "    model_dir,\n",
    "    n_layers=3,\n",
    "    prefixes=DEFAULT_PREFIXES,\n",
    "    skip_regexes=DEFAULT_SKIP_REGEXES,\n",
    "):\n",
    "    files = iter_safetensors_files(model_dir)\n",
    "    regs = compile_prefixes(prefixes)\n",
    "    skip_regs = compile_regexes(skip_regexes)\n",
    "\n",
    "    layer_to_keys = {i: {} for i in range(n_layers)}\n",
    "    for path in files:\n",
    "        with safe_open(path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for k in f.keys():\n",
    "                if skip_regs and _should_skip_key(k, skip_regs):\n",
    "                    continue\n",
    "                lid = extract_layer_id(k, regs)\n",
    "                if lid is None or lid >= n_layers:\n",
    "                    continue\n",
    "                layer_to_keys[lid][k] = path\n",
    "    return layer_to_keys\n",
    "\n",
    "# ---------- 2) metrics ----------\n",
    "def _cos_sim(fa, fb, eps=1e-12):\n",
    "    denom = (fa.norm() * fb.norm()).clamp_min(eps)\n",
    "    return (fa @ fb / denom).item()\n",
    "\n",
    "def _pearson(fa, fb, eps=1e-12):\n",
    "    fa_c = fa - fa.mean()\n",
    "    fb_c = fb - fb.mean()\n",
    "    denom = (fa_c.norm() * fb_c.norm()).clamp_min(eps)\n",
    "    return (fa_c @ fb_c / denom).item()\n",
    "\n",
    "def _spearman(fa, fb, eps=1e-12):\n",
    "    # ранги через двойной argsort\n",
    "    ra = torch.argsort(torch.argsort(fa))\n",
    "    rb = torch.argsort(torch.argsort(fb))\n",
    "    ra = ra.float() - ra.float().mean()\n",
    "    rb = rb.float() - rb.float().mean()\n",
    "    denom = (ra.norm() * rb.norm()).clamp_min(eps)\n",
    "    return (ra @ rb / denom).item()\n",
    "\n",
    "def _quantiles(abs_diff, qs=(0.01, 0.05, 0.5, 0.95, 0.99), max_samples=None):\n",
    "    if abs_diff.numel() == 0:\n",
    "        return {}\n",
    "\n",
    "    vals = abs_diff.flatten()\n",
    "\n",
    "    if max_samples is not None and vals.numel() > max_samples:\n",
    "        idx = torch.randperm(vals.numel(), device=vals.device)[:max_samples]\n",
    "        vals = vals[idx]\n",
    "\n",
    "    qv = torch.tensor(qs, device=vals.device, dtype=vals.dtype)\n",
    "    try:\n",
    "        out = torch.quantile(vals, qv)\n",
    "    except RuntimeError:\n",
    "        vals_cpu = vals.float().cpu().numpy()\n",
    "        qv_np = qv.float().cpu().numpy()\n",
    "        out_np = np.quantile(vals_cpu, qv_np)\n",
    "        out = torch.from_numpy(out_np).to(vals)\n",
    "\n",
    "    return {f\"q{int(q*100):02d}_abs_diff\": out[i].item() for i, q in enumerate(qs)}\n",
    "\n",
    "def _sample_pair(fa, fb, max_samples=None):\n",
    "    if max_samples is None or fa.numel() <= max_samples:\n",
    "        return fa, fb\n",
    "    idx = torch.randint(0, fa.numel(), (max_samples,), device=fa.device)\n",
    "    return fa[idx], fb[idx]\n",
    "\n",
    "def _rel_l2_err(fa, fb, eps=1e-12):\n",
    "    return (fa - fb).norm().div(fa.norm().clamp_min(eps)).item()\n",
    "\n",
    "def _rel_max_abs_diff(fa, fb, eps=1e-12):\n",
    "    denom = fa.abs().clamp_min(eps)\n",
    "    return ((fa - fb).abs() / denom).max().item()\n",
    "\n",
    "def _rel_mean_abs_diff(fa, fb, eps=1e-12):\n",
    "    denom = fa.abs().clamp_min(eps)\n",
    "    return ((fa - fb).abs() / denom).mean().item()\n",
    "\n",
    "\n",
    "# ---------- 2.5) spectral / SVD helpers ----------\n",
    "def _to_2d_matrix(t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Приводим произвольный тензор к 2D-матрице для SVD.\n",
    "    Первая ось = строки, остальное = столбцы.\n",
    "      - 1D -> (1, N)\n",
    "      - 2D -> (M, N)\n",
    "      - kD -> (d0, prod(d1..dk))\n",
    "    \"\"\"\n",
    "    if t.ndim == 1:\n",
    "        return t.unsqueeze(0)\n",
    "    if t.ndim == 2:\n",
    "        return t\n",
    "    return t.reshape(t.shape[0], -1)\n",
    "\n",
    "def _safe_svd_full(x: torch.Tensor, *, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Полное SVD (без усечения ранга): x = U diag(S) Vh.\n",
    "    full_matrices=False -> экономичное U/Vh, но спектр S полный по рангу.\n",
    "    \"\"\"\n",
    "    if x.numel() == 0 or x.abs().max().item() < eps:\n",
    "        m, n = x.shape\n",
    "        r = min(m, n)\n",
    "        U = torch.zeros((m, r), device=x.device, dtype=x.dtype)\n",
    "        S = torch.zeros((r,), device=x.device, dtype=x.dtype)\n",
    "        Vh = torch.zeros((r, n), device=x.device, dtype=x.dtype)\n",
    "        return U, S, Vh\n",
    "\n",
    "    return torch.linalg.svd(x, full_matrices=False)\n",
    "\n",
    "def _spectral_metrics(\n",
    "    a: torch.Tensor,\n",
    "    b: torch.Tensor,\n",
    "    *,\n",
    "    topk: int = 128,\n",
    "    max_numel: Optional[int] = None,  # <-- по умолчанию без гарда\n",
    "    force_cpu: bool = False,\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Считает метрики по полному SVD:\n",
    "      - spec_cos_sim / spec_rel_l2_err / spec_pearson / spec_spearman по спектрам S\n",
    "      - spec_topk_* по сингулярным векторам (U/V), |cos| с учётом знака\n",
    "      - spec_subspace_overlap_* по подпространствам топ-k (1=совпало)\n",
    "    \"\"\"\n",
    "    A = _to_2d_matrix(a)\n",
    "    B = _to_2d_matrix(b)\n",
    "\n",
    "    # гард на размер (если задан)\n",
    "    if (max_numel is not None) and (A.numel() > max_numel or B.numel() > max_numel):\n",
    "        return {\"spec_note\": f\"skipped_large(numel_a={A.numel()}, numel_b={B.numel()})\"}\n",
    "\n",
    "    if force_cpu:\n",
    "        A_ = A.detach().to(\"cpu\", dtype=dtype)\n",
    "        B_ = B.detach().to(\"cpu\", dtype=dtype)\n",
    "    else:\n",
    "        A_ = A.detach().to(dtype=dtype)\n",
    "        B_ = B.detach().to(dtype=dtype)\n",
    "\n",
    "    try:\n",
    "        Ua, Sa, Vha = _safe_svd_full(A_)\n",
    "        Ub, Sb, Vhb = _safe_svd_full(B_)\n",
    "    except RuntimeError as e:\n",
    "        return {\"spec_note\": f\"svd_failed({type(e).__name__})\"}\n",
    "\n",
    "    r = min(Sa.numel(), Sb.numel())\n",
    "    Sa = Sa[:r]\n",
    "    Sb = Sb[:r]\n",
    "\n",
    "    out = {}\n",
    "    out[\"spec_rel_l2_err\"] = _rel_l2_err(Sa, Sb)\n",
    "    out[\"spec_a_max\"] = Sa.max()\n",
    "    out[\"spec_a_min\"] = Sa.min()\n",
    "\n",
    "    out[\"spec_b_max\"] = Sb.max()\n",
    "    out[\"spec_b_min\"] = Sb.min()\n",
    "\n",
    "    k = int(min(topk, r))\n",
    "    if k > 0:\n",
    "        Ua_k = Ua[:, :k]\n",
    "        Ub_k = Ub[:, :k]\n",
    "        Va_k = Vha[:k, :].T   # V = Vh^T\n",
    "        Vb_k = Vhb[:k, :].T\n",
    "\n",
    "        # cos соответствующих сингулярных векторов (берём abs из-за знака)\n",
    "        u_pair_cos = (Ua_k * Ub_k).sum(dim=0) / (\n",
    "            Ua_k.norm(dim=0) * Ub_k.norm(dim=0)\n",
    "        ).clamp_min(1e-12)\n",
    "        v_pair_cos = (Va_k * Vb_k).sum(dim=0) / (\n",
    "            Va_k.norm(dim=0) * Vb_k.norm(dim=0)\n",
    "        ).clamp_min(1e-12)\n",
    "\n",
    "        out[\"spec_topk_u_cos_mean\"] = u_pair_cos.abs().mean().item()\n",
    "        out[\"spec_topk_u_cos_min\"]  = u_pair_cos.abs().min().item()\n",
    "        out[\"spec_topk_v_cos_mean\"] = v_pair_cos.abs().mean().item()\n",
    "        out[\"spec_topk_v_cos_min\"]  = v_pair_cos.abs().min().item()\n",
    "\n",
    "        # overlap подпространств U/V: ||U_a^T U_b||_F / k\n",
    "        overlap_u = torch.linalg.norm(Ua_k.T @ Ub_k, ord=\"fro\") / max(k, 1)\n",
    "        overlap_v = torch.linalg.norm(Va_k.T @ Vb_k, ord=\"fro\") / max(k, 1)\n",
    "        out[\"spec_subspace_overlap_u\"] = overlap_u.item()\n",
    "        out[\"spec_subspace_overlap_v\"] = overlap_v.item()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- 3) streaming compare per layer ----------\n",
    "def compare_models_streaming(\n",
    "    gigachat_dir,\n",
    "    deepseek_dir,\n",
    "    n_layers=3,\n",
    "    prefixes=DEFAULT_PREFIXES,\n",
    "    cast_to=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    do_spearman=True,\n",
    "    quantile_max_samples: Optional[int] = None,\n",
    "    spearman_max_samples: Optional[int] = None,\n",
    "    log_every=5,\n",
    "    max_tensors=None,\n",
    "    verbose=True,\n",
    "    skip_regexes=DEFAULT_SKIP_REGEXES,\n",
    "\n",
    "    # --- spectral params ---\n",
    "    do_spectral: bool = True,\n",
    "    spectral_topk: int = 128,\n",
    "    spectral_max_numel: Optional[int] = None,  # <-- без гарда по умолчанию\n",
    "    spectral_force_cpu: bool = False,\n",
    "    spectral_dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    # lightweight indexes\n",
    "    gc_index = build_layer_index(\n",
    "        gigachat_dir,\n",
    "        n_layers=n_layers,\n",
    "        prefixes=prefixes,\n",
    "        skip_regexes=skip_regexes,\n",
    "    )\n",
    "    ds_index = build_layer_index(\n",
    "        deepseek_dir,\n",
    "        n_layers=n_layers,\n",
    "        prefixes=prefixes,\n",
    "        skip_regexes=skip_regexes,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    processed = 0\n",
    "    interrupted = False\n",
    "    start_time = time.time()\n",
    "    stop_requested = False\n",
    "\n",
    "    try:\n",
    "        for lid in range(n_layers):\n",
    "            gc_keys = gc_index[lid]\n",
    "            ds_keys = ds_index[lid]\n",
    "            common_keys = sorted(set(gc_keys) & set(ds_keys))\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"[{time.strftime('%H:%M:%S')}] layer {lid} \"\n",
    "                    f\"({len(common_keys)} common tensors)\"\n",
    "                )\n",
    "\n",
    "            if not common_keys:\n",
    "                continue\n",
    "\n",
    "            layer_start = time.time()\n",
    "\n",
    "            with ExitStack() as stack:\n",
    "                gc_handles = {}\n",
    "                ds_handles = {}\n",
    "\n",
    "                def get_tensor(handles, path, key):\n",
    "                    if path not in handles:\n",
    "                        handles[path] = stack.enter_context(\n",
    "                            safe_open(path, framework=\"pt\", device=str(device))\n",
    "                        )\n",
    "                    return handles[path].get_tensor(key)\n",
    "\n",
    "                for idx, k in enumerate(common_keys, 1):\n",
    "                    a = get_tensor(gc_handles, gc_keys[k], k).to(dtype=cast_to)\n",
    "                    b = get_tensor(ds_handles, ds_keys[k], k).to(dtype=cast_to)\n",
    "\n",
    "                    if a.shape != b.shape:\n",
    "                        rows.append(dict(\n",
    "                            layer=lid, key=k,\n",
    "                            shape_a=tuple(a.shape), shape_b=tuple(b.shape),\n",
    "                            note=\"shape_mismatch\",\n",
    "                        ))\n",
    "                        processed += 1\n",
    "                        continue\n",
    "\n",
    "                    fa = a.reshape(-1)\n",
    "                    fb = b.reshape(-1)\n",
    "                    abs_diff = (fa - fb).abs()\n",
    "\n",
    "                    row = dict(\n",
    "                        layer=lid,\n",
    "                        key=k,\n",
    "                        shape=tuple(a.shape),\n",
    "                        numel=int(fa.numel()),\n",
    "\n",
    "                        norm_a=fa.norm().item(),\n",
    "                        norm_b=fb.norm().item(),\n",
    "                        norm_ratio=(fa.norm() / fb.norm().clamp_min(1e-12)).item(),\n",
    "\n",
    "                        mean_a=fa.mean().item(),\n",
    "                        mean_b=fb.mean().item(),\n",
    "                        mean_ratio=(fa.mean() / fb.mean().clamp_min(1e-12)).item(),\n",
    "\n",
    "                        std_a=fa.std(unbiased=False).item(),\n",
    "                        std_b=fb.std(unbiased=False).item(),\n",
    "                        std_ratio=(\n",
    "                            fa.std(unbiased=False)\n",
    "                            / fb.std(unbiased=False).clamp_min(1e-12)\n",
    "                        ).item(),\n",
    "\n",
    "                        zero_frac_a=(fa == 0).float().mean().item(),\n",
    "                        zero_frac_b=(fb == 0).float().mean().item(),\n",
    "\n",
    "                        cos_sim=_cos_sim(fa, fb),\n",
    "                        rel_l2_err=_rel_l2_err(fa, fb),\n",
    "                        mean_rel_diff=_rel_mean_abs_diff(fa, fb),\n",
    "                        max_rel_diff=_rel_max_abs_diff(fa, fb),\n",
    "\n",
    "                        pearson=_pearson(fa, fb),\n",
    "\n",
    "                        max_abs_diff=abs_diff.max().item(),\n",
    "                        mean_abs_diff=abs_diff.mean().item(),\n",
    "                    )\n",
    "\n",
    "                    if do_spearman:\n",
    "                        fa_sp, fb_sp = _sample_pair(fa, fb, spearman_max_samples)\n",
    "                        row[\"spearman\"] = _spearman(fa_sp, fb_sp)\n",
    "\n",
    "                    row.update(_quantiles(abs_diff, max_samples=quantile_max_samples))\n",
    "\n",
    "                    # --- spectral add ---\n",
    "                    if do_spectral:\n",
    "                        row.update(_spectral_metrics(\n",
    "                            a, b,\n",
    "                            topk=spectral_topk,\n",
    "                            max_numel=spectral_max_numel,\n",
    "                            force_cpu=spectral_force_cpu,\n",
    "                            dtype=spectral_dtype,\n",
    "                        ))\n",
    "\n",
    "                    rows.append(row)\n",
    "                    processed += 1\n",
    "\n",
    "                    if verbose and (processed == 1 or processed % max(1, log_every) == 0):\n",
    "                        elapsed = time.time() - start_time\n",
    "                        rate = processed / max(elapsed, 1e-6)\n",
    "                        layer_elapsed = time.time() - layer_start\n",
    "                        print(\n",
    "                            f\"[{time.strftime('%H:%M:%S')}] processed \"\n",
    "                            f\"{processed} tensors ({rate:.1f}/s, \"\n",
    "                            f\"layer {lid} {idx}/{len(common_keys)} in {layer_elapsed:.1f}s)\"\n",
    "                        )\n",
    "\n",
    "                    if max_tensors is not None and processed >= max_tensors:\n",
    "                        stop_requested = True\n",
    "                        break\n",
    "\n",
    "                if stop_requested:\n",
    "                    break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        interrupted = True\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{time.strftime('%H:%M:%S')}] KeyboardInterrupt received, \"\n",
    "                \"returning partial results.\"\n",
    "            )\n",
    "\n",
    "    total_elapsed = time.time() - start_time\n",
    "    if verbose:\n",
    "        status = \"interrupted\" if interrupted else \"finished\"\n",
    "        print(\n",
    "            f\"[{time.strftime('%H:%M:%S')}] {status}: {processed} tensors \"\n",
    "            f\"in {total_elapsed:.1f}s ({processed / max(total_elapsed, 1e-6):.1f}/s)\"\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.attrs[\"interrupted\"] = interrupted\n",
    "    df.attrs[\"processed_tensors\"] = processed\n",
    "    df.attrs[\"elapsed_seconds\"] = total_elapsed\n",
    "    df.attrs[\"stop_requested\"] = stop_requested\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- 4) usage ----------\n",
    "# Ожидается, что Вы заранее задали:\n",
    "# GIGACHAT_DIR, DEEPSEEK_DIR, DEVICE, NUM_LAYERS\n",
    "df = compare_models_streaming(\n",
    "    gigachat_dir=GIGACHAT_DIR,\n",
    "    deepseek_dir=DEEPSEEK_DIR,\n",
    "    n_layers=NUM_LAYERS,\n",
    "    device=DEVICE,\n",
    "    # do_spectral=True по умолчанию и spectral_max_numel=None по умолчанию\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe2fd765-addf-4703-a991-541928d763f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== non-layernorm stats (describe) ===\n",
      "          cos_sim     pearson    spearman    rel_l2_err  mean_rel_diff  \\\n",
      "count  363.000000  363.000000  363.000000    363.000000     363.000000   \n",
      "mean    -0.000037   -0.000040   -0.000002   4294.096856   57084.277631   \n",
      "std      0.001984    0.001982    0.001965   2463.475244   43614.327872   \n",
      "min     -0.009123   -0.009121   -0.008588      1.144950       4.780324   \n",
      "1%      -0.006066   -0.006074   -0.006189      1.159569       5.800548   \n",
      "5%      -0.003547   -0.003558   -0.003408      1.181075       6.962997   \n",
      "50%      0.000011    0.000011    0.000010   4663.833496   53996.414062   \n",
      "95%      0.003594    0.003576    0.003543   7572.696387  123171.325000   \n",
      "99%      0.006864    0.006845    0.006718  11331.787813  209752.977500   \n",
      "max      0.007981    0.007958    0.008460  16530.933594  326736.812500   \n",
      "\n",
      "       max_rel_diff  mean_abs_diff  max_abs_diff  norm_ratio   std_ratio  \\\n",
      "count  3.630000e+02     363.000000    363.000000  363.000000  363.000000   \n",
      "mean   1.356075e+11      45.850916    376.558432    0.231714    0.231715   \n",
      "std    3.392392e+11      24.643936    164.208483    0.539690    0.539693   \n",
      "min    1.075075e+05       0.021599      0.277832    0.000060    0.000060   \n",
      "1%     2.869566e+05       0.023559      0.371387    0.000088    0.000088   \n",
      "5%     8.936970e+05       0.031007      0.458531    0.000132    0.000132   \n",
      "50%    4.133502e+10      48.836674    448.050781    0.000214    0.000214   \n",
      "95%    5.063086e+11      82.750228    448.128711    1.590086    1.590120   \n",
      "99%    1.602375e+12      84.169096    448.200000    1.691253    1.691307   \n",
      "max    3.728145e+12      85.509880    448.259766    1.777323    1.777332   \n",
      "\n",
      "         mean_ratio  spec_rel_l2_err  spec_topk_u_cos_mean  \\\n",
      "count  3.630000e+02       363.000000            363.000000   \n",
      "mean  -9.349179e+06      4293.218815              0.026289   \n",
      "std    4.061707e+07      2463.539040              0.015514   \n",
      "min   -2.069384e+08         0.062820              0.004700   \n",
      "1%    -1.824003e+08         0.109414              0.008143   \n",
      "5%    -1.146533e+08         0.277505              0.009077   \n",
      "50%   -8.076385e-06      4662.889160              0.020648   \n",
      "95%    9.265593e+06      7572.174609              0.058576   \n",
      "99%    2.442668e+07     11331.178223              0.061310   \n",
      "max    1.989925e+08     16530.671875              0.065414   \n",
      "\n",
      "       spec_topk_u_cos_min  spec_topk_v_cos_mean  spec_topk_v_cos_min  \\\n",
      "count         3.630000e+02            363.000000         3.630000e+02   \n",
      "mean          2.856984e-04              0.010724         1.161353e-04   \n",
      "std           3.424358e-04              0.003102         1.400965e-04   \n",
      "min           1.902691e-07              0.005309         4.796919e-08   \n",
      "1%            2.320772e-06              0.007966         1.562781e-06   \n",
      "5%            1.088289e-05              0.008475         4.639085e-06   \n",
      "50%           1.670447e-04              0.009598         7.636492e-05   \n",
      "95%           9.761090e-04              0.018048         4.087396e-04   \n",
      "99%           1.708070e-03              0.019326         6.226645e-04   \n",
      "max           2.375107e-03              0.020611         1.456863e-03   \n",
      "\n",
      "       spec_subspace_overlap_u  spec_subspace_overlap_v  \n",
      "count               363.000000               363.000000  \n",
      "mean                  0.030476                 0.013409  \n",
      "std                   0.016593                 0.003820  \n",
      "min                   0.006312                 0.006596  \n",
      "1%                    0.009653                 0.011625  \n",
      "5%                    0.011741                 0.011691  \n",
      "50%                   0.024102                 0.011813  \n",
      "95%                   0.062787                 0.022288  \n",
      "99%                   0.063490                 0.022911  \n",
      "max                   0.063870                 0.024147  \n",
      "\n",
      "=== per-layer mean metrics (non-layernorm) ===\n",
      "        cos_sim   pearson  spearman   rel_l2_err  mean_rel_diff  max_rel_diff  \\\n",
      "layer                                                                           \n",
      "0     -0.000135 -0.000130 -0.000623  7026.511914   91911.600781  5.577121e+11   \n",
      "1     -0.000602 -0.000606 -0.000942  9311.209961  103031.828125  2.816871e+11   \n",
      "2     -0.000346 -0.000347 -0.000753  6882.745264   97897.479688  6.337466e+11   \n",
      "3      0.000632  0.000627 -0.001283  6614.248081   87685.230215  8.916687e+10   \n",
      "4     -0.001191 -0.001195 -0.001825  6200.696583   83600.781367  1.347536e+11   \n",
      "5      0.001811  0.001806  0.001117  5337.763031   61829.800468  8.698469e+10   \n",
      "6      0.001424  0.001424  0.000871  5419.931874   61739.098724  8.558960e+10   \n",
      "7      0.000279  0.000279 -0.000411  4849.219060   52643.242496  7.655435e+10   \n",
      "8      0.000103  0.000092 -0.000208  4303.811008   87571.120382  4.744828e+11   \n",
      "9      0.000308  0.000295  0.000141  4417.576350   59645.623364  1.318525e+11   \n",
      "10    -0.000660 -0.000667 -0.000329  4181.631169   54274.677305  4.898702e+10   \n",
      "11    -0.000479 -0.000488 -0.000203  3951.850684   51376.466808  6.820438e+10   \n",
      "12    -0.000487 -0.000496 -0.000256  4017.827218   47979.758995  2.100822e+10   \n",
      "13    -0.000814 -0.000822 -0.000454  3889.521894   58801.965441  9.503264e+10   \n",
      "14    -0.000936 -0.000951 -0.000565  3636.478184   58667.353584  1.872031e+11   \n",
      "15    -0.000686 -0.000693 -0.000472  3570.938780   47676.521263  6.216946e+10   \n",
      "16    -0.001210 -0.001212 -0.001112  3670.140803   57776.752816  9.130974e+10   \n",
      "17    -0.000840 -0.000842 -0.000558  3761.970839   49010.932669  3.313251e+10   \n",
      "18    -0.000771 -0.000771 -0.000476  3921.191300   72819.044997  2.480720e+11   \n",
      "19    -0.001115 -0.001115 -0.001042  3533.985649   52428.366760  1.005843e+11   \n",
      "20    -0.001140 -0.001139 -0.000866  3942.705001   59123.267792  1.190118e+11   \n",
      "21    -0.001001 -0.001001 -0.000806  3983.494529   57156.300433  1.475448e+11   \n",
      "22    -0.000873 -0.000873 -0.000706  3739.336923   61823.552769  3.081871e+11   \n",
      "23    -0.000885 -0.000884 -0.000680  3816.099226   50512.566020  9.672341e+10   \n",
      "24    -0.001406 -0.001406 -0.001314  3719.275757   43976.915225  4.755554e+10   \n",
      "25    -0.001123 -0.001124 -0.000949  3860.239021   46191.630724  8.211684e+10   \n",
      "26    -0.000883 -0.000882 -0.000718  3912.268674   48277.338083  9.245679e+10   \n",
      "27    -0.001646 -0.001645 -0.001503  4333.685103   46601.670398  4.366977e+10   \n",
      "28    -0.001321 -0.001322 -0.001225  3911.369726   45450.073346  3.641720e+10   \n",
      "29    -0.001070 -0.001069 -0.000816  3933.355396   47289.569196  6.684731e+10   \n",
      "30    -0.000685 -0.000686 -0.000698  4058.771872   45771.137511  4.218073e+10   \n",
      "31    -0.000732 -0.000733 -0.000569  3923.669108   43011.521439  5.682617e+10   \n",
      "32    -0.000289 -0.000289 -0.000190  3825.969224   58276.759696  1.655002e+11   \n",
      "33    -0.000599 -0.000598 -0.000607  3842.479649   49370.380105  1.884936e+11   \n",
      "34    -0.000106 -0.000107 -0.000035  3758.958718   54281.940386  1.450933e+11   \n",
      "35    -0.000183 -0.000182 -0.000192  3693.310013   40152.212649  3.401919e+10   \n",
      "36     0.000229  0.000226  0.000316  4122.610588   44082.176437  3.210474e+10   \n",
      "37     0.000350  0.000347  0.000435  3945.891608   46788.268109  6.579517e+10   \n",
      "38     0.000290  0.000287  0.000429  3801.323583   41392.615699  4.452161e+10   \n",
      "39     0.000251  0.000249  0.000309  4089.731600   64214.326960  1.625791e+11   \n",
      "40     0.000767  0.000763  0.000969  3833.658317   91813.798357  6.976923e+11   \n",
      "41     0.001136  0.001129  0.001352  3926.065169   42978.645225  6.692783e+10   \n",
      "42     0.000927  0.000922  0.001083  3959.288880   44596.229273  4.034060e+10   \n",
      "43     0.000846  0.000840  0.001023  3777.743049   35844.374952  1.632306e+10   \n",
      "44     0.000959  0.000954  0.001165  3871.786476   61948.501360  9.523794e+10   \n",
      "45     0.001222  0.001219  0.001310  3881.738720   39021.885669  3.057472e+10   \n",
      "46     0.001109  0.001104  0.001187  3897.186598   41322.190609  3.373693e+10   \n",
      "47     0.000607  0.000603  0.000707  4220.556733   46598.678812  5.540907e+10   \n",
      "48     0.001331  0.001326  0.001544  4576.280139   51694.369589  8.586971e+10   \n",
      "49     0.001030  0.001027  0.001250  4532.365096   71329.527170  2.545884e+11   \n",
      "50     0.001037  0.001030  0.001186  4096.003124   53466.502738  1.724499e+11   \n",
      "51     0.000911  0.000903  0.001077  4271.564467   54452.429306  9.593829e+10   \n",
      "52     0.001219  0.001211  0.001393  4332.804286   51560.960813  7.001991e+10   \n",
      "53     0.000510  0.000504  0.000831  4184.673489   49669.152920  8.111408e+10   \n",
      "54     0.000777  0.000772  0.001084  4632.718320   80594.917183  3.032219e+11   \n",
      "55     0.000670  0.000668  0.000782  4659.282773   59719.724455  8.824719e+10   \n",
      "56     0.000932  0.000931  0.001037  4441.013091   58924.626417  1.275267e+11   \n",
      "57     0.000505  0.000503  0.000634  4283.544529   56881.284219  6.783192e+10   \n",
      "58    -0.000140 -0.000136 -0.000015  4257.464816   88592.957123  4.421627e+11   \n",
      "59     0.000246  0.000253  0.000199  3774.962268   45120.024937  6.437445e+10   \n",
      "60    -0.000489 -0.000481 -0.000566  3538.442367   44162.964427  7.431137e+10   \n",
      "\n",
      "       mean_abs_diff  max_abs_diff  norm_ratio  std_ratio    mean_ratio  \\\n",
      "layer                                                                     \n",
      "0          36.095914    448.039722    0.000176   0.000176  2.022600e+06   \n",
      "1          23.279104    448.039648    0.000134   0.000134  6.717640e+04   \n",
      "2          20.811070    448.076025    0.000174   0.000174 -1.070413e+06   \n",
      "3          42.545957    373.418823    0.146903   0.146904 -3.957470e+05   \n",
      "4          45.634215    373.459147    0.174559   0.174559  1.635415e+05   \n",
      "5          42.294876    373.472270    0.169059   0.169060 -3.113163e+04   \n",
      "6          45.047117    373.493652    0.169408   0.169409  5.302880e+06   \n",
      "7          44.509487    373.485738    0.182962   0.182960  3.320241e+07   \n",
      "8          41.832731    373.493856    0.201253   0.201246  3.075810e+05   \n",
      "9          44.867018    373.484985    0.191212   0.191206 -1.690569e+05   \n",
      "10         44.791637    373.481110    0.177095   0.177088 -1.651539e+06   \n",
      "11         45.094709    373.468343    0.178119   0.178112  3.380822e+05   \n",
      "12         44.663183    373.490763    0.183944   0.183938  2.688658e+07   \n",
      "13         44.325340    373.507462    0.193578   0.193577  2.119224e-01   \n",
      "14         43.773825    373.504272    0.202696   0.202701  1.758884e+05   \n",
      "15         43.650303    373.479858    0.213633   0.213640  4.347012e+05   \n",
      "16         43.957077    373.489156    0.202052   0.202064  2.079754e+06   \n",
      "17         44.236493    373.487956    0.212088   0.212093  1.132580e+06   \n",
      "18         45.237489    373.482422    0.219458   0.219458  2.307796e+06   \n",
      "19         45.480223    373.502724    0.229976   0.229977 -5.266936e+05   \n",
      "20         47.668445    373.538371    0.223859   0.223859  4.111479e+06   \n",
      "21         48.306880    373.503204    0.233131   0.233132 -1.983102e+06   \n",
      "22         46.940085    373.495773    0.246239   0.246238  1.937957e+06   \n",
      "23         47.705673    373.504801    0.262922   0.262919  8.457962e+04   \n",
      "24         46.845186    373.523229    0.267828   0.267825  8.758429e+04   \n",
      "25         46.103125    373.508158    0.263827   0.263824 -3.538511e+07   \n",
      "26         47.454010    373.478058    0.261123   0.261117  1.175494e+06   \n",
      "27         47.593796    373.479696    0.264381   0.264379  4.586115e+06   \n",
      "28         48.874617    373.481527    0.269012   0.269009 -3.414088e+07   \n",
      "29         49.483899    373.486287    0.267872   0.267868 -2.064774e+06   \n",
      "30         49.320511    373.475057    0.263836   0.263834 -2.816930e+07   \n",
      "31         46.905888    373.475179    0.266316   0.266315 -2.900786e+07   \n",
      "32         47.747174    373.469604    0.268888   0.268887 -1.617503e+07   \n",
      "33         48.830886    373.491364    0.254523   0.254521  2.197639e+06   \n",
      "34         46.921373    373.479268    0.261392   0.261391 -2.025165e+07   \n",
      "35         46.300569    373.492472    0.263062   0.263059  5.104522e+06   \n",
      "36         50.155621    373.484843    0.256716   0.256717 -2.817037e+07   \n",
      "37         48.253192    373.456472    0.265274   0.265280 -2.032090e+07   \n",
      "38         46.772023    373.479513    0.262685   0.262687 -1.755644e+07   \n",
      "39         46.559349    373.483538    0.275903   0.275901 -3.027038e+07   \n",
      "40         47.360487    373.457540    0.268529   0.268531 -2.336229e+07   \n",
      "41         46.845509    373.452647    0.264500   0.264505 -3.009107e+07   \n",
      "42         48.445379    373.459432    0.252501   0.252510 -1.767003e+07   \n",
      "43         45.399606    373.482890    0.258154   0.258157 -2.805347e+07   \n",
      "44         47.051765    373.462097    0.261030   0.261032 -2.496118e+07   \n",
      "45         45.690856    373.474955    0.264485   0.264487 -1.693497e+07   \n",
      "46         44.954813    373.458171    0.261305   0.261306 -2.793436e+07   \n",
      "47         46.198360    373.459025    0.262705   0.262716 -1.228775e+07   \n",
      "48         49.735172    373.448771    0.267742   0.267751 -1.932760e+07   \n",
      "49         49.053340    373.464668    0.278844   0.278848 -1.629451e+07   \n",
      "50         47.331959    373.476186    0.273476   0.273475 -3.448145e+07   \n",
      "51         48.859772    373.454590    0.277335   0.277342 -2.491777e+07   \n",
      "52         49.056022    373.453735    0.270328   0.270335 -2.332959e+07   \n",
      "53         47.857891    373.469035    0.287251   0.287268 -1.530711e+07   \n",
      "54         49.280820    373.443729    0.275656   0.275658 -2.823010e+07   \n",
      "55         49.119225    373.438899    0.295842   0.295849 -1.346278e+07   \n",
      "56         51.014257    373.442312    0.296383   0.296384 -8.374003e+06   \n",
      "57         49.309720    373.468562    0.288442   0.288439 -2.614121e+07   \n",
      "58         48.638377    373.440592    0.271862   0.271865 -1.326911e-01   \n",
      "59         46.544265    373.483276    0.229642   0.229645 -5.312970e+05   \n",
      "60         42.727091    373.475545    0.165511   0.165520 -1.294610e+05   \n",
      "\n",
      "      spec_a_max spec_a_min    spec_b_max   spec_b_min  spec_rel_l2_err  \\\n",
      "layer                                                                     \n",
      "0      17.500139   0.098603   101057.4875   225.939307      7025.684229   \n",
      "1      15.597185   0.046446   126885.0375   152.792346      9310.703613   \n",
      "2      15.841028   0.059874    80067.4125   128.158545      6881.948633   \n",
      "3      11.276704   0.114946  54510.552083   491.064779      6613.244868   \n",
      "4      15.713058   0.203396  44070.458333   619.397176      6200.122110   \n",
      "5      16.469251   0.248691  44714.421875    649.72465      5337.069959   \n",
      "6      17.870425   0.294295  46540.927083   885.073649      5419.106229   \n",
      "7       20.24066   0.358414  46344.791667   978.396566      4848.417612   \n",
      "8      21.744202   0.392013  48857.223958   752.364339      4302.961207   \n",
      "9      22.249964    0.34106  43053.416667   994.396403      4416.755826   \n",
      "10      23.52032   0.432077  42266.557292  1084.638672      4180.871183   \n",
      "11     24.365049   0.453549  41714.276042    968.78833      3951.039874   \n",
      "12     23.027184   0.469342  43358.666667  1029.780436      4016.960815   \n",
      "13     21.763115   0.452921  39593.747396  1025.954102      3888.583196   \n",
      "14     22.493459   0.501969  30575.460938   894.070231      3635.562153   \n",
      "15      21.30614   0.488041  29331.723958   957.395182      3570.064818   \n",
      "16     20.296089   0.411525   23714.21875    952.56779      3669.317413   \n",
      "17     20.569509   0.445792  33002.734375  1033.156006      3761.039223   \n",
      "18     19.721779   0.518683  30226.119792   932.833333      3920.371346   \n",
      "19       20.8394   0.433464  31041.161458   933.082275      3533.169928   \n",
      "20     19.876068   0.508729  35112.723958   839.792562      3941.893005   \n",
      "21     19.553089   0.494286  36946.348958   866.363444      3982.743744   \n",
      "22     19.103574   0.419468  33107.393229   769.608643      3738.532587   \n",
      "23     17.847416    0.46835  34161.052083   813.299235      3815.267126   \n",
      "24     17.433187   0.485287  33396.236979   748.267171      3718.374315   \n",
      "25     16.205828   0.433217  31324.276042   748.267334      3859.347688   \n",
      "26     16.016953   0.415701  31170.427083   800.727702      3911.372495   \n",
      "27     13.714483   0.404164   32215.09375   772.045654      4332.815896   \n",
      "28     16.201285   0.451023  31875.109375   835.843424      3910.479064   \n",
      "29     15.026797   0.442045  32883.401042   861.508708      3932.446817   \n",
      "30     14.857853   0.423243  29385.252604   822.552734      4057.882676   \n",
      "31     14.470816   0.411687  31121.286458   752.234945      3922.781661   \n",
      "32     15.205223    0.48507  30230.661458   846.612467      3825.087563   \n",
      "33     15.320573   0.442845  37562.854167   827.043457      3841.550948   \n",
      "34     15.140373   0.455753  34442.252604   892.642822      3758.009798   \n",
      "35     14.519112    0.41532  34695.911458    850.04777      3692.347962   \n",
      "36     14.657738   0.457541  33246.367188   829.731445      4121.720280   \n",
      "37     13.931561   0.437188  30528.286458   799.773275      3944.943415   \n",
      "38     13.209178   0.410271  31976.208333    848.55778      3800.365362   \n",
      "39     13.735709   0.370305  33046.502604   891.564535      4088.861137   \n",
      "40     13.454149   0.407377  32230.476562   902.755371      3832.742479   \n",
      "41      12.19097   0.406983  32437.825521   866.811279      3925.113602   \n",
      "42     12.297834     0.3528    32159.0625   943.077148      3958.371568   \n",
      "43      13.08673   0.414239  32699.869792   875.834229      3776.785991   \n",
      "44     13.044731   0.419979  32822.442708   755.815348      3870.837152   \n",
      "45     13.020288   0.411734  34015.596354   854.952311      3880.817870   \n",
      "46     13.578031   0.434911  36979.166667   807.062174      3896.260802   \n",
      "47     12.207072   0.372998  38154.882812   923.733968      4219.659426   \n",
      "48     12.049366   0.390429    39969.4375   838.462728      4575.344204   \n",
      "49     12.510384   0.422975    41788.6875   841.744629      4531.526584   \n",
      "50     12.495842   0.358555  39427.078125   766.137614      4095.036190   \n",
      "51     13.140569   0.393131  40158.322917   815.285563      4270.629847   \n",
      "52     12.488483   0.381229  39834.942708   762.855469      4331.836719   \n",
      "53     12.738614   0.373783  37684.216146    873.23234      4183.719416   \n",
      "54     11.524822   0.339473  37920.111979    774.75887      4631.835241   \n",
      "55     12.241959    0.37549   38550.28125   826.880697      4658.424475   \n",
      "56       11.7085   0.335528  40089.578125   854.505697      4440.077068   \n",
      "57     12.545601   0.351292  42409.695312   593.186646      4282.648814   \n",
      "58     13.332329   0.316451   44646.34375   513.295207      4256.565378   \n",
      "59     12.313375   0.305423  42416.734375   611.399007      3774.021976   \n",
      "60     11.966503   0.252084  56974.666667   315.890951      3537.388501   \n",
      "\n",
      "       spec_topk_u_cos_mean  spec_topk_u_cos_min  spec_topk_v_cos_mean  \\\n",
      "layer                                                                    \n",
      "0                  0.016537             0.000160              0.008958   \n",
      "1                  0.015710             0.000114              0.008785   \n",
      "2                  0.016849             0.000140              0.008332   \n",
      "3                  0.025523             0.000754              0.010342   \n",
      "4                  0.027598             0.000199              0.011064   \n",
      "5                  0.027039             0.000307              0.010179   \n",
      "6                  0.026626             0.000218              0.011247   \n",
      "7                  0.025475             0.000247              0.010719   \n",
      "8                  0.026400             0.000281              0.011162   \n",
      "9                  0.026938             0.000444              0.010396   \n",
      "10                 0.026285             0.000317              0.010038   \n",
      "11                 0.025525             0.000270              0.010900   \n",
      "12                 0.027018             0.000230              0.011099   \n",
      "13                 0.026349             0.000239              0.010652   \n",
      "14                 0.026394             0.000439              0.010480   \n",
      "15                 0.025361             0.000298              0.010930   \n",
      "16                 0.026199             0.000575              0.010902   \n",
      "17                 0.025479             0.000590              0.010823   \n",
      "18                 0.025258             0.000167              0.010853   \n",
      "19                 0.025544             0.000366              0.010661   \n",
      "20                 0.026439             0.000386              0.011062   \n",
      "21                 0.027014             0.000412              0.011183   \n",
      "22                 0.026634             0.000346              0.010555   \n",
      "23                 0.025230             0.000346              0.010953   \n",
      "24                 0.026866             0.000117              0.010154   \n",
      "25                 0.026860             0.000334              0.011149   \n",
      "26                 0.027186             0.000324              0.010509   \n",
      "27                 0.025656             0.000171              0.011453   \n",
      "28                 0.027887             0.000304              0.010975   \n",
      "29                 0.027088             0.000386              0.010370   \n",
      "30                 0.027691             0.000356              0.010509   \n",
      "31                 0.026768             0.000424              0.010799   \n",
      "32                 0.026257             0.000399              0.010515   \n",
      "33                 0.026502             0.000150              0.011153   \n",
      "34                 0.028345             0.000139              0.010709   \n",
      "35                 0.028019             0.000418              0.010971   \n",
      "36                 0.025154             0.000286              0.010641   \n",
      "37                 0.027563             0.000493              0.011085   \n",
      "38                 0.028110             0.000198              0.010701   \n",
      "39                 0.026396             0.000112              0.010641   \n",
      "40                 0.025712             0.000375              0.010311   \n",
      "41                 0.025898             0.000162              0.010847   \n",
      "42                 0.027357             0.000276              0.011016   \n",
      "43                 0.028029             0.000328              0.010901   \n",
      "44                 0.026942             0.000204              0.011445   \n",
      "45                 0.029617             0.000298              0.010552   \n",
      "46                 0.026935             0.000156              0.010908   \n",
      "47                 0.028264             0.000257              0.010988   \n",
      "48                 0.026254             0.000455              0.010873   \n",
      "49                 0.026562             0.000156              0.010780   \n",
      "50                 0.027426             0.000260              0.011474   \n",
      "51                 0.028622             0.000275              0.010670   \n",
      "52                 0.025849             0.000154              0.010961   \n",
      "53                 0.027661             0.000391              0.010535   \n",
      "54                 0.025506             0.000286              0.010840   \n",
      "55                 0.026475             0.000151              0.010648   \n",
      "56                 0.026505             0.000064              0.010989   \n",
      "57                 0.026903             0.000254              0.011087   \n",
      "58                 0.026940             0.000195              0.011130   \n",
      "59                 0.026539             0.000125              0.010547   \n",
      "60                 0.026904             0.000077              0.011056   \n",
      "\n",
      "       spec_topk_v_cos_min  spec_subspace_overlap_u  spec_subspace_overlap_v  \n",
      "layer                                                                         \n",
      "0                 0.000101                 0.019027                 0.010922  \n",
      "1                 0.000046                 0.019063                 0.010772  \n",
      "2                 0.000062                 0.020446                 0.011147  \n",
      "3                 0.000085                 0.031353                 0.013555  \n",
      "4                 0.000122                 0.031313                 0.013488  \n",
      "5                 0.000094                 0.031824                 0.013591  \n",
      "6                 0.000138                 0.030986                 0.013456  \n",
      "7                 0.000091                 0.031147                 0.013511  \n",
      "8                 0.000169                 0.030696                 0.013581  \n",
      "9                 0.000097                 0.031066                 0.013537  \n",
      "10                0.000083                 0.030760                 0.013438  \n",
      "11                0.000047                 0.030492                 0.013451  \n",
      "12                0.000100                 0.031139                 0.013698  \n",
      "13                0.000033                 0.030816                 0.013535  \n",
      "14                0.000168                 0.031047                 0.013750  \n",
      "15                0.000185                 0.030508                 0.013306  \n",
      "16                0.000035                 0.030690                 0.013484  \n",
      "17                0.000176                 0.030983                 0.013516  \n",
      "18                0.000075                 0.030645                 0.013332  \n",
      "19                0.000105                 0.031064                 0.013852  \n",
      "20                0.000054                 0.030629                 0.013631  \n",
      "21                0.000108                 0.030744                 0.013380  \n",
      "22                0.000130                 0.030877                 0.013577  \n",
      "23                0.000196                 0.030875                 0.013345  \n",
      "24                0.000082                 0.030918                 0.013350  \n",
      "25                0.000132                 0.030730                 0.013343  \n",
      "26                0.000061                 0.030839                 0.013525  \n",
      "27                0.000217                 0.031041                 0.013513  \n",
      "28                0.000075                 0.030930                 0.013507  \n",
      "29                0.000039                 0.031042                 0.013470  \n",
      "30                0.000064                 0.030923                 0.013480  \n",
      "31                0.000116                 0.030990                 0.013587  \n",
      "32                0.000040                 0.030824                 0.013359  \n",
      "33                0.000134                 0.031058                 0.013585  \n",
      "34                0.000195                 0.031129                 0.013603  \n",
      "35                0.000354                 0.031030                 0.013543  \n",
      "36                0.000211                 0.030899                 0.013400  \n",
      "37                0.000128                 0.030968                 0.013521  \n",
      "38                0.000044                 0.030877                 0.013493  \n",
      "39                0.000099                 0.031255                 0.013488  \n",
      "40                0.000049                 0.030719                 0.013478  \n",
      "41                0.000157                 0.030578                 0.013511  \n",
      "42                0.000094                 0.031013                 0.013522  \n",
      "43                0.000092                 0.031194                 0.013426  \n",
      "44                0.000160                 0.031055                 0.013632  \n",
      "45                0.000091                 0.031446                 0.013664  \n",
      "46                0.000039                 0.031128                 0.013383  \n",
      "47                0.000055                 0.031102                 0.013537  \n",
      "48                0.000075                 0.031071                 0.013495  \n",
      "49                0.000099                 0.030743                 0.013512  \n",
      "50                0.000185                 0.031035                 0.013635  \n",
      "51                0.000176                 0.031037                 0.013413  \n",
      "52                0.000076                 0.030716                 0.013541  \n",
      "53                0.000098                 0.030700                 0.013554  \n",
      "54                0.000173                 0.030420                 0.013577  \n",
      "55                0.000118                 0.031146                 0.013520  \n",
      "56                0.000190                 0.031121                 0.013592  \n",
      "57                0.000090                 0.030939                 0.013462  \n",
      "58                0.000260                 0.030858                 0.013563  \n",
      "59                0.000213                 0.030980                 0.013473  \n",
      "60                0.000083                 0.030917                 0.013598  \n",
      "\n",
      "=== layernorm stats (describe) ===\n",
      "          cos_sim     pearson    spearman  rel_l2_err  mean_rel_diff  \\\n",
      "count  302.000000  302.000000  302.000000  302.000000     302.000000   \n",
      "mean     0.963563    0.001364    0.003930    0.903966       1.404837   \n",
      "std      0.072419    0.037280    0.037178    1.081123       2.742865   \n",
      "min      0.498078   -0.144866   -0.141759    0.016897       0.012783   \n",
      "1%       0.557142   -0.090683   -0.082903    0.024140       0.023490   \n",
      "5%       0.855185   -0.054296   -0.057509    0.098984       0.090186   \n",
      "50%      0.993157    0.002341    0.002388    0.474432       0.504654   \n",
      "95%      0.999965    0.067485    0.072153    3.192692       4.561763   \n",
      "99%      0.999997    0.117415    0.112628    4.945868      16.161101   \n",
      "max      0.999999    0.183239    0.137209    7.319476      24.702936   \n",
      "\n",
      "       max_rel_diff  mean_abs_diff  max_abs_diff  norm_ratio   std_ratio  \\\n",
      "count    302.000000     302.000000    302.000000  302.000000  302.000000   \n",
      "mean     156.681234       0.443565      0.824930    0.888084    2.000243   \n",
      "std      797.474330       0.533522      0.676851    0.508395    2.553445   \n",
      "min        0.070988       0.006171      0.031281    0.120433    0.080051   \n",
      "1%         0.088940       0.008520      0.041569    0.169147    0.178505   \n",
      "5%         0.138170       0.017868      0.138205    0.239501    0.267284   \n",
      "50%       12.716930       0.242872      0.596283    0.778921    0.891027   \n",
      "95%      287.434053       1.448285      2.005762    1.802262    8.077391   \n",
      "99%     4393.195371       2.333940      2.572470    2.451044   10.240369   \n",
      "max    10239.000000       3.316026      3.513270    3.051423   12.237870   \n",
      "\n",
      "       mean_ratio  spec_rel_l2_err  spec_topk_u_cos_mean  spec_topk_u_cos_min  \\\n",
      "count  302.000000       302.000000                 302.0                302.0   \n",
      "mean     0.887491         0.823906                   1.0                  1.0   \n",
      "std      0.510084         1.078790                   0.0                  0.0   \n",
      "min      0.119603         0.000015                   1.0                  1.0   \n",
      "1%       0.165605         0.008605                   1.0                  1.0   \n",
      "5%       0.238993         0.039730                   1.0                  1.0   \n",
      "50%      0.771332         0.396779                   1.0                  1.0   \n",
      "95%      1.788723         3.175373                   1.0                  1.0   \n",
      "99%      2.453490         4.912921                   1.0                  1.0   \n",
      "max      3.063137         7.303339                   1.0                  1.0   \n",
      "\n",
      "       spec_topk_v_cos_mean  spec_topk_v_cos_min  spec_subspace_overlap_u  \\\n",
      "count            302.000000           302.000000                    302.0   \n",
      "mean               0.963563             0.963563                      1.0   \n",
      "std                0.072419             0.072419                      0.0   \n",
      "min                0.498078             0.498078                      1.0   \n",
      "1%                 0.557142             0.557142                      1.0   \n",
      "5%                 0.855185             0.855185                      1.0   \n",
      "50%                0.993157             0.993157                      1.0   \n",
      "95%                0.999965             0.999965                      1.0   \n",
      "99%                0.999996             0.999996                      1.0   \n",
      "max                0.999999             0.999999                      1.0   \n",
      "\n",
      "       spec_subspace_overlap_v  \n",
      "count               302.000000  \n",
      "mean                  0.963563  \n",
      "std                   0.072419  \n",
      "min                   0.498078  \n",
      "1%                    0.557142  \n",
      "5%                    0.855185  \n",
      "50%                   0.993157  \n",
      "95%                   0.999965  \n",
      "99%                   0.999997  \n",
      "max                   1.000001  \n"
     ]
    }
   ],
   "source": [
    "SUMMARY_METRICS = [\n",
    "    # base\n",
    "    \"cos_sim\",\n",
    "    \"pearson\",\n",
    "    \"spearman\",\n",
    "    \"rel_l2_err\",\n",
    "    \"mean_rel_diff\",\n",
    "    \"max_rel_diff\",\n",
    "    \"mean_abs_diff\",\n",
    "    \"max_abs_diff\",\n",
    "    \"norm_ratio\",\n",
    "    \"std_ratio\",\n",
    "    \"mean_ratio\",\n",
    "\n",
    "    # spectral (SVD)\n",
    "    \"spec_a_max\",\n",
    "    \"spec_a_min\",\n",
    "    \"spec_b_max\",\n",
    "    \"spec_b_min\",\n",
    "    \"spec_rel_l2_err\",\n",
    "    \"spec_topk_u_cos_mean\",\n",
    "    \"spec_topk_u_cos_min\",\n",
    "    \"spec_topk_v_cos_mean\",\n",
    "    \"spec_topk_v_cos_min\",\n",
    "    \"spec_subspace_overlap_u\",\n",
    "    \"spec_subspace_overlap_v\",\n",
    "]\n",
    "\n",
    "def _safe_filter_columns(df, cols: Sequence[str]):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "# --- LayerNorm detection ---\n",
    "LAYERNORM_SUFFIXES = (\n",
    "    \".layernorm.weight\",\n",
    "    \".layer_norm.weight\",\n",
    "    \".ln.weight\",\n",
    "    \".ln_f.weight\",\n",
    "    \"layernorm.weight\",\n",
    "    \"layer_norm.weight\",\n",
    "    # bias here too\n",
    "    \"e_score_correction_bias\",\n",
    ")\n",
    "def is_layernorm_key(key: str, suffixes=LAYERNORM_SUFFIXES) -> bool:\n",
    "    return any(key.endswith(suf) for suf in suffixes)\n",
    "\n",
    "def _describe(df_part: pd.DataFrame, metrics: Sequence[str]):\n",
    "    if df_part is None or len(df_part) == 0:\n",
    "        return pd.DataFrame()\n",
    "    return df_part[list(metrics)].describe(\n",
    "        percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]\n",
    "    )\n",
    "\n",
    "def _closeness_stats(df_part: pd.DataFrame, prefix=\"\"):\n",
    "    out = {}\n",
    "    if df_part is None or len(df_part) == 0:\n",
    "        return out\n",
    "    if \"cos_sim\" in df_part:\n",
    "        out[f\"{prefix}cos_gt_0.99_frac\"] = (df_part[\"cos_sim\"] > 0.99).mean()\n",
    "        out[f\"{prefix}cos_gt_0.999_frac\"] = (df_part[\"cos_sim\"] > 0.999).mean()\n",
    "    return out\n",
    "    \n",
    "def summarize_results(df: pd.DataFrame):\n",
    "    # drop shape mismatches and other non-comparable rows\n",
    "    comparable = df[df.get(\"note\").isna()]\n",
    "    shape_mismatches = df[\"note\"].eq(\"shape_mismatch\").sum() if \"note\" in df else 0\n",
    "\n",
    "    metrics = _safe_filter_columns(comparable, SUMMARY_METRICS)\n",
    "\n",
    "    # split layernorm vs others\n",
    "    if \"key\" in comparable:\n",
    "        ln_mask = comparable[\"key\"].apply(is_layernorm_key)\n",
    "    else:\n",
    "        ln_mask = pd.Series(False, index=comparable.index)\n",
    "\n",
    "    ln_part = comparable[ln_mask]\n",
    "    other_part = comparable[~ln_mask]\n",
    "\n",
    "    ln_summary = _describe(ln_part, metrics)\n",
    "    other_summary = _describe(other_part, metrics)\n",
    "\n",
    "    layer_summary = {}\n",
    "    layer_summary_ln = {}\n",
    "    layer_summary_other = {}\n",
    "    if \"layer\" in comparable:\n",
    "        if len(comparable) > 0:\n",
    "            layer_summary = comparable.groupby(\"layer\")[metrics].mean()\n",
    "        if len(ln_part) > 0:\n",
    "            layer_summary_ln = ln_part.groupby(\"layer\")[metrics].mean()\n",
    "        if len(other_part) > 0:\n",
    "            layer_summary_other = other_part.groupby(\"layer\")[metrics].mean()\n",
    "\n",
    "    closeness = {}\n",
    "    closeness.update(_closeness_stats(comparable, prefix=\"all_\"))\n",
    "    closeness.update(_closeness_stats(ln_part, prefix=\"ln_\"))\n",
    "    closeness.update(_closeness_stats(other_part, prefix=\"other_\"))\n",
    "\n",
    "    coverage = {\n",
    "        \"total_rows\": len(df),\n",
    "        \"comparable_rows\": len(comparable),\n",
    "        \"shape_mismatches\": int(shape_mismatches),\n",
    "        \"layernorm_rows\": int(len(ln_part)),\n",
    "        \"other_rows\": int(len(other_part)),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"coverage\": coverage,\n",
    "        \"closeness\": closeness,\n",
    "        \"layer_mean\": layer_summary,\n",
    "        \"layernorm_summary\": ln_summary,\n",
    "        \"other_summary\": other_summary,\n",
    "        \"layernorm_layer_mean\": layer_summary_ln,\n",
    "        \"other_layer_mean\": layer_summary_other,\n",
    "    }\n",
    "\n",
    "def print_summary(summary):\n",
    "    if isinstance(summary.get(\"other_summary\"), pd.DataFrame) and not summary[\"other_summary\"].empty:\n",
    "        print(\"\\n=== non-layernorm stats (describe) ===\")\n",
    "        print(summary[\"other_summary\"])\n",
    "\n",
    "    if isinstance(summary.get(\"other_layer_mean\"), pd.DataFrame) and not summary[\"other_layer_mean\"].empty:\n",
    "        print(\"\\n=== per-layer mean metrics (non-layernorm) ===\")\n",
    "        print(summary[\"other_layer_mean\"])\n",
    "\n",
    "    if isinstance(summary.get(\"layernorm_summary\"), pd.DataFrame) and not summary[\"layernorm_summary\"].empty:\n",
    "        print(\"\\n=== layernorm stats (describe) ===\")\n",
    "        print(summary[\"layernorm_summary\"])\n",
    "\n",
    "summary = summarize_results(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09d9029b-9199-4442-87ae-c55f05f04f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>key</th>\n",
       "      <th>shape</th>\n",
       "      <th>numel</th>\n",
       "      <th>norm_a</th>\n",
       "      <th>norm_b</th>\n",
       "      <th>norm_ratio</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_a</th>\n",
       "      <th>std_b</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>zero_frac_a</th>\n",
       "      <th>zero_frac_b</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rel_l2_err</th>\n",
       "      <th>mean_rel_diff</th>\n",
       "      <th>max_rel_diff</th>\n",
       "      <th>pearson</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "      <th>spearman</th>\n",
       "      <th>q01_abs_diff</th>\n",
       "      <th>q05_abs_diff</th>\n",
       "      <th>q50_abs_diff</th>\n",
       "      <th>q95_abs_diff</th>\n",
       "      <th>q99_abs_diff</th>\n",
       "      <th>spec_rel_l2_err</th>\n",
       "      <th>spec_a_max</th>\n",
       "      <th>spec_a_min</th>\n",
       "      <th>spec_b_max</th>\n",
       "      <th>spec_b_min</th>\n",
       "      <th>spec_topk_u_cos_mean</th>\n",
       "      <th>spec_topk_u_cos_min</th>\n",
       "      <th>spec_topk_v_cos_mean</th>\n",
       "      <th>spec_topk_v_cos_min</th>\n",
       "      <th>spec_subspace_overlap_u</th>\n",
       "      <th>spec_subspace_overlap_v</th>\n",
       "      <th>shape_a</th>\n",
       "      <th>shape_b</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>59.667873</td>\n",
       "      <td>428978.468750</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>1.938400e-07</td>\n",
       "      <td>-5.042707e-03</td>\n",
       "      <td>1.938400e+05</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>37.320744</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>7189.438477</td>\n",
       "      <td>83933.062500</td>\n",
       "      <td>6.245747e+11</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>23.491154</td>\n",
       "      <td>-6.912752e-06</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>1.003906</td>\n",
       "      <td>13.997543</td>\n",
       "      <td>80.000687</td>\n",
       "      <td>143.996338</td>\n",
       "      <td>7188.874512</td>\n",
       "      <td>tensor(10.6355, device='cuda:0')</td>\n",
       "      <td>tensor(0.0307, device='cuda:0')</td>\n",
       "      <td>tensor(88471.5312, device='cuda:0')</td>\n",
       "      <td>tensor(123.8643, device='cuda:0')</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>2.135959e-05</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>8.940118e-05</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>56.593945</td>\n",
       "      <td>233500.296875</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-1.141391e-05</td>\n",
       "      <td>2.023005e-01</td>\n",
       "      <td>-5.642058e-05</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>20.313309</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>4125.888672</td>\n",
       "      <td>94711.351562</td>\n",
       "      <td>1.379779e+12</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>448.040039</td>\n",
       "      <td>6.796145</td>\n",
       "      <td>-2.233854e-03</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.186165</td>\n",
       "      <td>2.499613</td>\n",
       "      <td>23.998825</td>\n",
       "      <td>79.999825</td>\n",
       "      <td>4124.767578</td>\n",
       "      <td>tensor(42.7907, device='cuda:0')</td>\n",
       "      <td>tensor(0.0222, device='cuda:0')</td>\n",
       "      <td>tensor(172167.4219, device='cuda:0')</td>\n",
       "      <td>tensor(14.0500, device='cuda:0')</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>1.085157e-05</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>6.676973e-05</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>51.375027</td>\n",
       "      <td>589028.500000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>4.222969e-07</td>\n",
       "      <td>-3.271475e-03</td>\n",
       "      <td>4.222969e+05</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>51.244949</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>11465.268555</td>\n",
       "      <td>144081.312500</td>\n",
       "      <td>6.944284e+11</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>448.027222</td>\n",
       "      <td>35.005745</td>\n",
       "      <td>1.957554e-05</td>\n",
       "      <td>0.376633</td>\n",
       "      <td>1.876915</td>\n",
       "      <td>23.983521</td>\n",
       "      <td>111.997208</td>\n",
       "      <td>176.000168</td>\n",
       "      <td>11464.057617</td>\n",
       "      <td>tensor(9.5120, device='cuda:0')</td>\n",
       "      <td>tensor(0.0260, device='cuda:0')</td>\n",
       "      <td>tensor(171213.8281, device='cuda:0')</td>\n",
       "      <td>tensor(193.5397, device='cuda:0')</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>7.110900e-05</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>2.253988e-04</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.883209</td>\n",
       "      <td>143063.109375</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>8.415574e-06</td>\n",
       "      <td>-5.285055e-02</td>\n",
       "      <td>8.415574e+06</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>70.407242</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>3336.111328</td>\n",
       "      <td>27890.207031</td>\n",
       "      <td>5.200393e+09</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>448.052734</td>\n",
       "      <td>47.079998</td>\n",
       "      <td>-8.733455e-04</td>\n",
       "      <td>0.450989</td>\n",
       "      <td>2.255432</td>\n",
       "      <td>27.993683</td>\n",
       "      <td>160.000259</td>\n",
       "      <td>239.989075</td>\n",
       "      <td>3335.079834</td>\n",
       "      <td>tensor(10.8030, device='cuda:0')</td>\n",
       "      <td>tensor(0.3528, device='cuda:0')</td>\n",
       "      <td>tensor(24165.8203, device='cuda:0')</td>\n",
       "      <td>tensor(349.4814, device='cuda:0')</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>3.276460e-04</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>1.366049e-05</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>32.806965</td>\n",
       "      <td>295782.718750</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.081290e-06</td>\n",
       "      <td>-1.848673e-02</td>\n",
       "      <td>1.081290e+06</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>89.141144</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>9015.852539</td>\n",
       "      <td>108942.070312</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>448.038086</td>\n",
       "      <td>68.106529</td>\n",
       "      <td>-2.073852e-05</td>\n",
       "      <td>0.940406</td>\n",
       "      <td>4.515320</td>\n",
       "      <td>52.008484</td>\n",
       "      <td>176.012634</td>\n",
       "      <td>255.995758</td>\n",
       "      <td>9015.641602</td>\n",
       "      <td>tensor(13.7596, device='cuda:0')</td>\n",
       "      <td>tensor(0.0613, device='cuda:0')</td>\n",
       "      <td>tensor(49268.8477, device='cuda:0')</td>\n",
       "      <td>tensor(448.7613, device='cuda:0')</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>3.701173e-04</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>1.076259e-04</td>\n",
       "      <td>0.025462</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>31.056589</td>\n",
       "      <td>311506.968750</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.974590e-08</td>\n",
       "      <td>-6.014036e-03</td>\n",
       "      <td>1.974590e+04</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>27.100826</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>10030.302734</td>\n",
       "      <td>92496.351562</td>\n",
       "      <td>2.210074e+11</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>448.031982</td>\n",
       "      <td>15.785647</td>\n",
       "      <td>-8.367174e-05</td>\n",
       "      <td>0.142975</td>\n",
       "      <td>0.748177</td>\n",
       "      <td>9.001137</td>\n",
       "      <td>52.000927</td>\n",
       "      <td>104.000656</td>\n",
       "      <td>10030.518555</td>\n",
       "      <td>tensor(14.0962, device='cuda:0')</td>\n",
       "      <td>tensor(0.0196, device='cuda:0')</td>\n",
       "      <td>tensor(152488.9688, device='cuda:0')</td>\n",
       "      <td>tensor(54.7479, device='cuda:0')</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>2.635098e-05</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>2.208141e-05</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>46.198711</td>\n",
       "      <td>275344.031250</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>7.893201e-06</td>\n",
       "      <td>2.129500e-01</td>\n",
       "      <td>3.706598e-05</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>23.953739</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-0.002543</td>\n",
       "      <td>5959.996582</td>\n",
       "      <td>80385.343750</td>\n",
       "      <td>1.901858e+11</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>448.058594</td>\n",
       "      <td>5.853664</td>\n",
       "      <td>-4.157898e-03</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.102169</td>\n",
       "      <td>1.375315</td>\n",
       "      <td>17.999088</td>\n",
       "      <td>111.999542</td>\n",
       "      <td>5958.773926</td>\n",
       "      <td>tensor(39.3205, device='cuda:0')</td>\n",
       "      <td>tensor(0.0202, device='cuda:0')</td>\n",
       "      <td>tensor(243742.2188, device='cuda:0')</td>\n",
       "      <td>tensor(14.6983, device='cuda:0')</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>2.853623e-05</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>9.212323e-05</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>24.128511</td>\n",
       "      <td>398866.781250</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-7.624888e-08</td>\n",
       "      <td>7.651516e-03</td>\n",
       "      <td>-9.965200e-06</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>34.701054</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>16530.933594</td>\n",
       "      <td>175742.328125</td>\n",
       "      <td>9.296684e+11</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>448.016846</td>\n",
       "      <td>19.753969</td>\n",
       "      <td>8.872247e-05</td>\n",
       "      <td>0.171158</td>\n",
       "      <td>0.872360</td>\n",
       "      <td>10.002838</td>\n",
       "      <td>72.000519</td>\n",
       "      <td>143.999527</td>\n",
       "      <td>16530.671875</td>\n",
       "      <td>tensor(8.9352, device='cuda:0')</td>\n",
       "      <td>tensor(0.0173, device='cuda:0')</td>\n",
       "      <td>tensor(183980.1406, device='cuda:0')</td>\n",
       "      <td>tensor(92.7970, device='cuda:0')</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>2.599603e-05</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>8.757383e-05</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>28.544937</td>\n",
       "      <td>119154.664062</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-4.458476e-08</td>\n",
       "      <td>-2.386205e-02</td>\n",
       "      <td>-4.458476e+04</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>58.640915</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>4174.283691</td>\n",
       "      <td>40850.437500</td>\n",
       "      <td>1.004120e+10</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>448.053955</td>\n",
       "      <td>38.335239</td>\n",
       "      <td>3.593929e-05</td>\n",
       "      <td>0.347580</td>\n",
       "      <td>1.748683</td>\n",
       "      <td>23.976929</td>\n",
       "      <td>127.997711</td>\n",
       "      <td>208.010315</td>\n",
       "      <td>4173.245117</td>\n",
       "      <td>tensor(8.2266, device='cuda:0')</td>\n",
       "      <td>tensor(0.1509, device='cuda:0')</td>\n",
       "      <td>tensor(18662.9473, device='cuda:0')</td>\n",
       "      <td>tensor(459.6478, device='cuda:0')</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>3.778761e-05</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>1.464497e-05</td>\n",
       "      <td>0.042643</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>17.876047</td>\n",
       "      <td>176267.359375</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>3.607209e-07</td>\n",
       "      <td>-9.147654e-03</td>\n",
       "      <td>3.607209e+05</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>53.122345</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>9860.533203</td>\n",
       "      <td>125684.679688</td>\n",
       "      <td>5.753258e+10</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>36.667000</td>\n",
       "      <td>-5.945576e-04</td>\n",
       "      <td>0.406069</td>\n",
       "      <td>1.999565</td>\n",
       "      <td>24.006989</td>\n",
       "      <td>111.999786</td>\n",
       "      <td>176.004730</td>\n",
       "      <td>9860.308594</td>\n",
       "      <td>tensor(7.4074, device='cuda:0')</td>\n",
       "      <td>tensor(0.0243, device='cuda:0')</td>\n",
       "      <td>tensor(35550.9570, device='cuda:0')</td>\n",
       "      <td>tensor(142.0708, device='cuda:0')</td>\n",
       "      <td>0.021420</td>\n",
       "      <td>4.508418e-04</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>1.584741e-05</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.down_proj.weight</td>\n",
       "      <td>(7168, 18432)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>35.113667</td>\n",
       "      <td>253710.390625</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>2.642451e-07</td>\n",
       "      <td>-2.943784e-04</td>\n",
       "      <td>2.642451e+05</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>22.072577</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>7225.403320</td>\n",
       "      <td>84006.882812</td>\n",
       "      <td>5.088649e+11</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>12.308104</td>\n",
       "      <td>3.585698e-05</td>\n",
       "      <td>0.115158</td>\n",
       "      <td>0.563599</td>\n",
       "      <td>7.004242</td>\n",
       "      <td>39.999340</td>\n",
       "      <td>87.996933</td>\n",
       "      <td>7226.452637</td>\n",
       "      <td>tensor(15.4160, device='cuda:0')</td>\n",
       "      <td>tensor(0.0190, device='cuda:0')</td>\n",
       "      <td>tensor(84441.4688, device='cuda:0')</td>\n",
       "      <td>tensor(54.8235, device='cuda:0')</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>1.097677e-04</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>3.087616e-05</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.gate_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>47.933502</td>\n",
       "      <td>201596.265625</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>3.276502e-06</td>\n",
       "      <td>9.338737e-02</td>\n",
       "      <td>3.508507e-05</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>17.538445</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>4205.749023</td>\n",
       "      <td>78158.953125</td>\n",
       "      <td>1.039538e+12</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>448.207031</td>\n",
       "      <td>4.621072</td>\n",
       "      <td>-2.001503e-03</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.093677</td>\n",
       "      <td>1.249559</td>\n",
       "      <td>15.999390</td>\n",
       "      <td>71.999466</td>\n",
       "      <td>4203.634766</td>\n",
       "      <td>tensor(36.6742, device='cuda:0')</td>\n",
       "      <td>tensor(0.0205, device='cuda:0')</td>\n",
       "      <td>tensor(140462.8750, device='cuda:0')</td>\n",
       "      <td>tensor(14.2677, device='cuda:0')</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>2.442019e-06</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>1.423434e-04</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.mlp.up_proj.weight</td>\n",
       "      <td>(18432, 7168)</td>\n",
       "      <td>132120576.0</td>\n",
       "      <td>28.609304</td>\n",
       "      <td>325057.093750</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2.105856e-07</td>\n",
       "      <td>9.443110e-04</td>\n",
       "      <td>2.230045e-04</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>28.279673</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>11361.936523</td>\n",
       "      <td>136232.515625</td>\n",
       "      <td>9.815383e+11</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>448.032227</td>\n",
       "      <td>15.789912</td>\n",
       "      <td>-6.906464e-05</td>\n",
       "      <td>0.155973</td>\n",
       "      <td>0.752869</td>\n",
       "      <td>9.000614</td>\n",
       "      <td>52.000919</td>\n",
       "      <td>112.000687</td>\n",
       "      <td>11360.679688</td>\n",
       "      <td>tensor(9.6203, device='cuda:0')</td>\n",
       "      <td>tensor(0.0193, device='cuda:0')</td>\n",
       "      <td>tensor(109925.6328, device='cuda:0')</td>\n",
       "      <td>tensor(82.5646, device='cuda:0')</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>1.657797e-04</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>3.409907e-05</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>27.854443</td>\n",
       "      <td>98536.000000</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-3.046824e-06</td>\n",
       "      <td>-1.653090e-02</td>\n",
       "      <td>-3.046824e+06</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>48.493622</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>3537.533447</td>\n",
       "      <td>48838.906250</td>\n",
       "      <td>6.926057e+10</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>-1.181142e-03</td>\n",
       "      <td>0.276855</td>\n",
       "      <td>1.376617</td>\n",
       "      <td>17.991028</td>\n",
       "      <td>104.005463</td>\n",
       "      <td>191.986572</td>\n",
       "      <td>3536.529297</td>\n",
       "      <td>tensor(9.8898, device='cuda:0')</td>\n",
       "      <td>tensor(0.2098, device='cuda:0')</td>\n",
       "      <td>tensor(23450.2578, device='cuda:0')</td>\n",
       "      <td>tensor(299.2184, device='cuda:0')</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>3.163759e-04</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>8.393408e-05</td>\n",
       "      <td>0.045957</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>23.909323</td>\n",
       "      <td>193261.531250</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-2.569489e-06</td>\n",
       "      <td>-1.133139e-02</td>\n",
       "      <td>-2.569488e+06</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>58.243946</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>8083.104004</td>\n",
       "      <td>142250.140625</td>\n",
       "      <td>5.695312e+11</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>448.025635</td>\n",
       "      <td>41.066807</td>\n",
       "      <td>-5.489405e-04</td>\n",
       "      <td>0.488159</td>\n",
       "      <td>2.496185</td>\n",
       "      <td>28.007050</td>\n",
       "      <td>120.005280</td>\n",
       "      <td>192.003342</td>\n",
       "      <td>8082.446777</td>\n",
       "      <td>tensor(7.6048, device='cuda:0')</td>\n",
       "      <td>tensor(0.0309, device='cuda:0')</td>\n",
       "      <td>tensor(42056.8438, device='cuda:0')</td>\n",
       "      <td>tensor(189.9186, device='cuda:0')</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>1.052731e-04</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.998310e-05</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>29.393806</td>\n",
       "      <td>33.376320</td>\n",
       "      <td>0.880678</td>\n",
       "      <td>7.770116e-05</td>\n",
       "      <td>1.165834e-04</td>\n",
       "      <td>6.664856e-01</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>0.024639</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>1.515584</td>\n",
       "      <td>13.248475</td>\n",
       "      <td>1.562718e+06</td>\n",
       "      <td>-0.003391</td>\n",
       "      <td>0.277832</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>-3.804966e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>0.250704</td>\n",
       "      <td>tensor(10.6866, device='cuda:0')</td>\n",
       "      <td>tensor(0.3523, device='cuda:0')</td>\n",
       "      <td>tensor(17.3292, device='cuda:0')</td>\n",
       "      <td>tensor(0.6943, device='cuda:0')</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>2.375107e-03</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>1.735121e-04</td>\n",
       "      <td>0.063449</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>28.635567</td>\n",
       "      <td>241520.312500</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-2.374483e-06</td>\n",
       "      <td>-6.645652e-03</td>\n",
       "      <td>-2.374483e+06</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>63.036152</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>8434.277344</td>\n",
       "      <td>111086.609375</td>\n",
       "      <td>1.099512e+11</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.027954</td>\n",
       "      <td>45.915237</td>\n",
       "      <td>2.101869e-04</td>\n",
       "      <td>0.570087</td>\n",
       "      <td>2.995636</td>\n",
       "      <td>32.006226</td>\n",
       "      <td>128.003174</td>\n",
       "      <td>192.008850</td>\n",
       "      <td>8433.610352</td>\n",
       "      <td>tensor(8.8674, device='cuda:0')</td>\n",
       "      <td>tensor(0.0510, device='cuda:0')</td>\n",
       "      <td>tensor(25072.1465, device='cuda:0')</td>\n",
       "      <td>tensor(734.4297, device='cuda:0')</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>1.157948e-04</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>3.225813e-05</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.022368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>31.387489</td>\n",
       "      <td>230882.187500</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>3.296047e-05</td>\n",
       "      <td>2.247492e-01</td>\n",
       "      <td>1.466545e-04</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>60.259205</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>7355.858887</td>\n",
       "      <td>106107.656250</td>\n",
       "      <td>4.311810e+10</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>448.034912</td>\n",
       "      <td>40.476818</td>\n",
       "      <td>-3.379034e-03</td>\n",
       "      <td>0.409973</td>\n",
       "      <td>2.003235</td>\n",
       "      <td>26.005737</td>\n",
       "      <td>127.991394</td>\n",
       "      <td>223.995483</td>\n",
       "      <td>7353.974121</td>\n",
       "      <td>tensor(25.5352, device='cuda:0')</td>\n",
       "      <td>tensor(0.0300, device='cuda:0')</td>\n",
       "      <td>tensor(208050.1562, device='cuda:0')</td>\n",
       "      <td>tensor(317.1217, device='cuda:0')</td>\n",
       "      <td>0.023236</td>\n",
       "      <td>3.001294e-05</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>6.010657e-05</td>\n",
       "      <td>0.021871</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>25.626366</td>\n",
       "      <td>355590.343750</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>6.067139e-07</td>\n",
       "      <td>1.293623e-03</td>\n",
       "      <td>4.690038e-04</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>92.808113</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>13875.956055</td>\n",
       "      <td>188024.328125</td>\n",
       "      <td>2.638828e+11</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>448.029175</td>\n",
       "      <td>72.166595</td>\n",
       "      <td>3.838496e-04</td>\n",
       "      <td>1.007935</td>\n",
       "      <td>5.490479</td>\n",
       "      <td>59.993073</td>\n",
       "      <td>191.994324</td>\n",
       "      <td>255.998505</td>\n",
       "      <td>13875.400391</td>\n",
       "      <td>tensor(5.3848, device='cuda:0')</td>\n",
       "      <td>tensor(0.0481, device='cuda:0')</td>\n",
       "      <td>tensor(32384.3535, device='cuda:0')</td>\n",
       "      <td>tensor(1131.4620, device='cuda:0')</td>\n",
       "      <td>0.019030</td>\n",
       "      <td>1.416251e-03</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>1.322419e-04</td>\n",
       "      <td>0.022202</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>34.273003</td>\n",
       "      <td>139565.296875</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>5.541524e-06</td>\n",
       "      <td>3.586704e-02</td>\n",
       "      <td>1.545019e-04</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>68.685829</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>4072.165283</td>\n",
       "      <td>44838.820312</td>\n",
       "      <td>1.610613e+10</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>448.102539</td>\n",
       "      <td>47.355137</td>\n",
       "      <td>-9.473588e-04</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>2.491821</td>\n",
       "      <td>30.020508</td>\n",
       "      <td>144.023438</td>\n",
       "      <td>224.016846</td>\n",
       "      <td>4071.075928</td>\n",
       "      <td>tensor(11.2872, device='cuda:0')</td>\n",
       "      <td>tensor(0.1793, device='cuda:0')</td>\n",
       "      <td>tensor(19336.4766, device='cuda:0')</td>\n",
       "      <td>tensor(493.9148, device='cuda:0')</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>3.697004e-04</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>1.054758e-04</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>37.585987</td>\n",
       "      <td>223475.562500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-1.298052e-06</td>\n",
       "      <td>1.999416e-02</td>\n",
       "      <td>-6.492158e-05</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>67.349655</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>5945.715332</td>\n",
       "      <td>76040.718750</td>\n",
       "      <td>1.019415e+11</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>49.336349</td>\n",
       "      <td>-1.592607e-04</td>\n",
       "      <td>0.629211</td>\n",
       "      <td>3.240967</td>\n",
       "      <td>36.002991</td>\n",
       "      <td>143.994354</td>\n",
       "      <td>208.007111</td>\n",
       "      <td>5945.157715</td>\n",
       "      <td>tensor(5.8989, device='cuda:0')</td>\n",
       "      <td>tensor(0.0289, device='cuda:0')</td>\n",
       "      <td>tensor(42202.8633, device='cuda:0')</td>\n",
       "      <td>tensor(268.7662, device='cuda:0')</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>2.149240e-04</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>4.613798e-06</td>\n",
       "      <td>0.025574</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.083839</td>\n",
       "      <td>38.301109</td>\n",
       "      <td>1.046545</td>\n",
       "      <td>9.968146e-05</td>\n",
       "      <td>1.027509e-04</td>\n",
       "      <td>9.701275e-01</td>\n",
       "      <td>0.029590</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>1.046546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005643</td>\n",
       "      <td>1.387016</td>\n",
       "      <td>10.403044</td>\n",
       "      <td>2.972342e+06</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>0.514404</td>\n",
       "      <td>0.032241</td>\n",
       "      <td>-4.600448e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.081299</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>tensor(18.2650, device='cuda:0')</td>\n",
       "      <td>tensor(0.7453, device='cuda:0')</td>\n",
       "      <td>tensor(18.6203, device='cuda:0')</td>\n",
       "      <td>tensor(0.8897, device='cuda:0')</td>\n",
       "      <td>0.061384</td>\n",
       "      <td>6.467307e-04</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>2.562767e-04</td>\n",
       "      <td>0.062927</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>31.385395</td>\n",
       "      <td>252685.328125</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>9.522834e-07</td>\n",
       "      <td>-7.535151e-03</td>\n",
       "      <td>9.522834e+05</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>65.950188</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>8051.048340</td>\n",
       "      <td>104473.632812</td>\n",
       "      <td>2.286984e+11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>448.034668</td>\n",
       "      <td>48.497044</td>\n",
       "      <td>3.059335e-04</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>3.016235</td>\n",
       "      <td>35.999348</td>\n",
       "      <td>143.989685</td>\n",
       "      <td>207.994507</td>\n",
       "      <td>8050.613770</td>\n",
       "      <td>tensor(6.2823, device='cuda:0')</td>\n",
       "      <td>tensor(0.0831, device='cuda:0')</td>\n",
       "      <td>tensor(22417.9316, device='cuda:0')</td>\n",
       "      <td>tensor(1011.9544, device='cuda:0')</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>7.492003e-05</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>2.823336e-04</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.515797</td>\n",
       "      <td>200585.921875</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>3.550852e-05</td>\n",
       "      <td>2.336629e-01</td>\n",
       "      <td>1.519648e-04</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>52.351864</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>3748.165527</td>\n",
       "      <td>41904.957031</td>\n",
       "      <td>1.778622e+10</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>448.047607</td>\n",
       "      <td>35.467117</td>\n",
       "      <td>-7.591132e-03</td>\n",
       "      <td>0.379333</td>\n",
       "      <td>1.878891</td>\n",
       "      <td>23.997864</td>\n",
       "      <td>104.023315</td>\n",
       "      <td>176.067383</td>\n",
       "      <td>3748.627930</td>\n",
       "      <td>tensor(50.2790, device='cuda:0')</td>\n",
       "      <td>tensor(0.0472, device='cuda:0')</td>\n",
       "      <td>tensor(161259.3125, device='cuda:0')</td>\n",
       "      <td>tensor(336.0762, device='cuda:0')</td>\n",
       "      <td>0.023238</td>\n",
       "      <td>1.302439e-04</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>9.551667e-05</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>30.086203</td>\n",
       "      <td>340374.531250</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2.896452e-08</td>\n",
       "      <td>-2.909102e-02</td>\n",
       "      <td>2.896452e+04</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>88.836830</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>11313.309570</td>\n",
       "      <td>123050.289062</td>\n",
       "      <td>9.657872e+10</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>448.027832</td>\n",
       "      <td>68.796997</td>\n",
       "      <td>-9.841732e-05</td>\n",
       "      <td>0.998769</td>\n",
       "      <td>5.001511</td>\n",
       "      <td>55.997406</td>\n",
       "      <td>176.004272</td>\n",
       "      <td>255.986877</td>\n",
       "      <td>11313.096680</td>\n",
       "      <td>tensor(4.1486, device='cuda:0')</td>\n",
       "      <td>tensor(0.0846, device='cuda:0')</td>\n",
       "      <td>tensor(27389.6152, device='cuda:0')</td>\n",
       "      <td>tensor(1417.6627, device='cuda:0')</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>2.775257e-04</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>6.161588e-06</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.011721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>34.652184</td>\n",
       "      <td>153807.328125</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-4.588853e-06</td>\n",
       "      <td>4.405908e-02</td>\n",
       "      <td>-1.041523e-04</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>75.694916</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>4438.604004</td>\n",
       "      <td>103584.546875</td>\n",
       "      <td>2.521173e+11</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>54.851147</td>\n",
       "      <td>2.915825e-04</td>\n",
       "      <td>0.569122</td>\n",
       "      <td>2.974731</td>\n",
       "      <td>39.991089</td>\n",
       "      <td>160.002487</td>\n",
       "      <td>239.970703</td>\n",
       "      <td>4437.705078</td>\n",
       "      <td>tensor(7.6429, device='cuda:0')</td>\n",
       "      <td>tensor(0.2280, device='cuda:0')</td>\n",
       "      <td>tensor(18042.6191, device='cuda:0')</td>\n",
       "      <td>tensor(811.0349, device='cuda:0')</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>1.780987e-05</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>6.047131e-05</td>\n",
       "      <td>0.042516</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>29.676378</td>\n",
       "      <td>286426.500000</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>8.800778e-07</td>\n",
       "      <td>3.902343e-03</td>\n",
       "      <td>2.255255e-04</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>86.321419</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>9651.665039</td>\n",
       "      <td>128580.859375</td>\n",
       "      <td>2.133381e+11</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>448.054688</td>\n",
       "      <td>66.160744</td>\n",
       "      <td>7.446480e-04</td>\n",
       "      <td>0.933838</td>\n",
       "      <td>4.505768</td>\n",
       "      <td>52.001846</td>\n",
       "      <td>175.999649</td>\n",
       "      <td>240.010193</td>\n",
       "      <td>9650.624023</td>\n",
       "      <td>tensor(7.6605, device='cuda:0')</td>\n",
       "      <td>tensor(0.0321, device='cuda:0')</td>\n",
       "      <td>tensor(35294.6602, device='cuda:0')</td>\n",
       "      <td>tensor(138.7651, device='cuda:0')</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>4.665591e-05</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>3.330892e-05</td>\n",
       "      <td>0.025471</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>47.636959</td>\n",
       "      <td>47.007324</td>\n",
       "      <td>1.013394</td>\n",
       "      <td>6.166619e-05</td>\n",
       "      <td>1.320220e-04</td>\n",
       "      <td>4.670901e-01</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>0.034701</td>\n",
       "      <td>1.013400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>1.402891</td>\n",
       "      <td>10.279372</td>\n",
       "      <td>1.655645e+06</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>3.035732e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>0.062820</td>\n",
       "      <td>tensor(20.6921, device='cuda:0')</td>\n",
       "      <td>tensor(0.9284, device='cuda:0')</td>\n",
       "      <td>tensor(22.3953, device='cuda:0')</td>\n",
       "      <td>tensor(1.1303, device='cuda:0')</td>\n",
       "      <td>0.060588</td>\n",
       "      <td>5.232801e-04</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>9.767702e-05</td>\n",
       "      <td>0.062512</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>32.378353</td>\n",
       "      <td>258382.609375</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>3.037285e-06</td>\n",
       "      <td>4.000738e-03</td>\n",
       "      <td>7.591810e-04</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>67.437164</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7980.104004</td>\n",
       "      <td>83325.734375</td>\n",
       "      <td>9.926146e+10</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>448.026367</td>\n",
       "      <td>49.998989</td>\n",
       "      <td>1.949253e-04</td>\n",
       "      <td>0.635193</td>\n",
       "      <td>3.250435</td>\n",
       "      <td>36.008972</td>\n",
       "      <td>143.994904</td>\n",
       "      <td>207.996582</td>\n",
       "      <td>7979.346191</td>\n",
       "      <td>tensor(5.5833, device='cuda:0')</td>\n",
       "      <td>tensor(0.0977, device='cuda:0')</td>\n",
       "      <td>tensor(20716.1113, device='cuda:0')</td>\n",
       "      <td>tensor(1176.4631, device='cuda:0')</td>\n",
       "      <td>0.009212</td>\n",
       "      <td>2.122949e-06</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>2.944023e-04</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.022372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.461613</td>\n",
       "      <td>204030.687500</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>3.864144e-05</td>\n",
       "      <td>4.771323e-01</td>\n",
       "      <td>8.098686e-05</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>53.249321</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>3489.986328</td>\n",
       "      <td>59396.566406</td>\n",
       "      <td>1.157381e+11</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>35.807480</td>\n",
       "      <td>3.278170e-03</td>\n",
       "      <td>0.373726</td>\n",
       "      <td>1.872040</td>\n",
       "      <td>23.996719</td>\n",
       "      <td>111.992462</td>\n",
       "      <td>191.994537</td>\n",
       "      <td>3490.273682</td>\n",
       "      <td>tensor(53.9900, device='cuda:0')</td>\n",
       "      <td>tensor(0.0620, device='cuda:0')</td>\n",
       "      <td>tensor(173785.4688, device='cuda:0')</td>\n",
       "      <td>tensor(307.6887, device='cuda:0')</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>6.432866e-05</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>2.406337e-05</td>\n",
       "      <td>0.025065</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>32.674606</td>\n",
       "      <td>322552.281250</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-1.867902e-07</td>\n",
       "      <td>-7.872188e-03</td>\n",
       "      <td>-1.867902e+05</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>84.185272</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>9871.651367</td>\n",
       "      <td>122963.664062</td>\n",
       "      <td>2.057566e+11</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>448.029419</td>\n",
       "      <td>64.861771</td>\n",
       "      <td>-6.318197e-04</td>\n",
       "      <td>0.935623</td>\n",
       "      <td>4.508240</td>\n",
       "      <td>51.999256</td>\n",
       "      <td>175.991150</td>\n",
       "      <td>239.998718</td>\n",
       "      <td>9870.957031</td>\n",
       "      <td>tensor(3.6562, device='cuda:0')</td>\n",
       "      <td>tensor(0.1020, device='cuda:0')</td>\n",
       "      <td>tensor(25935.9727, device='cuda:0')</td>\n",
       "      <td>tensor(1433.1211, device='cuda:0')</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>2.067901e-04</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>5.233132e-05</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>39.866913</td>\n",
       "      <td>127441.625000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-3.083006e-06</td>\n",
       "      <td>2.253130e-02</td>\n",
       "      <td>-1.368322e-04</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>62.719273</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>3196.676270</td>\n",
       "      <td>26617.050781</td>\n",
       "      <td>6.568774e+09</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>448.097168</td>\n",
       "      <td>42.111485</td>\n",
       "      <td>7.890060e-04</td>\n",
       "      <td>0.415527</td>\n",
       "      <td>2.018799</td>\n",
       "      <td>26.019531</td>\n",
       "      <td>143.984955</td>\n",
       "      <td>223.992340</td>\n",
       "      <td>3195.761475</td>\n",
       "      <td>tensor(7.4591, device='cuda:0')</td>\n",
       "      <td>tensor(0.2666, device='cuda:0')</td>\n",
       "      <td>tensor(15341.8379, device='cuda:0')</td>\n",
       "      <td>tensor(684.1966, device='cuda:0')</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>1.895294e-04</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>1.491961e-05</td>\n",
       "      <td>0.043641</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>35.922665</td>\n",
       "      <td>268944.281250</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-6.152970e-06</td>\n",
       "      <td>6.052906e-03</td>\n",
       "      <td>-1.016532e-03</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>81.052742</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>7486.757324</td>\n",
       "      <td>78665.507812</td>\n",
       "      <td>9.458165e+10</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>60.950573</td>\n",
       "      <td>3.757286e-05</td>\n",
       "      <td>0.811775</td>\n",
       "      <td>4.000033</td>\n",
       "      <td>47.989502</td>\n",
       "      <td>160.019287</td>\n",
       "      <td>240.001343</td>\n",
       "      <td>7486.018555</td>\n",
       "      <td>tensor(7.4348, device='cuda:0')</td>\n",
       "      <td>tensor(0.0354, device='cuda:0')</td>\n",
       "      <td>tensor(32484.7441, device='cuda:0')</td>\n",
       "      <td>tensor(295.7480, device='cuda:0')</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>8.571552e-04</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>7.961850e-05</td>\n",
       "      <td>0.025509</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>52.055973</td>\n",
       "      <td>51.258682</td>\n",
       "      <td>1.015554</td>\n",
       "      <td>3.220308e-05</td>\n",
       "      <td>-1.018610e-04</td>\n",
       "      <td>3.220308e+07</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>1.015558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>1.402278</td>\n",
       "      <td>11.150939</td>\n",
       "      <td>1.377131e+06</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.675049</td>\n",
       "      <td>0.042596</td>\n",
       "      <td>1.835468e-03</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.143066</td>\n",
       "      <td>0.134935</td>\n",
       "      <td>tensor(21.5354, device='cuda:0')</td>\n",
       "      <td>tensor(1.1733, device='cuda:0')</td>\n",
       "      <td>tensor(27.1338, device='cuda:0')</td>\n",
       "      <td>tensor(1.3835, device='cuda:0')</td>\n",
       "      <td>0.057435</td>\n",
       "      <td>3.428339e-04</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>1.212706e-04</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>35.252045</td>\n",
       "      <td>265794.281250</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.716296e-06</td>\n",
       "      <td>-2.312120e-02</td>\n",
       "      <td>1.716296e+06</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>69.371590</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>7539.826172</td>\n",
       "      <td>68780.289062</td>\n",
       "      <td>1.816374e+10</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>448.034180</td>\n",
       "      <td>51.997993</td>\n",
       "      <td>-1.342449e-05</td>\n",
       "      <td>0.686539</td>\n",
       "      <td>3.494934</td>\n",
       "      <td>39.998970</td>\n",
       "      <td>143.998383</td>\n",
       "      <td>207.999298</td>\n",
       "      <td>7539.156738</td>\n",
       "      <td>tensor(6.2277, device='cuda:0')</td>\n",
       "      <td>tensor(0.1143, device='cuda:0')</td>\n",
       "      <td>tensor(18087.9453, device='cuda:0')</td>\n",
       "      <td>tensor(1691.2562, device='cuda:0')</td>\n",
       "      <td>0.008484</td>\n",
       "      <td>2.478153e-05</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>2.363533e-05</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>65.565948</td>\n",
       "      <td>208179.843750</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-7.949048e-06</td>\n",
       "      <td>2.292349e-01</td>\n",
       "      <td>-3.467642e-05</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>54.333893</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>3175.114746</td>\n",
       "      <td>42008.457031</td>\n",
       "      <td>7.996448e+10</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>34.640247</td>\n",
       "      <td>3.572013e-03</td>\n",
       "      <td>0.338318</td>\n",
       "      <td>1.726318</td>\n",
       "      <td>21.988647</td>\n",
       "      <td>112.004150</td>\n",
       "      <td>208.000977</td>\n",
       "      <td>3174.354004</td>\n",
       "      <td>tensor(59.3648, device='cuda:0')</td>\n",
       "      <td>tensor(0.0794, device='cuda:0')</td>\n",
       "      <td>tensor(182581.6094, device='cuda:0')</td>\n",
       "      <td>tensor(457.8208, device='cuda:0')</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>9.256021e-05</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>1.226376e-04</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>35.650501</td>\n",
       "      <td>316225.750000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>4.467801e-07</td>\n",
       "      <td>-1.222656e-02</td>\n",
       "      <td>4.467801e+05</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>82.534065</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>8870.164062</td>\n",
       "      <td>96643.554688</td>\n",
       "      <td>1.178048e+11</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>63.304726</td>\n",
       "      <td>-5.896445e-04</td>\n",
       "      <td>0.918457</td>\n",
       "      <td>4.501740</td>\n",
       "      <td>51.987183</td>\n",
       "      <td>160.014648</td>\n",
       "      <td>239.997330</td>\n",
       "      <td>8869.392578</td>\n",
       "      <td>tensor(3.4186, device='cuda:0')</td>\n",
       "      <td>tensor(0.1222, device='cuda:0')</td>\n",
       "      <td>tensor(23857.4258, device='cuda:0')</td>\n",
       "      <td>tensor(1973.3673, device='cuda:0')</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>5.425171e-04</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>1.882706e-04</td>\n",
       "      <td>0.022151</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>35.578690</td>\n",
       "      <td>165172.265625</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>7.151962e-07</td>\n",
       "      <td>5.476070e-02</td>\n",
       "      <td>1.306039e-05</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>81.288063</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>4642.449219</td>\n",
       "      <td>56666.421875</td>\n",
       "      <td>6.972513e+10</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>58.334003</td>\n",
       "      <td>2.724180e-05</td>\n",
       "      <td>0.632538</td>\n",
       "      <td>3.237610</td>\n",
       "      <td>40.003754</td>\n",
       "      <td>176.001343</td>\n",
       "      <td>255.988953</td>\n",
       "      <td>4641.583496</td>\n",
       "      <td>tensor(8.6704, device='cuda:0')</td>\n",
       "      <td>tensor(0.2414, device='cuda:0')</td>\n",
       "      <td>tensor(16534.1836, device='cuda:0')</td>\n",
       "      <td>tensor(974.3234, device='cuda:0')</td>\n",
       "      <td>0.033464</td>\n",
       "      <td>2.147381e-04</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>3.603280e-04</td>\n",
       "      <td>0.041454</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>32.842499</td>\n",
       "      <td>272285.156250</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-2.548874e-06</td>\n",
       "      <td>-2.222098e-02</td>\n",
       "      <td>-2.548874e+06</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>82.059593</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>8290.634766</td>\n",
       "      <td>106324.718750</td>\n",
       "      <td>2.278781e+11</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>448.031982</td>\n",
       "      <td>61.963135</td>\n",
       "      <td>3.921397e-04</td>\n",
       "      <td>0.833496</td>\n",
       "      <td>4.010559</td>\n",
       "      <td>47.998489</td>\n",
       "      <td>175.985352</td>\n",
       "      <td>240.002960</td>\n",
       "      <td>8290.015625</td>\n",
       "      <td>tensor(8.0057, device='cuda:0')</td>\n",
       "      <td>tensor(0.0351, device='cuda:0')</td>\n",
       "      <td>tensor(38157.2656, device='cuda:0')</td>\n",
       "      <td>tensor(212.2912, device='cuda:0')</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>9.200790e-05</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>1.176521e-05</td>\n",
       "      <td>0.025444</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.166615</td>\n",
       "      <td>56.682781</td>\n",
       "      <td>1.096746</td>\n",
       "      <td>1.989925e-04</td>\n",
       "      <td>-5.538079e-05</td>\n",
       "      <td>1.989925e+08</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>1.096737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>1.353423</td>\n",
       "      <td>8.175681</td>\n",
       "      <td>5.932172e+05</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.621704</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>-3.559407e-04</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.040955</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.165039</td>\n",
       "      <td>0.113337</td>\n",
       "      <td>tensor(29.2355, device='cuda:0')</td>\n",
       "      <td>tensor(1.4342, device='cuda:0')</td>\n",
       "      <td>tensor(29.4863, device='cuda:0')</td>\n",
       "      <td>tensor(1.5054, device='cuda:0')</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>6.354765e-05</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>1.136579e-04</td>\n",
       "      <td>0.063360</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>34.187748</td>\n",
       "      <td>274685.562500</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>6.911815e-07</td>\n",
       "      <td>-3.381542e-03</td>\n",
       "      <td>6.911815e+05</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>71.692192</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>8034.620117</td>\n",
       "      <td>86767.773438</td>\n",
       "      <td>1.824075e+11</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>448.025879</td>\n",
       "      <td>53.748817</td>\n",
       "      <td>5.208848e-04</td>\n",
       "      <td>0.704590</td>\n",
       "      <td>3.508240</td>\n",
       "      <td>40.007050</td>\n",
       "      <td>144.005157</td>\n",
       "      <td>208.012329</td>\n",
       "      <td>8033.922363</td>\n",
       "      <td>tensor(5.3051, device='cuda:0')</td>\n",
       "      <td>tensor(0.1301, device='cuda:0')</td>\n",
       "      <td>tensor(18387.5215, device='cuda:0')</td>\n",
       "      <td>tensor(1795.1691, device='cuda:0')</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>8.888672e-05</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>7.636492e-05</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>73.995186</td>\n",
       "      <td>214966.609375</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>5.357097e-05</td>\n",
       "      <td>1.608118e-01</td>\n",
       "      <td>3.331284e-04</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>56.105476</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>2905.140869</td>\n",
       "      <td>33285.167969</td>\n",
       "      <td>2.114446e+10</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>34.820297</td>\n",
       "      <td>-1.786743e-03</td>\n",
       "      <td>0.329346</td>\n",
       "      <td>1.632996</td>\n",
       "      <td>20.013794</td>\n",
       "      <td>119.993774</td>\n",
       "      <td>223.989624</td>\n",
       "      <td>2904.607422</td>\n",
       "      <td>tensor(68.4619, device='cuda:0')</td>\n",
       "      <td>tensor(0.1037, device='cuda:0')</td>\n",
       "      <td>tensor(190385.5625, device='cuda:0')</td>\n",
       "      <td>tensor(548.3376, device='cuda:0')</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>5.034434e-04</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>1.137765e-04</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>36.493416</td>\n",
       "      <td>296291.062500</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-3.694102e-06</td>\n",
       "      <td>2.692454e-02</td>\n",
       "      <td>-1.372020e-04</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>77.331161</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>8119.027832</td>\n",
       "      <td>90334.429688</td>\n",
       "      <td>1.449906e+11</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>448.033447</td>\n",
       "      <td>58.566914</td>\n",
       "      <td>1.396643e-04</td>\n",
       "      <td>0.806244</td>\n",
       "      <td>3.994720</td>\n",
       "      <td>44.012390</td>\n",
       "      <td>159.997574</td>\n",
       "      <td>224.006592</td>\n",
       "      <td>8118.274414</td>\n",
       "      <td>tensor(3.3527, device='cuda:0')</td>\n",
       "      <td>tensor(0.1451, device='cuda:0')</td>\n",
       "      <td>tensor(17994.7598, device='cuda:0')</td>\n",
       "      <td>tensor(2252.2698, device='cuda:0')</td>\n",
       "      <td>0.018230</td>\n",
       "      <td>1.923553e-04</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>8.513871e-05</td>\n",
       "      <td>0.022226</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.163628</td>\n",
       "      <td>158275.140625</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-3.632149e-06</td>\n",
       "      <td>-5.050855e-02</td>\n",
       "      <td>-3.632149e+06</td>\n",
       "      <td>0.021735</td>\n",
       "      <td>77.893707</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>3583.836182</td>\n",
       "      <td>28647.994141</td>\n",
       "      <td>2.987803e+09</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>448.128906</td>\n",
       "      <td>54.644348</td>\n",
       "      <td>-8.211295e-04</td>\n",
       "      <td>0.527466</td>\n",
       "      <td>2.732056</td>\n",
       "      <td>36.001358</td>\n",
       "      <td>175.983154</td>\n",
       "      <td>240.047607</td>\n",
       "      <td>3582.825928</td>\n",
       "      <td>tensor(7.8193, device='cuda:0')</td>\n",
       "      <td>tensor(0.3029, device='cuda:0')</td>\n",
       "      <td>tensor(16278.3340, device='cuda:0')</td>\n",
       "      <td>tensor(1032.4326, device='cuda:0')</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>1.081334e-04</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>6.582138e-05</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>44.411427</td>\n",
       "      <td>286513.031250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>3.162919e-06</td>\n",
       "      <td>-2.790407e-02</td>\n",
       "      <td>3.162919e+06</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>86.347496</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>6451.335938</td>\n",
       "      <td>76815.914062</td>\n",
       "      <td>1.077953e+11</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>448.043213</td>\n",
       "      <td>65.227463</td>\n",
       "      <td>-1.600708e-04</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>4.491943</td>\n",
       "      <td>51.966553</td>\n",
       "      <td>176.005432</td>\n",
       "      <td>255.989624</td>\n",
       "      <td>6450.762207</td>\n",
       "      <td>tensor(7.2695, device='cuda:0')</td>\n",
       "      <td>tensor(0.0344, device='cuda:0')</td>\n",
       "      <td>tensor(34993.1016, device='cuda:0')</td>\n",
       "      <td>tensor(240.6645, device='cuda:0')</td>\n",
       "      <td>0.018368</td>\n",
       "      <td>5.254057e-04</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>9.408009e-05</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.920872</td>\n",
       "      <td>52.985229</td>\n",
       "      <td>1.206390</td>\n",
       "      <td>4.126995e-04</td>\n",
       "      <td>7.247948e-05</td>\n",
       "      <td>5.694018e+00</td>\n",
       "      <td>0.047185</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>1.206346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>1.300376</td>\n",
       "      <td>7.747681</td>\n",
       "      <td>6.337558e+05</td>\n",
       "      <td>-0.002351</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>-1.099915e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.040474</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.182524</td>\n",
       "      <td>tensor(30.0838, device='cuda:0')</td>\n",
       "      <td>tensor(1.4665, device='cuda:0')</td>\n",
       "      <td>tensor(27.6877, device='cuda:0')</td>\n",
       "      <td>tensor(1.3173, device='cuda:0')</td>\n",
       "      <td>0.055703</td>\n",
       "      <td>8.076369e-04</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>9.113410e-05</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>37.425797</td>\n",
       "      <td>232908.671875</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.845480e-06</td>\n",
       "      <td>-2.657622e-03</td>\n",
       "      <td>1.845480e+06</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>60.788536</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>6223.212402</td>\n",
       "      <td>72496.890625</td>\n",
       "      <td>1.360221e+11</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>448.045654</td>\n",
       "      <td>43.508984</td>\n",
       "      <td>1.693380e-04</td>\n",
       "      <td>0.490967</td>\n",
       "      <td>2.497208</td>\n",
       "      <td>31.980713</td>\n",
       "      <td>127.994049</td>\n",
       "      <td>192.008850</td>\n",
       "      <td>6222.487305</td>\n",
       "      <td>tensor(4.5972, device='cuda:0')</td>\n",
       "      <td>tensor(0.1704, device='cuda:0')</td>\n",
       "      <td>tensor(15784.7109, device='cuda:0')</td>\n",
       "      <td>tensor(1117.1893, device='cuda:0')</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>1.346304e-04</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>6.900202e-04</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>83.790474</td>\n",
       "      <td>224043.687500</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>2.012922e-04</td>\n",
       "      <td>3.143978e-01</td>\n",
       "      <td>6.402470e-04</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>58.473953</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>2673.854492</td>\n",
       "      <td>33780.730469</td>\n",
       "      <td>2.987803e+10</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>35.894470</td>\n",
       "      <td>-1.253507e-03</td>\n",
       "      <td>0.335999</td>\n",
       "      <td>1.660400</td>\n",
       "      <td>20.009705</td>\n",
       "      <td>127.996002</td>\n",
       "      <td>224.015503</td>\n",
       "      <td>2672.982910</td>\n",
       "      <td>tensor(77.3653, device='cuda:0')</td>\n",
       "      <td>tensor(0.1586, device='cuda:0')</td>\n",
       "      <td>tensor(196888.1406, device='cuda:0')</td>\n",
       "      <td>tensor(727.8314, device='cuda:0')</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>6.705386e-05</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>3.321376e-05</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>39.538883</td>\n",
       "      <td>287792.812500</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>6.882189e-07</td>\n",
       "      <td>3.672514e-02</td>\n",
       "      <td>1.873972e-05</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>75.113144</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>7278.729492</td>\n",
       "      <td>326736.812500</td>\n",
       "      <td>2.645441e+12</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>448.039551</td>\n",
       "      <td>56.034348</td>\n",
       "      <td>-5.232000e-04</td>\n",
       "      <td>0.746902</td>\n",
       "      <td>3.745941</td>\n",
       "      <td>43.991028</td>\n",
       "      <td>159.990540</td>\n",
       "      <td>224.013000</td>\n",
       "      <td>7278.065430</td>\n",
       "      <td>tensor(3.2951, device='cuda:0')</td>\n",
       "      <td>tensor(0.1850, device='cuda:0')</td>\n",
       "      <td>tensor(17395.1250, device='cuda:0')</td>\n",
       "      <td>tensor(1791.0648, device='cuda:0')</td>\n",
       "      <td>0.017679</td>\n",
       "      <td>3.042362e-04</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>1.139945e-04</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.211086</td>\n",
       "      <td>148725.421875</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-2.210979e-07</td>\n",
       "      <td>2.284615e-02</td>\n",
       "      <td>-9.677687e-06</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>73.193909</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3363.983643</td>\n",
       "      <td>31014.486328</td>\n",
       "      <td>6.921386e+09</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>53.058487</td>\n",
       "      <td>1.029713e-03</td>\n",
       "      <td>0.623327</td>\n",
       "      <td>3.216797</td>\n",
       "      <td>36.137207</td>\n",
       "      <td>159.985657</td>\n",
       "      <td>224.022705</td>\n",
       "      <td>3363.019775</td>\n",
       "      <td>tensor(7.9007, device='cuda:0')</td>\n",
       "      <td>tensor(0.3347, device='cuda:0')</td>\n",
       "      <td>tensor(19525.2109, device='cuda:0')</td>\n",
       "      <td>tensor(701.4940, device='cuda:0')</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>1.025921e-04</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>3.514080e-06</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>43.829700</td>\n",
       "      <td>275328.781250</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.262830e-05</td>\n",
       "      <td>2.441130e-03</td>\n",
       "      <td>5.173140e-03</td>\n",
       "      <td>0.013209</td>\n",
       "      <td>82.976860</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>6281.785645</td>\n",
       "      <td>61390.054688</td>\n",
       "      <td>2.863311e+10</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>62.451614</td>\n",
       "      <td>4.300878e-04</td>\n",
       "      <td>0.850277</td>\n",
       "      <td>4.020264</td>\n",
       "      <td>47.998512</td>\n",
       "      <td>175.991638</td>\n",
       "      <td>240.016113</td>\n",
       "      <td>6281.029297</td>\n",
       "      <td>tensor(7.2231, device='cuda:0')</td>\n",
       "      <td>tensor(0.0369, device='cuda:0')</td>\n",
       "      <td>tensor(43522.4688, device='cuda:0')</td>\n",
       "      <td>tensor(175.2891, device='cuda:0')</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>2.691646e-04</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>7.940549e-05</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.512337</td>\n",
       "      <td>53.668427</td>\n",
       "      <td>1.146155</td>\n",
       "      <td>3.828389e-04</td>\n",
       "      <td>1.262108e-04</td>\n",
       "      <td>3.033328e+00</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.039618</td>\n",
       "      <td>1.146120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>1.327242</td>\n",
       "      <td>9.150343</td>\n",
       "      <td>1.513408e+06</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.047580</td>\n",
       "      <td>8.339830e-04</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.140180</td>\n",
       "      <td>tensor(30.2342, device='cuda:0')</td>\n",
       "      <td>tensor(0.9594, device='cuda:0')</td>\n",
       "      <td>tensor(27.9796, device='cuda:0')</td>\n",
       "      <td>tensor(1.2535, device='cuda:0')</td>\n",
       "      <td>0.060233</td>\n",
       "      <td>7.667489e-04</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>1.277797e-04</td>\n",
       "      <td>0.062641</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.872108</td>\n",
       "      <td>251042.640625</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-7.462968e-07</td>\n",
       "      <td>-5.120226e-05</td>\n",
       "      <td>-7.462969e+05</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>65.521454</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>6142.150391</td>\n",
       "      <td>94325.835938</td>\n",
       "      <td>3.845286e+11</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>448.035645</td>\n",
       "      <td>47.616280</td>\n",
       "      <td>3.318621e-04</td>\n",
       "      <td>0.571205</td>\n",
       "      <td>2.990845</td>\n",
       "      <td>35.993347</td>\n",
       "      <td>128.019531</td>\n",
       "      <td>208.003082</td>\n",
       "      <td>6141.354492</td>\n",
       "      <td>tensor(4.7362, device='cuda:0')</td>\n",
       "      <td>tensor(0.2347, device='cuda:0')</td>\n",
       "      <td>tensor(14637.7373, device='cuda:0')</td>\n",
       "      <td>tensor(1790.4146, device='cuda:0')</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>2.256520e-04</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>5.387106e-06</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>86.544426</td>\n",
       "      <td>211574.093750</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>2.213672e-04</td>\n",
       "      <td>2.932894e-01</td>\n",
       "      <td>7.547740e-04</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>55.219490</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>2444.686279</td>\n",
       "      <td>36657.710938</td>\n",
       "      <td>3.642960e+10</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>448.090332</td>\n",
       "      <td>33.766823</td>\n",
       "      <td>-3.190789e-04</td>\n",
       "      <td>0.333740</td>\n",
       "      <td>1.635498</td>\n",
       "      <td>19.997711</td>\n",
       "      <td>120.000870</td>\n",
       "      <td>223.992004</td>\n",
       "      <td>2443.913330</td>\n",
       "      <td>tensor(79.9523, device='cuda:0')</td>\n",
       "      <td>tensor(0.2264, device='cuda:0')</td>\n",
       "      <td>tensor(179836.4219, device='cuda:0')</td>\n",
       "      <td>tensor(828.9401, device='cuda:0')</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>7.612236e-05</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>3.374169e-04</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.083069</td>\n",
       "      <td>264269.031250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-2.680473e-07</td>\n",
       "      <td>-9.782354e-03</td>\n",
       "      <td>-2.680473e+05</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>68.973503</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>6432.552734</td>\n",
       "      <td>74949.867188</td>\n",
       "      <td>1.022802e+11</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>448.033447</td>\n",
       "      <td>50.510826</td>\n",
       "      <td>2.795917e-04</td>\n",
       "      <td>0.621231</td>\n",
       "      <td>3.011292</td>\n",
       "      <td>36.010742</td>\n",
       "      <td>143.999207</td>\n",
       "      <td>223.983276</td>\n",
       "      <td>6431.841797</td>\n",
       "      <td>tensor(2.9016, device='cuda:0')</td>\n",
       "      <td>tensor(0.2492, device='cuda:0')</td>\n",
       "      <td>tensor(15065.3594, device='cuda:0')</td>\n",
       "      <td>tensor(1970.3135, device='cuda:0')</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>5.873727e-04</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>4.488669e-05</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.943066</td>\n",
       "      <td>171746.765625</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.195049e-06</td>\n",
       "      <td>5.308273e-02</td>\n",
       "      <td>2.251295e-05</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>84.523651</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>3908.392822</td>\n",
       "      <td>38092.027344</td>\n",
       "      <td>1.365288e+10</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>448.082031</td>\n",
       "      <td>61.989113</td>\n",
       "      <td>3.512416e-04</td>\n",
       "      <td>0.514893</td>\n",
       "      <td>2.721191</td>\n",
       "      <td>44.042236</td>\n",
       "      <td>176.005432</td>\n",
       "      <td>240.064941</td>\n",
       "      <td>3907.441895</td>\n",
       "      <td>tensor(8.9111, device='cuda:0')</td>\n",
       "      <td>tensor(0.3376, device='cuda:0')</td>\n",
       "      <td>tensor(16353.3037, device='cuda:0')</td>\n",
       "      <td>tensor(1192.0713, device='cuda:0')</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>4.360771e-04</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>3.108490e-05</td>\n",
       "      <td>0.041528</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>42.547871</td>\n",
       "      <td>322357.468750</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>5.205086e-06</td>\n",
       "      <td>2.235255e-02</td>\n",
       "      <td>2.328632e-04</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>97.150070</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>7576.348633</td>\n",
       "      <td>113839.148438</td>\n",
       "      <td>2.542223e+11</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>448.040527</td>\n",
       "      <td>75.271484</td>\n",
       "      <td>-6.341565e-04</td>\n",
       "      <td>1.105835</td>\n",
       "      <td>5.493256</td>\n",
       "      <td>60.002914</td>\n",
       "      <td>192.009827</td>\n",
       "      <td>256.013733</td>\n",
       "      <td>7575.843262</td>\n",
       "      <td>tensor(6.7645, device='cuda:0')</td>\n",
       "      <td>tensor(0.0392, device='cuda:0')</td>\n",
       "      <td>tensor(32399.7051, device='cuda:0')</td>\n",
       "      <td>tensor(183.3855, device='cuda:0')</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>5.730405e-04</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>3.684941e-05</td>\n",
       "      <td>0.025645</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>59.963379</td>\n",
       "      <td>56.496185</td>\n",
       "      <td>1.061370</td>\n",
       "      <td>4.075590e-04</td>\n",
       "      <td>1.312464e-04</td>\n",
       "      <td>3.105295e+00</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>1.061331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>1.376859</td>\n",
       "      <td>9.255237</td>\n",
       "      <td>5.682615e+05</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.048087</td>\n",
       "      <td>-2.849257e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.163010</td>\n",
       "      <td>0.099659</td>\n",
       "      <td>tensor(31.0215, device='cuda:0')</td>\n",
       "      <td>tensor(1.4224, device='cuda:0')</td>\n",
       "      <td>tensor(31.8564, device='cuda:0')</td>\n",
       "      <td>tensor(1.5520, device='cuda:0')</td>\n",
       "      <td>0.059070</td>\n",
       "      <td>7.475888e-04</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>2.245625e-05</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.310238</td>\n",
       "      <td>263960.593750</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-4.547229e-06</td>\n",
       "      <td>-2.533327e-03</td>\n",
       "      <td>-4.547230e+06</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>68.893005</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>5825.627930</td>\n",
       "      <td>75546.671875</td>\n",
       "      <td>1.027581e+11</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>51.127525</td>\n",
       "      <td>2.469720e-04</td>\n",
       "      <td>0.671936</td>\n",
       "      <td>3.255890</td>\n",
       "      <td>39.991577</td>\n",
       "      <td>143.996109</td>\n",
       "      <td>208.006927</td>\n",
       "      <td>5825.145508</td>\n",
       "      <td>tensor(5.2519, device='cuda:0')</td>\n",
       "      <td>tensor(0.2631, device='cuda:0')</td>\n",
       "      <td>tensor(16205.9287, device='cuda:0')</td>\n",
       "      <td>tensor(2026.8906, device='cuda:0')</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>1.118059e-04</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>3.188674e-04</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>91.581459</td>\n",
       "      <td>205267.031250</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>2.173313e-04</td>\n",
       "      <td>7.173754e-02</td>\n",
       "      <td>3.029533e-03</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>53.574089</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>2241.360596</td>\n",
       "      <td>46266.199219</td>\n",
       "      <td>6.871948e+10</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>448.088867</td>\n",
       "      <td>32.213394</td>\n",
       "      <td>2.221519e-04</td>\n",
       "      <td>0.326538</td>\n",
       "      <td>1.627747</td>\n",
       "      <td>19.988403</td>\n",
       "      <td>112.002502</td>\n",
       "      <td>224.000320</td>\n",
       "      <td>2240.567139</td>\n",
       "      <td>tensor(84.5384, device='cuda:0')</td>\n",
       "      <td>tensor(0.2769, device='cuda:0')</td>\n",
       "      <td>tensor(174247.9844, device='cuda:0')</td>\n",
       "      <td>tensor(896.1336, device='cuda:0')</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>1.968195e-04</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>3.507027e-05</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.552773</td>\n",
       "      <td>262363.000000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-6.160434e-06</td>\n",
       "      <td>9.338681e-03</td>\n",
       "      <td>-6.596685e-04</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>68.476036</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>6024.025879</td>\n",
       "      <td>71460.921875</td>\n",
       "      <td>3.248557e+10</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>448.050537</td>\n",
       "      <td>50.749287</td>\n",
       "      <td>-7.098765e-05</td>\n",
       "      <td>0.632996</td>\n",
       "      <td>3.247665</td>\n",
       "      <td>39.987732</td>\n",
       "      <td>143.994507</td>\n",
       "      <td>208.005646</td>\n",
       "      <td>6023.332520</td>\n",
       "      <td>tensor(3.1104, device='cuda:0')</td>\n",
       "      <td>tensor(0.2709, device='cuda:0')</td>\n",
       "      <td>tensor(15159.9688, device='cuda:0')</td>\n",
       "      <td>tensor(2129.5164, device='cuda:0')</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>3.450912e-04</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>7.936008e-05</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>46.502293</td>\n",
       "      <td>165971.343750</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-3.878666e-06</td>\n",
       "      <td>1.243844e-03</td>\n",
       "      <td>-3.118289e-03</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>81.681343</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>3569.100342</td>\n",
       "      <td>33626.273438</td>\n",
       "      <td>9.111975e+09</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>448.125000</td>\n",
       "      <td>59.024380</td>\n",
       "      <td>1.225635e-04</td>\n",
       "      <td>0.536621</td>\n",
       "      <td>2.743713</td>\n",
       "      <td>43.968994</td>\n",
       "      <td>175.995392</td>\n",
       "      <td>255.968506</td>\n",
       "      <td>3568.109131</td>\n",
       "      <td>tensor(8.8456, device='cuda:0')</td>\n",
       "      <td>tensor(0.3235, device='cuda:0')</td>\n",
       "      <td>tensor(15920.2061, device='cuda:0')</td>\n",
       "      <td>tensor(1197.1150, device='cuda:0')</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>4.101652e-04</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>1.561108e-06</td>\n",
       "      <td>0.040662</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>43.622997</td>\n",
       "      <td>324044.500000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-5.362010e-06</td>\n",
       "      <td>-3.328361e-02</td>\n",
       "      <td>-5.362010e+06</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>97.658493</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>7428.295410</td>\n",
       "      <td>98738.742188</td>\n",
       "      <td>8.084645e+10</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>448.048828</td>\n",
       "      <td>75.587151</td>\n",
       "      <td>3.544447e-04</td>\n",
       "      <td>1.106934</td>\n",
       "      <td>5.491821</td>\n",
       "      <td>60.003540</td>\n",
       "      <td>192.013794</td>\n",
       "      <td>256.017578</td>\n",
       "      <td>7427.973145</td>\n",
       "      <td>tensor(8.3540, device='cuda:0')</td>\n",
       "      <td>tensor(0.0357, device='cuda:0')</td>\n",
       "      <td>tensor(32033.4043, device='cuda:0')</td>\n",
       "      <td>tensor(256.6241, device='cuda:0')</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>9.337109e-05</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>3.924416e-05</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.361385</td>\n",
       "      <td>57.482117</td>\n",
       "      <td>1.067487</td>\n",
       "      <td>4.563871e-04</td>\n",
       "      <td>2.085474e-04</td>\n",
       "      <td>2.188409e+00</td>\n",
       "      <td>0.045295</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002468</td>\n",
       "      <td>1.371926</td>\n",
       "      <td>11.144596</td>\n",
       "      <td>1.712673e+06</td>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>-1.191945e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.103013</td>\n",
       "      <td>tensor(32.5306, device='cuda:0')</td>\n",
       "      <td>tensor(1.5274, device='cuda:0')</td>\n",
       "      <td>tensor(31.8147, device='cuda:0')</td>\n",
       "      <td>tensor(1.6265, device='cuda:0')</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>9.776780e-04</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>2.670465e-05</td>\n",
       "      <td>0.062497</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.967201</td>\n",
       "      <td>250408.062500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1.679038e-06</td>\n",
       "      <td>1.292949e-02</td>\n",
       "      <td>1.298611e-04</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>65.355827</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>5966.756348</td>\n",
       "      <td>87873.343750</td>\n",
       "      <td>1.917753e+11</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>47.950573</td>\n",
       "      <td>-1.841962e-04</td>\n",
       "      <td>0.612549</td>\n",
       "      <td>3.001550</td>\n",
       "      <td>36.000183</td>\n",
       "      <td>128.007629</td>\n",
       "      <td>208.000015</td>\n",
       "      <td>5965.989746</td>\n",
       "      <td>tensor(4.3905, device='cuda:0')</td>\n",
       "      <td>tensor(0.2790, device='cuda:0')</td>\n",
       "      <td>tensor(15349.4199, device='cuda:0')</td>\n",
       "      <td>tensor(1880.5460, device='cuda:0')</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>2.409700e-04</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>1.344823e-05</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>94.314461</td>\n",
       "      <td>206260.328125</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>2.190171e-04</td>\n",
       "      <td>1.562747e-02</td>\n",
       "      <td>1.401488e-02</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>53.833389</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>2186.943359</td>\n",
       "      <td>36411.246094</td>\n",
       "      <td>2.824088e+10</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>448.088379</td>\n",
       "      <td>32.682415</td>\n",
       "      <td>6.006173e-04</td>\n",
       "      <td>0.340088</td>\n",
       "      <td>1.700195</td>\n",
       "      <td>19.997894</td>\n",
       "      <td>112.004181</td>\n",
       "      <td>224.000977</td>\n",
       "      <td>2186.717773</td>\n",
       "      <td>tensor(87.7969, device='cuda:0')</td>\n",
       "      <td>tensor(0.2807, device='cuda:0')</td>\n",
       "      <td>tensor(171196.5312, device='cuda:0')</td>\n",
       "      <td>tensor(929.4828, device='cuda:0')</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>3.744127e-05</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>1.574015e-04</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.831738</td>\n",
       "      <td>254143.609375</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>7.714563e-07</td>\n",
       "      <td>8.034391e-03</td>\n",
       "      <td>9.601926e-05</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>66.330795</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>5933.535156</td>\n",
       "      <td>81376.351562</td>\n",
       "      <td>1.268667e+11</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>48.853081</td>\n",
       "      <td>-9.829581e-06</td>\n",
       "      <td>0.617920</td>\n",
       "      <td>3.005066</td>\n",
       "      <td>36.004578</td>\n",
       "      <td>128.024780</td>\n",
       "      <td>207.999374</td>\n",
       "      <td>5932.769043</td>\n",
       "      <td>tensor(2.9041, device='cuda:0')</td>\n",
       "      <td>tensor(0.2855, device='cuda:0')</td>\n",
       "      <td>tensor(14481.7334, device='cuda:0')</td>\n",
       "      <td>tensor(1779.7095, device='cuda:0')</td>\n",
       "      <td>0.016646</td>\n",
       "      <td>1.365797e-04</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>6.072643e-05</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.810741</td>\n",
       "      <td>192736.578125</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>2.028491e-06</td>\n",
       "      <td>-3.845371e-02</td>\n",
       "      <td>2.028491e+06</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>94.853600</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>3793.225342</td>\n",
       "      <td>37852.476562</td>\n",
       "      <td>1.453681e+10</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>448.090820</td>\n",
       "      <td>70.807175</td>\n",
       "      <td>-3.470240e-04</td>\n",
       "      <td>0.587402</td>\n",
       "      <td>2.997269</td>\n",
       "      <td>55.970459</td>\n",
       "      <td>192.017090</td>\n",
       "      <td>256.023560</td>\n",
       "      <td>3792.199707</td>\n",
       "      <td>tensor(9.5055, device='cuda:0')</td>\n",
       "      <td>tensor(0.3141, device='cuda:0')</td>\n",
       "      <td>tensor(17867.8242, device='cuda:0')</td>\n",
       "      <td>tensor(1105.7489, device='cuda:0')</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>2.214524e-04</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>5.137134e-06</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>52.763145</td>\n",
       "      <td>307570.718750</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>8.200746e-07</td>\n",
       "      <td>4.014836e-02</td>\n",
       "      <td>2.042610e-05</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>92.693726</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>5829.271973</td>\n",
       "      <td>64734.238281</td>\n",
       "      <td>4.780485e+10</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>448.048096</td>\n",
       "      <td>70.225998</td>\n",
       "      <td>-8.608949e-05</td>\n",
       "      <td>0.888306</td>\n",
       "      <td>4.499134</td>\n",
       "      <td>52.032227</td>\n",
       "      <td>191.998734</td>\n",
       "      <td>256.008057</td>\n",
       "      <td>5828.459961</td>\n",
       "      <td>tensor(9.0627, device='cuda:0')</td>\n",
       "      <td>tensor(0.0346, device='cuda:0')</td>\n",
       "      <td>tensor(31358.3262, device='cuda:0')</td>\n",
       "      <td>tensor(115.6161, device='cuda:0')</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>8.701634e-06</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>1.715627e-05</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.909180</td>\n",
       "      <td>55.247620</td>\n",
       "      <td>1.102476</td>\n",
       "      <td>4.544015e-04</td>\n",
       "      <td>2.422025e-04</td>\n",
       "      <td>1.876122e+00</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.040784</td>\n",
       "      <td>1.102439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001725</td>\n",
       "      <td>1.351247</td>\n",
       "      <td>14.124280</td>\n",
       "      <td>1.053342e+07</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>-1.109093e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>0.114990</td>\n",
       "      <td>tensor(32.7956, device='cuda:0')</td>\n",
       "      <td>tensor(1.4570, device='cuda:0')</td>\n",
       "      <td>tensor(31.5748, device='cuda:0')</td>\n",
       "      <td>tensor(1.5206, device='cuda:0')</td>\n",
       "      <td>0.058849</td>\n",
       "      <td>1.813016e-04</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>5.757692e-05</td>\n",
       "      <td>0.062286</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.653931</td>\n",
       "      <td>261757.046875</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-2.420139e-06</td>\n",
       "      <td>1.095472e-02</td>\n",
       "      <td>-2.209221e-04</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>68.317879</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>5861.903809</td>\n",
       "      <td>67611.867188</td>\n",
       "      <td>2.224445e+10</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>448.050049</td>\n",
       "      <td>50.335476</td>\n",
       "      <td>1.039982e-05</td>\n",
       "      <td>0.658813</td>\n",
       "      <td>3.253235</td>\n",
       "      <td>39.986267</td>\n",
       "      <td>143.991516</td>\n",
       "      <td>223.994385</td>\n",
       "      <td>5861.134766</td>\n",
       "      <td>tensor(4.6922, device='cuda:0')</td>\n",
       "      <td>tensor(0.2851, device='cuda:0')</td>\n",
       "      <td>tensor(15713.1016, device='cuda:0')</td>\n",
       "      <td>tensor(1916.7957, device='cuda:0')</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>2.814135e-04</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>2.380415e-04</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>88.550323</td>\n",
       "      <td>213861.343750</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.613195e-04</td>\n",
       "      <td>-4.928809e-02</td>\n",
       "      <td>1.613195e+08</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>55.817215</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>2415.140869</td>\n",
       "      <td>44485.601562</td>\n",
       "      <td>1.963414e+10</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>34.325626</td>\n",
       "      <td>-6.342654e-04</td>\n",
       "      <td>0.359253</td>\n",
       "      <td>1.772827</td>\n",
       "      <td>21.949707</td>\n",
       "      <td>119.996979</td>\n",
       "      <td>224.009094</td>\n",
       "      <td>2414.261230</td>\n",
       "      <td>tensor(80.0076, device='cuda:0')</td>\n",
       "      <td>tensor(0.2964, device='cuda:0')</td>\n",
       "      <td>tensor(177511.2344, device='cuda:0')</td>\n",
       "      <td>tensor(1006.9933, device='cuda:0')</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>2.180625e-04</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>3.035114e-05</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.156055</td>\n",
       "      <td>254356.968750</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-1.379924e-06</td>\n",
       "      <td>5.655065e-04</td>\n",
       "      <td>-2.440156e-03</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>66.386482</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5760.409668</td>\n",
       "      <td>63613.476562</td>\n",
       "      <td>1.636178e+10</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>448.053955</td>\n",
       "      <td>48.593182</td>\n",
       "      <td>1.552255e-04</td>\n",
       "      <td>0.619751</td>\n",
       "      <td>3.006042</td>\n",
       "      <td>36.002228</td>\n",
       "      <td>128.022827</td>\n",
       "      <td>208.008850</td>\n",
       "      <td>5759.628906</td>\n",
       "      <td>tensor(3.0871, device='cuda:0')</td>\n",
       "      <td>tensor(0.2907, device='cuda:0')</td>\n",
       "      <td>tensor(14483.9434, device='cuda:0')</td>\n",
       "      <td>tensor(1965.0605, device='cuda:0')</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>1.663378e-04</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>5.675370e-05</td>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.693699</td>\n",
       "      <td>179631.687500</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-2.288964e-06</td>\n",
       "      <td>9.703936e-02</td>\n",
       "      <td>-2.358800e-05</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>88.404106</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>3689.012695</td>\n",
       "      <td>33560.445312</td>\n",
       "      <td>4.805558e+09</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>448.106934</td>\n",
       "      <td>65.864243</td>\n",
       "      <td>3.001177e-04</td>\n",
       "      <td>0.628906</td>\n",
       "      <td>3.230469</td>\n",
       "      <td>51.960938</td>\n",
       "      <td>176.037842</td>\n",
       "      <td>255.989197</td>\n",
       "      <td>3687.999512</td>\n",
       "      <td>tensor(9.6809, device='cuda:0')</td>\n",
       "      <td>tensor(0.4493, device='cuda:0')</td>\n",
       "      <td>tensor(19733.8086, device='cuda:0')</td>\n",
       "      <td>tensor(988.1455, device='cuda:0')</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>3.266752e-04</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>1.183076e-04</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>47.013763</td>\n",
       "      <td>299907.625000</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3.287169e-06</td>\n",
       "      <td>4.231628e-03</td>\n",
       "      <td>7.768095e-04</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>90.384285</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>6379.145020</td>\n",
       "      <td>78593.039062</td>\n",
       "      <td>6.299286e+10</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>448.057373</td>\n",
       "      <td>68.812584</td>\n",
       "      <td>-2.605715e-04</td>\n",
       "      <td>0.936611</td>\n",
       "      <td>4.515076</td>\n",
       "      <td>52.014038</td>\n",
       "      <td>191.983521</td>\n",
       "      <td>256.000092</td>\n",
       "      <td>6378.625488</td>\n",
       "      <td>tensor(7.8997, device='cuda:0')</td>\n",
       "      <td>tensor(0.0375, device='cuda:0')</td>\n",
       "      <td>tensor(32678.3418, device='cuda:0')</td>\n",
       "      <td>tensor(300.1672, device='cuda:0')</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>2.058231e-04</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>9.691253e-05</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.685085</td>\n",
       "      <td>54.026512</td>\n",
       "      <td>1.160265</td>\n",
       "      <td>2.984306e-04</td>\n",
       "      <td>2.348996e-04</td>\n",
       "      <td>1.270460e+00</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>0.039882</td>\n",
       "      <td>1.160261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>10.097334</td>\n",
       "      <td>1.601146e+06</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>0.601654</td>\n",
       "      <td>0.048259</td>\n",
       "      <td>-2.003028e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.040192</td>\n",
       "      <td>0.120361</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>0.148590</td>\n",
       "      <td>tensor(34.3094, device='cuda:0')</td>\n",
       "      <td>tensor(1.4869, device='cuda:0')</td>\n",
       "      <td>tensor(30.9469, device='cuda:0')</td>\n",
       "      <td>tensor(1.5001, device='cuda:0')</td>\n",
       "      <td>0.054921</td>\n",
       "      <td>4.291588e-04</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>4.455452e-05</td>\n",
       "      <td>0.062748</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.977657</td>\n",
       "      <td>255123.500000</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>2.263072e-06</td>\n",
       "      <td>2.233088e-02</td>\n",
       "      <td>1.013427e-04</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>66.586540</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5936.188965</td>\n",
       "      <td>72545.148438</td>\n",
       "      <td>5.429687e+10</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>48.868233</td>\n",
       "      <td>-9.275613e-05</td>\n",
       "      <td>0.624369</td>\n",
       "      <td>3.232300</td>\n",
       "      <td>36.006989</td>\n",
       "      <td>128.011536</td>\n",
       "      <td>223.966553</td>\n",
       "      <td>5935.464355</td>\n",
       "      <td>tensor(5.1420, device='cuda:0')</td>\n",
       "      <td>tensor(0.2822, device='cuda:0')</td>\n",
       "      <td>tensor(15097.4561, device='cuda:0')</td>\n",
       "      <td>tensor(1847.8428, device='cuda:0')</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>9.094416e-06</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>4.463206e-05</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>80.258064</td>\n",
       "      <td>197298.640625</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>9.398915e-05</td>\n",
       "      <td>9.880558e-02</td>\n",
       "      <td>9.512535e-04</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>51.494320</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.002048</td>\n",
       "      <td>2458.305176</td>\n",
       "      <td>50679.742188</td>\n",
       "      <td>5.961208e+10</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>448.101074</td>\n",
       "      <td>31.786739</td>\n",
       "      <td>-8.464399e-04</td>\n",
       "      <td>0.337982</td>\n",
       "      <td>1.656738</td>\n",
       "      <td>19.997437</td>\n",
       "      <td>104.005585</td>\n",
       "      <td>208.006439</td>\n",
       "      <td>2457.090332</td>\n",
       "      <td>tensor(69.9281, device='cuda:0')</td>\n",
       "      <td>tensor(0.3015, device='cuda:0')</td>\n",
       "      <td>tensor(157167.2812, device='cuda:0')</td>\n",
       "      <td>tensor(980.4156, device='cuda:0')</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>2.312965e-04</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>2.254441e-05</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.370766</td>\n",
       "      <td>249163.703125</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.542116e-06</td>\n",
       "      <td>3.286558e-02</td>\n",
       "      <td>4.692192e-05</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>65.031044</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>5744.969238</td>\n",
       "      <td>137100.203125</td>\n",
       "      <td>4.317101e+11</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>47.781593</td>\n",
       "      <td>-6.801366e-05</td>\n",
       "      <td>0.620422</td>\n",
       "      <td>3.008301</td>\n",
       "      <td>36.000195</td>\n",
       "      <td>128.005127</td>\n",
       "      <td>207.999573</td>\n",
       "      <td>5744.305664</td>\n",
       "      <td>tensor(3.1006, device='cuda:0')</td>\n",
       "      <td>tensor(0.2961, device='cuda:0')</td>\n",
       "      <td>tensor(14406.3359, device='cuda:0')</td>\n",
       "      <td>tensor(1940.9368, device='cuda:0')</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>6.163601e-05</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>2.254407e-05</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.868774</td>\n",
       "      <td>186268.890625</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4.309190e-06</td>\n",
       "      <td>7.512900e-02</td>\n",
       "      <td>5.735721e-05</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>91.670570</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>3661.753174</td>\n",
       "      <td>35885.093750</td>\n",
       "      <td>9.554579e+09</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>448.188477</td>\n",
       "      <td>68.483772</td>\n",
       "      <td>4.107679e-04</td>\n",
       "      <td>0.619507</td>\n",
       "      <td>3.217285</td>\n",
       "      <td>52.008484</td>\n",
       "      <td>191.992615</td>\n",
       "      <td>256.006226</td>\n",
       "      <td>3660.708008</td>\n",
       "      <td>tensor(8.8461, device='cuda:0')</td>\n",
       "      <td>tensor(0.3148, device='cuda:0')</td>\n",
       "      <td>tensor(18407.6309, device='cuda:0')</td>\n",
       "      <td>tensor(1166.3866, device='cuda:0')</td>\n",
       "      <td>0.037458</td>\n",
       "      <td>5.678153e-04</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>2.449809e-05</td>\n",
       "      <td>0.041439</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>54.821720</td>\n",
       "      <td>303415.875000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-1.320386e-06</td>\n",
       "      <td>1.594279e-02</td>\n",
       "      <td>-8.282024e-05</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>91.441566</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>5534.592773</td>\n",
       "      <td>56591.507812</td>\n",
       "      <td>1.502065e+10</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>68.983444</td>\n",
       "      <td>-1.252155e-04</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>4.496109</td>\n",
       "      <td>52.004486</td>\n",
       "      <td>191.994751</td>\n",
       "      <td>256.007629</td>\n",
       "      <td>5533.782227</td>\n",
       "      <td>tensor(9.2524, device='cuda:0')</td>\n",
       "      <td>tensor(0.0359, device='cuda:0')</td>\n",
       "      <td>tensor(32452.8301, device='cuda:0')</td>\n",
       "      <td>tensor(218.6425, device='cuda:0')</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>1.322738e-04</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>3.932869e-05</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.182152</td>\n",
       "      <td>52.010090</td>\n",
       "      <td>1.214806</td>\n",
       "      <td>3.551023e-04</td>\n",
       "      <td>4.025494e-04</td>\n",
       "      <td>8.821335e-01</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.038392</td>\n",
       "      <td>1.214837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>1.297325</td>\n",
       "      <td>7.492600</td>\n",
       "      <td>5.786942e+05</td>\n",
       "      <td>-0.003380</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>0.047714</td>\n",
       "      <td>-2.543100e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039706</td>\n",
       "      <td>0.118896</td>\n",
       "      <td>0.161591</td>\n",
       "      <td>0.184687</td>\n",
       "      <td>tensor(35.1854, device='cuda:0')</td>\n",
       "      <td>tensor(1.7850, device='cuda:0')</td>\n",
       "      <td>tensor(30.4998, device='cuda:0')</td>\n",
       "      <td>tensor(1.0434, device='cuda:0')</td>\n",
       "      <td>0.056231</td>\n",
       "      <td>8.062422e-04</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>6.801846e-05</td>\n",
       "      <td>0.062661</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.694138</td>\n",
       "      <td>253349.312500</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-3.134209e-06</td>\n",
       "      <td>-2.396222e-02</td>\n",
       "      <td>-3.134208e+06</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>66.123482</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>5798.245605</td>\n",
       "      <td>103942.492188</td>\n",
       "      <td>4.773074e+11</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>448.169922</td>\n",
       "      <td>49.261894</td>\n",
       "      <td>-1.668757e-04</td>\n",
       "      <td>0.567585</td>\n",
       "      <td>2.988892</td>\n",
       "      <td>36.024536</td>\n",
       "      <td>128.008850</td>\n",
       "      <td>192.010742</td>\n",
       "      <td>5797.519531</td>\n",
       "      <td>tensor(5.1990, device='cuda:0')</td>\n",
       "      <td>tensor(0.2842, device='cuda:0')</td>\n",
       "      <td>tensor(19167.4121, device='cuda:0')</td>\n",
       "      <td>tensor(1216.9896, device='cuda:0')</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>6.068109e-06</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>4.098071e-04</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>83.070198</td>\n",
       "      <td>152293.328125</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>8.412390e-05</td>\n",
       "      <td>8.334381e-02</td>\n",
       "      <td>1.009360e-03</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>39.748058</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>1833.311279</td>\n",
       "      <td>60341.679688</td>\n",
       "      <td>2.532906e+11</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>448.087402</td>\n",
       "      <td>25.531776</td>\n",
       "      <td>-1.006113e-03</td>\n",
       "      <td>0.294250</td>\n",
       "      <td>1.496918</td>\n",
       "      <td>17.990234</td>\n",
       "      <td>72.002457</td>\n",
       "      <td>159.990173</td>\n",
       "      <td>1832.239746</td>\n",
       "      <td>tensor(73.2654, device='cuda:0')</td>\n",
       "      <td>tensor(0.3051, device='cuda:0')</td>\n",
       "      <td>tensor(102054.1328, device='cuda:0')</td>\n",
       "      <td>tensor(920.8010, device='cuda:0')</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>4.372881e-04</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>2.298953e-04</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.037579</td>\n",
       "      <td>238882.812500</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-2.181807e-06</td>\n",
       "      <td>-1.616513e-02</td>\n",
       "      <td>-2.181807e+06</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>62.347771</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5424.522461</td>\n",
       "      <td>87642.031250</td>\n",
       "      <td>3.227924e+11</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>46.309608</td>\n",
       "      <td>4.099178e-04</td>\n",
       "      <td>0.616943</td>\n",
       "      <td>3.004120</td>\n",
       "      <td>35.994324</td>\n",
       "      <td>127.995575</td>\n",
       "      <td>191.996231</td>\n",
       "      <td>5423.809570</td>\n",
       "      <td>tensor(3.3358, device='cuda:0')</td>\n",
       "      <td>tensor(0.2981, device='cuda:0')</td>\n",
       "      <td>tensor(16865.2500, device='cuda:0')</td>\n",
       "      <td>tensor(1912.5502, device='cuda:0')</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>4.675386e-05</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>1.215996e-04</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.171547</td>\n",
       "      <td>189226.890625</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-1.168154e-05</td>\n",
       "      <td>3.427737e-02</td>\n",
       "      <td>-3.407946e-04</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>93.126350</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3697.892822</td>\n",
       "      <td>43932.089844</td>\n",
       "      <td>3.435974e+10</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>448.087891</td>\n",
       "      <td>68.981293</td>\n",
       "      <td>1.938382e-04</td>\n",
       "      <td>0.607259</td>\n",
       "      <td>3.019043</td>\n",
       "      <td>51.998413</td>\n",
       "      <td>192.010559</td>\n",
       "      <td>256.025513</td>\n",
       "      <td>3696.920654</td>\n",
       "      <td>tensor(9.7541, device='cuda:0')</td>\n",
       "      <td>tensor(0.3067, device='cuda:0')</td>\n",
       "      <td>tensor(15866.1582, device='cuda:0')</td>\n",
       "      <td>tensor(1095.8082, device='cuda:0')</td>\n",
       "      <td>0.037729</td>\n",
       "      <td>8.237747e-05</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>7.996759e-05</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>62.171219</td>\n",
       "      <td>314810.125000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>6.371345e-06</td>\n",
       "      <td>-2.448407e-03</td>\n",
       "      <td>6.371344e+06</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>94.875511</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>5063.599609</td>\n",
       "      <td>56138.335938</td>\n",
       "      <td>3.546812e+10</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>448.065430</td>\n",
       "      <td>72.510666</td>\n",
       "      <td>-2.761971e-04</td>\n",
       "      <td>0.952332</td>\n",
       "      <td>4.978561</td>\n",
       "      <td>56.007233</td>\n",
       "      <td>192.006836</td>\n",
       "      <td>256.015137</td>\n",
       "      <td>5062.698730</td>\n",
       "      <td>tensor(8.2211, device='cuda:0')</td>\n",
       "      <td>tensor(0.0328, device='cuda:0')</td>\n",
       "      <td>tensor(29469.3066, device='cuda:0')</td>\n",
       "      <td>tensor(217.2288, device='cuda:0')</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>1.257130e-03</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>9.863065e-05</td>\n",
       "      <td>0.025368</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.850780</td>\n",
       "      <td>49.865566</td>\n",
       "      <td>1.280458</td>\n",
       "      <td>1.851208e-04</td>\n",
       "      <td>3.350106e-04</td>\n",
       "      <td>5.525820e-01</td>\n",
       "      <td>0.047135</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>1.280502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>1.270987</td>\n",
       "      <td>7.658829</td>\n",
       "      <td>1.154136e+06</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>-2.689425e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.159729</td>\n",
       "      <td>0.222280</td>\n",
       "      <td>tensor(35.2729, device='cuda:0')</td>\n",
       "      <td>tensor(1.7216, device='cuda:0')</td>\n",
       "      <td>tensor(28.7350, device='cuda:0')</td>\n",
       "      <td>tensor(1.0092, device='cuda:0')</td>\n",
       "      <td>0.056154</td>\n",
       "      <td>1.166427e-03</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>8.060056e-05</td>\n",
       "      <td>0.061841</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.938866</td>\n",
       "      <td>231562.562500</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>2.060468e-06</td>\n",
       "      <td>7.649785e-03</td>\n",
       "      <td>2.693498e-04</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>60.437206</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5392.842773</td>\n",
       "      <td>89205.640625</td>\n",
       "      <td>2.199023e+11</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>44.529606</td>\n",
       "      <td>3.690844e-04</td>\n",
       "      <td>0.560165</td>\n",
       "      <td>2.753052</td>\n",
       "      <td>32.012451</td>\n",
       "      <td>120.006836</td>\n",
       "      <td>191.990845</td>\n",
       "      <td>5391.880859</td>\n",
       "      <td>tensor(5.1456, device='cuda:0')</td>\n",
       "      <td>tensor(0.2394, device='cuda:0')</td>\n",
       "      <td>tensor(15627.5420, device='cuda:0')</td>\n",
       "      <td>tensor(1616.5973, device='cuda:0')</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>6.592246e-05</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>6.505140e-04</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>76.841179</td>\n",
       "      <td>154447.515625</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>4.140424e-05</td>\n",
       "      <td>7.981002e-02</td>\n",
       "      <td>5.187850e-04</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>40.310303</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>2009.958862</td>\n",
       "      <td>34416.296875</td>\n",
       "      <td>4.678773e+10</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>448.074219</td>\n",
       "      <td>26.249416</td>\n",
       "      <td>-8.827740e-04</td>\n",
       "      <td>0.307098</td>\n",
       "      <td>1.506195</td>\n",
       "      <td>17.998337</td>\n",
       "      <td>72.027344</td>\n",
       "      <td>159.937012</td>\n",
       "      <td>2009.329468</td>\n",
       "      <td>tensor(65.6767, device='cuda:0')</td>\n",
       "      <td>tensor(0.3097, device='cuda:0')</td>\n",
       "      <td>tensor(98299.5859, device='cuda:0')</td>\n",
       "      <td>tensor(926.6945, device='cuda:0')</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>1.392960e-04</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>4.151587e-05</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.662048</td>\n",
       "      <td>231356.515625</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>2.608207e-06</td>\n",
       "      <td>-1.491899e-02</td>\n",
       "      <td>2.608207e+06</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>60.383430</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5423.005859</td>\n",
       "      <td>68517.617188</td>\n",
       "      <td>4.006318e+10</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>44.436245</td>\n",
       "      <td>1.883693e-04</td>\n",
       "      <td>0.563178</td>\n",
       "      <td>2.758484</td>\n",
       "      <td>32.004517</td>\n",
       "      <td>127.978271</td>\n",
       "      <td>191.986328</td>\n",
       "      <td>5422.176270</td>\n",
       "      <td>tensor(3.1881, device='cuda:0')</td>\n",
       "      <td>tensor(0.2954, device='cuda:0')</td>\n",
       "      <td>tensor(14303.2695, device='cuda:0')</td>\n",
       "      <td>tensor(1833.2781, device='cuda:0')</td>\n",
       "      <td>0.015459</td>\n",
       "      <td>1.670447e-04</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>1.486905e-04</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.585777</td>\n",
       "      <td>194538.734375</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>-2.157557e-05</td>\n",
       "      <td>3.859184e-03</td>\n",
       "      <td>-5.590707e-03</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>95.740532</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>3771.169922</td>\n",
       "      <td>36770.828125</td>\n",
       "      <td>6.650272e+09</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>448.105957</td>\n",
       "      <td>71.288094</td>\n",
       "      <td>1.848901e-04</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>3.222778</td>\n",
       "      <td>55.962402</td>\n",
       "      <td>192.034424</td>\n",
       "      <td>256.044678</td>\n",
       "      <td>3770.162354</td>\n",
       "      <td>tensor(9.7458, device='cuda:0')</td>\n",
       "      <td>tensor(0.3408, device='cuda:0')</td>\n",
       "      <td>tensor(17169.6426, device='cuda:0')</td>\n",
       "      <td>tensor(1218.4589, device='cuda:0')</td>\n",
       "      <td>0.032655</td>\n",
       "      <td>2.093654e-04</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>7.862057e-05</td>\n",
       "      <td>0.041586</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.028961</td>\n",
       "      <td>323574.531250</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>9.261754e-06</td>\n",
       "      <td>3.194254e-02</td>\n",
       "      <td>2.899505e-04</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>97.516869</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>4827.384277</td>\n",
       "      <td>57141.085938</td>\n",
       "      <td>5.961208e+10</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>448.062256</td>\n",
       "      <td>75.351212</td>\n",
       "      <td>-1.204373e-06</td>\n",
       "      <td>1.020264</td>\n",
       "      <td>5.461426</td>\n",
       "      <td>60.001373</td>\n",
       "      <td>192.020996</td>\n",
       "      <td>256.025513</td>\n",
       "      <td>4826.617676</td>\n",
       "      <td>tensor(8.8077, device='cuda:0')</td>\n",
       "      <td>tensor(0.0213, device='cuda:0')</td>\n",
       "      <td>tensor(30561.5840, device='cuda:0')</td>\n",
       "      <td>tensor(148.3328, device='cuda:0')</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>4.107460e-05</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>1.082079e-04</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.051323</td>\n",
       "      <td>51.242741</td>\n",
       "      <td>1.210929</td>\n",
       "      <td>5.022708e-05</td>\n",
       "      <td>4.078590e-04</td>\n",
       "      <td>1.231481e-01</td>\n",
       "      <td>0.045807</td>\n",
       "      <td>0.037826</td>\n",
       "      <td>1.210999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006046</td>\n",
       "      <td>1.300750</td>\n",
       "      <td>7.540335</td>\n",
       "      <td>7.418769e+05</td>\n",
       "      <td>-0.006058</td>\n",
       "      <td>0.579712</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>-5.781804e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>0.158447</td>\n",
       "      <td>0.179377</td>\n",
       "      <td>tensor(34.8382, device='cuda:0')</td>\n",
       "      <td>tensor(1.2862, device='cuda:0')</td>\n",
       "      <td>tensor(30.3641, device='cuda:0')</td>\n",
       "      <td>tensor(1.2814, device='cuda:0')</td>\n",
       "      <td>0.056924</td>\n",
       "      <td>1.763348e-03</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>5.293634e-05</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.100792</td>\n",
       "      <td>251104.656250</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.771797e-06</td>\n",
       "      <td>-2.997688e-05</td>\n",
       "      <td>-1.771797e+06</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>65.537636</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>5567.632812</td>\n",
       "      <td>65712.617188</td>\n",
       "      <td>8.078044e+10</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>48.383396</td>\n",
       "      <td>2.285991e-04</td>\n",
       "      <td>0.565744</td>\n",
       "      <td>2.978027</td>\n",
       "      <td>36.000435</td>\n",
       "      <td>128.027222</td>\n",
       "      <td>192.014282</td>\n",
       "      <td>5567.040039</td>\n",
       "      <td>tensor(5.0391, device='cuda:0')</td>\n",
       "      <td>tensor(0.2663, device='cuda:0')</td>\n",
       "      <td>tensor(26416.4805, device='cuda:0')</td>\n",
       "      <td>tensor(1835.0660, device='cuda:0')</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>1.819824e-04</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>3.795329e-05</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>75.130760</td>\n",
       "      <td>130005.640625</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>1.298265e-05</td>\n",
       "      <td>5.368698e-02</td>\n",
       "      <td>2.418213e-04</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>33.931076</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>1730.392944</td>\n",
       "      <td>38455.523438</td>\n",
       "      <td>4.754645e+10</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>448.109863</td>\n",
       "      <td>23.628176</td>\n",
       "      <td>-5.342925e-04</td>\n",
       "      <td>0.292969</td>\n",
       "      <td>1.493958</td>\n",
       "      <td>17.973511</td>\n",
       "      <td>64.004578</td>\n",
       "      <td>104.011292</td>\n",
       "      <td>1729.790527</td>\n",
       "      <td>tensor(62.4396, device='cuda:0')</td>\n",
       "      <td>tensor(0.3165, device='cuda:0')</td>\n",
       "      <td>tensor(56517.0039, device='cuda:0')</td>\n",
       "      <td>tensor(709.9133, device='cuda:0')</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>5.585758e-04</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>3.116904e-05</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.422676</td>\n",
       "      <td>231655.156250</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>5.882713e-07</td>\n",
       "      <td>-2.174682e-02</td>\n",
       "      <td>5.882714e+05</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>60.461372</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>5214.794922</td>\n",
       "      <td>68696.265625</td>\n",
       "      <td>1.691556e+11</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>44.068352</td>\n",
       "      <td>2.352858e-04</td>\n",
       "      <td>0.552856</td>\n",
       "      <td>2.747253</td>\n",
       "      <td>31.996460</td>\n",
       "      <td>127.993500</td>\n",
       "      <td>191.994934</td>\n",
       "      <td>5214.052734</td>\n",
       "      <td>tensor(2.9875, device='cuda:0')</td>\n",
       "      <td>tensor(0.2978, device='cuda:0')</td>\n",
       "      <td>tensor(13671.3311, device='cuda:0')</td>\n",
       "      <td>tensor(1862.6338, device='cuda:0')</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>6.165392e-04</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>1.563807e-06</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.504116</td>\n",
       "      <td>189007.765625</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>1.287167e-05</td>\n",
       "      <td>-2.249974e-02</td>\n",
       "      <td>1.287167e+07</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>93.018517</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>3896.737061</td>\n",
       "      <td>108091.843750</td>\n",
       "      <td>1.809323e+11</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>448.100586</td>\n",
       "      <td>69.130898</td>\n",
       "      <td>-4.219027e-04</td>\n",
       "      <td>0.634135</td>\n",
       "      <td>3.242462</td>\n",
       "      <td>52.002319</td>\n",
       "      <td>192.006134</td>\n",
       "      <td>256.014648</td>\n",
       "      <td>3895.725586</td>\n",
       "      <td>tensor(7.9838, device='cuda:0')</td>\n",
       "      <td>tensor(0.2766, device='cuda:0')</td>\n",
       "      <td>tensor(17774.9434, device='cuda:0')</td>\n",
       "      <td>tensor(1060.8881, device='cuda:0')</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>1.585503e-04</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>8.236145e-05</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.526833</td>\n",
       "      <td>333944.687500</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>7.903849e-07</td>\n",
       "      <td>-3.563926e-02</td>\n",
       "      <td>7.903849e+05</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>100.642151</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>5609.986328</td>\n",
       "      <td>65696.726562</td>\n",
       "      <td>6.944284e+10</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>448.056396</td>\n",
       "      <td>78.484642</td>\n",
       "      <td>-3.994679e-04</td>\n",
       "      <td>1.128547</td>\n",
       "      <td>5.526367</td>\n",
       "      <td>63.991028</td>\n",
       "      <td>207.982300</td>\n",
       "      <td>287.971436</td>\n",
       "      <td>5609.116211</td>\n",
       "      <td>tensor(8.4884, device='cuda:0')</td>\n",
       "      <td>tensor(0.0258, device='cuda:0')</td>\n",
       "      <td>tensor(27875.1953, device='cuda:0')</td>\n",
       "      <td>tensor(245.6241, device='cuda:0')</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>1.680081e-04</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>4.294467e-06</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.750134</td>\n",
       "      <td>49.359756</td>\n",
       "      <td>1.271281</td>\n",
       "      <td>4.912720e-05</td>\n",
       "      <td>2.551288e-04</td>\n",
       "      <td>1.925584e-01</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>1.271312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003551</td>\n",
       "      <td>1.274495</td>\n",
       "      <td>8.138981</td>\n",
       "      <td>2.219794e+06</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>0.552246</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>-3.055236e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>0.215808</td>\n",
       "      <td>tensor(35.2901, device='cuda:0')</td>\n",
       "      <td>tensor(1.4422, device='cuda:0')</td>\n",
       "      <td>tensor(27.1107, device='cuda:0')</td>\n",
       "      <td>tensor(0.9067, device='cuda:0')</td>\n",
       "      <td>0.052852</td>\n",
       "      <td>1.666386e-03</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>1.330105e-04</td>\n",
       "      <td>0.062817</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.149212</td>\n",
       "      <td>247063.156250</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-1.787721e-06</td>\n",
       "      <td>-1.017821e-02</td>\n",
       "      <td>-1.787721e+06</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>64.482819</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>5861.631836</td>\n",
       "      <td>83600.359375</td>\n",
       "      <td>4.386349e+10</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>448.059570</td>\n",
       "      <td>48.018024</td>\n",
       "      <td>3.088471e-04</td>\n",
       "      <td>0.629456</td>\n",
       "      <td>3.245850</td>\n",
       "      <td>36.007324</td>\n",
       "      <td>127.998901</td>\n",
       "      <td>207.968506</td>\n",
       "      <td>5860.645996</td>\n",
       "      <td>tensor(5.2692, device='cuda:0')</td>\n",
       "      <td>tensor(0.2936, device='cuda:0')</td>\n",
       "      <td>tensor(20189.6152, device='cuda:0')</td>\n",
       "      <td>tensor(1538.2830, device='cuda:0')</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>2.258347e-04</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>4.459386e-04</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.022098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>72.227585</td>\n",
       "      <td>181604.406250</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1.781603e-05</td>\n",
       "      <td>1.264764e-02</td>\n",
       "      <td>1.408644e-03</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>47.398262</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>2514.337891</td>\n",
       "      <td>46348.429688</td>\n",
       "      <td>4.898814e+10</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>448.113281</td>\n",
       "      <td>31.664038</td>\n",
       "      <td>-8.246223e-04</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>1.865723</td>\n",
       "      <td>21.994659</td>\n",
       "      <td>95.987976</td>\n",
       "      <td>175.998718</td>\n",
       "      <td>2513.658447</td>\n",
       "      <td>tensor(60.2398, device='cuda:0')</td>\n",
       "      <td>tensor(0.3184, device='cuda:0')</td>\n",
       "      <td>tensor(115457.6406, device='cuda:0')</td>\n",
       "      <td>tensor(1075.5168, device='cuda:0')</td>\n",
       "      <td>0.018606</td>\n",
       "      <td>7.672733e-06</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>2.643484e-04</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.069752</td>\n",
       "      <td>252705.421875</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>3.127269e-06</td>\n",
       "      <td>-2.167179e-03</td>\n",
       "      <td>3.127269e+06</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>65.955437</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>6006.819824</td>\n",
       "      <td>78606.656250</td>\n",
       "      <td>8.144531e+10</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>448.051270</td>\n",
       "      <td>48.941292</td>\n",
       "      <td>3.948596e-04</td>\n",
       "      <td>0.630859</td>\n",
       "      <td>3.244995</td>\n",
       "      <td>36.005676</td>\n",
       "      <td>128.016357</td>\n",
       "      <td>207.982422</td>\n",
       "      <td>6005.924316</td>\n",
       "      <td>tensor(3.2789, device='cuda:0')</td>\n",
       "      <td>tensor(0.3085, device='cuda:0')</td>\n",
       "      <td>tensor(13867.5547, device='cuda:0')</td>\n",
       "      <td>tensor(1974.4187, device='cuda:0')</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>3.160204e-04</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>7.972325e-05</td>\n",
       "      <td>0.021479</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.250446</td>\n",
       "      <td>170246.734375</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.038563e-05</td>\n",
       "      <td>-2.859824e-02</td>\n",
       "      <td>1.038563e+07</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>83.785439</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>3258.283447</td>\n",
       "      <td>32944.500000</td>\n",
       "      <td>6.170728e+09</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>448.080566</td>\n",
       "      <td>62.261913</td>\n",
       "      <td>-3.090911e-04</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>2.970825</td>\n",
       "      <td>47.990540</td>\n",
       "      <td>175.990295</td>\n",
       "      <td>240.007263</td>\n",
       "      <td>3257.300537</td>\n",
       "      <td>tensor(9.2863, device='cuda:0')</td>\n",
       "      <td>tensor(0.2852, device='cuda:0')</td>\n",
       "      <td>tensor(15599.6973, device='cuda:0')</td>\n",
       "      <td>tensor(1491.3947, device='cuda:0')</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>1.174607e-03</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>4.496304e-05</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>65.144463</td>\n",
       "      <td>321128.125000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-4.929692e-06</td>\n",
       "      <td>-1.455903e-02</td>\n",
       "      <td>-4.929692e+06</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>96.779587</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>4929.477539</td>\n",
       "      <td>52557.511719</td>\n",
       "      <td>1.832519e+10</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>448.070801</td>\n",
       "      <td>74.487129</td>\n",
       "      <td>1.362136e-04</td>\n",
       "      <td>0.996406</td>\n",
       "      <td>5.004059</td>\n",
       "      <td>59.988464</td>\n",
       "      <td>192.015503</td>\n",
       "      <td>256.021118</td>\n",
       "      <td>4928.490234</td>\n",
       "      <td>tensor(10.0527, device='cuda:0')</td>\n",
       "      <td>tensor(0.0268, device='cuda:0')</td>\n",
       "      <td>tensor(32874.7734, device='cuda:0')</td>\n",
       "      <td>tensor(118.4166, device='cuda:0')</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>1.493023e-04</td>\n",
       "      <td>0.009489</td>\n",
       "      <td>8.747861e-05</td>\n",
       "      <td>0.025384</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>62.404762</td>\n",
       "      <td>47.435638</td>\n",
       "      <td>1.315567</td>\n",
       "      <td>-1.113991e-06</td>\n",
       "      <td>6.144195e-05</td>\n",
       "      <td>-1.813078e-02</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>0.035017</td>\n",
       "      <td>1.315569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>1.258886</td>\n",
       "      <td>7.086387</td>\n",
       "      <td>4.426945e+05</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>-3.929820e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>0.154053</td>\n",
       "      <td>0.243457</td>\n",
       "      <td>tensor(35.2985, device='cuda:0')</td>\n",
       "      <td>tensor(1.8774, device='cuda:0')</td>\n",
       "      <td>tensor(26.0717, device='cuda:0')</td>\n",
       "      <td>tensor(1.1170, device='cuda:0')</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>4.706438e-04</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>2.697046e-05</td>\n",
       "      <td>0.061548</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.535549</td>\n",
       "      <td>240439.250000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.445487e-06</td>\n",
       "      <td>-1.753473e-04</td>\n",
       "      <td>1.445487e+06</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>62.753994</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>5522.825684</td>\n",
       "      <td>59994.035156</td>\n",
       "      <td>1.871509e+10</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>448.047119</td>\n",
       "      <td>46.171185</td>\n",
       "      <td>1.870972e-04</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>2.750587</td>\n",
       "      <td>35.991638</td>\n",
       "      <td>127.995972</td>\n",
       "      <td>192.002701</td>\n",
       "      <td>5522.009766</td>\n",
       "      <td>tensor(5.7537, device='cuda:0')</td>\n",
       "      <td>tensor(0.2922, device='cuda:0')</td>\n",
       "      <td>tensor(18232.0234, device='cuda:0')</td>\n",
       "      <td>tensor(1471.2906, device='cuda:0')</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>5.950281e-05</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>2.524187e-04</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>68.102524</td>\n",
       "      <td>174105.203125</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-1.824098e-06</td>\n",
       "      <td>-1.665290e-02</td>\n",
       "      <td>-1.824098e+06</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>45.440990</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>2556.518311</td>\n",
       "      <td>41185.980469</td>\n",
       "      <td>3.646339e+10</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>448.090332</td>\n",
       "      <td>30.620880</td>\n",
       "      <td>-6.035906e-04</td>\n",
       "      <td>0.361694</td>\n",
       "      <td>1.772949</td>\n",
       "      <td>21.965332</td>\n",
       "      <td>88.005005</td>\n",
       "      <td>160.004303</td>\n",
       "      <td>2555.861328</td>\n",
       "      <td>tensor(55.2427, device='cuda:0')</td>\n",
       "      <td>tensor(0.3185, device='cuda:0')</td>\n",
       "      <td>tensor(102982.2969, device='cuda:0')</td>\n",
       "      <td>tensor(1028.6125, device='cuda:0')</td>\n",
       "      <td>0.019666</td>\n",
       "      <td>1.306992e-04</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>6.721320e-06</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.068176</td>\n",
       "      <td>245458.218750</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>4.456436e-06</td>\n",
       "      <td>-2.655647e-02</td>\n",
       "      <td>4.456436e+06</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>64.063927</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>5699.294434</td>\n",
       "      <td>114335.671875</td>\n",
       "      <td>3.021559e+11</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>448.049561</td>\n",
       "      <td>47.354362</td>\n",
       "      <td>3.372317e-04</td>\n",
       "      <td>0.614807</td>\n",
       "      <td>3.001030</td>\n",
       "      <td>35.996933</td>\n",
       "      <td>128.004608</td>\n",
       "      <td>192.005432</td>\n",
       "      <td>5698.498535</td>\n",
       "      <td>tensor(3.3285, device='cuda:0')</td>\n",
       "      <td>tensor(0.3107, device='cuda:0')</td>\n",
       "      <td>tensor(15044.6943, device='cuda:0')</td>\n",
       "      <td>tensor(1861.3116, device='cuda:0')</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>2.388387e-05</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>7.444618e-05</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.018276</td>\n",
       "      <td>186641.953125</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>9.768949e-06</td>\n",
       "      <td>-3.703205e-02</td>\n",
       "      <td>9.768949e+06</td>\n",
       "      <td>0.024616</td>\n",
       "      <td>91.854195</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>3731.474609</td>\n",
       "      <td>38760.339844</td>\n",
       "      <td>8.191726e+09</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>68.218445</td>\n",
       "      <td>7.925935e-04</td>\n",
       "      <td>0.640869</td>\n",
       "      <td>3.250557</td>\n",
       "      <td>51.990417</td>\n",
       "      <td>191.998032</td>\n",
       "      <td>256.009949</td>\n",
       "      <td>3730.482666</td>\n",
       "      <td>tensor(9.7517, device='cuda:0')</td>\n",
       "      <td>tensor(0.2779, device='cuda:0')</td>\n",
       "      <td>tensor(18978.3945, device='cuda:0')</td>\n",
       "      <td>tensor(901.4807, device='cuda:0')</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>6.165561e-05</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>5.563757e-05</td>\n",
       "      <td>0.040442</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>55.811195</td>\n",
       "      <td>335747.656250</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-1.355623e-06</td>\n",
       "      <td>6.798734e-02</td>\n",
       "      <td>-1.993935e-05</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>101.185501</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>6015.775879</td>\n",
       "      <td>182631.156250</td>\n",
       "      <td>1.122905e+12</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>79.014297</td>\n",
       "      <td>3.621618e-04</td>\n",
       "      <td>1.133606</td>\n",
       "      <td>5.972412</td>\n",
       "      <td>63.995483</td>\n",
       "      <td>207.987122</td>\n",
       "      <td>287.977295</td>\n",
       "      <td>6015.132324</td>\n",
       "      <td>tensor(8.9557, device='cuda:0')</td>\n",
       "      <td>tensor(0.0354, device='cuda:0')</td>\n",
       "      <td>tensor(26093.2520, device='cuda:0')</td>\n",
       "      <td>tensor(333.1879, device='cuda:0')</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>2.578904e-04</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>3.315162e-05</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>63.084209</td>\n",
       "      <td>45.760281</td>\n",
       "      <td>1.378580</td>\n",
       "      <td>-1.221991e-05</td>\n",
       "      <td>1.062308e-04</td>\n",
       "      <td>-1.150317e-01</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.033781</td>\n",
       "      <td>1.378587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004642</td>\n",
       "      <td>1.238110</td>\n",
       "      <td>8.630249</td>\n",
       "      <td>3.332972e+06</td>\n",
       "      <td>-0.004641</td>\n",
       "      <td>0.630844</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>-4.209928e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>0.153564</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>tensor(34.6667, device='cuda:0')</td>\n",
       "      <td>tensor(1.3730, device='cuda:0')</td>\n",
       "      <td>tensor(25.0578, device='cuda:0')</td>\n",
       "      <td>tensor(1.0984, device='cuda:0')</td>\n",
       "      <td>0.055092</td>\n",
       "      <td>8.172798e-04</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>4.815317e-05</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.389908</td>\n",
       "      <td>230632.750000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>5.718708e-07</td>\n",
       "      <td>-1.643468e-02</td>\n",
       "      <td>5.718708e+05</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>60.194527</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>4971.615234</td>\n",
       "      <td>60915.753906</td>\n",
       "      <td>5.286114e+10</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>44.023239</td>\n",
       "      <td>-1.658506e-04</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>2.743347</td>\n",
       "      <td>32.004303</td>\n",
       "      <td>120.006378</td>\n",
       "      <td>191.998077</td>\n",
       "      <td>4970.740723</td>\n",
       "      <td>tensor(5.7697, device='cuda:0')</td>\n",
       "      <td>tensor(0.2989, device='cuda:0')</td>\n",
       "      <td>tensor(16192.5449, device='cuda:0')</td>\n",
       "      <td>tensor(1354.5665, device='cuda:0')</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>3.720384e-04</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>3.154096e-04</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>74.325966</td>\n",
       "      <td>183386.718750</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-1.808949e-05</td>\n",
       "      <td>-8.035551e-02</td>\n",
       "      <td>-1.808949e+07</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>47.863373</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>2467.332031</td>\n",
       "      <td>37515.609375</td>\n",
       "      <td>1.784921e+10</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>448.105469</td>\n",
       "      <td>32.712452</td>\n",
       "      <td>-1.095551e-03</td>\n",
       "      <td>0.383545</td>\n",
       "      <td>1.889160</td>\n",
       "      <td>22.010559</td>\n",
       "      <td>95.999458</td>\n",
       "      <td>160.028320</td>\n",
       "      <td>2466.726562</td>\n",
       "      <td>tensor(62.3582, device='cuda:0')</td>\n",
       "      <td>tensor(0.3244, device='cuda:0')</td>\n",
       "      <td>tensor(107664.1719, device='cuda:0')</td>\n",
       "      <td>tensor(1081.9030, device='cuda:0')</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>4.921704e-05</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>2.676544e-05</td>\n",
       "      <td>0.022770</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.460163</td>\n",
       "      <td>235976.156250</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>1.905539e-06</td>\n",
       "      <td>-1.813463e-02</td>\n",
       "      <td>1.905539e+06</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>61.589142</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>5079.107910</td>\n",
       "      <td>69824.281250</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>448.075195</td>\n",
       "      <td>45.274456</td>\n",
       "      <td>-4.907714e-04</td>\n",
       "      <td>0.568390</td>\n",
       "      <td>2.983276</td>\n",
       "      <td>32.012329</td>\n",
       "      <td>127.993652</td>\n",
       "      <td>191.998138</td>\n",
       "      <td>5078.368652</td>\n",
       "      <td>tensor(3.4392, device='cuda:0')</td>\n",
       "      <td>tensor(0.3141, device='cuda:0')</td>\n",
       "      <td>tensor(14081.6943, device='cuda:0')</td>\n",
       "      <td>tensor(1777.1334, device='cuda:0')</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>2.238143e-04</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>2.883684e-05</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.282570</td>\n",
       "      <td>191723.765625</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.245191e-05</td>\n",
       "      <td>-1.889592e-02</td>\n",
       "      <td>1.245192e+07</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>94.355164</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>3598.245117</td>\n",
       "      <td>32920.160156</td>\n",
       "      <td>5.245762e+09</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>70.256126</td>\n",
       "      <td>1.060141e-04</td>\n",
       "      <td>0.630615</td>\n",
       "      <td>3.245422</td>\n",
       "      <td>52.023926</td>\n",
       "      <td>192.017212</td>\n",
       "      <td>256.026123</td>\n",
       "      <td>3597.247070</td>\n",
       "      <td>tensor(9.0024, device='cuda:0')</td>\n",
       "      <td>tensor(0.2656, device='cuda:0')</td>\n",
       "      <td>tensor(16797.7227, device='cuda:0')</td>\n",
       "      <td>tensor(1195.6292, device='cuda:0')</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>3.202272e-04</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>1.087242e-04</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.073479</td>\n",
       "      <td>341160.906250</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>3.105785e-06</td>\n",
       "      <td>3.046496e-02</td>\n",
       "      <td>1.019461e-04</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>102.816933</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>5086.375488</td>\n",
       "      <td>113385.765625</td>\n",
       "      <td>4.429687e+11</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>80.569618</td>\n",
       "      <td>-3.955459e-04</td>\n",
       "      <td>1.205078</td>\n",
       "      <td>5.996490</td>\n",
       "      <td>64.007874</td>\n",
       "      <td>207.994110</td>\n",
       "      <td>287.981934</td>\n",
       "      <td>5085.660156</td>\n",
       "      <td>tensor(9.8001, device='cuda:0')</td>\n",
       "      <td>tensor(0.0248, device='cuda:0')</td>\n",
       "      <td>tensor(31485.7852, device='cuda:0')</td>\n",
       "      <td>tensor(188.1636, device='cuda:0')</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>4.116604e-04</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>1.002822e-04</td>\n",
       "      <td>0.025544</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.973553</td>\n",
       "      <td>46.179924</td>\n",
       "      <td>1.342002</td>\n",
       "      <td>-5.842796e-06</td>\n",
       "      <td>2.846467e-05</td>\n",
       "      <td>-2.052648e-01</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.342003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>1.249538</td>\n",
       "      <td>8.309877</td>\n",
       "      <td>2.365393e+06</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>-3.411457e-03</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.112061</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.257446</td>\n",
       "      <td>tensor(35.0667, device='cuda:0')</td>\n",
       "      <td>tensor(1.7887, device='cuda:0')</td>\n",
       "      <td>tensor(25.2752, device='cuda:0')</td>\n",
       "      <td>tensor(1.0226, device='cuda:0')</td>\n",
       "      <td>0.058086</td>\n",
       "      <td>9.619877e-04</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>5.926202e-05</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.197800</td>\n",
       "      <td>247829.406250</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>9.818995e-06</td>\n",
       "      <td>1.695100e-02</td>\n",
       "      <td>5.792574e-04</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>64.682808</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>5483.218750</td>\n",
       "      <td>65615.882812</td>\n",
       "      <td>5.216661e+10</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>448.055664</td>\n",
       "      <td>47.841057</td>\n",
       "      <td>1.265548e-04</td>\n",
       "      <td>0.578735</td>\n",
       "      <td>2.997284</td>\n",
       "      <td>36.004364</td>\n",
       "      <td>128.001801</td>\n",
       "      <td>207.991699</td>\n",
       "      <td>5482.394043</td>\n",
       "      <td>tensor(6.1783, device='cuda:0')</td>\n",
       "      <td>tensor(0.2644, device='cuda:0')</td>\n",
       "      <td>tensor(19561.3613, device='cuda:0')</td>\n",
       "      <td>tensor(1344.3741, device='cuda:0')</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>2.105567e-04</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>3.937582e-05</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>70.298676</td>\n",
       "      <td>199909.265625</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>1.465653e-05</td>\n",
       "      <td>-1.079188e-01</td>\n",
       "      <td>1.465653e+07</td>\n",
       "      <td>0.018348</td>\n",
       "      <td>52.175667</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>2843.714844</td>\n",
       "      <td>45011.886719</td>\n",
       "      <td>4.302437e+10</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>35.923420</td>\n",
       "      <td>-8.924748e-04</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>2.035645</td>\n",
       "      <td>24.034180</td>\n",
       "      <td>104.005585</td>\n",
       "      <td>176.023193</td>\n",
       "      <td>2842.921387</td>\n",
       "      <td>tensor(55.7006, device='cuda:0')</td>\n",
       "      <td>tensor(0.3296, device='cuda:0')</td>\n",
       "      <td>tensor(122954.3828, device='cuda:0')</td>\n",
       "      <td>tensor(920.9156, device='cuda:0')</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>2.575951e-05</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>1.066473e-05</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.633236</td>\n",
       "      <td>251577.046875</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.387375e-06</td>\n",
       "      <td>-3.892486e-03</td>\n",
       "      <td>2.387375e+06</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>65.660934</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>5636.540527</td>\n",
       "      <td>70258.507812</td>\n",
       "      <td>1.499334e+11</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>448.055664</td>\n",
       "      <td>48.812527</td>\n",
       "      <td>-2.093344e-04</td>\n",
       "      <td>0.632385</td>\n",
       "      <td>3.247543</td>\n",
       "      <td>36.006805</td>\n",
       "      <td>128.010742</td>\n",
       "      <td>207.953613</td>\n",
       "      <td>5635.711426</td>\n",
       "      <td>tensor(3.4504, device='cuda:0')</td>\n",
       "      <td>tensor(0.3134, device='cuda:0')</td>\n",
       "      <td>tensor(15990.5225, device='cuda:0')</td>\n",
       "      <td>tensor(1514.9631, device='cuda:0')</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>4.330596e-04</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>5.852825e-06</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.084736</td>\n",
       "      <td>189800.718750</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-6.229685e-06</td>\n",
       "      <td>7.405902e-02</td>\n",
       "      <td>-8.411784e-05</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>93.408730</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>3644.076660</td>\n",
       "      <td>55398.613281</td>\n",
       "      <td>5.662721e+10</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>448.102539</td>\n",
       "      <td>69.423103</td>\n",
       "      <td>-5.787857e-04</td>\n",
       "      <td>0.672485</td>\n",
       "      <td>3.324707</td>\n",
       "      <td>52.001808</td>\n",
       "      <td>192.010925</td>\n",
       "      <td>256.019531</td>\n",
       "      <td>3643.032227</td>\n",
       "      <td>tensor(10.0985, device='cuda:0')</td>\n",
       "      <td>tensor(0.3279, device='cuda:0')</td>\n",
       "      <td>tensor(16415.3613, device='cuda:0')</td>\n",
       "      <td>tensor(1050.2319, device='cuda:0')</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>4.140799e-04</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>6.365346e-05</td>\n",
       "      <td>0.039439</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>58.247837</td>\n",
       "      <td>352249.687500</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>7.624965e-06</td>\n",
       "      <td>-1.217848e-02</td>\n",
       "      <td>7.624965e+06</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>106.158806</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>6047.429688</td>\n",
       "      <td>118446.406250</td>\n",
       "      <td>4.123169e+11</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>448.054443</td>\n",
       "      <td>83.965500</td>\n",
       "      <td>-2.292487e-04</td>\n",
       "      <td>1.261597</td>\n",
       "      <td>6.494751</td>\n",
       "      <td>71.989197</td>\n",
       "      <td>208.006378</td>\n",
       "      <td>287.992310</td>\n",
       "      <td>6047.041504</td>\n",
       "      <td>tensor(8.7619, device='cuda:0')</td>\n",
       "      <td>tensor(0.0283, device='cuda:0')</td>\n",
       "      <td>tensor(35729.4570, device='cuda:0')</td>\n",
       "      <td>tensor(207.2476, device='cuda:0')</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>2.713648e-04</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>1.451743e-04</td>\n",
       "      <td>0.025384</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.863007</td>\n",
       "      <td>43.545822</td>\n",
       "      <td>1.397677</td>\n",
       "      <td>-4.725270e-05</td>\n",
       "      <td>7.091826e-05</td>\n",
       "      <td>-6.662980e-01</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>0.032146</td>\n",
       "      <td>1.397680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>1.232308</td>\n",
       "      <td>7.579942</td>\n",
       "      <td>1.231282e+06</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>-3.491116e-03</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.108643</td>\n",
       "      <td>0.147583</td>\n",
       "      <td>0.287414</td>\n",
       "      <td>tensor(34.0958, device='cuda:0')</td>\n",
       "      <td>tensor(1.6073, device='cuda:0')</td>\n",
       "      <td>tensor(23.0769, device='cuda:0')</td>\n",
       "      <td>tensor(0.8903, device='cuda:0')</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>1.043467e-03</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>5.744134e-05</td>\n",
       "      <td>0.062316</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.931683</td>\n",
       "      <td>258967.203125</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.960684e-06</td>\n",
       "      <td>-1.130648e-02</td>\n",
       "      <td>1.960684e+06</td>\n",
       "      <td>0.012510</td>\n",
       "      <td>67.589737</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>5402.839844</td>\n",
       "      <td>94233.632812</td>\n",
       "      <td>2.393495e+11</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>448.042480</td>\n",
       "      <td>49.313259</td>\n",
       "      <td>-1.862604e-04</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>3.007172</td>\n",
       "      <td>36.006104</td>\n",
       "      <td>143.991577</td>\n",
       "      <td>223.992554</td>\n",
       "      <td>5402.047363</td>\n",
       "      <td>tensor(7.2430, device='cuda:0')</td>\n",
       "      <td>tensor(0.2892, device='cuda:0')</td>\n",
       "      <td>tensor(17627.8613, device='cuda:0')</td>\n",
       "      <td>tensor(1171.0211, device='cuda:0')</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>2.085403e-04</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>1.132557e-05</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>68.468765</td>\n",
       "      <td>223264.484375</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-1.311062e-05</td>\n",
       "      <td>-7.179382e-02</td>\n",
       "      <td>-1.311062e+07</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>58.271381</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>3260.823730</td>\n",
       "      <td>42319.062500</td>\n",
       "      <td>3.276690e+10</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>448.080078</td>\n",
       "      <td>40.509304</td>\n",
       "      <td>-9.134573e-04</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>2.256592</td>\n",
       "      <td>27.996506</td>\n",
       "      <td>120.006439</td>\n",
       "      <td>192.013550</td>\n",
       "      <td>3260.158447</td>\n",
       "      <td>tensor(52.5615, device='cuda:0')</td>\n",
       "      <td>tensor(0.3353, device='cuda:0')</td>\n",
       "      <td>tensor(137620.5469, device='cuda:0')</td>\n",
       "      <td>tensor(1012.3903, device='cuda:0')</td>\n",
       "      <td>0.019430</td>\n",
       "      <td>5.128735e-04</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>2.521355e-04</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.949577</td>\n",
       "      <td>258003.062500</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-1.868062e-06</td>\n",
       "      <td>-6.031224e-04</td>\n",
       "      <td>-1.868062e+06</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>67.338104</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>5495.322266</td>\n",
       "      <td>59840.785156</td>\n",
       "      <td>1.381296e+10</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>448.048340</td>\n",
       "      <td>49.617111</td>\n",
       "      <td>-1.027135e-04</td>\n",
       "      <td>0.634949</td>\n",
       "      <td>3.249195</td>\n",
       "      <td>36.008301</td>\n",
       "      <td>143.990601</td>\n",
       "      <td>208.004974</td>\n",
       "      <td>5494.527344</td>\n",
       "      <td>tensor(4.5010, device='cuda:0')</td>\n",
       "      <td>tensor(0.3151, device='cuda:0')</td>\n",
       "      <td>tensor(15610.8281, device='cuda:0')</td>\n",
       "      <td>tensor(1610.6716, device='cuda:0')</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>1.189172e-04</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>3.211034e-05</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.602535</td>\n",
       "      <td>185338.343750</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-1.446391e-05</td>\n",
       "      <td>5.707364e-02</td>\n",
       "      <td>-2.534253e-04</td>\n",
       "      <td>0.024904</td>\n",
       "      <td>91.212624</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>3662.629883</td>\n",
       "      <td>35816.812500</td>\n",
       "      <td>6.343336e+09</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>67.374046</td>\n",
       "      <td>-3.494063e-04</td>\n",
       "      <td>0.582845</td>\n",
       "      <td>2.994274</td>\n",
       "      <td>51.965332</td>\n",
       "      <td>191.995544</td>\n",
       "      <td>256.009705</td>\n",
       "      <td>3661.629395</td>\n",
       "      <td>tensor(9.3704, device='cuda:0')</td>\n",
       "      <td>tensor(0.3820, device='cuda:0')</td>\n",
       "      <td>tensor(14346.7393, device='cuda:0')</td>\n",
       "      <td>tensor(1192.5704, device='cuda:0')</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>4.928890e-04</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>1.853030e-04</td>\n",
       "      <td>0.040653</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>57.460434</td>\n",
       "      <td>349251.406250</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>1.119392e-06</td>\n",
       "      <td>-2.197577e-02</td>\n",
       "      <td>1.119392e+06</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>105.255188</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>6078.119141</td>\n",
       "      <td>110719.929688</td>\n",
       "      <td>5.929950e+11</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>82.983955</td>\n",
       "      <td>2.064742e-04</td>\n",
       "      <td>1.252747</td>\n",
       "      <td>6.475098</td>\n",
       "      <td>71.977539</td>\n",
       "      <td>208.003937</td>\n",
       "      <td>287.991150</td>\n",
       "      <td>6077.812500</td>\n",
       "      <td>tensor(9.5468, device='cuda:0')</td>\n",
       "      <td>tensor(0.0369, device='cuda:0')</td>\n",
       "      <td>tensor(36449.0430, device='cuda:0')</td>\n",
       "      <td>tensor(210.6368, device='cuda:0')</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>9.473615e-05</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>1.113752e-04</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.605721</td>\n",
       "      <td>41.730858</td>\n",
       "      <td>1.476263</td>\n",
       "      <td>-1.530145e-04</td>\n",
       "      <td>2.700510e-05</td>\n",
       "      <td>-5.666134e+00</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>1.476255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>1.210989</td>\n",
       "      <td>6.799035</td>\n",
       "      <td>1.167164e+06</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.651154</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>-4.214777e-03</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.036011</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0.324428</td>\n",
       "      <td>tensor(35.0970, device='cuda:0')</td>\n",
       "      <td>tensor(1.3668, device='cuda:0')</td>\n",
       "      <td>tensor(22.7419, device='cuda:0')</td>\n",
       "      <td>tensor(1.0490, device='cuda:0')</td>\n",
       "      <td>0.054744</td>\n",
       "      <td>1.035609e-03</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>7.382348e-05</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.564346</td>\n",
       "      <td>237526.000000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.318720e-06</td>\n",
       "      <td>-1.888927e-03</td>\n",
       "      <td>2.318720e+06</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>61.993645</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>5101.026855</td>\n",
       "      <td>60454.804688</td>\n",
       "      <td>3.214946e+10</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>45.218090</td>\n",
       "      <td>5.208935e-04</td>\n",
       "      <td>0.554871</td>\n",
       "      <td>2.748199</td>\n",
       "      <td>32.011597</td>\n",
       "      <td>127.994049</td>\n",
       "      <td>192.008179</td>\n",
       "      <td>5100.184082</td>\n",
       "      <td>tensor(7.1026, device='cuda:0')</td>\n",
       "      <td>tensor(0.2615, device='cuda:0')</td>\n",
       "      <td>tensor(15760.3555, device='cuda:0')</td>\n",
       "      <td>tensor(926.3517, device='cuda:0')</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>3.911988e-05</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>4.389784e-04</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>66.990974</td>\n",
       "      <td>220415.093750</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-4.016560e-06</td>\n",
       "      <td>-1.647688e-01</td>\n",
       "      <td>-4.016560e+06</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>57.527512</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>3290.221191</td>\n",
       "      <td>154464.421875</td>\n",
       "      <td>1.599290e+12</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>448.083496</td>\n",
       "      <td>40.729774</td>\n",
       "      <td>-4.129802e-04</td>\n",
       "      <td>0.482666</td>\n",
       "      <td>2.490784</td>\n",
       "      <td>28.013306</td>\n",
       "      <td>119.999237</td>\n",
       "      <td>191.995178</td>\n",
       "      <td>3289.649902</td>\n",
       "      <td>tensor(49.3033, device='cuda:0')</td>\n",
       "      <td>tensor(0.3401, device='cuda:0')</td>\n",
       "      <td>tensor(114131.9844, device='cuda:0')</td>\n",
       "      <td>tensor(1015.9985, device='cuda:0')</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>6.489080e-04</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>3.023008e-05</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.014114</td>\n",
       "      <td>243710.812500</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>5.867026e-06</td>\n",
       "      <td>-6.488448e-03</td>\n",
       "      <td>5.867026e+06</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>63.607864</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>5296.436035</td>\n",
       "      <td>54421.101562</td>\n",
       "      <td>1.906668e+10</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>448.040283</td>\n",
       "      <td>46.840004</td>\n",
       "      <td>-1.056472e-04</td>\n",
       "      <td>0.617981</td>\n",
       "      <td>3.005493</td>\n",
       "      <td>35.992767</td>\n",
       "      <td>128.002899</td>\n",
       "      <td>192.010803</td>\n",
       "      <td>5295.571777</td>\n",
       "      <td>tensor(3.8287, device='cuda:0')</td>\n",
       "      <td>tensor(0.3118, device='cuda:0')</td>\n",
       "      <td>tensor(18768.5391, device='cuda:0')</td>\n",
       "      <td>tensor(1365.4669, device='cuda:0')</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>6.410672e-05</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>1.923737e-05</td>\n",
       "      <td>0.021738</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.571045</td>\n",
       "      <td>178447.593750</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>1.410764e-05</td>\n",
       "      <td>-7.414980e-02</td>\n",
       "      <td>1.410764e+07</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>87.821396</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3394.408691</td>\n",
       "      <td>28110.822266</td>\n",
       "      <td>3.435974e+09</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>448.089355</td>\n",
       "      <td>65.355232</td>\n",
       "      <td>-9.170552e-05</td>\n",
       "      <td>0.674968</td>\n",
       "      <td>3.474365</td>\n",
       "      <td>48.023193</td>\n",
       "      <td>176.031982</td>\n",
       "      <td>255.986328</td>\n",
       "      <td>3393.353027</td>\n",
       "      <td>tensor(9.2986, device='cuda:0')</td>\n",
       "      <td>tensor(0.2067, device='cuda:0')</td>\n",
       "      <td>tensor(17803.4785, device='cuda:0')</td>\n",
       "      <td>tensor(1042.3430, device='cuda:0')</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>2.195175e-04</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>2.140864e-04</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>65.445320</td>\n",
       "      <td>350310.343750</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-6.649078e-06</td>\n",
       "      <td>-5.937477e-02</td>\n",
       "      <td>-6.649078e+06</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>105.574318</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>5352.717773</td>\n",
       "      <td>73483.367188</td>\n",
       "      <td>1.951796e+11</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>448.059570</td>\n",
       "      <td>83.454048</td>\n",
       "      <td>7.091999e-05</td>\n",
       "      <td>1.261597</td>\n",
       "      <td>6.491272</td>\n",
       "      <td>71.983521</td>\n",
       "      <td>208.004395</td>\n",
       "      <td>287.989746</td>\n",
       "      <td>5352.112305</td>\n",
       "      <td>tensor(9.9913, device='cuda:0')</td>\n",
       "      <td>tensor(0.0299, device='cuda:0')</td>\n",
       "      <td>tensor(32157.2461, device='cuda:0')</td>\n",
       "      <td>tensor(266.4430, device='cuda:0')</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>6.731620e-05</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>5.585853e-06</td>\n",
       "      <td>0.025731</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>61.044193</td>\n",
       "      <td>38.723587</td>\n",
       "      <td>1.576409</td>\n",
       "      <td>-2.331353e-04</td>\n",
       "      <td>1.089518e-07</td>\n",
       "      <td>-2.139803e+03</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>1.576388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005457</td>\n",
       "      <td>1.187151</td>\n",
       "      <td>6.806275</td>\n",
       "      <td>9.437174e+05</td>\n",
       "      <td>-0.005457</td>\n",
       "      <td>0.676025</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>-4.461233e-03</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.035095</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.366428</td>\n",
       "      <td>tensor(35.0660, device='cuda:0')</td>\n",
       "      <td>tensor(1.7004, device='cuda:0')</td>\n",
       "      <td>tensor(21.5537, device='cuda:0')</td>\n",
       "      <td>tensor(0.8511, device='cuda:0')</td>\n",
       "      <td>0.053567</td>\n",
       "      <td>2.362516e-04</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>2.061941e-04</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.011139</td>\n",
       "      <td>245694.359375</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>5.785107e-07</td>\n",
       "      <td>-1.659142e-02</td>\n",
       "      <td>5.785106e+05</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>64.125565</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>5226.300781</td>\n",
       "      <td>53237.601562</td>\n",
       "      <td>1.812382e+10</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.056885</td>\n",
       "      <td>46.886604</td>\n",
       "      <td>2.620186e-04</td>\n",
       "      <td>0.561195</td>\n",
       "      <td>2.756317</td>\n",
       "      <td>35.993256</td>\n",
       "      <td>128.003708</td>\n",
       "      <td>207.991394</td>\n",
       "      <td>5225.451660</td>\n",
       "      <td>tensor(7.7590, device='cuda:0')</td>\n",
       "      <td>tensor(0.1619, device='cuda:0')</td>\n",
       "      <td>tensor(17626.8984, device='cuda:0')</td>\n",
       "      <td>tensor(1101.2554, device='cuda:0')</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>1.345080e-04</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>6.055955e-04</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>61.929295</td>\n",
       "      <td>229450.031250</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>1.733290e-06</td>\n",
       "      <td>-2.156630e-01</td>\n",
       "      <td>1.733290e+06</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>59.885452</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3705.032227</td>\n",
       "      <td>51236.792969</td>\n",
       "      <td>1.124501e+11</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>42.024529</td>\n",
       "      <td>3.742337e-06</td>\n",
       "      <td>0.476196</td>\n",
       "      <td>2.484131</td>\n",
       "      <td>28.022461</td>\n",
       "      <td>127.988831</td>\n",
       "      <td>192.015442</td>\n",
       "      <td>3704.261963</td>\n",
       "      <td>tensor(42.5599, device='cuda:0')</td>\n",
       "      <td>tensor(0.3218, device='cuda:0')</td>\n",
       "      <td>tensor(122437.1953, device='cuda:0')</td>\n",
       "      <td>tensor(1090.6274, device='cuda:0')</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>5.235159e-04</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>6.713955e-05</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.404636</td>\n",
       "      <td>237881.484375</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-1.802183e-06</td>\n",
       "      <td>-1.224682e-02</td>\n",
       "      <td>-1.802183e+06</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>62.086426</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>5126.244629</td>\n",
       "      <td>56260.359375</td>\n",
       "      <td>2.159755e+10</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>448.051270</td>\n",
       "      <td>45.346439</td>\n",
       "      <td>-1.868989e-04</td>\n",
       "      <td>0.569519</td>\n",
       "      <td>2.988403</td>\n",
       "      <td>32.010132</td>\n",
       "      <td>127.996765</td>\n",
       "      <td>192.007874</td>\n",
       "      <td>5125.369141</td>\n",
       "      <td>tensor(3.8526, device='cuda:0')</td>\n",
       "      <td>tensor(0.3003, device='cuda:0')</td>\n",
       "      <td>tensor(18192.6016, device='cuda:0')</td>\n",
       "      <td>tensor(1252.9811, device='cuda:0')</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>1.100783e-04</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>1.756690e-04</td>\n",
       "      <td>0.021686</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.397686</td>\n",
       "      <td>185549.109375</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-7.090073e-06</td>\n",
       "      <td>3.424453e-02</td>\n",
       "      <td>-2.070425e-04</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>91.316360</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>3610.067383</td>\n",
       "      <td>40893.218750</td>\n",
       "      <td>1.385939e+10</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>448.090820</td>\n",
       "      <td>67.768341</td>\n",
       "      <td>3.919393e-04</td>\n",
       "      <td>0.680461</td>\n",
       "      <td>3.486267</td>\n",
       "      <td>51.973633</td>\n",
       "      <td>191.995636</td>\n",
       "      <td>256.010437</td>\n",
       "      <td>3609.004150</td>\n",
       "      <td>tensor(8.9584, device='cuda:0')</td>\n",
       "      <td>tensor(0.3000, device='cuda:0')</td>\n",
       "      <td>tensor(14206.6006, device='cuda:0')</td>\n",
       "      <td>tensor(1083.7571, device='cuda:0')</td>\n",
       "      <td>0.033890</td>\n",
       "      <td>6.738935e-04</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>2.472647e-05</td>\n",
       "      <td>0.040639</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>67.362633</td>\n",
       "      <td>352155.875000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-1.075843e-05</td>\n",
       "      <td>1.588381e-02</td>\n",
       "      <td>-6.773203e-04</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>106.130531</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>5227.763184</td>\n",
       "      <td>101440.617188</td>\n",
       "      <td>4.143087e+11</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>84.165985</td>\n",
       "      <td>-8.860804e-05</td>\n",
       "      <td>1.282471</td>\n",
       "      <td>6.501228</td>\n",
       "      <td>71.991333</td>\n",
       "      <td>208.005585</td>\n",
       "      <td>287.988403</td>\n",
       "      <td>5227.149414</td>\n",
       "      <td>tensor(8.8887, device='cuda:0')</td>\n",
       "      <td>tensor(0.0258, device='cuda:0')</td>\n",
       "      <td>tensor(32481.4766, device='cuda:0')</td>\n",
       "      <td>tensor(350.3239, device='cuda:0')</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>3.983682e-04</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>9.850290e-05</td>\n",
       "      <td>0.025529</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>60.068474</td>\n",
       "      <td>37.407093</td>\n",
       "      <td>1.605804</td>\n",
       "      <td>-2.001737e-04</td>\n",
       "      <td>1.250116e-05</td>\n",
       "      <td>-1.601241e+01</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>1.605788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009123</td>\n",
       "      <td>1.182865</td>\n",
       "      <td>6.967912</td>\n",
       "      <td>2.037659e+06</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>0.783661</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>-8.587734e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.102905</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.377728</td>\n",
       "      <td>tensor(34.5209, device='cuda:0')</td>\n",
       "      <td>tensor(1.6631, device='cuda:0')</td>\n",
       "      <td>tensor(21.5754, device='cuda:0')</td>\n",
       "      <td>tensor(0.5796, device='cuda:0')</td>\n",
       "      <td>0.056543</td>\n",
       "      <td>1.236015e-04</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>1.455596e-05</td>\n",
       "      <td>0.063082</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.927448</td>\n",
       "      <td>254102.531250</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.557896e-06</td>\n",
       "      <td>-5.352998e-03</td>\n",
       "      <td>2.557896e+06</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>66.320076</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>5532.694336</td>\n",
       "      <td>70815.179688</td>\n",
       "      <td>1.963414e+11</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>448.044189</td>\n",
       "      <td>48.983410</td>\n",
       "      <td>1.331191e-04</td>\n",
       "      <td>0.573914</td>\n",
       "      <td>2.993988</td>\n",
       "      <td>36.006317</td>\n",
       "      <td>143.959229</td>\n",
       "      <td>207.990845</td>\n",
       "      <td>5531.844727</td>\n",
       "      <td>tensor(7.1540, device='cuda:0')</td>\n",
       "      <td>tensor(0.2712, device='cuda:0')</td>\n",
       "      <td>tensor(22022.6387, device='cuda:0')</td>\n",
       "      <td>tensor(1115.9261, device='cuda:0')</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>4.795391e-05</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>1.886502e-04</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>60.150677</td>\n",
       "      <td>223982.171875</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-5.872026e-06</td>\n",
       "      <td>-2.892585e-01</td>\n",
       "      <td>-5.872026e+06</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>58.458031</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>3723.685547</td>\n",
       "      <td>53367.753906</td>\n",
       "      <td>3.515880e+10</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>40.885448</td>\n",
       "      <td>-1.275543e-04</td>\n",
       "      <td>0.458862</td>\n",
       "      <td>2.255890</td>\n",
       "      <td>27.998032</td>\n",
       "      <td>120.027466</td>\n",
       "      <td>192.003601</td>\n",
       "      <td>3722.689941</td>\n",
       "      <td>tensor(40.0021, device='cuda:0')</td>\n",
       "      <td>tensor(0.3187, device='cuda:0')</td>\n",
       "      <td>tensor(108499.3672, device='cuda:0')</td>\n",
       "      <td>tensor(1099.7976, device='cuda:0')</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>1.938065e-04</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>2.137514e-06</td>\n",
       "      <td>0.022722</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.011257</td>\n",
       "      <td>229948.515625</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>3.839652e-06</td>\n",
       "      <td>-7.054937e-03</td>\n",
       "      <td>3.839652e+06</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>60.015942</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>5108.688965</td>\n",
       "      <td>57816.910156</td>\n",
       "      <td>2.237378e+10</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>448.062988</td>\n",
       "      <td>43.369343</td>\n",
       "      <td>-7.604867e-05</td>\n",
       "      <td>0.546936</td>\n",
       "      <td>2.742432</td>\n",
       "      <td>31.986145</td>\n",
       "      <td>127.987976</td>\n",
       "      <td>191.999283</td>\n",
       "      <td>5107.795410</td>\n",
       "      <td>tensor(4.1000, device='cuda:0')</td>\n",
       "      <td>tensor(0.2955, device='cuda:0')</td>\n",
       "      <td>tensor(18150.1934, device='cuda:0')</td>\n",
       "      <td>tensor(1265.5392, device='cuda:0')</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>1.016326e-04</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>7.439352e-05</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.090969</td>\n",
       "      <td>176628.812500</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-9.493078e-06</td>\n",
       "      <td>3.381686e-02</td>\n",
       "      <td>-2.807202e-04</td>\n",
       "      <td>0.026128</td>\n",
       "      <td>86.926315</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>3326.908203</td>\n",
       "      <td>34240.996094</td>\n",
       "      <td>1.275805e+10</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>448.092773</td>\n",
       "      <td>63.937683</td>\n",
       "      <td>5.589550e-04</td>\n",
       "      <td>0.666138</td>\n",
       "      <td>3.280273</td>\n",
       "      <td>47.973511</td>\n",
       "      <td>176.037109</td>\n",
       "      <td>255.991211</td>\n",
       "      <td>3325.903809</td>\n",
       "      <td>tensor(9.0232, device='cuda:0')</td>\n",
       "      <td>tensor(0.3400, device='cuda:0')</td>\n",
       "      <td>tensor(13768.9824, device='cuda:0')</td>\n",
       "      <td>tensor(681.5680, device='cuda:0')</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>9.789478e-06</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>8.082546e-05</td>\n",
       "      <td>0.040950</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>75.970032</td>\n",
       "      <td>351171.062500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-8.975815e-06</td>\n",
       "      <td>9.288421e-02</td>\n",
       "      <td>-9.663446e-05</td>\n",
       "      <td>0.022895</td>\n",
       "      <td>105.833694</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>4622.494629</td>\n",
       "      <td>47613.683594</td>\n",
       "      <td>1.869918e+10</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>83.853996</td>\n",
       "      <td>2.126476e-04</td>\n",
       "      <td>1.277466</td>\n",
       "      <td>6.499177</td>\n",
       "      <td>71.986572</td>\n",
       "      <td>208.004944</td>\n",
       "      <td>287.985779</td>\n",
       "      <td>4621.634277</td>\n",
       "      <td>tensor(9.7990, device='cuda:0')</td>\n",
       "      <td>tensor(0.0232, device='cuda:0')</td>\n",
       "      <td>tensor(37914.6758, device='cuda:0')</td>\n",
       "      <td>tensor(326.1928, device='cuda:0')</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>2.266864e-04</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>1.312394e-04</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>58.858749</td>\n",
       "      <td>37.209473</td>\n",
       "      <td>1.581822</td>\n",
       "      <td>-2.069383e-04</td>\n",
       "      <td>-1.533429e-05</td>\n",
       "      <td>-2.069384e+08</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>1.581804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>1.186325</td>\n",
       "      <td>6.157388</td>\n",
       "      <td>8.881391e+05</td>\n",
       "      <td>-0.006102</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>-5.414727e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>0.368356</td>\n",
       "      <td>tensor(34.1422, device='cuda:0')</td>\n",
       "      <td>tensor(1.4320, device='cuda:0')</td>\n",
       "      <td>tensor(21.7181, device='cuda:0')</td>\n",
       "      <td>tensor(0.5242, device='cuda:0')</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>8.696014e-04</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>1.375237e-04</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.812443</td>\n",
       "      <td>263204.593750</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>4.622842e-06</td>\n",
       "      <td>1.639827e-02</td>\n",
       "      <td>2.819104e-04</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>68.695694</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>6007.531250</td>\n",
       "      <td>66962.312500</td>\n",
       "      <td>7.186351e+10</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>448.048828</td>\n",
       "      <td>51.221184</td>\n",
       "      <td>1.382830e-05</td>\n",
       "      <td>0.623573</td>\n",
       "      <td>3.222900</td>\n",
       "      <td>39.994354</td>\n",
       "      <td>143.994781</td>\n",
       "      <td>207.997833</td>\n",
       "      <td>6006.755371</td>\n",
       "      <td>tensor(7.7261, device='cuda:0')</td>\n",
       "      <td>tensor(0.2662, device='cuda:0')</td>\n",
       "      <td>tensor(21057.7773, device='cuda:0')</td>\n",
       "      <td>tensor(1094.6136, device='cuda:0')</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>1.458897e-04</td>\n",
       "      <td>0.018369</td>\n",
       "      <td>2.088620e-04</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.144016</td>\n",
       "      <td>209996.078125</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-5.015406e-06</td>\n",
       "      <td>-3.113505e-01</td>\n",
       "      <td>-5.015406e+06</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>54.807526</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>3740.311035</td>\n",
       "      <td>50413.109375</td>\n",
       "      <td>1.537778e+11</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>37.953381</td>\n",
       "      <td>1.617814e-04</td>\n",
       "      <td>0.422852</td>\n",
       "      <td>2.031128</td>\n",
       "      <td>25.992981</td>\n",
       "      <td>119.971191</td>\n",
       "      <td>191.924805</td>\n",
       "      <td>3739.360107</td>\n",
       "      <td>tensor(33.1355, device='cuda:0')</td>\n",
       "      <td>tensor(0.3207, device='cuda:0')</td>\n",
       "      <td>tensor(97272.2812, device='cuda:0')</td>\n",
       "      <td>tensor(859.8816, device='cuda:0')</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>2.934152e-04</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>2.580496e-05</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.932861</td>\n",
       "      <td>230937.734375</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-3.569238e-07</td>\n",
       "      <td>-2.094859e-02</td>\n",
       "      <td>-3.569238e+05</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>60.274117</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>5379.043457</td>\n",
       "      <td>59902.082031</td>\n",
       "      <td>2.411210e+10</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>43.627922</td>\n",
       "      <td>1.329182e-04</td>\n",
       "      <td>0.550537</td>\n",
       "      <td>2.745544</td>\n",
       "      <td>31.989929</td>\n",
       "      <td>127.991577</td>\n",
       "      <td>191.999146</td>\n",
       "      <td>5378.153320</td>\n",
       "      <td>tensor(4.0144, device='cuda:0')</td>\n",
       "      <td>tensor(0.2964, device='cuda:0')</td>\n",
       "      <td>tensor(19661.4785, device='cuda:0')</td>\n",
       "      <td>tensor(1283.7434, device='cuda:0')</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>4.725865e-04</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>4.861219e-05</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.336922</td>\n",
       "      <td>166856.593750</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-3.956973e-06</td>\n",
       "      <td>5.946008e-02</td>\n",
       "      <td>-6.654839e-05</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>82.116997</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>3188.125244</td>\n",
       "      <td>26756.935547</td>\n",
       "      <td>2.177730e+09</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>60.438431</td>\n",
       "      <td>-9.862677e-04</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>3.271606</td>\n",
       "      <td>44.004913</td>\n",
       "      <td>175.987488</td>\n",
       "      <td>240.024902</td>\n",
       "      <td>3187.085205</td>\n",
       "      <td>tensor(8.6951, device='cuda:0')</td>\n",
       "      <td>tensor(0.2638, device='cuda:0')</td>\n",
       "      <td>tensor(16902.2070, device='cuda:0')</td>\n",
       "      <td>tensor(914.3749, device='cuda:0')</td>\n",
       "      <td>0.033887</td>\n",
       "      <td>1.048039e-04</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>4.796919e-08</td>\n",
       "      <td>0.040652</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.086006</td>\n",
       "      <td>349273.781250</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-7.950891e-06</td>\n",
       "      <td>1.419720e-02</td>\n",
       "      <td>-5.600323e-04</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>105.261940</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>4845.236816</td>\n",
       "      <td>73109.187500</td>\n",
       "      <td>2.407690e+11</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>448.098633</td>\n",
       "      <td>83.337296</td>\n",
       "      <td>4.009024e-04</td>\n",
       "      <td>1.265503</td>\n",
       "      <td>6.492493</td>\n",
       "      <td>71.983154</td>\n",
       "      <td>208.001678</td>\n",
       "      <td>287.985107</td>\n",
       "      <td>4844.363770</td>\n",
       "      <td>tensor(9.5217, device='cuda:0')</td>\n",
       "      <td>tensor(0.0202, device='cuda:0')</td>\n",
       "      <td>tensor(33030.1836, device='cuda:0')</td>\n",
       "      <td>tensor(336.4664, device='cuda:0')</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>1.179662e-04</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>3.701523e-04</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>58.200573</td>\n",
       "      <td>37.173981</td>\n",
       "      <td>1.565627</td>\n",
       "      <td>-2.780234e-04</td>\n",
       "      <td>4.305819e-05</td>\n",
       "      <td>-6.456923e+00</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>1.565596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>1.189681</td>\n",
       "      <td>28.079277</td>\n",
       "      <td>3.535601e+07</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.514099</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>-4.877809e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.033279</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.137451</td>\n",
       "      <td>0.362165</td>\n",
       "      <td>tensor(33.0655, device='cuda:0')</td>\n",
       "      <td>tensor(1.2455, device='cuda:0')</td>\n",
       "      <td>tensor(21.8570, device='cuda:0')</td>\n",
       "      <td>tensor(0.8358, device='cuda:0')</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>7.401875e-04</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>6.787359e-05</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.615864</td>\n",
       "      <td>265324.500000</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-2.007923e-06</td>\n",
       "      <td>-1.622766e-02</td>\n",
       "      <td>-2.007923e+06</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>69.248978</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>5816.496094</td>\n",
       "      <td>71131.429688</td>\n",
       "      <td>1.434146e+11</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>448.053711</td>\n",
       "      <td>51.775349</td>\n",
       "      <td>2.043054e-04</td>\n",
       "      <td>0.626462</td>\n",
       "      <td>3.240356</td>\n",
       "      <td>39.998238</td>\n",
       "      <td>143.996628</td>\n",
       "      <td>207.998383</td>\n",
       "      <td>5815.586914</td>\n",
       "      <td>tensor(7.2302, device='cuda:0')</td>\n",
       "      <td>tensor(0.2594, device='cuda:0')</td>\n",
       "      <td>tensor(22312.5020, device='cuda:0')</td>\n",
       "      <td>tensor(1257.2622, device='cuda:0')</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>3.501372e-04</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>7.452597e-05</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.633945</td>\n",
       "      <td>216835.828125</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-5.254829e-06</td>\n",
       "      <td>-3.287365e-01</td>\n",
       "      <td>-5.254830e+06</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>56.592617</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>3828.726318</td>\n",
       "      <td>46579.980469</td>\n",
       "      <td>6.077703e+10</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>448.072266</td>\n",
       "      <td>39.595421</td>\n",
       "      <td>9.823422e-05</td>\n",
       "      <td>0.442596</td>\n",
       "      <td>2.246964</td>\n",
       "      <td>26.025879</td>\n",
       "      <td>120.000984</td>\n",
       "      <td>191.988953</td>\n",
       "      <td>3827.705811</td>\n",
       "      <td>tensor(33.1488, device='cuda:0')</td>\n",
       "      <td>tensor(0.3260, device='cuda:0')</td>\n",
       "      <td>tensor(92865.7578, device='cuda:0')</td>\n",
       "      <td>tensor(908.4090, device='cuda:0')</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>7.254230e-05</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>7.073116e-05</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.797127</td>\n",
       "      <td>242268.687500</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.348566e-06</td>\n",
       "      <td>-2.978748e-03</td>\n",
       "      <td>1.348566e+06</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>63.231472</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>5408.130371</td>\n",
       "      <td>53408.792969</td>\n",
       "      <td>3.133323e+10</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>448.043457</td>\n",
       "      <td>45.956284</td>\n",
       "      <td>-3.414328e-04</td>\n",
       "      <td>0.564034</td>\n",
       "      <td>2.760315</td>\n",
       "      <td>32.007812</td>\n",
       "      <td>128.006714</td>\n",
       "      <td>192.013916</td>\n",
       "      <td>5407.208984</td>\n",
       "      <td>tensor(4.4266, device='cuda:0')</td>\n",
       "      <td>tensor(0.2900, device='cuda:0')</td>\n",
       "      <td>tensor(20410.8105, device='cuda:0')</td>\n",
       "      <td>tensor(1364.3462, device='cuda:0')</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>1.122044e-05</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>1.972930e-05</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.520401</td>\n",
       "      <td>177910.296875</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>1.296716e-05</td>\n",
       "      <td>-2.945281e-03</td>\n",
       "      <td>1.296716e+07</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>87.556984</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>3453.199951</td>\n",
       "      <td>38679.003906</td>\n",
       "      <td>2.466853e+10</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>448.123047</td>\n",
       "      <td>64.604950</td>\n",
       "      <td>7.026309e-04</td>\n",
       "      <td>0.673584</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>47.991333</td>\n",
       "      <td>176.046631</td>\n",
       "      <td>255.992615</td>\n",
       "      <td>3452.196289</td>\n",
       "      <td>tensor(8.3758, device='cuda:0')</td>\n",
       "      <td>tensor(0.3543, device='cuda:0')</td>\n",
       "      <td>tensor(15081.3223, device='cuda:0')</td>\n",
       "      <td>tensor(730.5581, device='cuda:0')</td>\n",
       "      <td>0.037116</td>\n",
       "      <td>2.482850e-04</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>4.530067e-05</td>\n",
       "      <td>0.041162</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>69.948273</td>\n",
       "      <td>347354.000000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>8.303167e-08</td>\n",
       "      <td>5.813380e-03</td>\n",
       "      <td>1.428286e-05</td>\n",
       "      <td>0.021081</td>\n",
       "      <td>104.683365</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>4965.869629</td>\n",
       "      <td>79836.742188</td>\n",
       "      <td>2.945120e+11</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>82.751930</td>\n",
       "      <td>-9.464523e-05</td>\n",
       "      <td>1.259033</td>\n",
       "      <td>6.485718</td>\n",
       "      <td>71.975708</td>\n",
       "      <td>207.999298</td>\n",
       "      <td>287.983643</td>\n",
       "      <td>4965.174805</td>\n",
       "      <td>tensor(9.8549, device='cuda:0')</td>\n",
       "      <td>tensor(0.0190, device='cuda:0')</td>\n",
       "      <td>tensor(36330.3047, device='cuda:0')</td>\n",
       "      <td>tensor(542.9551, device='cuda:0')</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>5.231717e-04</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>8.569611e-05</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>57.779716</td>\n",
       "      <td>36.448174</td>\n",
       "      <td>1.585257</td>\n",
       "      <td>-1.634033e-04</td>\n",
       "      <td>3.412114e-05</td>\n",
       "      <td>-4.788915e+00</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.026906</td>\n",
       "      <td>1.585246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008816</td>\n",
       "      <td>1.187033</td>\n",
       "      <td>7.955982</td>\n",
       "      <td>2.352456e+06</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>0.039701</td>\n",
       "      <td>-8.011762e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.099243</td>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.369740</td>\n",
       "      <td>tensor(33.8981, device='cuda:0')</td>\n",
       "      <td>tensor(1.3409, device='cuda:0')</td>\n",
       "      <td>tensor(21.7236, device='cuda:0')</td>\n",
       "      <td>tensor(0.5479, device='cuda:0')</td>\n",
       "      <td>0.054753</td>\n",
       "      <td>1.802947e-04</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>2.327667e-04</td>\n",
       "      <td>0.062583</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.154556</td>\n",
       "      <td>284785.656250</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>-2.963604e-06</td>\n",
       "      <td>-3.467131e-03</td>\n",
       "      <td>-2.963604e+06</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>74.328285</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6919.906738</td>\n",
       "      <td>81858.500000</td>\n",
       "      <td>8.457782e+10</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>448.039062</td>\n",
       "      <td>56.084431</td>\n",
       "      <td>1.824292e-04</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>3.493866</td>\n",
       "      <td>43.997589</td>\n",
       "      <td>144.019775</td>\n",
       "      <td>223.986206</td>\n",
       "      <td>6919.095215</td>\n",
       "      <td>tensor(7.0887, device='cuda:0')</td>\n",
       "      <td>tensor(0.2641, device='cuda:0')</td>\n",
       "      <td>tensor(26344.2734, device='cuda:0')</td>\n",
       "      <td>tensor(1134.4048, device='cuda:0')</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>2.241372e-05</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>7.626469e-05</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>49.128021</td>\n",
       "      <td>229124.890625</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-2.033020e-06</td>\n",
       "      <td>-3.252713e-01</td>\n",
       "      <td>-2.033020e+06</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>59.800095</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>4663.833496</td>\n",
       "      <td>55310.933594</td>\n",
       "      <td>9.407586e+10</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>448.057617</td>\n",
       "      <td>42.273369</td>\n",
       "      <td>-6.983956e-04</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>2.267334</td>\n",
       "      <td>29.979492</td>\n",
       "      <td>127.993225</td>\n",
       "      <td>192.003677</td>\n",
       "      <td>4662.889160</td>\n",
       "      <td>tensor(19.3714, device='cuda:0')</td>\n",
       "      <td>tensor(0.3050, device='cuda:0')</td>\n",
       "      <td>tensor(92487.5469, device='cuda:0')</td>\n",
       "      <td>tensor(913.3782, device='cuda:0')</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>1.989583e-05</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>2.860786e-04</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.624657</td>\n",
       "      <td>256067.140625</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.440451e-06</td>\n",
       "      <td>-8.315486e-03</td>\n",
       "      <td>1.440451e+06</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>66.832832</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>6303.244629</td>\n",
       "      <td>61047.878906</td>\n",
       "      <td>5.590737e+10</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>448.044922</td>\n",
       "      <td>48.959206</td>\n",
       "      <td>1.930326e-06</td>\n",
       "      <td>0.617432</td>\n",
       "      <td>3.005371</td>\n",
       "      <td>35.999245</td>\n",
       "      <td>143.993927</td>\n",
       "      <td>207.998749</td>\n",
       "      <td>6302.318359</td>\n",
       "      <td>tensor(3.8445, device='cuda:0')</td>\n",
       "      <td>tensor(0.2880, device='cuda:0')</td>\n",
       "      <td>tensor(20570.0273, device='cuda:0')</td>\n",
       "      <td>tensor(1336.8438, device='cuda:0')</td>\n",
       "      <td>0.017752</td>\n",
       "      <td>3.539885e-05</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>3.778445e-06</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.640358</td>\n",
       "      <td>164400.296875</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2.422474e-05</td>\n",
       "      <td>-2.134536e-02</td>\n",
       "      <td>2.422474e+07</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>80.908165</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>3311.828369</td>\n",
       "      <td>30653.859375</td>\n",
       "      <td>2.627510e+09</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>59.762985</td>\n",
       "      <td>-7.713508e-04</td>\n",
       "      <td>0.665161</td>\n",
       "      <td>3.274902</td>\n",
       "      <td>44.002380</td>\n",
       "      <td>175.961182</td>\n",
       "      <td>240.003448</td>\n",
       "      <td>3310.805420</td>\n",
       "      <td>tensor(8.8982, device='cuda:0')</td>\n",
       "      <td>tensor(0.2005, device='cuda:0')</td>\n",
       "      <td>tensor(16094.1943, device='cuda:0')</td>\n",
       "      <td>tensor(734.1368, device='cuda:0')</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>5.572631e-04</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>2.131149e-04</td>\n",
       "      <td>0.041204</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>68.983093</td>\n",
       "      <td>331264.437500</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>6.848127e-06</td>\n",
       "      <td>-1.303290e-02</td>\n",
       "      <td>6.848127e+06</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>99.834404</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>4802.110352</td>\n",
       "      <td>50730.894531</td>\n",
       "      <td>2.482768e+10</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>448.082520</td>\n",
       "      <td>78.443085</td>\n",
       "      <td>2.769766e-04</td>\n",
       "      <td>1.207520</td>\n",
       "      <td>5.993988</td>\n",
       "      <td>63.997574</td>\n",
       "      <td>192.032715</td>\n",
       "      <td>256.023438</td>\n",
       "      <td>4801.417480</td>\n",
       "      <td>tensor(9.1859, device='cuda:0')</td>\n",
       "      <td>tensor(0.0265, device='cuda:0')</td>\n",
       "      <td>tensor(37772.8008, device='cuda:0')</td>\n",
       "      <td>tensor(512.9623, device='cuda:0')</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>2.082170e-04</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>4.899863e-04</td>\n",
       "      <td>0.025476</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>57.039749</td>\n",
       "      <td>35.363419</td>\n",
       "      <td>1.612959</td>\n",
       "      <td>-1.894469e-04</td>\n",
       "      <td>-1.777002e-05</td>\n",
       "      <td>-1.894469e+08</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.026106</td>\n",
       "      <td>1.612943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006990</td>\n",
       "      <td>1.180271</td>\n",
       "      <td>6.859995</td>\n",
       "      <td>1.125183e+06</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.039013</td>\n",
       "      <td>-6.854678e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.097412</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.380730</td>\n",
       "      <td>tensor(32.8058, device='cuda:0')</td>\n",
       "      <td>tensor(1.4807, device='cuda:0')</td>\n",
       "      <td>tensor(20.9985, device='cuda:0')</td>\n",
       "      <td>tensor(0.7559, device='cuda:0')</td>\n",
       "      <td>0.061572</td>\n",
       "      <td>6.797977e-04</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>7.364851e-06</td>\n",
       "      <td>0.061732</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.880848</td>\n",
       "      <td>282893.593750</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>2.965367e-06</td>\n",
       "      <td>3.939144e-02</td>\n",
       "      <td>7.527947e-05</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>73.834450</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>5908.282715</td>\n",
       "      <td>86174.664062</td>\n",
       "      <td>1.115447e+11</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>55.759281</td>\n",
       "      <td>4.105823e-04</td>\n",
       "      <td>0.684433</td>\n",
       "      <td>3.492798</td>\n",
       "      <td>43.996429</td>\n",
       "      <td>144.014587</td>\n",
       "      <td>223.977173</td>\n",
       "      <td>5907.347168</td>\n",
       "      <td>tensor(6.9771, device='cuda:0')</td>\n",
       "      <td>tensor(0.2654, device='cuda:0')</td>\n",
       "      <td>tensor(24798.3457, device='cuda:0')</td>\n",
       "      <td>tensor(1460.1954, device='cuda:0')</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>1.012004e-04</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>1.879230e-04</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.813526</td>\n",
       "      <td>212324.312500</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1.570648e-07</td>\n",
       "      <td>-2.391088e-01</td>\n",
       "      <td>1.570648e+05</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>55.415562</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>3737.214844</td>\n",
       "      <td>38064.398438</td>\n",
       "      <td>1.182271e+10</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>448.062500</td>\n",
       "      <td>39.028008</td>\n",
       "      <td>-6.908864e-04</td>\n",
       "      <td>0.451454</td>\n",
       "      <td>2.251640</td>\n",
       "      <td>27.957520</td>\n",
       "      <td>119.983276</td>\n",
       "      <td>176.018311</td>\n",
       "      <td>3736.301514</td>\n",
       "      <td>tensor(32.0362, device='cuda:0')</td>\n",
       "      <td>tensor(0.2799, device='cuda:0')</td>\n",
       "      <td>tensor(92835.1875, device='cuda:0')</td>\n",
       "      <td>tensor(795.9445, device='cuda:0')</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>7.000451e-04</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>6.398346e-06</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.198658</td>\n",
       "      <td>254270.328125</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>2.451872e-06</td>\n",
       "      <td>3.403801e-02</td>\n",
       "      <td>7.203335e-05</td>\n",
       "      <td>0.012058</td>\n",
       "      <td>66.363869</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>5503.847168</td>\n",
       "      <td>55380.269531</td>\n",
       "      <td>4.228891e+10</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>448.041992</td>\n",
       "      <td>48.690922</td>\n",
       "      <td>-1.330027e-04</td>\n",
       "      <td>0.620636</td>\n",
       "      <td>3.010559</td>\n",
       "      <td>35.998871</td>\n",
       "      <td>143.989746</td>\n",
       "      <td>207.995758</td>\n",
       "      <td>5502.916504</td>\n",
       "      <td>tensor(6.1927, device='cuda:0')</td>\n",
       "      <td>tensor(0.2799, device='cuda:0')</td>\n",
       "      <td>tensor(19403.6621, device='cuda:0')</td>\n",
       "      <td>tensor(1267.0066, device='cuda:0')</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>1.961612e-04</td>\n",
       "      <td>0.009489</td>\n",
       "      <td>2.848488e-05</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.230282</td>\n",
       "      <td>180721.046875</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-1.555544e-05</td>\n",
       "      <td>-4.958065e-02</td>\n",
       "      <td>-1.555544e+07</td>\n",
       "      <td>0.025705</td>\n",
       "      <td>88.940269</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>3460.082031</td>\n",
       "      <td>30954.318359</td>\n",
       "      <td>2.614328e+09</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>448.137695</td>\n",
       "      <td>65.849876</td>\n",
       "      <td>-1.032151e-04</td>\n",
       "      <td>0.685664</td>\n",
       "      <td>3.489563</td>\n",
       "      <td>48.012695</td>\n",
       "      <td>191.972290</td>\n",
       "      <td>255.999542</td>\n",
       "      <td>3459.086670</td>\n",
       "      <td>tensor(7.8490, device='cuda:0')</td>\n",
       "      <td>tensor(0.3846, device='cuda:0')</td>\n",
       "      <td>tensor(15609.6777, device='cuda:0')</td>\n",
       "      <td>tensor(884.9722, device='cuda:0')</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>2.988074e-05</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>3.133365e-05</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.279205</td>\n",
       "      <td>351104.250000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>4.962117e-06</td>\n",
       "      <td>1.478509e-02</td>\n",
       "      <td>3.356162e-04</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>105.813599</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>4857.611328</td>\n",
       "      <td>62119.929688</td>\n",
       "      <td>5.023150e+10</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>83.880600</td>\n",
       "      <td>2.170406e-05</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>6.500224</td>\n",
       "      <td>71.988464</td>\n",
       "      <td>208.004089</td>\n",
       "      <td>287.986694</td>\n",
       "      <td>4856.841797</td>\n",
       "      <td>tensor(11.3470, device='cuda:0')</td>\n",
       "      <td>tensor(0.0156, device='cuda:0')</td>\n",
       "      <td>tensor(38582.8047, device='cuda:0')</td>\n",
       "      <td>tensor(606.1862, device='cuda:0')</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>1.169605e-04</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>1.888735e-04</td>\n",
       "      <td>0.025670</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>56.890789</td>\n",
       "      <td>35.420940</td>\n",
       "      <td>1.606134</td>\n",
       "      <td>-2.449994e-04</td>\n",
       "      <td>4.622344e-05</td>\n",
       "      <td>-5.300328e+00</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>1.606110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>1.180957</td>\n",
       "      <td>10.829238</td>\n",
       "      <td>3.797211e+06</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>0.595947</td>\n",
       "      <td>0.038860</td>\n",
       "      <td>-4.465818e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>0.377681</td>\n",
       "      <td>tensor(33.5202, device='cuda:0')</td>\n",
       "      <td>tensor(1.4655, device='cuda:0')</td>\n",
       "      <td>tensor(21.0717, device='cuda:0')</td>\n",
       "      <td>tensor(0.8710, device='cuda:0')</td>\n",
       "      <td>0.058088</td>\n",
       "      <td>1.342546e-03</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>8.502888e-06</td>\n",
       "      <td>0.062384</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.138607</td>\n",
       "      <td>278421.906250</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>6.203331e-06</td>\n",
       "      <td>7.772340e-03</td>\n",
       "      <td>7.981291e-04</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>72.667374</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>5906.451660</td>\n",
       "      <td>72467.890625</td>\n",
       "      <td>8.078044e+10</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>54.839592</td>\n",
       "      <td>-4.564773e-06</td>\n",
       "      <td>0.682007</td>\n",
       "      <td>3.488647</td>\n",
       "      <td>43.990662</td>\n",
       "      <td>144.007568</td>\n",
       "      <td>208.014832</td>\n",
       "      <td>5905.577148</td>\n",
       "      <td>tensor(6.5437, device='cuda:0')</td>\n",
       "      <td>tensor(0.2510, device='cuda:0')</td>\n",
       "      <td>tensor(25753.0391, device='cuda:0')</td>\n",
       "      <td>tensor(1490.7745, device='cuda:0')</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>2.336063e-04</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>9.816625e-05</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>0.021950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.204090</td>\n",
       "      <td>229367.781250</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-9.100067e-06</td>\n",
       "      <td>-3.669771e-01</td>\n",
       "      <td>-9.100068e+06</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>59.863251</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>4231.559082</td>\n",
       "      <td>39594.101562</td>\n",
       "      <td>8.371916e+09</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>448.049805</td>\n",
       "      <td>42.527416</td>\n",
       "      <td>-9.614210e-05</td>\n",
       "      <td>0.483643</td>\n",
       "      <td>2.491272</td>\n",
       "      <td>29.993164</td>\n",
       "      <td>127.991882</td>\n",
       "      <td>192.003510</td>\n",
       "      <td>4230.649414</td>\n",
       "      <td>tensor(25.9776, device='cuda:0')</td>\n",
       "      <td>tensor(0.3056, device='cuda:0')</td>\n",
       "      <td>tensor(94814.4688, device='cuda:0')</td>\n",
       "      <td>tensor(915.3406, device='cuda:0')</td>\n",
       "      <td>0.023896</td>\n",
       "      <td>1.576220e-04</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>1.726403e-05</td>\n",
       "      <td>0.023023</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.840836</td>\n",
       "      <td>256352.265625</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.288569e-06</td>\n",
       "      <td>-1.102681e-02</td>\n",
       "      <td>-3.288569e+06</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>66.907257</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>5592.225098</td>\n",
       "      <td>69093.937500</td>\n",
       "      <td>8.365849e+10</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>49.193718</td>\n",
       "      <td>-8.202424e-05</td>\n",
       "      <td>0.624697</td>\n",
       "      <td>3.223511</td>\n",
       "      <td>36.002594</td>\n",
       "      <td>143.991821</td>\n",
       "      <td>207.997772</td>\n",
       "      <td>5591.329590</td>\n",
       "      <td>tensor(4.6236, device='cuda:0')</td>\n",
       "      <td>tensor(0.2892, device='cuda:0')</td>\n",
       "      <td>tensor(20008.4414, device='cuda:0')</td>\n",
       "      <td>tensor(1421.3143, device='cuda:0')</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>3.429909e-04</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>8.180193e-05</td>\n",
       "      <td>0.022352</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.593529</td>\n",
       "      <td>186104.609375</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-1.703942e-07</td>\n",
       "      <td>4.032629e-03</td>\n",
       "      <td>-4.225387e-05</td>\n",
       "      <td>0.025883</td>\n",
       "      <td>91.589745</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>3538.546143</td>\n",
       "      <td>32983.320312</td>\n",
       "      <td>7.362801e+09</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>448.108398</td>\n",
       "      <td>68.122375</td>\n",
       "      <td>-1.174289e-04</td>\n",
       "      <td>0.719971</td>\n",
       "      <td>3.526123</td>\n",
       "      <td>51.981445</td>\n",
       "      <td>191.997528</td>\n",
       "      <td>256.011292</td>\n",
       "      <td>3537.553711</td>\n",
       "      <td>tensor(8.9488, device='cuda:0')</td>\n",
       "      <td>tensor(0.3111, device='cuda:0')</td>\n",
       "      <td>tensor(17005.9180, device='cuda:0')</td>\n",
       "      <td>tensor(825.5083, device='cuda:0')</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.612856e-04</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>1.171612e-05</td>\n",
       "      <td>0.041057</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>79.557137</td>\n",
       "      <td>344495.843750</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>4.319254e-07</td>\n",
       "      <td>3.405518e-02</td>\n",
       "      <td>1.268310e-05</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>103.821999</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>4330.169434</td>\n",
       "      <td>69587.335938</td>\n",
       "      <td>2.209064e+11</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>448.072266</td>\n",
       "      <td>82.181435</td>\n",
       "      <td>-1.277678e-04</td>\n",
       "      <td>1.263855</td>\n",
       "      <td>6.480957</td>\n",
       "      <td>71.966553</td>\n",
       "      <td>207.990601</td>\n",
       "      <td>287.968018</td>\n",
       "      <td>4329.193359</td>\n",
       "      <td>tensor(10.5468, device='cuda:0')</td>\n",
       "      <td>tensor(0.0298, device='cuda:0')</td>\n",
       "      <td>tensor(39697.4688, device='cuda:0')</td>\n",
       "      <td>tensor(515.2435, device='cuda:0')</td>\n",
       "      <td>0.020079</td>\n",
       "      <td>7.954473e-05</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>1.686784e-05</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>56.199585</td>\n",
       "      <td>35.525330</td>\n",
       "      <td>1.581958</td>\n",
       "      <td>-1.777210e-04</td>\n",
       "      <td>-7.934801e-05</td>\n",
       "      <td>-1.777210e+08</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>1.581951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>1.185189</td>\n",
       "      <td>6.934441</td>\n",
       "      <td>7.369352e+05</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.479492</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>-3.889156e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>0.368324</td>\n",
       "      <td>tensor(33.2472, device='cuda:0')</td>\n",
       "      <td>tensor(1.4521, device='cuda:0')</td>\n",
       "      <td>tensor(21.4225, device='cuda:0')</td>\n",
       "      <td>tensor(0.6377, device='cuda:0')</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>1.779902e-04</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>3.891367e-05</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.984955</td>\n",
       "      <td>279280.562500</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-2.315411e-06</td>\n",
       "      <td>5.455615e-03</td>\n",
       "      <td>-4.244088e-04</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>72.891472</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>5944.042480</td>\n",
       "      <td>60451.601562</td>\n",
       "      <td>4.606892e+10</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>448.071289</td>\n",
       "      <td>54.965805</td>\n",
       "      <td>-1.055490e-04</td>\n",
       "      <td>0.668457</td>\n",
       "      <td>3.262573</td>\n",
       "      <td>43.989807</td>\n",
       "      <td>144.009399</td>\n",
       "      <td>208.012390</td>\n",
       "      <td>5943.116699</td>\n",
       "      <td>tensor(6.9730, device='cuda:0')</td>\n",
       "      <td>tensor(0.1612, device='cuda:0')</td>\n",
       "      <td>tensor(22748.5547, device='cuda:0')</td>\n",
       "      <td>tensor(1350.3138, device='cuda:0')</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>6.554968e-05</td>\n",
       "      <td>0.016692</td>\n",
       "      <td>1.957595e-06</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.022129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.816029</td>\n",
       "      <td>222334.625000</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.553173e-05</td>\n",
       "      <td>-2.199446e-01</td>\n",
       "      <td>1.553173e+07</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>58.028320</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>3983.347656</td>\n",
       "      <td>41168.976562</td>\n",
       "      <td>2.860001e+10</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>41.206360</td>\n",
       "      <td>-2.697963e-04</td>\n",
       "      <td>0.479248</td>\n",
       "      <td>2.485840</td>\n",
       "      <td>28.020142</td>\n",
       "      <td>120.012390</td>\n",
       "      <td>191.995361</td>\n",
       "      <td>3982.486084</td>\n",
       "      <td>tensor(25.8032, device='cuda:0')</td>\n",
       "      <td>tensor(0.3102, device='cuda:0')</td>\n",
       "      <td>tensor(75260.8750, device='cuda:0')</td>\n",
       "      <td>tensor(983.3224, device='cuda:0')</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>4.780053e-04</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>1.693933e-04</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.959114</td>\n",
       "      <td>253979.453125</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-3.223807e-06</td>\n",
       "      <td>-4.895579e-03</td>\n",
       "      <td>-3.223807e+06</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>66.287956</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>5526.204590</td>\n",
       "      <td>81316.234375</td>\n",
       "      <td>1.393747e+11</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>448.040283</td>\n",
       "      <td>48.643196</td>\n",
       "      <td>5.542580e-06</td>\n",
       "      <td>0.612976</td>\n",
       "      <td>3.004028</td>\n",
       "      <td>35.998398</td>\n",
       "      <td>143.988342</td>\n",
       "      <td>207.992432</td>\n",
       "      <td>5525.297363</td>\n",
       "      <td>tensor(4.9741, device='cuda:0')</td>\n",
       "      <td>tensor(0.2806, device='cuda:0')</td>\n",
       "      <td>tensor(20831.9355, device='cuda:0')</td>\n",
       "      <td>tensor(1428.4304, device='cuda:0')</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>3.790357e-04</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>4.092219e-05</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.171612</td>\n",
       "      <td>186653.390625</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>-2.392116e-06</td>\n",
       "      <td>4.066739e-02</td>\n",
       "      <td>-5.882148e-05</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>91.859833</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>3956.901123</td>\n",
       "      <td>38724.601562</td>\n",
       "      <td>1.120426e+10</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>448.106934</td>\n",
       "      <td>68.162651</td>\n",
       "      <td>1.360824e-04</td>\n",
       "      <td>0.721802</td>\n",
       "      <td>3.668144</td>\n",
       "      <td>51.974609</td>\n",
       "      <td>192.001785</td>\n",
       "      <td>256.014282</td>\n",
       "      <td>3955.901123</td>\n",
       "      <td>tensor(8.3059, device='cuda:0')</td>\n",
       "      <td>tensor(0.3105, device='cuda:0')</td>\n",
       "      <td>tensor(16569.9727, device='cuda:0')</td>\n",
       "      <td>tensor(844.2772, device='cuda:0')</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>4.317692e-04</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>3.053472e-05</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>70.334183</td>\n",
       "      <td>347517.656250</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-3.602708e-06</td>\n",
       "      <td>-6.330750e-03</td>\n",
       "      <td>-3.602708e+06</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>104.732697</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>4940.950195</td>\n",
       "      <td>52958.476562</td>\n",
       "      <td>2.783574e+10</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>448.076172</td>\n",
       "      <td>82.906509</td>\n",
       "      <td>-6.393679e-05</td>\n",
       "      <td>1.258545</td>\n",
       "      <td>6.489685</td>\n",
       "      <td>71.979492</td>\n",
       "      <td>207.998367</td>\n",
       "      <td>287.980591</td>\n",
       "      <td>4940.126465</td>\n",
       "      <td>tensor(9.8437, device='cuda:0')</td>\n",
       "      <td>tensor(0.0248, device='cuda:0')</td>\n",
       "      <td>tensor(40878.7461, device='cuda:0')</td>\n",
       "      <td>tensor(328.3351, device='cuda:0')</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>6.041315e-04</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>9.956510e-05</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>54.366833</td>\n",
       "      <td>34.047428</td>\n",
       "      <td>1.596797</td>\n",
       "      <td>-1.708427e-04</td>\n",
       "      <td>-7.752867e-05</td>\n",
       "      <td>-1.708427e+08</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>1.596790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>1.182130</td>\n",
       "      <td>8.236053</td>\n",
       "      <td>3.431704e+06</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>0.486572</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>-3.039527e-03</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.375026</td>\n",
       "      <td>tensor(31.9272, device='cuda:0')</td>\n",
       "      <td>tensor(1.3381, device='cuda:0')</td>\n",
       "      <td>tensor(20.8508, device='cuda:0')</td>\n",
       "      <td>tensor(0.5326, device='cuda:0')</td>\n",
       "      <td>0.057099</td>\n",
       "      <td>1.674190e-03</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>6.675431e-05</td>\n",
       "      <td>0.063660</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.985538</td>\n",
       "      <td>274074.875000</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>5.314093e-07</td>\n",
       "      <td>8.933453e-03</td>\n",
       "      <td>5.948532e-05</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>71.532806</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5960.023926</td>\n",
       "      <td>76537.062500</td>\n",
       "      <td>1.891633e+11</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>53.644447</td>\n",
       "      <td>-1.450413e-05</td>\n",
       "      <td>0.628754</td>\n",
       "      <td>3.246826</td>\n",
       "      <td>40.012817</td>\n",
       "      <td>144.003555</td>\n",
       "      <td>208.011047</td>\n",
       "      <td>5959.095215</td>\n",
       "      <td>tensor(7.8461, device='cuda:0')</td>\n",
       "      <td>tensor(0.2417, device='cuda:0')</td>\n",
       "      <td>tensor(24869.6250, device='cuda:0')</td>\n",
       "      <td>tensor(1201.0504, device='cuda:0')</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>1.246531e-05</td>\n",
       "      <td>0.018140</td>\n",
       "      <td>7.349366e-05</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.188286</td>\n",
       "      <td>213671.890625</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>7.053688e-06</td>\n",
       "      <td>-2.400984e-01</td>\n",
       "      <td>7.053688e+06</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>55.767273</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>4017.274170</td>\n",
       "      <td>45879.109375</td>\n",
       "      <td>6.686219e+10</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>448.050049</td>\n",
       "      <td>39.280289</td>\n",
       "      <td>-2.074025e-04</td>\n",
       "      <td>0.444611</td>\n",
       "      <td>2.246552</td>\n",
       "      <td>27.978882</td>\n",
       "      <td>119.991455</td>\n",
       "      <td>176.019653</td>\n",
       "      <td>4016.382324</td>\n",
       "      <td>tensor(24.5433, device='cuda:0')</td>\n",
       "      <td>tensor(0.2591, device='cuda:0')</td>\n",
       "      <td>tensor(85930.2031, device='cuda:0')</td>\n",
       "      <td>tensor(875.6617, device='cuda:0')</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>2.234755e-05</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>1.520225e-04</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.167343</td>\n",
       "      <td>242867.578125</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-4.167405e-06</td>\n",
       "      <td>-9.471465e-03</td>\n",
       "      <td>-4.167405e+06</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>63.387787</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5377.061523</td>\n",
       "      <td>56659.636719</td>\n",
       "      <td>6.108398e+10</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>46.169350</td>\n",
       "      <td>2.426678e-04</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>2.765137</td>\n",
       "      <td>32.015625</td>\n",
       "      <td>128.004211</td>\n",
       "      <td>192.015625</td>\n",
       "      <td>5376.119141</td>\n",
       "      <td>tensor(4.7539, device='cuda:0')</td>\n",
       "      <td>tensor(0.2822, device='cuda:0')</td>\n",
       "      <td>tensor(19412.5586, device='cuda:0')</td>\n",
       "      <td>tensor(1275.1847, device='cuda:0')</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>2.383912e-04</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>3.007845e-05</td>\n",
       "      <td>0.022164</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.067039</td>\n",
       "      <td>175714.812500</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-6.090719e-06</td>\n",
       "      <td>-2.176526e-02</td>\n",
       "      <td>-6.090718e+06</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>86.476509</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>3581.117920</td>\n",
       "      <td>30605.884766</td>\n",
       "      <td>2.699694e+09</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>448.158203</td>\n",
       "      <td>63.707577</td>\n",
       "      <td>-4.979322e-04</td>\n",
       "      <td>0.673218</td>\n",
       "      <td>3.286133</td>\n",
       "      <td>47.974609</td>\n",
       "      <td>176.025757</td>\n",
       "      <td>255.984680</td>\n",
       "      <td>3580.065430</td>\n",
       "      <td>tensor(8.1744, device='cuda:0')</td>\n",
       "      <td>tensor(0.3243, device='cuda:0')</td>\n",
       "      <td>tensor(15031.0605, device='cuda:0')</td>\n",
       "      <td>tensor(778.5264, device='cuda:0')</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>2.476494e-04</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>3.619543e-04</td>\n",
       "      <td>0.039963</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>71.968002</td>\n",
       "      <td>331438.187500</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>5.583176e-06</td>\n",
       "      <td>4.792462e-03</td>\n",
       "      <td>1.164991e-03</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>99.886757</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>4605.354980</td>\n",
       "      <td>48379.199219</td>\n",
       "      <td>2.114446e+10</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>78.596474</td>\n",
       "      <td>1.050658e-04</td>\n",
       "      <td>1.209961</td>\n",
       "      <td>5.997131</td>\n",
       "      <td>64.000008</td>\n",
       "      <td>192.031250</td>\n",
       "      <td>256.021973</td>\n",
       "      <td>4604.652832</td>\n",
       "      <td>tensor(9.5801, device='cuda:0')</td>\n",
       "      <td>tensor(0.0247, device='cuda:0')</td>\n",
       "      <td>tensor(41463.4297, device='cuda:0')</td>\n",
       "      <td>tensor(382.4539, device='cuda:0')</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>3.489057e-04</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>8.914230e-06</td>\n",
       "      <td>0.025382</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>53.960705</td>\n",
       "      <td>33.469986</td>\n",
       "      <td>1.612212</td>\n",
       "      <td>-1.149284e-04</td>\n",
       "      <td>-3.365870e-05</td>\n",
       "      <td>-1.149284e+08</td>\n",
       "      <td>0.039834</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>1.612207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>1.177651</td>\n",
       "      <td>7.581616</td>\n",
       "      <td>3.099565e+06</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>-1.364358e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>tensor(31.3766, device='cuda:0')</td>\n",
       "      <td>tensor(1.6840, device='cuda:0')</td>\n",
       "      <td>tensor(20.4495, device='cuda:0')</td>\n",
       "      <td>tensor(0.6083, device='cuda:0')</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>1.221055e-03</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>3.587130e-05</td>\n",
       "      <td>0.063182</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.308689</td>\n",
       "      <td>270485.625000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>4.064856e-07</td>\n",
       "      <td>-1.043761e-02</td>\n",
       "      <td>4.064856e+05</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>70.596008</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>5599.109375</td>\n",
       "      <td>86737.960938</td>\n",
       "      <td>2.145388e+11</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>448.042969</td>\n",
       "      <td>52.913498</td>\n",
       "      <td>2.298434e-05</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>3.233643</td>\n",
       "      <td>40.007080</td>\n",
       "      <td>143.999985</td>\n",
       "      <td>208.004059</td>\n",
       "      <td>5598.126465</td>\n",
       "      <td>tensor(7.7607, device='cuda:0')</td>\n",
       "      <td>tensor(0.2507, device='cuda:0')</td>\n",
       "      <td>tensor(22602.1641, device='cuda:0')</td>\n",
       "      <td>tensor(1530.0123, device='cuda:0')</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>1.858424e-05</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>3.743844e-06</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.021282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.150475</td>\n",
       "      <td>212072.375000</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.142472e-05</td>\n",
       "      <td>-2.508570e-01</td>\n",
       "      <td>1.142472e+07</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>55.349747</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3916.353027</td>\n",
       "      <td>106709.531250</td>\n",
       "      <td>6.066271e+11</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>39.291393</td>\n",
       "      <td>-7.743487e-05</td>\n",
       "      <td>0.460754</td>\n",
       "      <td>2.257935</td>\n",
       "      <td>27.991882</td>\n",
       "      <td>119.977173</td>\n",
       "      <td>176.010315</td>\n",
       "      <td>3915.739746</td>\n",
       "      <td>tensor(26.6882, device='cuda:0')</td>\n",
       "      <td>tensor(0.2607, device='cuda:0')</td>\n",
       "      <td>tensor(78950.4062, device='cuda:0')</td>\n",
       "      <td>tensor(884.8000, device='cuda:0')</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>2.739299e-04</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>1.415235e-06</td>\n",
       "      <td>0.023220</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.262604</td>\n",
       "      <td>241527.921875</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-4.910673e-06</td>\n",
       "      <td>9.193955e-03</td>\n",
       "      <td>-5.341198e-04</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>63.038136</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>5110.338867</td>\n",
       "      <td>51973.976562</td>\n",
       "      <td>2.164393e+10</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>448.046387</td>\n",
       "      <td>46.139214</td>\n",
       "      <td>3.565793e-04</td>\n",
       "      <td>0.571045</td>\n",
       "      <td>2.984863</td>\n",
       "      <td>35.966553</td>\n",
       "      <td>128.001205</td>\n",
       "      <td>192.008362</td>\n",
       "      <td>5109.399414</td>\n",
       "      <td>tensor(5.6837, device='cuda:0')</td>\n",
       "      <td>tensor(0.2861, device='cuda:0')</td>\n",
       "      <td>tensor(19598.0859, device='cuda:0')</td>\n",
       "      <td>tensor(1365.5833, device='cuda:0')</td>\n",
       "      <td>0.016535</td>\n",
       "      <td>9.091378e-05</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>4.929966e-05</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.011680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.026100</td>\n",
       "      <td>179884.656250</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>6.047038e-06</td>\n",
       "      <td>-4.908935e-02</td>\n",
       "      <td>6.047038e+06</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>88.528648</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>3669.161621</td>\n",
       "      <td>37208.312500</td>\n",
       "      <td>5.726623e+09</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>448.118164</td>\n",
       "      <td>65.399979</td>\n",
       "      <td>-1.855232e-04</td>\n",
       "      <td>0.660522</td>\n",
       "      <td>3.263916</td>\n",
       "      <td>48.004364</td>\n",
       "      <td>191.969849</td>\n",
       "      <td>255.994751</td>\n",
       "      <td>3668.151367</td>\n",
       "      <td>tensor(8.2013, device='cuda:0')</td>\n",
       "      <td>tensor(0.4124, device='cuda:0')</td>\n",
       "      <td>tensor(16082.4844, device='cuda:0')</td>\n",
       "      <td>tensor(850.0392, device='cuda:0')</td>\n",
       "      <td>0.033253</td>\n",
       "      <td>4.768497e-04</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>1.044966e-04</td>\n",
       "      <td>0.040387</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>74.409676</td>\n",
       "      <td>346724.875000</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-1.429682e-06</td>\n",
       "      <td>4.509106e-02</td>\n",
       "      <td>-3.170655e-05</td>\n",
       "      <td>0.022425</td>\n",
       "      <td>104.493759</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>4659.674805</td>\n",
       "      <td>67023.195312</td>\n",
       "      <td>1.444614e+11</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>448.074707</td>\n",
       "      <td>82.702156</td>\n",
       "      <td>1.101691e-04</td>\n",
       "      <td>1.261719</td>\n",
       "      <td>6.485657</td>\n",
       "      <td>71.975464</td>\n",
       "      <td>207.997055</td>\n",
       "      <td>287.977539</td>\n",
       "      <td>4658.727051</td>\n",
       "      <td>tensor(11.5208, device='cuda:0')</td>\n",
       "      <td>tensor(0.0165, device='cuda:0')</td>\n",
       "      <td>tensor(44130.3750, device='cuda:0')</td>\n",
       "      <td>tensor(448.6319, device='cuda:0')</td>\n",
       "      <td>0.021628</td>\n",
       "      <td>3.123549e-04</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>4.293425e-05</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>52.822144</td>\n",
       "      <td>34.614334</td>\n",
       "      <td>1.526019</td>\n",
       "      <td>-1.508373e-04</td>\n",
       "      <td>2.858262e-05</td>\n",
       "      <td>-5.277240e+00</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>1.526009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>1.198452</td>\n",
       "      <td>6.573598</td>\n",
       "      <td>6.546205e+05</td>\n",
       "      <td>-0.005238</td>\n",
       "      <td>0.544861</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>-4.668207e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>0.347193</td>\n",
       "      <td>tensor(31.0485, device='cuda:0')</td>\n",
       "      <td>tensor(1.3195, device='cuda:0')</td>\n",
       "      <td>tensor(21.6039, device='cuda:0')</td>\n",
       "      <td>tensor(0.5621, device='cuda:0')</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>3.284667e-05</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>3.695511e-05</td>\n",
       "      <td>0.062743</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>49.340076</td>\n",
       "      <td>268255.343750</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>5.842824e-07</td>\n",
       "      <td>-9.231600e-03</td>\n",
       "      <td>5.842824e+05</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>70.013916</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5436.865234</td>\n",
       "      <td>124730.500000</td>\n",
       "      <td>1.055531e+12</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>448.057861</td>\n",
       "      <td>51.854233</td>\n",
       "      <td>2.746141e-05</td>\n",
       "      <td>0.618427</td>\n",
       "      <td>3.012268</td>\n",
       "      <td>39.995605</td>\n",
       "      <td>143.999695</td>\n",
       "      <td>208.039307</td>\n",
       "      <td>5435.884766</td>\n",
       "      <td>tensor(7.9644, device='cuda:0')</td>\n",
       "      <td>tensor(0.2851, device='cuda:0')</td>\n",
       "      <td>tensor(25319.5820, device='cuda:0')</td>\n",
       "      <td>tensor(1087.7020, device='cuda:0')</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>9.026210e-05</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>2.592006e-04</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.313282</td>\n",
       "      <td>248781.703125</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>3.733487e-06</td>\n",
       "      <td>-3.760223e-01</td>\n",
       "      <td>3.733487e+06</td>\n",
       "      <td>0.014176</td>\n",
       "      <td>64.930260</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>4580.493652</td>\n",
       "      <td>42255.625000</td>\n",
       "      <td>1.075609e+10</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>448.058594</td>\n",
       "      <td>46.975239</td>\n",
       "      <td>5.735542e-04</td>\n",
       "      <td>0.558792</td>\n",
       "      <td>2.754822</td>\n",
       "      <td>32.014160</td>\n",
       "      <td>143.977051</td>\n",
       "      <td>207.990723</td>\n",
       "      <td>4579.685547</td>\n",
       "      <td>tensor(26.8722, device='cuda:0')</td>\n",
       "      <td>tensor(0.3012, device='cuda:0')</td>\n",
       "      <td>tensor(109519.3672, device='cuda:0')</td>\n",
       "      <td>tensor(1267.0739, device='cuda:0')</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>1.378335e-04</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>6.259223e-06</td>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.547146</td>\n",
       "      <td>254547.875000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>2.896968e-06</td>\n",
       "      <td>2.988487e-03</td>\n",
       "      <td>9.693764e-04</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>66.436310</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5243.312988</td>\n",
       "      <td>53005.238281</td>\n",
       "      <td>2.699694e+10</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>448.058350</td>\n",
       "      <td>48.525593</td>\n",
       "      <td>-5.084596e-05</td>\n",
       "      <td>0.617065</td>\n",
       "      <td>3.007172</td>\n",
       "      <td>35.997879</td>\n",
       "      <td>143.986267</td>\n",
       "      <td>208.003204</td>\n",
       "      <td>5242.381348</td>\n",
       "      <td>tensor(5.4867, device='cuda:0')</td>\n",
       "      <td>tensor(0.3040, device='cuda:0')</td>\n",
       "      <td>tensor(17943.7246, device='cuda:0')</td>\n",
       "      <td>tensor(1398.8707, device='cuda:0')</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>2.627929e-04</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>4.313570e-04</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.848537</td>\n",
       "      <td>172664.937500</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.885699e-06</td>\n",
       "      <td>6.064153e-02</td>\n",
       "      <td>6.407653e-05</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>84.975517</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>3267.165771</td>\n",
       "      <td>31396.652344</td>\n",
       "      <td>1.327913e+10</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>448.151367</td>\n",
       "      <td>62.332523</td>\n",
       "      <td>8.414559e-05</td>\n",
       "      <td>0.581787</td>\n",
       "      <td>2.988281</td>\n",
       "      <td>44.045654</td>\n",
       "      <td>176.010742</td>\n",
       "      <td>255.972412</td>\n",
       "      <td>3266.143555</td>\n",
       "      <td>tensor(8.9086, device='cuda:0')</td>\n",
       "      <td>tensor(0.4214, device='cuda:0')</td>\n",
       "      <td>tensor(17713.7090, device='cuda:0')</td>\n",
       "      <td>tensor(926.3890, device='cuda:0')</td>\n",
       "      <td>0.034343</td>\n",
       "      <td>5.474986e-06</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>2.161141e-05</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.089249</td>\n",
       "      <td>348893.781250</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>8.868068e-06</td>\n",
       "      <td>-6.743153e-03</td>\n",
       "      <td>8.868068e+06</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>105.147415</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>4525.841797</td>\n",
       "      <td>44827.691406</td>\n",
       "      <td>2.439745e+10</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>83.261055</td>\n",
       "      <td>3.946591e-04</td>\n",
       "      <td>1.266602</td>\n",
       "      <td>6.493195</td>\n",
       "      <td>71.980835</td>\n",
       "      <td>208.000824</td>\n",
       "      <td>287.981689</td>\n",
       "      <td>4524.863281</td>\n",
       "      <td>tensor(11.6431, device='cuda:0')</td>\n",
       "      <td>tensor(0.0258, device='cuda:0')</td>\n",
       "      <td>tensor(54859.1641, device='cuda:0')</td>\n",
       "      <td>tensor(281.6629, device='cuda:0')</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>3.717479e-04</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>4.853477e-05</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>51.809036</td>\n",
       "      <td>33.058929</td>\n",
       "      <td>1.567172</td>\n",
       "      <td>-1.320829e-04</td>\n",
       "      <td>-4.541640e-05</td>\n",
       "      <td>-1.320829e+08</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>1.567166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>1.187365</td>\n",
       "      <td>6.077863</td>\n",
       "      <td>4.487540e+05</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.521851</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>-1.161391e-03</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029602</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>0.364697</td>\n",
       "      <td>tensor(30.8367, device='cuda:0')</td>\n",
       "      <td>tensor(1.4435, device='cuda:0')</td>\n",
       "      <td>tensor(20.9987, device='cuda:0')</td>\n",
       "      <td>tensor(0.3963, device='cuda:0')</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>1.105872e-04</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>6.255870e-05</td>\n",
       "      <td>0.062063</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.625832</td>\n",
       "      <td>274444.125000</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-1.152634e-06</td>\n",
       "      <td>-1.972780e-03</td>\n",
       "      <td>-1.152634e+06</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>71.629173</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>5643.998047</td>\n",
       "      <td>76338.273438</td>\n",
       "      <td>1.815707e+11</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>448.057617</td>\n",
       "      <td>53.525856</td>\n",
       "      <td>4.596278e-05</td>\n",
       "      <td>0.623199</td>\n",
       "      <td>3.237793</td>\n",
       "      <td>40.012573</td>\n",
       "      <td>144.003281</td>\n",
       "      <td>223.985962</td>\n",
       "      <td>5643.068359</td>\n",
       "      <td>tensor(8.3418, device='cuda:0')</td>\n",
       "      <td>tensor(0.2791, device='cuda:0')</td>\n",
       "      <td>tensor(21950.3672, device='cuda:0')</td>\n",
       "      <td>tensor(1301.0970, device='cuda:0')</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>1.144439e-04</td>\n",
       "      <td>0.017535</td>\n",
       "      <td>6.975065e-04</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.440929</td>\n",
       "      <td>239390.265625</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>8.834773e-06</td>\n",
       "      <td>-2.911580e-01</td>\n",
       "      <td>8.834773e+06</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>62.479534</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>4397.247070</td>\n",
       "      <td>74510.414062</td>\n",
       "      <td>2.679013e+11</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>448.051514</td>\n",
       "      <td>44.431938</td>\n",
       "      <td>7.626922e-04</td>\n",
       "      <td>0.492065</td>\n",
       "      <td>2.499317</td>\n",
       "      <td>30.018188</td>\n",
       "      <td>128.008423</td>\n",
       "      <td>207.977051</td>\n",
       "      <td>4396.266602</td>\n",
       "      <td>tensor(25.4881, device='cuda:0')</td>\n",
       "      <td>tensor(0.3221, device='cuda:0')</td>\n",
       "      <td>tensor(102203.7969, device='cuda:0')</td>\n",
       "      <td>tensor(1203.6633, device='cuda:0')</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>4.013958e-06</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>2.151840e-04</td>\n",
       "      <td>0.023110</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.147461</td>\n",
       "      <td>248760.671875</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.993115e-06</td>\n",
       "      <td>8.235618e-03</td>\n",
       "      <td>2.420116e-04</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>64.925858</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>5276.226562</td>\n",
       "      <td>76995.984375</td>\n",
       "      <td>2.403304e+11</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>47.508385</td>\n",
       "      <td>-1.157660e-04</td>\n",
       "      <td>0.610718</td>\n",
       "      <td>3.002182</td>\n",
       "      <td>35.993134</td>\n",
       "      <td>128.012451</td>\n",
       "      <td>207.992279</td>\n",
       "      <td>5275.293945</td>\n",
       "      <td>tensor(5.2782, device='cuda:0')</td>\n",
       "      <td>tensor(0.3044, device='cuda:0')</td>\n",
       "      <td>tensor(19079.1465, device='cuda:0')</td>\n",
       "      <td>tensor(1319.6487, device='cuda:0')</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>2.875610e-04</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>1.397024e-05</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.150894</td>\n",
       "      <td>147863.421875</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3.030488e-06</td>\n",
       "      <td>-3.417383e-02</td>\n",
       "      <td>3.030488e+06</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>72.769676</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>2781.955566</td>\n",
       "      <td>27765.283203</td>\n",
       "      <td>7.150003e+09</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>448.124512</td>\n",
       "      <td>52.785561</td>\n",
       "      <td>2.040821e-04</td>\n",
       "      <td>0.602783</td>\n",
       "      <td>3.005890</td>\n",
       "      <td>36.035889</td>\n",
       "      <td>159.971313</td>\n",
       "      <td>224.009644</td>\n",
       "      <td>2780.947510</td>\n",
       "      <td>tensor(9.3380, device='cuda:0')</td>\n",
       "      <td>tensor(0.3615, device='cuda:0')</td>\n",
       "      <td>tensor(17846.7578, device='cuda:0')</td>\n",
       "      <td>tensor(1214.6302, device='cuda:0')</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>3.052537e-04</td>\n",
       "      <td>0.009068</td>\n",
       "      <td>6.151332e-05</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>78.304436</td>\n",
       "      <td>348700.437500</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-1.396485e-07</td>\n",
       "      <td>-8.308860e-03</td>\n",
       "      <td>-1.396485e+05</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>105.089142</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>4453.137695</td>\n",
       "      <td>70075.609375</td>\n",
       "      <td>1.736071e+11</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>83.240868</td>\n",
       "      <td>5.324460e-05</td>\n",
       "      <td>1.266479</td>\n",
       "      <td>6.491821</td>\n",
       "      <td>71.980591</td>\n",
       "      <td>208.000214</td>\n",
       "      <td>287.979736</td>\n",
       "      <td>4452.117676</td>\n",
       "      <td>tensor(11.5594, device='cuda:0')</td>\n",
       "      <td>tensor(0.0239, device='cuda:0')</td>\n",
       "      <td>tensor(45552.4492, device='cuda:0')</td>\n",
       "      <td>tensor(316.4215, device='cuda:0')</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>1.465922e-05</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>1.189756e-04</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>51.533623</td>\n",
       "      <td>32.673985</td>\n",
       "      <td>1.577207</td>\n",
       "      <td>-1.692496e-04</td>\n",
       "      <td>2.098504e-05</td>\n",
       "      <td>-8.065253e+00</td>\n",
       "      <td>0.038042</td>\n",
       "      <td>0.024120</td>\n",
       "      <td>1.577191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>1.185274</td>\n",
       "      <td>6.299329</td>\n",
       "      <td>3.625386e+05</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>-1.705085e-03</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.367555</td>\n",
       "      <td>tensor(31.0071, device='cuda:0')</td>\n",
       "      <td>tensor(1.1022, device='cuda:0')</td>\n",
       "      <td>tensor(20.6515, device='cuda:0')</td>\n",
       "      <td>tensor(0.3777, device='cuda:0')</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>1.564323e-03</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>1.970843e-04</td>\n",
       "      <td>0.061691</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.569614</td>\n",
       "      <td>254154.312500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>4.154171e-06</td>\n",
       "      <td>-7.816254e-03</td>\n",
       "      <td>4.154171e+06</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>66.333588</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>5342.787109</td>\n",
       "      <td>59439.398438</td>\n",
       "      <td>5.235770e+10</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>448.159180</td>\n",
       "      <td>48.815750</td>\n",
       "      <td>-2.073805e-04</td>\n",
       "      <td>0.555023</td>\n",
       "      <td>2.754578</td>\n",
       "      <td>36.006866</td>\n",
       "      <td>128.018677</td>\n",
       "      <td>207.999466</td>\n",
       "      <td>5341.897461</td>\n",
       "      <td>tensor(7.7318, device='cuda:0')</td>\n",
       "      <td>tensor(0.2756, device='cuda:0')</td>\n",
       "      <td>tensor(21309.0898, device='cuda:0')</td>\n",
       "      <td>tensor(1291.6893, device='cuda:0')</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>1.032477e-04</td>\n",
       "      <td>0.018236</td>\n",
       "      <td>1.456863e-03</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.026478</td>\n",
       "      <td>237929.937500</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>1.108182e-06</td>\n",
       "      <td>-2.339160e-01</td>\n",
       "      <td>1.108182e+06</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>62.098629</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>4403.949219</td>\n",
       "      <td>45753.617188</td>\n",
       "      <td>2.174175e+10</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>44.380424</td>\n",
       "      <td>5.241273e-04</td>\n",
       "      <td>0.500254</td>\n",
       "      <td>2.507050</td>\n",
       "      <td>31.976440</td>\n",
       "      <td>128.003845</td>\n",
       "      <td>192.018799</td>\n",
       "      <td>4402.905762</td>\n",
       "      <td>tensor(23.6224, device='cuda:0')</td>\n",
       "      <td>tensor(0.3393, device='cuda:0')</td>\n",
       "      <td>tensor(105968.6094, device='cuda:0')</td>\n",
       "      <td>tensor(1047.5306, device='cuda:0')</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>6.860213e-05</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>1.491076e-04</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>0.011633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.178051</td>\n",
       "      <td>228491.671875</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>6.086235e-07</td>\n",
       "      <td>-9.359336e-03</td>\n",
       "      <td>6.086235e+05</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>59.635708</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>4843.177246</td>\n",
       "      <td>55582.941406</td>\n",
       "      <td>8.737841e+10</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>448.058105</td>\n",
       "      <td>42.723488</td>\n",
       "      <td>3.337132e-04</td>\n",
       "      <td>0.502991</td>\n",
       "      <td>2.509155</td>\n",
       "      <td>30.007202</td>\n",
       "      <td>127.977539</td>\n",
       "      <td>192.002441</td>\n",
       "      <td>4842.175781</td>\n",
       "      <td>tensor(4.7177, device='cuda:0')</td>\n",
       "      <td>tensor(0.3142, device='cuda:0')</td>\n",
       "      <td>tensor(19481.6309, device='cuda:0')</td>\n",
       "      <td>tensor(1279.8574, device='cuda:0')</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>1.116475e-05</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>1.435868e-04</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.218193</td>\n",
       "      <td>169141.671875</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>2.475617e-05</td>\n",
       "      <td>-1.117020e-01</td>\n",
       "      <td>2.475617e+07</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>83.241516</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>3178.268555</td>\n",
       "      <td>28743.703125</td>\n",
       "      <td>4.393026e+09</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>448.109863</td>\n",
       "      <td>60.987366</td>\n",
       "      <td>-1.598460e-04</td>\n",
       "      <td>0.655762</td>\n",
       "      <td>3.261292</td>\n",
       "      <td>44.003860</td>\n",
       "      <td>176.000885</td>\n",
       "      <td>255.961670</td>\n",
       "      <td>3177.235840</td>\n",
       "      <td>tensor(8.8309, device='cuda:0')</td>\n",
       "      <td>tensor(0.4307, device='cuda:0')</td>\n",
       "      <td>tensor(15784.6787, device='cuda:0')</td>\n",
       "      <td>tensor(1131.8569, device='cuda:0')</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>6.160758e-04</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>1.750136e-04</td>\n",
       "      <td>0.041136</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.360214</td>\n",
       "      <td>339649.406250</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>7.585611e-06</td>\n",
       "      <td>4.504902e-03</td>\n",
       "      <td>1.683857e-03</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>102.361404</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>4390.492676</td>\n",
       "      <td>51387.316406</td>\n",
       "      <td>3.824388e+10</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>80.860954</td>\n",
       "      <td>6.449795e-05</td>\n",
       "      <td>1.247299</td>\n",
       "      <td>6.033691</td>\n",
       "      <td>64.027588</td>\n",
       "      <td>207.979248</td>\n",
       "      <td>256.057861</td>\n",
       "      <td>4389.505371</td>\n",
       "      <td>tensor(11.2047, device='cuda:0')</td>\n",
       "      <td>tensor(0.0299, device='cuda:0')</td>\n",
       "      <td>tensor(45610.8125, device='cuda:0')</td>\n",
       "      <td>tensor(348.9747, device='cuda:0')</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>1.423036e-04</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>2.797982e-06</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.803822</td>\n",
       "      <td>33.005226</td>\n",
       "      <td>1.539266</td>\n",
       "      <td>-1.491089e-04</td>\n",
       "      <td>-1.254909e-04</td>\n",
       "      <td>-1.491089e+08</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>1.539274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>1.192828</td>\n",
       "      <td>5.917994</td>\n",
       "      <td>6.260166e+05</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.553589</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>2.500160e-04</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.119385</td>\n",
       "      <td>0.351707</td>\n",
       "      <td>tensor(30.7420, device='cuda:0')</td>\n",
       "      <td>tensor(1.4473, device='cuda:0')</td>\n",
       "      <td>tensor(20.8635, device='cuda:0')</td>\n",
       "      <td>tensor(0.5605, device='cuda:0')</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>4.935949e-04</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>2.167753e-06</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.462849</td>\n",
       "      <td>265520.093750</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.236842e-06</td>\n",
       "      <td>1.374267e-02</td>\n",
       "      <td>-2.355323e-04</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>69.300026</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>5594.271973</td>\n",
       "      <td>61939.054688</td>\n",
       "      <td>7.910156e+10</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>448.038330</td>\n",
       "      <td>52.318501</td>\n",
       "      <td>3.122127e-04</td>\n",
       "      <td>0.626183</td>\n",
       "      <td>3.246338</td>\n",
       "      <td>40.010071</td>\n",
       "      <td>143.990540</td>\n",
       "      <td>207.996735</td>\n",
       "      <td>5593.243652</td>\n",
       "      <td>tensor(8.2205, device='cuda:0')</td>\n",
       "      <td>tensor(0.2710, device='cuda:0')</td>\n",
       "      <td>tensor(24616.9980, device='cuda:0')</td>\n",
       "      <td>tensor(1253.4230, device='cuda:0')</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>8.316412e-05</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>1.333827e-04</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.385624</td>\n",
       "      <td>254744.312500</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1.347473e-05</td>\n",
       "      <td>-2.921647e-01</td>\n",
       "      <td>1.347473e+07</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>66.486938</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>4599.465820</td>\n",
       "      <td>50886.019531</td>\n",
       "      <td>2.876629e+10</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>48.241295</td>\n",
       "      <td>3.567025e-04</td>\n",
       "      <td>0.575989</td>\n",
       "      <td>2.988342</td>\n",
       "      <td>35.986511</td>\n",
       "      <td>143.991516</td>\n",
       "      <td>208.000931</td>\n",
       "      <td>4598.679199</td>\n",
       "      <td>tensor(24.5210, device='cuda:0')</td>\n",
       "      <td>tensor(0.3342, device='cuda:0')</td>\n",
       "      <td>tensor(92334.0156, device='cuda:0')</td>\n",
       "      <td>tensor(1105.7457, device='cuda:0')</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>1.356602e-04</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>3.103687e-05</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.529091</td>\n",
       "      <td>250556.265625</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-2.656181e-06</td>\n",
       "      <td>-2.184244e-02</td>\n",
       "      <td>-2.656181e+06</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>65.394508</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>5163.011719</td>\n",
       "      <td>46956.445312</td>\n",
       "      <td>1.863579e+10</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>448.052734</td>\n",
       "      <td>48.439747</td>\n",
       "      <td>1.253908e-04</td>\n",
       "      <td>0.629395</td>\n",
       "      <td>3.240234</td>\n",
       "      <td>36.003799</td>\n",
       "      <td>128.012878</td>\n",
       "      <td>192.026733</td>\n",
       "      <td>5162.035156</td>\n",
       "      <td>tensor(4.9976, device='cuda:0')</td>\n",
       "      <td>tensor(0.3143, device='cuda:0')</td>\n",
       "      <td>tensor(20366.8379, device='cuda:0')</td>\n",
       "      <td>tensor(1485.3699, device='cuda:0')</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>3.373288e-04</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>4.629541e-04</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.422222</td>\n",
       "      <td>185918.343750</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-3.073183e-05</td>\n",
       "      <td>-9.216955e-02</td>\n",
       "      <td>-3.073183e+07</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>91.498039</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>3920.489258</td>\n",
       "      <td>40093.097656</td>\n",
       "      <td>6.544712e+09</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>448.156250</td>\n",
       "      <td>67.872482</td>\n",
       "      <td>6.362249e-04</td>\n",
       "      <td>0.797241</td>\n",
       "      <td>3.980713</td>\n",
       "      <td>48.024414</td>\n",
       "      <td>192.001892</td>\n",
       "      <td>256.016235</td>\n",
       "      <td>3919.500244</td>\n",
       "      <td>tensor(9.8191, device='cuda:0')</td>\n",
       "      <td>tensor(0.3555, device='cuda:0')</td>\n",
       "      <td>tensor(19095.9648, device='cuda:0')</td>\n",
       "      <td>tensor(798.4045, device='cuda:0')</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>3.573753e-04</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>1.106731e-04</td>\n",
       "      <td>0.040488</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.470337</td>\n",
       "      <td>351829.625000</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>8.923560e-07</td>\n",
       "      <td>1.168493e-02</td>\n",
       "      <td>7.636809e-05</td>\n",
       "      <td>0.019430</td>\n",
       "      <td>106.032204</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>5457.231934</td>\n",
       "      <td>64612.523438</td>\n",
       "      <td>5.957945e+10</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>448.066406</td>\n",
       "      <td>84.026520</td>\n",
       "      <td>2.146558e-04</td>\n",
       "      <td>1.274536</td>\n",
       "      <td>6.499390</td>\n",
       "      <td>71.990662</td>\n",
       "      <td>208.004761</td>\n",
       "      <td>287.989929</td>\n",
       "      <td>5456.511719</td>\n",
       "      <td>tensor(9.6462, device='cuda:0')</td>\n",
       "      <td>tensor(0.0229, device='cuda:0')</td>\n",
       "      <td>tensor(43043.5156, device='cuda:0')</td>\n",
       "      <td>tensor(334.8853, device='cuda:0')</td>\n",
       "      <td>0.019658</td>\n",
       "      <td>3.069484e-04</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>5.258771e-04</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.808838</td>\n",
       "      <td>31.944159</td>\n",
       "      <td>1.590552</td>\n",
       "      <td>-1.105045e-04</td>\n",
       "      <td>-1.708675e-04</td>\n",
       "      <td>-1.105045e+08</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>1.590587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.180704</td>\n",
       "      <td>6.530527</td>\n",
       "      <td>4.013059e+05</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.411194</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>1.486029e-03</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.374111</td>\n",
       "      <td>tensor(30.6554, device='cuda:0')</td>\n",
       "      <td>tensor(1.3334, device='cuda:0')</td>\n",
       "      <td>tensor(20.5411, device='cuda:0')</td>\n",
       "      <td>tensor(0.2907, device='cuda:0')</td>\n",
       "      <td>0.057409</td>\n",
       "      <td>1.334565e-03</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>1.420775e-05</td>\n",
       "      <td>0.062548</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.174149</td>\n",
       "      <td>264156.875000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.395854e-07</td>\n",
       "      <td>-2.267782e-03</td>\n",
       "      <td>1.395854e+05</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>68.944221</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>5720.882324</td>\n",
       "      <td>62654.824219</td>\n",
       "      <td>2.617885e+10</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>52.007900</td>\n",
       "      <td>-3.376304e-04</td>\n",
       "      <td>0.610962</td>\n",
       "      <td>3.008484</td>\n",
       "      <td>40.004211</td>\n",
       "      <td>143.992798</td>\n",
       "      <td>192.032715</td>\n",
       "      <td>5719.911621</td>\n",
       "      <td>tensor(7.8940, device='cuda:0')</td>\n",
       "      <td>tensor(0.2603, device='cuda:0')</td>\n",
       "      <td>tensor(24254.5488, device='cuda:0')</td>\n",
       "      <td>tensor(1199.3651, device='cuda:0')</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>1.121841e-04</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>1.029048e-04</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.878120</td>\n",
       "      <td>238560.093750</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>4.846256e-06</td>\n",
       "      <td>-1.937132e-01</td>\n",
       "      <td>4.846256e+06</td>\n",
       "      <td>0.014062</td>\n",
       "      <td>62.263241</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>4427.772461</td>\n",
       "      <td>51412.230469</td>\n",
       "      <td>1.355562e+11</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>45.252541</td>\n",
       "      <td>6.383160e-04</td>\n",
       "      <td>0.556610</td>\n",
       "      <td>2.752640</td>\n",
       "      <td>32.003006</td>\n",
       "      <td>128.000900</td>\n",
       "      <td>192.006592</td>\n",
       "      <td>4426.887207</td>\n",
       "      <td>tensor(20.2097, device='cuda:0')</td>\n",
       "      <td>tensor(0.3261, device='cuda:0')</td>\n",
       "      <td>tensor(73135.3438, device='cuda:0')</td>\n",
       "      <td>tensor(1246.8788, device='cuda:0')</td>\n",
       "      <td>0.024083</td>\n",
       "      <td>1.766246e-04</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>3.234378e-04</td>\n",
       "      <td>0.023141</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.584557</td>\n",
       "      <td>246313.625000</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-1.477660e-06</td>\n",
       "      <td>-2.003634e-02</td>\n",
       "      <td>-1.477660e+06</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>64.287193</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>5287.452148</td>\n",
       "      <td>65662.820312</td>\n",
       "      <td>9.213785e+10</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>448.042236</td>\n",
       "      <td>47.736370</td>\n",
       "      <td>6.608267e-04</td>\n",
       "      <td>0.620056</td>\n",
       "      <td>3.009399</td>\n",
       "      <td>35.999550</td>\n",
       "      <td>128.007019</td>\n",
       "      <td>192.003510</td>\n",
       "      <td>5286.512207</td>\n",
       "      <td>tensor(5.2806, device='cuda:0')</td>\n",
       "      <td>tensor(0.3108, device='cuda:0')</td>\n",
       "      <td>tensor(19982.7285, device='cuda:0')</td>\n",
       "      <td>tensor(1357.3019, device='cuda:0')</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>4.324293e-05</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>2.710708e-05</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.028133</td>\n",
       "      <td>169801.312500</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-1.492910e-05</td>\n",
       "      <td>-3.902095e-02</td>\n",
       "      <td>-1.492910e+07</td>\n",
       "      <td>0.024621</td>\n",
       "      <td>83.566223</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>3394.116699</td>\n",
       "      <td>37682.843750</td>\n",
       "      <td>2.256460e+10</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>448.126953</td>\n",
       "      <td>61.171196</td>\n",
       "      <td>2.381159e-04</td>\n",
       "      <td>0.667358</td>\n",
       "      <td>3.280151</td>\n",
       "      <td>43.994263</td>\n",
       "      <td>176.003540</td>\n",
       "      <td>255.916626</td>\n",
       "      <td>3393.037842</td>\n",
       "      <td>tensor(9.4039, device='cuda:0')</td>\n",
       "      <td>tensor(0.3712, device='cuda:0')</td>\n",
       "      <td>tensor(19466.7344, device='cuda:0')</td>\n",
       "      <td>tensor(705.0221, device='cuda:0')</td>\n",
       "      <td>0.034346</td>\n",
       "      <td>1.214469e-03</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>2.946670e-04</td>\n",
       "      <td>0.040505</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.203667</td>\n",
       "      <td>349750.625000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-4.557790e-06</td>\n",
       "      <td>5.746814e-02</td>\n",
       "      <td>-7.930986e-05</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>105.405632</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>4843.945312</td>\n",
       "      <td>63310.359375</td>\n",
       "      <td>1.183331e+11</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>448.069336</td>\n",
       "      <td>83.316315</td>\n",
       "      <td>-7.628865e-05</td>\n",
       "      <td>1.262846</td>\n",
       "      <td>6.489075</td>\n",
       "      <td>71.980103</td>\n",
       "      <td>208.004089</td>\n",
       "      <td>287.987915</td>\n",
       "      <td>4842.937500</td>\n",
       "      <td>tensor(10.1458, device='cuda:0')</td>\n",
       "      <td>tensor(0.0212, device='cuda:0')</td>\n",
       "      <td>tensor(46309.8164, device='cuda:0')</td>\n",
       "      <td>tensor(289.7812, device='cuda:0')</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>7.614162e-05</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>3.801834e-06</td>\n",
       "      <td>0.025315</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.471760</td>\n",
       "      <td>32.046082</td>\n",
       "      <td>1.574974</td>\n",
       "      <td>-1.121770e-04</td>\n",
       "      <td>-1.210259e-04</td>\n",
       "      <td>-1.121770e+08</td>\n",
       "      <td>0.037259</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>1.574988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>1.183439</td>\n",
       "      <td>6.977399</td>\n",
       "      <td>1.141552e+06</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.456177</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>2.814621e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.086182</td>\n",
       "      <td>0.117554</td>\n",
       "      <td>0.367954</td>\n",
       "      <td>tensor(30.5340, device='cuda:0')</td>\n",
       "      <td>tensor(1.2833, device='cuda:0')</td>\n",
       "      <td>tensor(20.7299, device='cuda:0')</td>\n",
       "      <td>tensor(0.4193, device='cuda:0')</td>\n",
       "      <td>0.065414</td>\n",
       "      <td>5.260390e-04</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>9.123966e-06</td>\n",
       "      <td>0.062587</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.096180</td>\n",
       "      <td>251339.109375</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5.785394e-07</td>\n",
       "      <td>-6.294029e-03</td>\n",
       "      <td>5.785394e+05</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>65.598831</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>5452.493652</td>\n",
       "      <td>66814.710938</td>\n",
       "      <td>5.871179e+10</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>448.052979</td>\n",
       "      <td>48.993149</td>\n",
       "      <td>1.676418e-05</td>\n",
       "      <td>0.556915</td>\n",
       "      <td>2.761780</td>\n",
       "      <td>36.015503</td>\n",
       "      <td>128.010010</td>\n",
       "      <td>192.006805</td>\n",
       "      <td>5451.593262</td>\n",
       "      <td>tensor(7.8431, device='cuda:0')</td>\n",
       "      <td>tensor(0.2399, device='cuda:0')</td>\n",
       "      <td>tensor(23762.0703, device='cuda:0')</td>\n",
       "      <td>tensor(1360.1426, device='cuda:0')</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>4.566670e-04</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>8.976113e-05</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.693172</td>\n",
       "      <td>239392.328125</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-2.532516e-06</td>\n",
       "      <td>-2.024581e-01</td>\n",
       "      <td>-2.532516e+06</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>62.480423</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>4543.137207</td>\n",
       "      <td>48758.203125</td>\n",
       "      <td>9.995561e+10</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>448.042725</td>\n",
       "      <td>44.963810</td>\n",
       "      <td>6.734787e-05</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>2.731812</td>\n",
       "      <td>31.994019</td>\n",
       "      <td>128.004547</td>\n",
       "      <td>192.015137</td>\n",
       "      <td>4542.125488</td>\n",
       "      <td>tensor(15.9921, device='cuda:0')</td>\n",
       "      <td>tensor(0.3381, device='cuda:0')</td>\n",
       "      <td>tensor(76717.7969, device='cuda:0')</td>\n",
       "      <td>tensor(1092.5890, device='cuda:0')</td>\n",
       "      <td>0.025629</td>\n",
       "      <td>1.057993e-04</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>8.403857e-05</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.256454</td>\n",
       "      <td>232850.640625</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>4.575153e-06</td>\n",
       "      <td>-9.745409e-03</td>\n",
       "      <td>4.575152e+06</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>60.773392</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>5033.905762</td>\n",
       "      <td>50613.683594</td>\n",
       "      <td>3.616815e+10</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>448.051758</td>\n",
       "      <td>44.308361</td>\n",
       "      <td>5.938404e-04</td>\n",
       "      <td>0.554260</td>\n",
       "      <td>2.748375</td>\n",
       "      <td>31.997894</td>\n",
       "      <td>127.991211</td>\n",
       "      <td>191.993317</td>\n",
       "      <td>5032.910645</td>\n",
       "      <td>tensor(4.8418, device='cuda:0')</td>\n",
       "      <td>tensor(0.3159, device='cuda:0')</td>\n",
       "      <td>tensor(20962.4082, device='cuda:0')</td>\n",
       "      <td>tensor(1209.2291, device='cuda:0')</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>9.331973e-07</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>7.001583e-05</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.403919</td>\n",
       "      <td>161578.359375</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>8.130700e-06</td>\n",
       "      <td>2.347322e-02</td>\n",
       "      <td>3.463819e-04</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>79.519371</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>3143.308838</td>\n",
       "      <td>27983.072266</td>\n",
       "      <td>5.655924e+09</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>448.196289</td>\n",
       "      <td>57.879272</td>\n",
       "      <td>-6.406042e-04</td>\n",
       "      <td>0.614685</td>\n",
       "      <td>3.025146</td>\n",
       "      <td>40.012573</td>\n",
       "      <td>160.071289</td>\n",
       "      <td>239.993317</td>\n",
       "      <td>3142.317871</td>\n",
       "      <td>tensor(9.3497, device='cuda:0')</td>\n",
       "      <td>tensor(0.2544, device='cuda:0')</td>\n",
       "      <td>tensor(17588.1055, device='cuda:0')</td>\n",
       "      <td>tensor(1076.2759, device='cuda:0')</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>1.803401e-05</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>4.866677e-06</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>76.326584</td>\n",
       "      <td>353690.687500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>4.217153e-06</td>\n",
       "      <td>-5.704076e-03</td>\n",
       "      <td>4.217153e+06</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>106.593079</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>4633.912598</td>\n",
       "      <td>54179.046875</td>\n",
       "      <td>6.663707e+10</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>84.452888</td>\n",
       "      <td>-2.786990e-04</td>\n",
       "      <td>1.284668</td>\n",
       "      <td>6.504669</td>\n",
       "      <td>71.990234</td>\n",
       "      <td>208.010986</td>\n",
       "      <td>287.990723</td>\n",
       "      <td>4632.876953</td>\n",
       "      <td>tensor(10.6944, device='cuda:0')</td>\n",
       "      <td>tensor(0.0301, device='cuda:0')</td>\n",
       "      <td>tensor(52806.1328, device='cuda:0')</td>\n",
       "      <td>tensor(352.6909, device='cuda:0')</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>8.258442e-05</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>6.039991e-06</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>50.295757</td>\n",
       "      <td>30.401682</td>\n",
       "      <td>1.654374</td>\n",
       "      <td>-1.869524e-04</td>\n",
       "      <td>-5.243882e-05</td>\n",
       "      <td>-1.869524e+08</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>1.654358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>1.167676</td>\n",
       "      <td>5.328950</td>\n",
       "      <td>2.070192e+05</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.461042</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>2.463521e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.028381</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.398269</td>\n",
       "      <td>tensor(30.3129, device='cuda:0')</td>\n",
       "      <td>tensor(1.1106, device='cuda:0')</td>\n",
       "      <td>tensor(19.6710, device='cuda:0')</td>\n",
       "      <td>tensor(0.3133, device='cuda:0')</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>8.008681e-06</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>4.347075e-05</td>\n",
       "      <td>0.063557</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.349049</td>\n",
       "      <td>253563.968750</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>-2.036382e-06</td>\n",
       "      <td>-5.447127e-03</td>\n",
       "      <td>-2.036382e+06</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>66.179512</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>5470.748535</td>\n",
       "      <td>74789.625000</td>\n",
       "      <td>2.152890e+11</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>448.037109</td>\n",
       "      <td>49.486153</td>\n",
       "      <td>-4.554685e-04</td>\n",
       "      <td>0.561890</td>\n",
       "      <td>2.984741</td>\n",
       "      <td>39.986206</td>\n",
       "      <td>128.009094</td>\n",
       "      <td>192.027710</td>\n",
       "      <td>5469.806152</td>\n",
       "      <td>tensor(8.6974, device='cuda:0')</td>\n",
       "      <td>tensor(0.2094, device='cuda:0')</td>\n",
       "      <td>tensor(22790.2734, device='cuda:0')</td>\n",
       "      <td>tensor(1302.4084, device='cuda:0')</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>1.377258e-04</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>2.029782e-04</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.696072</td>\n",
       "      <td>243363.437500</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>6.955045e-06</td>\n",
       "      <td>-1.972267e-01</td>\n",
       "      <td>6.955044e+06</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>63.516895</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>4532.237793</td>\n",
       "      <td>46713.707031</td>\n",
       "      <td>5.320217e+10</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>448.056641</td>\n",
       "      <td>45.890270</td>\n",
       "      <td>1.008127e-03</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>2.744934</td>\n",
       "      <td>32.002930</td>\n",
       "      <td>128.011230</td>\n",
       "      <td>192.023438</td>\n",
       "      <td>4531.298828</td>\n",
       "      <td>tensor(19.2652, device='cuda:0')</td>\n",
       "      <td>tensor(0.2950, device='cuda:0')</td>\n",
       "      <td>tensor(84984.8125, device='cuda:0')</td>\n",
       "      <td>tensor(1116.7582, device='cuda:0')</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>1.531428e-04</td>\n",
       "      <td>0.009083</td>\n",
       "      <td>2.363928e-05</td>\n",
       "      <td>0.022795</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.525772</td>\n",
       "      <td>233164.468750</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>4.115060e-07</td>\n",
       "      <td>-2.233913e-03</td>\n",
       "      <td>4.115060e+05</td>\n",
       "      <td>0.012404</td>\n",
       "      <td>60.855301</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>4906.063965</td>\n",
       "      <td>57213.574219</td>\n",
       "      <td>7.374773e+10</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>448.043213</td>\n",
       "      <td>44.357609</td>\n",
       "      <td>-2.295087e-04</td>\n",
       "      <td>0.558771</td>\n",
       "      <td>2.752243</td>\n",
       "      <td>32.000149</td>\n",
       "      <td>127.988220</td>\n",
       "      <td>191.997543</td>\n",
       "      <td>4905.114746</td>\n",
       "      <td>tensor(5.4738, device='cuda:0')</td>\n",
       "      <td>tensor(0.3121, device='cuda:0')</td>\n",
       "      <td>tensor(21954.1309, device='cuda:0')</td>\n",
       "      <td>tensor(1331.0073, device='cuda:0')</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>7.180075e-06</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>1.331261e-04</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.421379</td>\n",
       "      <td>157419.468750</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-1.187304e-05</td>\n",
       "      <td>8.978627e-04</td>\n",
       "      <td>-1.322367e-02</td>\n",
       "      <td>0.020877</td>\n",
       "      <td>77.472610</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>3710.853271</td>\n",
       "      <td>67299.632812</td>\n",
       "      <td>1.499334e+11</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>448.242188</td>\n",
       "      <td>55.413795</td>\n",
       "      <td>-8.030227e-04</td>\n",
       "      <td>0.594971</td>\n",
       "      <td>2.994995</td>\n",
       "      <td>36.044434</td>\n",
       "      <td>160.031982</td>\n",
       "      <td>240.004547</td>\n",
       "      <td>3709.876953</td>\n",
       "      <td>tensor(9.3570, device='cuda:0')</td>\n",
       "      <td>tensor(0.2769, device='cuda:0')</td>\n",
       "      <td>tensor(16871.9629, device='cuda:0')</td>\n",
       "      <td>tensor(1119.1906, device='cuda:0')</td>\n",
       "      <td>0.034292</td>\n",
       "      <td>3.613753e-04</td>\n",
       "      <td>0.010481</td>\n",
       "      <td>1.812131e-04</td>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.475895</td>\n",
       "      <td>351937.812500</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>2.778476e-06</td>\n",
       "      <td>4.981333e-02</td>\n",
       "      <td>5.577775e-05</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>106.064796</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>5917.318359</td>\n",
       "      <td>139264.093750</td>\n",
       "      <td>4.833018e+11</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>448.061035</td>\n",
       "      <td>84.174171</td>\n",
       "      <td>-1.307745e-04</td>\n",
       "      <td>1.285645</td>\n",
       "      <td>6.502768</td>\n",
       "      <td>71.993652</td>\n",
       "      <td>208.003372</td>\n",
       "      <td>287.989502</td>\n",
       "      <td>5916.671875</td>\n",
       "      <td>tensor(9.3080, device='cuda:0')</td>\n",
       "      <td>tensor(0.0179, device='cuda:0')</td>\n",
       "      <td>tensor(51658.1523, device='cuda:0')</td>\n",
       "      <td>tensor(479.7096, device='cuda:0')</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>3.492055e-06</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>8.367666e-06</td>\n",
       "      <td>0.025450</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>48.734970</td>\n",
       "      <td>30.269274</td>\n",
       "      <td>1.610048</td>\n",
       "      <td>-1.270078e-04</td>\n",
       "      <td>-1.192450e-04</td>\n",
       "      <td>-1.270078e+08</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>1.610060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>1.175244</td>\n",
       "      <td>8.325297</td>\n",
       "      <td>1.611370e+06</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.440552</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>5.005906e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.112549</td>\n",
       "      <td>0.382855</td>\n",
       "      <td>tensor(29.5503, device='cuda:0')</td>\n",
       "      <td>tensor(1.3230, device='cuda:0')</td>\n",
       "      <td>tensor(19.8980, device='cuda:0')</td>\n",
       "      <td>tensor(0.3129, device='cuda:0')</td>\n",
       "      <td>0.055726</td>\n",
       "      <td>1.865421e-03</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>4.815899e-05</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.782246</td>\n",
       "      <td>264826.281250</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-2.627695e-06</td>\n",
       "      <td>5.786971e-03</td>\n",
       "      <td>-4.540709e-04</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>69.118950</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>5660.828613</td>\n",
       "      <td>324381.187500</td>\n",
       "      <td>3.728145e+12</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>448.034668</td>\n",
       "      <td>52.028522</td>\n",
       "      <td>3.012657e-04</td>\n",
       "      <td>0.567902</td>\n",
       "      <td>2.994263</td>\n",
       "      <td>40.003403</td>\n",
       "      <td>143.994476</td>\n",
       "      <td>207.986816</td>\n",
       "      <td>5659.797363</td>\n",
       "      <td>tensor(8.8600, device='cuda:0')</td>\n",
       "      <td>tensor(0.2617, device='cuda:0')</td>\n",
       "      <td>tensor(30910.1953, device='cuda:0')</td>\n",
       "      <td>tensor(1336.4958, device='cuda:0')</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>1.361835e-04</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>2.090650e-05</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.809319</td>\n",
       "      <td>249959.890625</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-6.566966e-06</td>\n",
       "      <td>-2.019484e-01</td>\n",
       "      <td>-6.566966e+06</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>65.238548</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>4733.252930</td>\n",
       "      <td>62941.453125</td>\n",
       "      <td>1.232211e+11</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>448.049072</td>\n",
       "      <td>47.894119</td>\n",
       "      <td>5.587788e-04</td>\n",
       "      <td>0.602173</td>\n",
       "      <td>2.998399</td>\n",
       "      <td>35.994904</td>\n",
       "      <td>128.019897</td>\n",
       "      <td>207.981934</td>\n",
       "      <td>4732.380371</td>\n",
       "      <td>tensor(16.9001, device='cuda:0')</td>\n",
       "      <td>tensor(0.2382, device='cuda:0')</td>\n",
       "      <td>tensor(73778.8125, device='cuda:0')</td>\n",
       "      <td>tensor(1321.6344, device='cuda:0')</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>1.317952e-04</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>1.202472e-05</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>47.837463</td>\n",
       "      <td>246854.312500</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-3.257190e-06</td>\n",
       "      <td>-8.360455e-03</td>\n",
       "      <td>-3.257190e+06</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>64.428314</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5160.271973</td>\n",
       "      <td>53996.414062</td>\n",
       "      <td>7.365149e+10</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>448.044678</td>\n",
       "      <td>47.846733</td>\n",
       "      <td>1.614659e-04</td>\n",
       "      <td>0.621674</td>\n",
       "      <td>3.016968</td>\n",
       "      <td>36.000328</td>\n",
       "      <td>128.007935</td>\n",
       "      <td>192.004944</td>\n",
       "      <td>5159.297363</td>\n",
       "      <td>tensor(5.2259, device='cuda:0')</td>\n",
       "      <td>tensor(0.3069, device='cuda:0')</td>\n",
       "      <td>tensor(25220.7832, device='cuda:0')</td>\n",
       "      <td>tensor(1410.1320, device='cuda:0')</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>4.377767e-05</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>7.652361e-05</td>\n",
       "      <td>0.021980</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.146156</td>\n",
       "      <td>166726.796875</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>5.031710e-06</td>\n",
       "      <td>7.347168e-03</td>\n",
       "      <td>6.848503e-04</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>82.053139</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>3259.811279</td>\n",
       "      <td>33941.050781</td>\n",
       "      <td>9.817069e+09</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>448.096680</td>\n",
       "      <td>59.874821</td>\n",
       "      <td>9.044335e-05</td>\n",
       "      <td>0.726318</td>\n",
       "      <td>3.595703</td>\n",
       "      <td>43.978394</td>\n",
       "      <td>175.999115</td>\n",
       "      <td>255.977539</td>\n",
       "      <td>3258.782959</td>\n",
       "      <td>tensor(9.1720, device='cuda:0')</td>\n",
       "      <td>tensor(0.2863, device='cuda:0')</td>\n",
       "      <td>tensor(18499.2578, device='cuda:0')</td>\n",
       "      <td>tensor(948.2445, device='cuda:0')</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>7.101535e-05</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>5.823203e-05</td>\n",
       "      <td>0.040188</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>77.038696</td>\n",
       "      <td>322530.968750</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-3.341826e-06</td>\n",
       "      <td>-1.406137e-02</td>\n",
       "      <td>-3.341826e+06</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>97.202354</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>4186.609863</td>\n",
       "      <td>75614.359375</td>\n",
       "      <td>2.513169e+11</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>76.485435</td>\n",
       "      <td>-3.062702e-04</td>\n",
       "      <td>1.142822</td>\n",
       "      <td>5.977295</td>\n",
       "      <td>63.982422</td>\n",
       "      <td>192.005890</td>\n",
       "      <td>256.007019</td>\n",
       "      <td>4185.813965</td>\n",
       "      <td>tensor(11.0167, device='cuda:0')</td>\n",
       "      <td>tensor(0.0281, device='cuda:0')</td>\n",
       "      <td>tensor(44953.9258, device='cuda:0')</td>\n",
       "      <td>tensor(399.7122, device='cuda:0')</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>1.269445e-06</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>7.778249e-05</td>\n",
       "      <td>0.025596</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>46.998287</td>\n",
       "      <td>29.635151</td>\n",
       "      <td>1.585897</td>\n",
       "      <td>-1.830576e-04</td>\n",
       "      <td>-1.751987e-04</td>\n",
       "      <td>-1.830576e+08</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>1.585925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>1.179102</td>\n",
       "      <td>10.375254</td>\n",
       "      <td>6.325101e+06</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.389709</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>6.643293e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.026825</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.374974</td>\n",
       "      <td>tensor(27.9507, device='cuda:0')</td>\n",
       "      <td>tensor(1.3222, device='cuda:0')</td>\n",
       "      <td>tensor(19.4090, device='cuda:0')</td>\n",
       "      <td>tensor(0.6169, device='cuda:0')</td>\n",
       "      <td>0.056536</td>\n",
       "      <td>3.782972e-04</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>2.704759e-05</td>\n",
       "      <td>0.062060</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.448711</td>\n",
       "      <td>249535.968750</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-6.396671e-07</td>\n",
       "      <td>-7.341177e-03</td>\n",
       "      <td>-6.396671e+05</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>65.128220</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>5490.496582</td>\n",
       "      <td>50347.285156</td>\n",
       "      <td>1.914572e+10</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>448.043457</td>\n",
       "      <td>48.936752</td>\n",
       "      <td>-1.968005e-04</td>\n",
       "      <td>0.556549</td>\n",
       "      <td>2.762268</td>\n",
       "      <td>39.982788</td>\n",
       "      <td>128.003357</td>\n",
       "      <td>192.002640</td>\n",
       "      <td>5489.632324</td>\n",
       "      <td>tensor(8.2664, device='cuda:0')</td>\n",
       "      <td>tensor(0.2334, device='cuda:0')</td>\n",
       "      <td>tensor(20308.2109, device='cuda:0')</td>\n",
       "      <td>tensor(1423.6157, device='cuda:0')</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>1.216412e-04</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>1.477298e-04</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>50.511700</td>\n",
       "      <td>247315.750000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>8.624909e-06</td>\n",
       "      <td>-1.405958e-01</td>\n",
       "      <td>8.624909e+06</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>64.548592</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>4896.206055</td>\n",
       "      <td>68080.296875</td>\n",
       "      <td>2.229424e+11</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>448.040039</td>\n",
       "      <td>47.032265</td>\n",
       "      <td>9.940417e-04</td>\n",
       "      <td>0.570557</td>\n",
       "      <td>2.982788</td>\n",
       "      <td>35.979248</td>\n",
       "      <td>128.014954</td>\n",
       "      <td>207.982422</td>\n",
       "      <td>4895.223145</td>\n",
       "      <td>tensor(11.1369, device='cuda:0')</td>\n",
       "      <td>tensor(0.2497, device='cuda:0')</td>\n",
       "      <td>tensor(79543.6953, device='cuda:0')</td>\n",
       "      <td>tensor(1148.2297, device='cuda:0')</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>9.051003e-05</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>1.755327e-04</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.237614</td>\n",
       "      <td>228836.593750</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>6.162876e-07</td>\n",
       "      <td>-3.677541e-02</td>\n",
       "      <td>6.162876e+05</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>59.725723</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>4949.143555</td>\n",
       "      <td>58560.859375</td>\n",
       "      <td>1.293543e+11</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>448.038574</td>\n",
       "      <td>44.166080</td>\n",
       "      <td>4.640776e-04</td>\n",
       "      <td>0.570679</td>\n",
       "      <td>2.984436</td>\n",
       "      <td>32.007996</td>\n",
       "      <td>120.009033</td>\n",
       "      <td>176.014404</td>\n",
       "      <td>4948.210449</td>\n",
       "      <td>tensor(5.2527, device='cuda:0')</td>\n",
       "      <td>tensor(0.2922, device='cuda:0')</td>\n",
       "      <td>tensor(21952.1660, device='cuda:0')</td>\n",
       "      <td>tensor(1366.4347, device='cuda:0')</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>5.166910e-05</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>9.950191e-05</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.286785</td>\n",
       "      <td>159359.562500</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-6.090324e-06</td>\n",
       "      <td>-3.130476e-02</td>\n",
       "      <td>-6.090324e+06</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>78.427406</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>3169.015137</td>\n",
       "      <td>27479.613281</td>\n",
       "      <td>3.939333e+09</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>448.134766</td>\n",
       "      <td>56.279320</td>\n",
       "      <td>3.306607e-04</td>\n",
       "      <td>0.625412</td>\n",
       "      <td>3.045898</td>\n",
       "      <td>39.979614</td>\n",
       "      <td>175.965820</td>\n",
       "      <td>240.018433</td>\n",
       "      <td>3167.979004</td>\n",
       "      <td>tensor(10.8628, device='cuda:0')</td>\n",
       "      <td>tensor(0.3276, device='cuda:0')</td>\n",
       "      <td>tensor(18994.0117, device='cuda:0')</td>\n",
       "      <td>tensor(980.2805, device='cuda:0')</td>\n",
       "      <td>0.030863</td>\n",
       "      <td>1.160460e-04</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>3.991327e-04</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>70.098717</td>\n",
       "      <td>354023.062500</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-1.144068e-05</td>\n",
       "      <td>5.585783e-02</td>\n",
       "      <td>-2.048178e-04</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>106.693237</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>5050.350586</td>\n",
       "      <td>53393.441406</td>\n",
       "      <td>2.617885e+10</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>448.069336</td>\n",
       "      <td>84.626434</td>\n",
       "      <td>-1.208794e-04</td>\n",
       "      <td>1.297607</td>\n",
       "      <td>6.506775</td>\n",
       "      <td>71.993256</td>\n",
       "      <td>208.009338</td>\n",
       "      <td>287.990234</td>\n",
       "      <td>5049.261719</td>\n",
       "      <td>tensor(9.6763, device='cuda:0')</td>\n",
       "      <td>tensor(0.0168, device='cuda:0')</td>\n",
       "      <td>tensor(53809.4688, device='cuda:0')</td>\n",
       "      <td>tensor(281.6903, device='cuda:0')</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>2.149590e-04</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>9.193044e-05</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.978374</td>\n",
       "      <td>29.709774</td>\n",
       "      <td>1.513925</td>\n",
       "      <td>-1.210729e-04</td>\n",
       "      <td>-1.989673e-04</td>\n",
       "      <td>-1.210729e+08</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>1.513977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>1.195682</td>\n",
       "      <td>7.656887</td>\n",
       "      <td>1.653523e+06</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.377197</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>5.908003e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>0.077759</td>\n",
       "      <td>0.105713</td>\n",
       "      <td>0.345376</td>\n",
       "      <td>tensor(27.0305, device='cuda:0')</td>\n",
       "      <td>tensor(0.9609, device='cuda:0')</td>\n",
       "      <td>tensor(19.6104, device='cuda:0')</td>\n",
       "      <td>tensor(0.7785, device='cuda:0')</td>\n",
       "      <td>0.057986</td>\n",
       "      <td>3.523288e-04</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>8.720708e-05</td>\n",
       "      <td>0.062748</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.732426</td>\n",
       "      <td>246747.593750</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.206265e-06</td>\n",
       "      <td>3.226588e-02</td>\n",
       "      <td>6.837764e-05</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>64.400452</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>5516.079102</td>\n",
       "      <td>51380.972656</td>\n",
       "      <td>1.018066e+10</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>48.669384</td>\n",
       "      <td>6.766855e-05</td>\n",
       "      <td>0.552368</td>\n",
       "      <td>2.757599</td>\n",
       "      <td>39.984375</td>\n",
       "      <td>127.999840</td>\n",
       "      <td>191.991821</td>\n",
       "      <td>5515.283691</td>\n",
       "      <td>tensor(8.7346, device='cuda:0')</td>\n",
       "      <td>tensor(0.2270, device='cuda:0')</td>\n",
       "      <td>tensor(21879.9336, device='cuda:0')</td>\n",
       "      <td>tensor(1451.9927, device='cuda:0')</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>1.730547e-04</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>2.765036e-04</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>51.111565</td>\n",
       "      <td>247076.625000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>5.742945e-06</td>\n",
       "      <td>-1.902667e-01</td>\n",
       "      <td>5.742945e+06</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>64.486053</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>4834.063965</td>\n",
       "      <td>49648.539062</td>\n",
       "      <td>2.733592e+10</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>448.082520</td>\n",
       "      <td>46.914322</td>\n",
       "      <td>9.604982e-04</td>\n",
       "      <td>0.565582</td>\n",
       "      <td>2.768921</td>\n",
       "      <td>35.968750</td>\n",
       "      <td>128.014160</td>\n",
       "      <td>207.983398</td>\n",
       "      <td>4833.089844</td>\n",
       "      <td>tensor(10.7964, device='cuda:0')</td>\n",
       "      <td>tensor(0.2880, device='cuda:0')</td>\n",
       "      <td>tensor(75548.2031, device='cuda:0')</td>\n",
       "      <td>tensor(995.4772, device='cuda:0')</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>3.799311e-04</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>1.342423e-04</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.126278</td>\n",
       "      <td>235508.343750</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>2.934498e-06</td>\n",
       "      <td>1.086098e-02</td>\n",
       "      <td>2.701873e-04</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>61.467045</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>5218.874512</td>\n",
       "      <td>52574.664062</td>\n",
       "      <td>5.497558e+10</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>448.041260</td>\n",
       "      <td>45.833378</td>\n",
       "      <td>-5.040774e-04</td>\n",
       "      <td>0.614357</td>\n",
       "      <td>3.003098</td>\n",
       "      <td>35.991760</td>\n",
       "      <td>127.986755</td>\n",
       "      <td>176.021729</td>\n",
       "      <td>5217.956543</td>\n",
       "      <td>tensor(5.2192, device='cuda:0')</td>\n",
       "      <td>tensor(0.2907, device='cuda:0')</td>\n",
       "      <td>tensor(26675.1309, device='cuda:0')</td>\n",
       "      <td>tensor(1549.4810, device='cuda:0')</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>6.752423e-05</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>2.721646e-05</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>51.099186</td>\n",
       "      <td>176098.312500</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>9.309763e-06</td>\n",
       "      <td>-2.666127e-02</td>\n",
       "      <td>9.309763e+06</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>86.665237</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>3446.206055</td>\n",
       "      <td>64964.792969</td>\n",
       "      <td>1.332741e+11</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>448.138672</td>\n",
       "      <td>63.714077</td>\n",
       "      <td>-5.134047e-05</td>\n",
       "      <td>0.688517</td>\n",
       "      <td>3.487366</td>\n",
       "      <td>47.945068</td>\n",
       "      <td>176.030762</td>\n",
       "      <td>255.991089</td>\n",
       "      <td>3445.195557</td>\n",
       "      <td>tensor(9.6691, device='cuda:0')</td>\n",
       "      <td>tensor(0.3248, device='cuda:0')</td>\n",
       "      <td>tensor(22065.8965, device='cuda:0')</td>\n",
       "      <td>tensor(1180.8955, device='cuda:0')</td>\n",
       "      <td>0.034803</td>\n",
       "      <td>5.432271e-04</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>2.948637e-05</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>75.349091</td>\n",
       "      <td>357103.000000</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-6.279362e-06</td>\n",
       "      <td>2.139048e-03</td>\n",
       "      <td>-2.935587e-03</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>107.621468</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4739.313965</td>\n",
       "      <td>49000.750000</td>\n",
       "      <td>1.627567e+10</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>85.509880</td>\n",
       "      <td>1.197895e-04</td>\n",
       "      <td>1.354370</td>\n",
       "      <td>6.522461</td>\n",
       "      <td>71.999550</td>\n",
       "      <td>208.015747</td>\n",
       "      <td>287.992126</td>\n",
       "      <td>4738.358398</td>\n",
       "      <td>tensor(12.3372, device='cuda:0')</td>\n",
       "      <td>tensor(0.0255, device='cuda:0')</td>\n",
       "      <td>tensor(46765.5938, device='cuda:0')</td>\n",
       "      <td>tensor(479.8380, device='cuda:0')</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>1.419322e-04</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>8.247992e-06</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.902657</td>\n",
       "      <td>29.010998</td>\n",
       "      <td>1.547781</td>\n",
       "      <td>-1.609426e-04</td>\n",
       "      <td>-1.404632e-04</td>\n",
       "      <td>-1.609426e+08</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>1.547796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>1.188272</td>\n",
       "      <td>7.097365</td>\n",
       "      <td>2.189672e+06</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.434937</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>5.312983e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>0.104614</td>\n",
       "      <td>0.357792</td>\n",
       "      <td>tensor(27.0423, device='cuda:0')</td>\n",
       "      <td>tensor(1.2050, device='cuda:0')</td>\n",
       "      <td>tensor(18.9062, device='cuda:0')</td>\n",
       "      <td>tensor(0.7413, device='cuda:0')</td>\n",
       "      <td>0.056541</td>\n",
       "      <td>1.004842e-03</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>1.812365e-04</td>\n",
       "      <td>0.062926</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.755562</td>\n",
       "      <td>230694.109375</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>3.613284e-06</td>\n",
       "      <td>-6.485780e-03</td>\n",
       "      <td>3.613284e+06</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>60.210541</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>5154.535156</td>\n",
       "      <td>49732.816406</td>\n",
       "      <td>2.210074e+10</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>448.051758</td>\n",
       "      <td>44.747868</td>\n",
       "      <td>2.549679e-05</td>\n",
       "      <td>0.499810</td>\n",
       "      <td>2.513611</td>\n",
       "      <td>35.989014</td>\n",
       "      <td>120.001884</td>\n",
       "      <td>176.017578</td>\n",
       "      <td>5153.592773</td>\n",
       "      <td>tensor(9.4703, device='cuda:0')</td>\n",
       "      <td>tensor(0.2036, device='cuda:0')</td>\n",
       "      <td>tensor(22988.7910, device='cuda:0')</td>\n",
       "      <td>tensor(1329.7961, device='cuda:0')</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>1.123857e-04</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>8.091390e-05</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>52.204166</td>\n",
       "      <td>244833.046875</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-7.717815e-06</td>\n",
       "      <td>-2.031770e-01</td>\n",
       "      <td>-7.717814e+06</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>63.900448</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>4689.913574</td>\n",
       "      <td>42603.464844</td>\n",
       "      <td>1.460704e+10</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>448.042725</td>\n",
       "      <td>46.344582</td>\n",
       "      <td>1.381631e-04</td>\n",
       "      <td>0.557392</td>\n",
       "      <td>2.752533</td>\n",
       "      <td>32.012573</td>\n",
       "      <td>128.010315</td>\n",
       "      <td>207.972290</td>\n",
       "      <td>4688.925781</td>\n",
       "      <td>tensor(14.1837, device='cuda:0')</td>\n",
       "      <td>tensor(0.3058, device='cuda:0')</td>\n",
       "      <td>tensor(82311.7031, device='cuda:0')</td>\n",
       "      <td>tensor(1160.0485, device='cuda:0')</td>\n",
       "      <td>0.024044</td>\n",
       "      <td>2.854981e-05</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>1.477597e-04</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.635883</td>\n",
       "      <td>229273.031250</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>3.854368e-06</td>\n",
       "      <td>1.034002e-02</td>\n",
       "      <td>3.727620e-04</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>59.839645</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5136.518555</td>\n",
       "      <td>52229.101562</td>\n",
       "      <td>4.363142e+10</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>448.037354</td>\n",
       "      <td>44.284389</td>\n",
       "      <td>3.172052e-04</td>\n",
       "      <td>0.574463</td>\n",
       "      <td>2.993896</td>\n",
       "      <td>32.012329</td>\n",
       "      <td>120.004944</td>\n",
       "      <td>176.023560</td>\n",
       "      <td>5135.521484</td>\n",
       "      <td>tensor(5.1143, device='cuda:0')</td>\n",
       "      <td>tensor(0.3024, device='cuda:0')</td>\n",
       "      <td>tensor(21297.1660, device='cuda:0')</td>\n",
       "      <td>tensor(1401.2380, device='cuda:0')</td>\n",
       "      <td>0.018315</td>\n",
       "      <td>9.541544e-05</td>\n",
       "      <td>0.009243</td>\n",
       "      <td>2.904060e-05</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>50.237015</td>\n",
       "      <td>153083.781250</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>-3.273722e-06</td>\n",
       "      <td>-5.559136e-02</td>\n",
       "      <td>-3.273722e+06</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>75.338821</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>3047.230957</td>\n",
       "      <td>25103.058594</td>\n",
       "      <td>3.011611e+09</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>448.259766</td>\n",
       "      <td>53.972969</td>\n",
       "      <td>5.291823e-04</td>\n",
       "      <td>0.583089</td>\n",
       "      <td>2.977539</td>\n",
       "      <td>36.021851</td>\n",
       "      <td>160.009460</td>\n",
       "      <td>239.980225</td>\n",
       "      <td>3046.197510</td>\n",
       "      <td>tensor(9.4088, device='cuda:0')</td>\n",
       "      <td>tensor(0.4393, device='cuda:0')</td>\n",
       "      <td>tensor(16195.7930, device='cuda:0')</td>\n",
       "      <td>tensor(915.5868, device='cuda:0')</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>4.503957e-04</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>1.045981e-04</td>\n",
       "      <td>0.041797</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>74.993248</td>\n",
       "      <td>347749.062500</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>8.232048e-06</td>\n",
       "      <td>3.023849e-02</td>\n",
       "      <td>2.722374e-04</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>104.802429</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>4637.071777</td>\n",
       "      <td>45390.710938</td>\n",
       "      <td>1.458536e+10</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>448.070801</td>\n",
       "      <td>83.016846</td>\n",
       "      <td>-1.836349e-04</td>\n",
       "      <td>1.264893</td>\n",
       "      <td>6.490601</td>\n",
       "      <td>71.980103</td>\n",
       "      <td>207.997803</td>\n",
       "      <td>287.978760</td>\n",
       "      <td>4636.120605</td>\n",
       "      <td>tensor(13.3010, device='cuda:0')</td>\n",
       "      <td>tensor(0.0292, device='cuda:0')</td>\n",
       "      <td>tensor(53386.8672, device='cuda:0')</td>\n",
       "      <td>tensor(447.5946, device='cuda:0')</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>2.759859e-04</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>8.263963e-06</td>\n",
       "      <td>0.025527</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.251369</td>\n",
       "      <td>28.274366</td>\n",
       "      <td>1.565070</td>\n",
       "      <td>-1.530798e-04</td>\n",
       "      <td>-1.352092e-04</td>\n",
       "      <td>-1.530798e+08</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.020872</td>\n",
       "      <td>1.565086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>1.184185</td>\n",
       "      <td>6.926130</td>\n",
       "      <td>2.296250e+06</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>6.259082e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>0.364463</td>\n",
       "      <td>tensor(27.0885, device='cuda:0')</td>\n",
       "      <td>tensor(1.2248, device='cuda:0')</td>\n",
       "      <td>tensor(18.6180, device='cuda:0')</td>\n",
       "      <td>tensor(0.6161, device='cuda:0')</td>\n",
       "      <td>0.052854</td>\n",
       "      <td>6.950810e-05</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>7.106597e-05</td>\n",
       "      <td>0.062554</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>44.357864</td>\n",
       "      <td>236758.187500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-4.030531e-06</td>\n",
       "      <td>-7.940068e-03</td>\n",
       "      <td>-4.030531e+06</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>61.793247</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>5337.457031</td>\n",
       "      <td>63366.921875</td>\n",
       "      <td>7.761259e+10</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>46.188362</td>\n",
       "      <td>2.676618e-04</td>\n",
       "      <td>0.503769</td>\n",
       "      <td>2.739807</td>\n",
       "      <td>36.001610</td>\n",
       "      <td>120.012207</td>\n",
       "      <td>191.991943</td>\n",
       "      <td>5336.548340</td>\n",
       "      <td>tensor(9.5175, device='cuda:0')</td>\n",
       "      <td>tensor(0.2913, device='cuda:0')</td>\n",
       "      <td>tensor(20778.1074, device='cuda:0')</td>\n",
       "      <td>tensor(1325.4924, device='cuda:0')</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>1.305350e-04</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>1.012218e-05</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.258675</td>\n",
       "      <td>242143.906250</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>2.750955e-06</td>\n",
       "      <td>-1.850301e-01</td>\n",
       "      <td>2.750955e+06</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>63.198639</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>4546.562500</td>\n",
       "      <td>42753.277344</td>\n",
       "      <td>2.568952e+10</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>448.041748</td>\n",
       "      <td>46.005123</td>\n",
       "      <td>2.948609e-04</td>\n",
       "      <td>0.564148</td>\n",
       "      <td>2.762280</td>\n",
       "      <td>32.014038</td>\n",
       "      <td>128.004333</td>\n",
       "      <td>192.015991</td>\n",
       "      <td>4545.520020</td>\n",
       "      <td>tensor(13.3592, device='cuda:0')</td>\n",
       "      <td>tensor(0.3128, device='cuda:0')</td>\n",
       "      <td>tensor(81746.3516, device='cuda:0')</td>\n",
       "      <td>tensor(968.7919, device='cuda:0')</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>8.711897e-05</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>7.416218e-05</td>\n",
       "      <td>0.023227</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.021950</td>\n",
       "      <td>233435.046875</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-1.456514e-06</td>\n",
       "      <td>1.647042e-02</td>\n",
       "      <td>-8.843213e-05</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>60.925915</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>5425.952637</td>\n",
       "      <td>53935.484375</td>\n",
       "      <td>4.557561e+10</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>448.037598</td>\n",
       "      <td>45.269539</td>\n",
       "      <td>-6.348122e-05</td>\n",
       "      <td>0.617126</td>\n",
       "      <td>3.005371</td>\n",
       "      <td>35.988525</td>\n",
       "      <td>120.015137</td>\n",
       "      <td>191.987915</td>\n",
       "      <td>5425.009766</td>\n",
       "      <td>tensor(5.4077, device='cuda:0')</td>\n",
       "      <td>tensor(0.3113, device='cuda:0')</td>\n",
       "      <td>tensor(27444.8730, device='cuda:0')</td>\n",
       "      <td>tensor(1330.8536, device='cuda:0')</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>1.998075e-04</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>4.316019e-04</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>53.222435</td>\n",
       "      <td>181203.046875</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>4.592324e-06</td>\n",
       "      <td>-4.400600e-02</td>\n",
       "      <td>4.592324e+06</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>89.177483</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>3404.636230</td>\n",
       "      <td>164057.468750</td>\n",
       "      <td>4.113281e+11</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>448.130859</td>\n",
       "      <td>66.646599</td>\n",
       "      <td>4.083858e-04</td>\n",
       "      <td>0.842651</td>\n",
       "      <td>4.032227</td>\n",
       "      <td>48.025513</td>\n",
       "      <td>191.978149</td>\n",
       "      <td>256.001831</td>\n",
       "      <td>3403.637939</td>\n",
       "      <td>tensor(9.9451, device='cuda:0')</td>\n",
       "      <td>tensor(0.3609, device='cuda:0')</td>\n",
       "      <td>tensor(24378.1270, device='cuda:0')</td>\n",
       "      <td>tensor(717.0118, device='cuda:0')</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>2.381118e-04</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>3.034903e-04</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>73.530098</td>\n",
       "      <td>331982.937500</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>4.888307e-06</td>\n",
       "      <td>4.533396e-03</td>\n",
       "      <td>1.078288e-03</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>100.050941</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>4514.926270</td>\n",
       "      <td>47570.929688</td>\n",
       "      <td>1.121951e+10</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>448.075684</td>\n",
       "      <td>78.170517</td>\n",
       "      <td>-1.743136e-04</td>\n",
       "      <td>1.139343</td>\n",
       "      <td>5.971436</td>\n",
       "      <td>63.988464</td>\n",
       "      <td>207.962891</td>\n",
       "      <td>287.953369</td>\n",
       "      <td>4513.942383</td>\n",
       "      <td>tensor(12.9504, device='cuda:0')</td>\n",
       "      <td>tensor(0.0187, device='cuda:0')</td>\n",
       "      <td>tensor(42568.5820, device='cuda:0')</td>\n",
       "      <td>tensor(192.1265, device='cuda:0')</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>4.981756e-04</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>6.747567e-05</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>44.192734</td>\n",
       "      <td>27.867537</td>\n",
       "      <td>1.585814</td>\n",
       "      <td>-1.046044e-04</td>\n",
       "      <td>-9.810292e-05</td>\n",
       "      <td>-1.046044e+08</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>1.585824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>1.178657</td>\n",
       "      <td>6.962451</td>\n",
       "      <td>1.811176e+06</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.486694</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>8.104665e-03</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.025330</td>\n",
       "      <td>0.075241</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>0.371823</td>\n",
       "      <td>tensor(27.2751, device='cuda:0')</td>\n",
       "      <td>tensor(1.2664, device='cuda:0')</td>\n",
       "      <td>tensor(18.2832, device='cuda:0')</td>\n",
       "      <td>tensor(0.4598, device='cuda:0')</td>\n",
       "      <td>0.063964</td>\n",
       "      <td>3.340774e-04</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>9.322339e-05</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.674278</td>\n",
       "      <td>236165.750000</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>3.017280e-06</td>\n",
       "      <td>2.051894e-02</td>\n",
       "      <td>1.470485e-04</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>61.638622</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>5407.433105</td>\n",
       "      <td>56981.671875</td>\n",
       "      <td>8.298201e+10</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>448.041016</td>\n",
       "      <td>46.059299</td>\n",
       "      <td>1.109678e-04</td>\n",
       "      <td>0.495667</td>\n",
       "      <td>2.511902</td>\n",
       "      <td>35.997787</td>\n",
       "      <td>127.983398</td>\n",
       "      <td>176.021484</td>\n",
       "      <td>5406.568359</td>\n",
       "      <td>tensor(10.5140, device='cuda:0')</td>\n",
       "      <td>tensor(0.2537, device='cuda:0')</td>\n",
       "      <td>tensor(22587.2969, device='cuda:0')</td>\n",
       "      <td>tensor(1243.1486, device='cuda:0')</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>2.248128e-05</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>1.169399e-04</td>\n",
       "      <td>0.011923</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.291489</td>\n",
       "      <td>239228.000000</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>3.023840e-06</td>\n",
       "      <td>-6.742522e-02</td>\n",
       "      <td>3.023840e+06</td>\n",
       "      <td>0.014170</td>\n",
       "      <td>62.437828</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>4406.362305</td>\n",
       "      <td>46007.796875</td>\n",
       "      <td>4.133502e+10</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>45.025131</td>\n",
       "      <td>6.357791e-04</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>2.744202</td>\n",
       "      <td>31.998016</td>\n",
       "      <td>128.001678</td>\n",
       "      <td>192.020508</td>\n",
       "      <td>4405.319336</td>\n",
       "      <td>tensor(13.9726, device='cuda:0')</td>\n",
       "      <td>tensor(0.3166, device='cuda:0')</td>\n",
       "      <td>tensor(72609.0625, device='cuda:0')</td>\n",
       "      <td>tensor(1066.7689, device='cuda:0')</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>3.024366e-04</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>1.462776e-04</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.223412</td>\n",
       "      <td>223178.593750</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.261310e-06</td>\n",
       "      <td>1.738634e-02</td>\n",
       "      <td>7.254606e-05</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>58.249008</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>5163.373047</td>\n",
       "      <td>48538.796875</td>\n",
       "      <td>1.991869e+10</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>448.037354</td>\n",
       "      <td>43.076241</td>\n",
       "      <td>1.679831e-05</td>\n",
       "      <td>0.564117</td>\n",
       "      <td>2.759705</td>\n",
       "      <td>31.999149</td>\n",
       "      <td>119.997650</td>\n",
       "      <td>176.002441</td>\n",
       "      <td>5162.484863</td>\n",
       "      <td>tensor(5.2357, device='cuda:0')</td>\n",
       "      <td>tensor(0.3117, device='cuda:0')</td>\n",
       "      <td>tensor(32460.4492, device='cuda:0')</td>\n",
       "      <td>tensor(1261.4333, device='cuda:0')</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>1.653466e-04</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>8.155032e-06</td>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>45.840549</td>\n",
       "      <td>162606.562500</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-1.813067e-06</td>\n",
       "      <td>-6.622984e-02</td>\n",
       "      <td>-1.813067e+06</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>80.025360</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>3547.221436</td>\n",
       "      <td>37411.636719</td>\n",
       "      <td>2.664015e+10</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>448.135742</td>\n",
       "      <td>57.219238</td>\n",
       "      <td>-9.910561e-04</td>\n",
       "      <td>0.635498</td>\n",
       "      <td>3.244751</td>\n",
       "      <td>39.982056</td>\n",
       "      <td>175.993958</td>\n",
       "      <td>255.963623</td>\n",
       "      <td>3546.243408</td>\n",
       "      <td>tensor(9.6800, device='cuda:0')</td>\n",
       "      <td>tensor(0.2917, device='cuda:0')</td>\n",
       "      <td>tensor(23673.7500, device='cuda:0')</td>\n",
       "      <td>tensor(1276.4473, device='cuda:0')</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>5.601079e-04</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>1.224874e-04</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>72.775063</td>\n",
       "      <td>346763.250000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>1.783787e-06</td>\n",
       "      <td>-3.087820e-02</td>\n",
       "      <td>1.783786e+06</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>104.505333</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>4764.863770</td>\n",
       "      <td>45184.449219</td>\n",
       "      <td>1.257064e+10</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>448.085449</td>\n",
       "      <td>82.734909</td>\n",
       "      <td>-1.828451e-05</td>\n",
       "      <td>1.264648</td>\n",
       "      <td>6.486694</td>\n",
       "      <td>71.976807</td>\n",
       "      <td>207.996353</td>\n",
       "      <td>287.978394</td>\n",
       "      <td>4763.919434</td>\n",
       "      <td>tensor(11.4444, device='cuda:0')</td>\n",
       "      <td>tensor(0.0303, device='cuda:0')</td>\n",
       "      <td>tensor(52744.7344, device='cuda:0')</td>\n",
       "      <td>tensor(281.4563, device='cuda:0')</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>4.030979e-04</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>5.648262e-05</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>41.863281</td>\n",
       "      <td>26.720890</td>\n",
       "      <td>1.566687</td>\n",
       "      <td>-1.596463e-04</td>\n",
       "      <td>-1.207755e-04</td>\n",
       "      <td>-1.596463e+08</td>\n",
       "      <td>0.030904</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>1.566696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>1.183551</td>\n",
       "      <td>7.063575</td>\n",
       "      <td>2.130708e+06</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>5.721314e-03</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.071442</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>0.363396</td>\n",
       "      <td>tensor(26.1319, device='cuda:0')</td>\n",
       "      <td>tensor(1.2379, device='cuda:0')</td>\n",
       "      <td>tensor(17.5274, device='cuda:0')</td>\n",
       "      <td>tensor(0.6244, device='cuda:0')</td>\n",
       "      <td>0.058605</td>\n",
       "      <td>2.931666e-04</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>4.330691e-05</td>\n",
       "      <td>0.062128</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.783043</td>\n",
       "      <td>240158.453125</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-2.821200e-06</td>\n",
       "      <td>3.617537e-03</td>\n",
       "      <td>-7.798676e-04</td>\n",
       "      <td>0.011427</td>\n",
       "      <td>62.680706</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>5485.193359</td>\n",
       "      <td>69517.117188</td>\n",
       "      <td>1.324713e+11</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>448.059814</td>\n",
       "      <td>46.030537</td>\n",
       "      <td>1.993600e-04</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>2.739319</td>\n",
       "      <td>35.991455</td>\n",
       "      <td>127.993927</td>\n",
       "      <td>192.010864</td>\n",
       "      <td>5484.255859</td>\n",
       "      <td>tensor(10.0300, device='cuda:0')</td>\n",
       "      <td>tensor(0.2771, device='cuda:0')</td>\n",
       "      <td>tensor(18962.4277, device='cuda:0')</td>\n",
       "      <td>tensor(1216.6095, device='cuda:0')</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>3.706485e-05</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>3.214202e-05</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>53.768604</td>\n",
       "      <td>257880.921875</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-7.959879e-06</td>\n",
       "      <td>-1.582177e-01</td>\n",
       "      <td>-7.959880e+06</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>67.306038</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>4796.124023</td>\n",
       "      <td>48101.644531</td>\n",
       "      <td>3.012361e+10</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>448.057373</td>\n",
       "      <td>48.837246</td>\n",
       "      <td>4.556970e-04</td>\n",
       "      <td>0.579468</td>\n",
       "      <td>2.993408</td>\n",
       "      <td>35.995239</td>\n",
       "      <td>143.993561</td>\n",
       "      <td>208.013306</td>\n",
       "      <td>4794.982422</td>\n",
       "      <td>tensor(15.9509, device='cuda:0')</td>\n",
       "      <td>tensor(0.3263, device='cuda:0')</td>\n",
       "      <td>tensor(106246.4297, device='cuda:0')</td>\n",
       "      <td>tensor(1193.6700, device='cuda:0')</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>5.098538e-04</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>3.034041e-05</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.861973</td>\n",
       "      <td>226822.234375</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-7.313890e-06</td>\n",
       "      <td>5.653849e-03</td>\n",
       "      <td>-1.293612e-03</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>59.199986</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>5291.922852</td>\n",
       "      <td>52456.207031</td>\n",
       "      <td>1.682926e+10</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>448.038818</td>\n",
       "      <td>43.042099</td>\n",
       "      <td>-3.289511e-04</td>\n",
       "      <td>0.556610</td>\n",
       "      <td>2.750534</td>\n",
       "      <td>31.993134</td>\n",
       "      <td>120.004333</td>\n",
       "      <td>191.995575</td>\n",
       "      <td>5290.937500</td>\n",
       "      <td>tensor(4.6399, device='cuda:0')</td>\n",
       "      <td>tensor(0.3127, device='cuda:0')</td>\n",
       "      <td>tensor(25293.5605, device='cuda:0')</td>\n",
       "      <td>tensor(1307.9918, device='cuda:0')</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>1.902691e-07</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>9.553224e-06</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.777794</td>\n",
       "      <td>144451.828125</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>1.207770e-06</td>\n",
       "      <td>4.197418e-02</td>\n",
       "      <td>2.877413e-05</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>71.090698</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>2736.980469</td>\n",
       "      <td>23214.568359</td>\n",
       "      <td>3.817749e+09</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>448.077148</td>\n",
       "      <td>51.204514</td>\n",
       "      <td>6.761709e-04</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>2.983276</td>\n",
       "      <td>36.001892</td>\n",
       "      <td>144.049561</td>\n",
       "      <td>223.999252</td>\n",
       "      <td>2736.013428</td>\n",
       "      <td>tensor(9.0613, device='cuda:0')</td>\n",
       "      <td>tensor(0.4277, device='cuda:0')</td>\n",
       "      <td>tensor(18433.9844, device='cuda:0')</td>\n",
       "      <td>tensor(835.9100, device='cuda:0')</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>8.734912e-05</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>7.414701e-05</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>66.715645</td>\n",
       "      <td>338362.750000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-2.672746e-06</td>\n",
       "      <td>1.946198e-02</td>\n",
       "      <td>-1.373317e-04</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>101.973648</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>5071.715332</td>\n",
       "      <td>54636.542969</td>\n",
       "      <td>1.917753e+10</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>448.073730</td>\n",
       "      <td>80.585632</td>\n",
       "      <td>3.964597e-04</td>\n",
       "      <td>1.244110</td>\n",
       "      <td>6.029785</td>\n",
       "      <td>64.021484</td>\n",
       "      <td>207.976685</td>\n",
       "      <td>256.035645</td>\n",
       "      <td>5071.012207</td>\n",
       "      <td>tensor(15.6541, device='cuda:0')</td>\n",
       "      <td>tensor(0.0278, device='cuda:0')</td>\n",
       "      <td>tensor(52921.0703, device='cuda:0')</td>\n",
       "      <td>tensor(287.5673, device='cuda:0')</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>6.230515e-06</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>4.414003e-05</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.910725</td>\n",
       "      <td>25.972263</td>\n",
       "      <td>1.575170</td>\n",
       "      <td>-1.012390e-04</td>\n",
       "      <td>-1.808002e-04</td>\n",
       "      <td>-1.012390e+08</td>\n",
       "      <td>0.030201</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>1.575231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>1.182441</td>\n",
       "      <td>14.109981</td>\n",
       "      <td>1.452872e+07</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>4.338760e-03</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.366468</td>\n",
       "      <td>tensor(25.7136, device='cuda:0')</td>\n",
       "      <td>tensor(1.0957, device='cuda:0')</td>\n",
       "      <td>tensor(17.0027, device='cuda:0')</td>\n",
       "      <td>tensor(0.6454, device='cuda:0')</td>\n",
       "      <td>0.057581</td>\n",
       "      <td>6.670345e-04</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>2.948388e-05</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.287209</td>\n",
       "      <td>260490.750000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>1.819590e-06</td>\n",
       "      <td>2.766303e-03</td>\n",
       "      <td>6.577697e-04</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>67.987389</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>6160.037109</td>\n",
       "      <td>69636.281250</td>\n",
       "      <td>1.699728e+11</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>448.039795</td>\n",
       "      <td>50.225204</td>\n",
       "      <td>-1.212179e-04</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>2.749714</td>\n",
       "      <td>39.973511</td>\n",
       "      <td>143.992279</td>\n",
       "      <td>208.003357</td>\n",
       "      <td>6159.307617</td>\n",
       "      <td>tensor(9.3290, device='cuda:0')</td>\n",
       "      <td>tensor(0.2280, device='cuda:0')</td>\n",
       "      <td>tensor(19675.5352, device='cuda:0')</td>\n",
       "      <td>tensor(1432.4521, device='cuda:0')</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>1.416054e-04</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>2.205350e-04</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>0.022037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>54.979279</td>\n",
       "      <td>266612.125000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>2.148646e-05</td>\n",
       "      <td>-2.301417e-01</td>\n",
       "      <td>2.148646e+07</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>69.584663</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>4849.319824</td>\n",
       "      <td>48564.054688</td>\n",
       "      <td>2.987803e+10</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>448.063477</td>\n",
       "      <td>50.489311</td>\n",
       "      <td>6.598887e-04</td>\n",
       "      <td>0.614563</td>\n",
       "      <td>3.006714</td>\n",
       "      <td>36.004059</td>\n",
       "      <td>144.005737</td>\n",
       "      <td>223.991211</td>\n",
       "      <td>4848.220703</td>\n",
       "      <td>tensor(12.2271, device='cuda:0')</td>\n",
       "      <td>tensor(0.3242, device='cuda:0')</td>\n",
       "      <td>tensor(111574.5156, device='cuda:0')</td>\n",
       "      <td>tensor(1224.0015, device='cuda:0')</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>3.551633e-04</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>2.138221e-05</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.763363</td>\n",
       "      <td>242888.062500</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-7.760198e-07</td>\n",
       "      <td>-1.859942e-02</td>\n",
       "      <td>-7.760198e+05</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>63.393131</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>5815.816895</td>\n",
       "      <td>60397.398438</td>\n",
       "      <td>4.474757e+10</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>448.040771</td>\n",
       "      <td>46.630215</td>\n",
       "      <td>-2.742977e-05</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>3.003830</td>\n",
       "      <td>35.991699</td>\n",
       "      <td>128.001282</td>\n",
       "      <td>192.011719</td>\n",
       "      <td>5814.898438</td>\n",
       "      <td>tensor(4.7878, device='cuda:0')</td>\n",
       "      <td>tensor(0.3095, device='cuda:0')</td>\n",
       "      <td>tensor(27845.4316, device='cuda:0')</td>\n",
       "      <td>tensor(1474.0465, device='cuda:0')</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>1.970258e-05</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>1.771758e-05</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>46.789642</td>\n",
       "      <td>136687.203125</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>6.802001e-06</td>\n",
       "      <td>-2.692598e-02</td>\n",
       "      <td>6.802002e+06</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>67.269402</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>2921.314209</td>\n",
       "      <td>28729.501953</td>\n",
       "      <td>1.627567e+10</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>448.094727</td>\n",
       "      <td>47.985260</td>\n",
       "      <td>-6.119655e-04</td>\n",
       "      <td>0.474365</td>\n",
       "      <td>2.467285</td>\n",
       "      <td>32.010681</td>\n",
       "      <td>143.998413</td>\n",
       "      <td>208.005554</td>\n",
       "      <td>2920.317627</td>\n",
       "      <td>tensor(10.4902, device='cuda:0')</td>\n",
       "      <td>tensor(0.2597, device='cuda:0')</td>\n",
       "      <td>tensor(18796.9766, device='cuda:0')</td>\n",
       "      <td>tensor(986.0127, device='cuda:0')</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>1.280727e-04</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>3.891859e-05</td>\n",
       "      <td>0.041840</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>61.593723</td>\n",
       "      <td>343426.281250</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-1.184558e-05</td>\n",
       "      <td>4.968539e-02</td>\n",
       "      <td>-2.384118e-04</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>103.499649</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>5575.669922</td>\n",
       "      <td>72250.726562</td>\n",
       "      <td>7.156584e+10</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>448.057129</td>\n",
       "      <td>81.831963</td>\n",
       "      <td>1.884710e-06</td>\n",
       "      <td>1.253776</td>\n",
       "      <td>6.474609</td>\n",
       "      <td>71.963623</td>\n",
       "      <td>207.992218</td>\n",
       "      <td>287.976318</td>\n",
       "      <td>5574.845703</td>\n",
       "      <td>tensor(10.6947, device='cuda:0')</td>\n",
       "      <td>tensor(0.0209, device='cuda:0')</td>\n",
       "      <td>tensor(51019.8320, device='cuda:0')</td>\n",
       "      <td>tensor(425.2454, device='cuda:0')</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>2.304637e-04</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>3.246274e-06</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>40.967010</td>\n",
       "      <td>25.516438</td>\n",
       "      <td>1.605515</td>\n",
       "      <td>-1.089947e-04</td>\n",
       "      <td>-1.687905e-04</td>\n",
       "      <td>-1.089947e+08</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>1.605569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>1.174486</td>\n",
       "      <td>8.580814</td>\n",
       "      <td>2.498458e+06</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>8.459683e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023491</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>tensor(25.9593, device='cuda:0')</td>\n",
       "      <td>tensor(1.2159, device='cuda:0')</td>\n",
       "      <td>tensor(16.7475, device='cuda:0')</td>\n",
       "      <td>tensor(0.6265, device='cuda:0')</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>1.151491e-04</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>3.919038e-05</td>\n",
       "      <td>0.062957</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.911053</td>\n",
       "      <td>266518.906250</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-5.961533e-06</td>\n",
       "      <td>6.079135e-03</td>\n",
       "      <td>-9.806550e-04</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>69.560707</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>6359.155762</td>\n",
       "      <td>82208.375000</td>\n",
       "      <td>3.190293e+11</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>448.044678</td>\n",
       "      <td>51.970615</td>\n",
       "      <td>-1.642748e-04</td>\n",
       "      <td>0.559769</td>\n",
       "      <td>2.989624</td>\n",
       "      <td>40.000893</td>\n",
       "      <td>143.997330</td>\n",
       "      <td>208.004883</td>\n",
       "      <td>6358.343262</td>\n",
       "      <td>tensor(8.8961, device='cuda:0')</td>\n",
       "      <td>tensor(0.2667, device='cuda:0')</td>\n",
       "      <td>tensor(21914.2793, device='cuda:0')</td>\n",
       "      <td>tensor(1514.9797, device='cuda:0')</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>1.614827e-04</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>2.200030e-05</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.824352</td>\n",
       "      <td>265747.937500</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-6.168965e-06</td>\n",
       "      <td>-2.367010e-01</td>\n",
       "      <td>-6.168965e+06</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>69.359093</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>4760.429199</td>\n",
       "      <td>46493.609375</td>\n",
       "      <td>8.975605e+10</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>448.061279</td>\n",
       "      <td>50.315189</td>\n",
       "      <td>7.506667e-04</td>\n",
       "      <td>0.612183</td>\n",
       "      <td>3.003387</td>\n",
       "      <td>36.003143</td>\n",
       "      <td>144.004578</td>\n",
       "      <td>223.988892</td>\n",
       "      <td>4759.201172</td>\n",
       "      <td>tensor(12.5823, device='cuda:0')</td>\n",
       "      <td>tensor(0.3174, device='cuda:0')</td>\n",
       "      <td>tensor(111422.4453, device='cuda:0')</td>\n",
       "      <td>tensor(925.5266, device='cuda:0')</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>2.325664e-04</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>6.317366e-07</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.388466</td>\n",
       "      <td>241293.421875</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-4.853365e-06</td>\n",
       "      <td>1.312750e-04</td>\n",
       "      <td>-3.697098e-02</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>62.976933</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>5829.967285</td>\n",
       "      <td>65039.093750</td>\n",
       "      <td>6.214631e+10</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>448.044434</td>\n",
       "      <td>46.345890</td>\n",
       "      <td>3.700178e-04</td>\n",
       "      <td>0.613525</td>\n",
       "      <td>3.002823</td>\n",
       "      <td>35.989441</td>\n",
       "      <td>127.999931</td>\n",
       "      <td>192.007690</td>\n",
       "      <td>5828.971680</td>\n",
       "      <td>tensor(4.3793, device='cuda:0')</td>\n",
       "      <td>tensor(0.3074, device='cuda:0')</td>\n",
       "      <td>tensor(29768.1719, device='cuda:0')</td>\n",
       "      <td>tensor(1483.9000, device='cuda:0')</td>\n",
       "      <td>0.017942</td>\n",
       "      <td>8.328965e-04</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>2.317139e-04</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>44.699005</td>\n",
       "      <td>184263.796875</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-4.431110e-06</td>\n",
       "      <td>-9.210092e-02</td>\n",
       "      <td>-4.431110e+06</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>90.683762</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>4122.324707</td>\n",
       "      <td>40340.566406</td>\n",
       "      <td>1.304800e+10</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>448.097656</td>\n",
       "      <td>66.549110</td>\n",
       "      <td>-3.216275e-04</td>\n",
       "      <td>0.693319</td>\n",
       "      <td>3.495403</td>\n",
       "      <td>47.993896</td>\n",
       "      <td>191.999619</td>\n",
       "      <td>256.011230</td>\n",
       "      <td>4121.309082</td>\n",
       "      <td>tensor(10.0276, device='cuda:0')</td>\n",
       "      <td>tensor(0.2170, device='cuda:0')</td>\n",
       "      <td>tensor(21571.7891, device='cuda:0')</td>\n",
       "      <td>tensor(802.8763, device='cuda:0')</td>\n",
       "      <td>0.035519</td>\n",
       "      <td>4.844767e-04</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>6.252765e-05</td>\n",
       "      <td>0.040529</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>54.549786</td>\n",
       "      <td>348280.156250</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3.629224e-06</td>\n",
       "      <td>-2.747159e-02</td>\n",
       "      <td>3.629224e+06</td>\n",
       "      <td>0.016440</td>\n",
       "      <td>104.962486</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>6384.629395</td>\n",
       "      <td>76075.992188</td>\n",
       "      <td>3.123613e+10</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>448.061768</td>\n",
       "      <td>83.202171</td>\n",
       "      <td>1.685682e-04</td>\n",
       "      <td>1.264465</td>\n",
       "      <td>6.495850</td>\n",
       "      <td>71.988403</td>\n",
       "      <td>207.998962</td>\n",
       "      <td>287.985840</td>\n",
       "      <td>6383.861816</td>\n",
       "      <td>tensor(10.4516, device='cuda:0')</td>\n",
       "      <td>tensor(0.0182, device='cuda:0')</td>\n",
       "      <td>tensor(55123.1797, device='cuda:0')</td>\n",
       "      <td>tensor(302.8674, device='cuda:0')</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>9.033222e-04</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>9.525313e-05</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>41.393047</td>\n",
       "      <td>24.754883</td>\n",
       "      <td>1.672117</td>\n",
       "      <td>-9.340945e-05</td>\n",
       "      <td>-1.160686e-04</td>\n",
       "      <td>-9.340945e+07</td>\n",
       "      <td>0.030557</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>1.672143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>1.162253</td>\n",
       "      <td>4.913018</td>\n",
       "      <td>1.075075e+05</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.497725</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>6.839227e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>0.069397</td>\n",
       "      <td>0.093384</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>tensor(25.8360, device='cuda:0')</td>\n",
       "      <td>tensor(1.2207, device='cuda:0')</td>\n",
       "      <td>tensor(15.9157, device='cuda:0')</td>\n",
       "      <td>tensor(0.6022, device='cuda:0')</td>\n",
       "      <td>0.057833</td>\n",
       "      <td>4.030301e-04</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>1.404873e-04</td>\n",
       "      <td>0.062070</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.868046</td>\n",
       "      <td>264151.750000</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>2.065495e-06</td>\n",
       "      <td>-8.322178e-03</td>\n",
       "      <td>2.065495e+06</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>68.942902</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>6309.149414</td>\n",
       "      <td>68588.726562</td>\n",
       "      <td>6.731704e+10</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>448.050293</td>\n",
       "      <td>51.094738</td>\n",
       "      <td>4.490079e-04</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>2.753357</td>\n",
       "      <td>39.991760</td>\n",
       "      <td>143.997162</td>\n",
       "      <td>208.006226</td>\n",
       "      <td>6308.447754</td>\n",
       "      <td>tensor(10.8229, device='cuda:0')</td>\n",
       "      <td>tensor(0.2358, device='cuda:0')</td>\n",
       "      <td>tensor(22331.1562, device='cuda:0')</td>\n",
       "      <td>tensor(1222.7699, device='cuda:0')</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>4.750127e-05</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>4.457620e-05</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.572136</td>\n",
       "      <td>269599.500000</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-9.959461e-08</td>\n",
       "      <td>-1.904464e-01</td>\n",
       "      <td>-9.959461e+04</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>70.364494</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>4851.342773</td>\n",
       "      <td>59792.234375</td>\n",
       "      <td>5.577233e+10</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>448.049805</td>\n",
       "      <td>51.351974</td>\n",
       "      <td>7.915903e-04</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>3.238525</td>\n",
       "      <td>36.014771</td>\n",
       "      <td>144.008667</td>\n",
       "      <td>223.993042</td>\n",
       "      <td>4850.221191</td>\n",
       "      <td>tensor(12.2919, device='cuda:0')</td>\n",
       "      <td>tensor(0.3040, device='cuda:0')</td>\n",
       "      <td>tensor(113972.4375, device='cuda:0')</td>\n",
       "      <td>tensor(1106.0845, device='cuda:0')</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>1.244578e-04</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>9.054493e-05</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.009579</td>\n",
       "      <td>243532.406250</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>2.872873e-07</td>\n",
       "      <td>-1.776119e-02</td>\n",
       "      <td>2.872873e+05</td>\n",
       "      <td>0.010964</td>\n",
       "      <td>63.561302</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>5797.069336</td>\n",
       "      <td>157433.500000</td>\n",
       "      <td>1.297784e+12</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>448.033936</td>\n",
       "      <td>46.773361</td>\n",
       "      <td>-4.251097e-04</td>\n",
       "      <td>0.620972</td>\n",
       "      <td>3.007544</td>\n",
       "      <td>35.992798</td>\n",
       "      <td>128.002625</td>\n",
       "      <td>192.015991</td>\n",
       "      <td>5796.203125</td>\n",
       "      <td>tensor(5.8122, device='cuda:0')</td>\n",
       "      <td>tensor(0.3093, device='cuda:0')</td>\n",
       "      <td>tensor(33630.3906, device='cuda:0')</td>\n",
       "      <td>tensor(1413.1527, device='cuda:0')</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>4.012492e-05</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>2.180876e-04</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.209965</td>\n",
       "      <td>172654.687500</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>-3.225490e-06</td>\n",
       "      <td>2.155166e-02</td>\n",
       "      <td>-1.496631e-04</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>84.970497</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>3995.715332</td>\n",
       "      <td>56327.046875</td>\n",
       "      <td>3.509080e+10</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>448.077637</td>\n",
       "      <td>62.526688</td>\n",
       "      <td>-4.013054e-05</td>\n",
       "      <td>0.690928</td>\n",
       "      <td>3.497015</td>\n",
       "      <td>44.019165</td>\n",
       "      <td>176.009155</td>\n",
       "      <td>255.982788</td>\n",
       "      <td>3994.631348</td>\n",
       "      <td>tensor(10.3821, device='cuda:0')</td>\n",
       "      <td>tensor(0.4347, device='cuda:0')</td>\n",
       "      <td>tensor(25700.1016, device='cuda:0')</td>\n",
       "      <td>tensor(1030.2719, device='cuda:0')</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>6.470664e-05</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>7.817513e-05</td>\n",
       "      <td>0.039423</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>55.441502</td>\n",
       "      <td>345941.156250</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-6.610821e-06</td>\n",
       "      <td>-3.157791e-03</td>\n",
       "      <td>-6.610822e+06</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>104.257576</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>6239.751465</td>\n",
       "      <td>85830.742188</td>\n",
       "      <td>7.156584e+10</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>448.078613</td>\n",
       "      <td>82.545204</td>\n",
       "      <td>-1.167669e-04</td>\n",
       "      <td>1.255890</td>\n",
       "      <td>6.488159</td>\n",
       "      <td>71.981812</td>\n",
       "      <td>207.996201</td>\n",
       "      <td>287.983276</td>\n",
       "      <td>6239.253418</td>\n",
       "      <td>tensor(9.9172, device='cuda:0')</td>\n",
       "      <td>tensor(0.0333, device='cuda:0')</td>\n",
       "      <td>tensor(55082.1211, device='cuda:0')</td>\n",
       "      <td>tensor(277.5867, device='cuda:0')</td>\n",
       "      <td>0.022478</td>\n",
       "      <td>2.531880e-04</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>2.241857e-05</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>39.940376</td>\n",
       "      <td>24.357220</td>\n",
       "      <td>1.639776</td>\n",
       "      <td>-1.819975e-04</td>\n",
       "      <td>-1.049985e-04</td>\n",
       "      <td>-1.819975e+08</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>1.639772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>1.169132</td>\n",
       "      <td>12.287910</td>\n",
       "      <td>1.018355e+07</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.515320</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>5.296745e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.022797</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.090515</td>\n",
       "      <td>0.390967</td>\n",
       "      <td>tensor(24.8836, device='cuda:0')</td>\n",
       "      <td>tensor(0.8439, device='cuda:0')</td>\n",
       "      <td>tensor(15.7200, device='cuda:0')</td>\n",
       "      <td>tensor(0.6150, device='cuda:0')</td>\n",
       "      <td>0.054628</td>\n",
       "      <td>4.109248e-04</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>3.294628e-06</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.579712</td>\n",
       "      <td>258156.953125</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-3.709344e-06</td>\n",
       "      <td>-3.467460e-02</td>\n",
       "      <td>-3.709344e+06</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>67.378258</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>6208.724121</td>\n",
       "      <td>59561.312500</td>\n",
       "      <td>2.342709e+10</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>448.036865</td>\n",
       "      <td>49.717842</td>\n",
       "      <td>-1.167812e-04</td>\n",
       "      <td>0.517456</td>\n",
       "      <td>2.748688</td>\n",
       "      <td>36.012329</td>\n",
       "      <td>143.991028</td>\n",
       "      <td>208.000671</td>\n",
       "      <td>6207.842285</td>\n",
       "      <td>tensor(9.2425, device='cuda:0')</td>\n",
       "      <td>tensor(0.2751, device='cuda:0')</td>\n",
       "      <td>tensor(20928.5957, device='cuda:0')</td>\n",
       "      <td>tensor(1156.3484, device='cuda:0')</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5.248255e-05</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>1.739248e-04</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>55.334579</td>\n",
       "      <td>266024.468750</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-2.191403e-05</td>\n",
       "      <td>-1.845903e-01</td>\n",
       "      <td>-2.191403e+07</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>69.431419</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>4807.561523</td>\n",
       "      <td>55200.367188</td>\n",
       "      <td>5.186376e+10</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>50.322086</td>\n",
       "      <td>1.110060e-03</td>\n",
       "      <td>0.610413</td>\n",
       "      <td>3.004761</td>\n",
       "      <td>36.002411</td>\n",
       "      <td>144.005402</td>\n",
       "      <td>223.991272</td>\n",
       "      <td>4806.309570</td>\n",
       "      <td>tensor(13.4124, device='cuda:0')</td>\n",
       "      <td>tensor(0.3350, device='cuda:0')</td>\n",
       "      <td>tensor(113269.5703, device='cuda:0')</td>\n",
       "      <td>tensor(759.3851, device='cuda:0')</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>1.790393e-04</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>2.128836e-04</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.802856</td>\n",
       "      <td>238225.250000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>7.321877e-07</td>\n",
       "      <td>-1.483387e-03</td>\n",
       "      <td>7.321878e+05</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>62.176151</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>5838.445801</td>\n",
       "      <td>123184.773438</td>\n",
       "      <td>8.747496e+11</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>448.036377</td>\n",
       "      <td>45.715626</td>\n",
       "      <td>2.584271e-04</td>\n",
       "      <td>0.605957</td>\n",
       "      <td>2.998970</td>\n",
       "      <td>35.983398</td>\n",
       "      <td>127.995636</td>\n",
       "      <td>192.005768</td>\n",
       "      <td>5837.430664</td>\n",
       "      <td>tensor(4.0343, device='cuda:0')</td>\n",
       "      <td>tensor(0.3159, device='cuda:0')</td>\n",
       "      <td>tensor(30227.0391, device='cuda:0')</td>\n",
       "      <td>tensor(1434.9103, device='cuda:0')</td>\n",
       "      <td>0.020795</td>\n",
       "      <td>7.465455e-05</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>1.317907e-04</td>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.474453</td>\n",
       "      <td>162472.593750</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>5.950097e-06</td>\n",
       "      <td>5.554332e-02</td>\n",
       "      <td>1.071253e-04</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>79.959450</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>3096.222656</td>\n",
       "      <td>29731.494141</td>\n",
       "      <td>1.278502e+10</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>448.141602</td>\n",
       "      <td>57.190922</td>\n",
       "      <td>3.464538e-04</td>\n",
       "      <td>0.636658</td>\n",
       "      <td>3.230347</td>\n",
       "      <td>39.986267</td>\n",
       "      <td>175.991638</td>\n",
       "      <td>255.967529</td>\n",
       "      <td>3095.226562</td>\n",
       "      <td>tensor(9.1672, device='cuda:0')</td>\n",
       "      <td>tensor(0.3530, device='cuda:0')</td>\n",
       "      <td>tensor(19608.1230, device='cuda:0')</td>\n",
       "      <td>tensor(944.1569, device='cuda:0')</td>\n",
       "      <td>0.034502</td>\n",
       "      <td>2.514485e-04</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>1.390895e-04</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>73.557915</td>\n",
       "      <td>340124.093750</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-1.052833e-05</td>\n",
       "      <td>3.655579e-02</td>\n",
       "      <td>-2.880072e-04</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>102.504456</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>4623.895508</td>\n",
       "      <td>53108.781250</td>\n",
       "      <td>7.186351e+10</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>448.081055</td>\n",
       "      <td>81.018059</td>\n",
       "      <td>2.196512e-04</td>\n",
       "      <td>1.249262</td>\n",
       "      <td>6.046143</td>\n",
       "      <td>64.031738</td>\n",
       "      <td>207.981079</td>\n",
       "      <td>256.065918</td>\n",
       "      <td>4623.017090</td>\n",
       "      <td>tensor(14.2350, device='cuda:0')</td>\n",
       "      <td>tensor(0.0285, device='cuda:0')</td>\n",
       "      <td>tensor(52513.4023, device='cuda:0')</td>\n",
       "      <td>tensor(301.4102, device='cuda:0')</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>5.901469e-04</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>4.513282e-04</td>\n",
       "      <td>0.025662</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>39.181675</td>\n",
       "      <td>23.561365</td>\n",
       "      <td>1.662963</td>\n",
       "      <td>-1.531837e-04</td>\n",
       "      <td>-1.507561e-04</td>\n",
       "      <td>-1.531837e+08</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>1.663002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>1.164390</td>\n",
       "      <td>7.146149</td>\n",
       "      <td>1.054305e+06</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.406006</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>6.245933e-03</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.065796</td>\n",
       "      <td>0.088257</td>\n",
       "      <td>0.399446</td>\n",
       "      <td>tensor(24.8240, device='cuda:0')</td>\n",
       "      <td>tensor(1.1101, device='cuda:0')</td>\n",
       "      <td>tensor(15.3637, device='cuda:0')</td>\n",
       "      <td>tensor(0.5136, device='cuda:0')</td>\n",
       "      <td>0.060453</td>\n",
       "      <td>4.498538e-04</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>1.654910e-04</td>\n",
       "      <td>0.062268</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.402748</td>\n",
       "      <td>274071.906250</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-3.844635e-06</td>\n",
       "      <td>6.481429e-03</td>\n",
       "      <td>-5.931771e-04</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>71.532028</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>6463.541016</td>\n",
       "      <td>116853.351562</td>\n",
       "      <td>4.435005e+11</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>448.032959</td>\n",
       "      <td>53.563866</td>\n",
       "      <td>4.448465e-05</td>\n",
       "      <td>0.559662</td>\n",
       "      <td>2.993866</td>\n",
       "      <td>40.010132</td>\n",
       "      <td>144.004913</td>\n",
       "      <td>208.011780</td>\n",
       "      <td>6462.721680</td>\n",
       "      <td>tensor(11.1681, device='cuda:0')</td>\n",
       "      <td>tensor(0.2780, device='cuda:0')</td>\n",
       "      <td>tensor(25004.5664, device='cuda:0')</td>\n",
       "      <td>tensor(1187.7864, device='cuda:0')</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>6.036117e-05</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>4.774121e-04</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>57.039303</td>\n",
       "      <td>263386.218750</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-4.383844e-06</td>\n",
       "      <td>-2.694015e-01</td>\n",
       "      <td>-4.383844e+06</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>68.742569</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>4617.626465</td>\n",
       "      <td>46510.121094</td>\n",
       "      <td>2.350930e+10</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>448.064453</td>\n",
       "      <td>49.847744</td>\n",
       "      <td>9.679577e-04</td>\n",
       "      <td>0.607666</td>\n",
       "      <td>3.001869</td>\n",
       "      <td>36.001144</td>\n",
       "      <td>144.001587</td>\n",
       "      <td>223.986389</td>\n",
       "      <td>4616.555664</td>\n",
       "      <td>tensor(14.4037, device='cuda:0')</td>\n",
       "      <td>tensor(0.3481, device='cuda:0')</td>\n",
       "      <td>tensor(101810.4688, device='cuda:0')</td>\n",
       "      <td>tensor(958.1579, device='cuda:0')</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>3.292871e-05</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>7.031342e-05</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.339771</td>\n",
       "      <td>250485.078125</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>3.685792e-07</td>\n",
       "      <td>5.844287e-03</td>\n",
       "      <td>6.306659e-05</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>65.375931</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>6059.179688</td>\n",
       "      <td>67946.906250</td>\n",
       "      <td>5.235770e+10</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>48.745476</td>\n",
       "      <td>1.663517e-05</td>\n",
       "      <td>0.645874</td>\n",
       "      <td>3.253784</td>\n",
       "      <td>36.008606</td>\n",
       "      <td>128.009705</td>\n",
       "      <td>192.014893</td>\n",
       "      <td>6058.180664</td>\n",
       "      <td>tensor(5.4343, device='cuda:0')</td>\n",
       "      <td>tensor(0.3239, device='cuda:0')</td>\n",
       "      <td>tensor(33316.6367, device='cuda:0')</td>\n",
       "      <td>tensor(1547.9927, device='cuda:0')</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>2.817766e-04</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>1.944273e-04</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>52.515038</td>\n",
       "      <td>160357.781250</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>7.729338e-06</td>\n",
       "      <td>-2.947754e-02</td>\n",
       "      <td>7.729338e+06</td>\n",
       "      <td>0.025845</td>\n",
       "      <td>78.918671</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3053.559326</td>\n",
       "      <td>40286.941406</td>\n",
       "      <td>4.106060e+10</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>448.089844</td>\n",
       "      <td>58.321678</td>\n",
       "      <td>-1.388629e-04</td>\n",
       "      <td>0.687287</td>\n",
       "      <td>3.481445</td>\n",
       "      <td>43.978149</td>\n",
       "      <td>160.019897</td>\n",
       "      <td>239.973022</td>\n",
       "      <td>3052.552490</td>\n",
       "      <td>tensor(11.8999, device='cuda:0')</td>\n",
       "      <td>tensor(0.2808, device='cuda:0')</td>\n",
       "      <td>tensor(29434.5645, device='cuda:0')</td>\n",
       "      <td>tensor(890.7657, device='cuda:0')</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>3.120405e-04</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>1.038434e-04</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>63.924370</td>\n",
       "      <td>347385.187500</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>3.315716e-07</td>\n",
       "      <td>-3.104924e-02</td>\n",
       "      <td>3.315717e+05</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>104.692764</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>5434.315918</td>\n",
       "      <td>55110.109375</td>\n",
       "      <td>1.520062e+10</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>448.083496</td>\n",
       "      <td>82.653221</td>\n",
       "      <td>-6.724389e-04</td>\n",
       "      <td>1.256500</td>\n",
       "      <td>6.479736</td>\n",
       "      <td>71.973999</td>\n",
       "      <td>208.000305</td>\n",
       "      <td>287.987549</td>\n",
       "      <td>5433.369141</td>\n",
       "      <td>tensor(11.1134, device='cuda:0')</td>\n",
       "      <td>tensor(0.0179, device='cuda:0')</td>\n",
       "      <td>tensor(51368.3398, device='cuda:0')</td>\n",
       "      <td>tensor(306.4969, device='cuda:0')</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>5.141289e-04</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>4.274285e-05</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>38.341373</td>\n",
       "      <td>23.653309</td>\n",
       "      <td>1.620973</td>\n",
       "      <td>-1.386354e-04</td>\n",
       "      <td>-1.537078e-04</td>\n",
       "      <td>-1.386354e+08</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>0.017460</td>\n",
       "      <td>1.621016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>1.171178</td>\n",
       "      <td>5.952379</td>\n",
       "      <td>5.672131e+05</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.416016</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>8.420032e-03</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.383349</td>\n",
       "      <td>tensor(24.0870, device='cuda:0')</td>\n",
       "      <td>tensor(0.9062, device='cuda:0')</td>\n",
       "      <td>tensor(15.0024, device='cuda:0')</td>\n",
       "      <td>tensor(0.6519, device='cuda:0')</td>\n",
       "      <td>0.055274</td>\n",
       "      <td>3.831508e-05</td>\n",
       "      <td>0.010296</td>\n",
       "      <td>3.229414e-06</td>\n",
       "      <td>0.061770</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.682983</td>\n",
       "      <td>258502.312500</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>1.346152e-06</td>\n",
       "      <td>-1.024971e-02</td>\n",
       "      <td>1.346152e+06</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>67.468399</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>6056.332031</td>\n",
       "      <td>65280.046875</td>\n",
       "      <td>7.036875e+10</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>448.035400</td>\n",
       "      <td>49.505333</td>\n",
       "      <td>7.916406e-05</td>\n",
       "      <td>0.513367</td>\n",
       "      <td>2.745636</td>\n",
       "      <td>36.005402</td>\n",
       "      <td>143.993927</td>\n",
       "      <td>208.001312</td>\n",
       "      <td>6055.370117</td>\n",
       "      <td>tensor(10.2170, device='cuda:0')</td>\n",
       "      <td>tensor(0.3027, device='cuda:0')</td>\n",
       "      <td>tensor(26607.0176, device='cuda:0')</td>\n",
       "      <td>tensor(836.8721, device='cuda:0')</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>9.331518e-05</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>2.683627e-05</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>56.438549</td>\n",
       "      <td>267154.718750</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-2.579942e-05</td>\n",
       "      <td>-3.413542e-01</td>\n",
       "      <td>-2.579942e+07</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>69.725830</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>4733.549805</td>\n",
       "      <td>67106.992188</td>\n",
       "      <td>1.851809e+11</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>448.052246</td>\n",
       "      <td>50.594616</td>\n",
       "      <td>6.921013e-04</td>\n",
       "      <td>0.624485</td>\n",
       "      <td>3.031494</td>\n",
       "      <td>36.005768</td>\n",
       "      <td>144.006348</td>\n",
       "      <td>223.996689</td>\n",
       "      <td>4732.395020</td>\n",
       "      <td>tensor(14.1978, device='cuda:0')</td>\n",
       "      <td>tensor(0.3566, device='cuda:0')</td>\n",
       "      <td>tensor(100312.7344, device='cuda:0')</td>\n",
       "      <td>tensor(1080.0212, device='cuda:0')</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>8.919198e-05</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>4.383679e-05</td>\n",
       "      <td>0.023145</td>\n",
       "      <td>0.012011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.821194</td>\n",
       "      <td>253036.984375</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.576601e-06</td>\n",
       "      <td>3.249281e-03</td>\n",
       "      <td>4.852152e-04</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>66.041969</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>6198.667480</td>\n",
       "      <td>72974.531250</td>\n",
       "      <td>7.635498e+10</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>448.035889</td>\n",
       "      <td>48.948296</td>\n",
       "      <td>-2.343239e-04</td>\n",
       "      <td>0.631744</td>\n",
       "      <td>3.246155</td>\n",
       "      <td>36.006409</td>\n",
       "      <td>128.019897</td>\n",
       "      <td>207.990601</td>\n",
       "      <td>6197.644531</td>\n",
       "      <td>tensor(4.2513, device='cuda:0')</td>\n",
       "      <td>tensor(0.3159, device='cuda:0')</td>\n",
       "      <td>tensor(33053.0625, device='cuda:0')</td>\n",
       "      <td>tensor(1500.3104, device='cuda:0')</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>1.194930e-04</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>1.317188e-04</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.905533</td>\n",
       "      <td>180060.421875</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.503743e-05</td>\n",
       "      <td>-3.311199e-02</td>\n",
       "      <td>1.503743e+07</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>88.615150</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>3758.656006</td>\n",
       "      <td>43898.667969</td>\n",
       "      <td>1.727804e+10</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>448.126953</td>\n",
       "      <td>65.467949</td>\n",
       "      <td>-1.291276e-04</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>3.531738</td>\n",
       "      <td>47.992218</td>\n",
       "      <td>191.977051</td>\n",
       "      <td>255.996140</td>\n",
       "      <td>3757.696045</td>\n",
       "      <td>tensor(10.3536, device='cuda:0')</td>\n",
       "      <td>tensor(0.3800, device='cuda:0')</td>\n",
       "      <td>tensor(27422.1973, device='cuda:0')</td>\n",
       "      <td>tensor(904.6476, device='cuda:0')</td>\n",
       "      <td>0.032327</td>\n",
       "      <td>7.373513e-05</td>\n",
       "      <td>0.008962</td>\n",
       "      <td>9.850677e-05</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.010201</td>\n",
       "      <td>335954.250000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>8.073707e-06</td>\n",
       "      <td>-3.664225e-02</td>\n",
       "      <td>8.073708e+06</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>101.247780</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>5248.449219</td>\n",
       "      <td>60099.574219</td>\n",
       "      <td>7.093623e+10</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>448.055908</td>\n",
       "      <td>79.793724</td>\n",
       "      <td>-4.726739e-04</td>\n",
       "      <td>1.237000</td>\n",
       "      <td>6.007996</td>\n",
       "      <td>64.009338</td>\n",
       "      <td>207.970581</td>\n",
       "      <td>256.032715</td>\n",
       "      <td>5247.531250</td>\n",
       "      <td>tensor(11.8242, device='cuda:0')</td>\n",
       "      <td>tensor(0.0261, device='cuda:0')</td>\n",
       "      <td>tensor(51599.6406, device='cuda:0')</td>\n",
       "      <td>tensor(254.6298, device='cuda:0')</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>5.098921e-04</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>1.534616e-04</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>37.370094</td>\n",
       "      <td>21.695557</td>\n",
       "      <td>1.722477</td>\n",
       "      <td>-7.633631e-05</td>\n",
       "      <td>-1.765326e-04</td>\n",
       "      <td>-7.633631e+07</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>1.722575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>1.155191</td>\n",
       "      <td>5.608924</td>\n",
       "      <td>3.359505e+05</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>4.248821e-03</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.420014</td>\n",
       "      <td>tensor(23.2654, device='cuda:0')</td>\n",
       "      <td>tensor(1.1133, device='cuda:0')</td>\n",
       "      <td>tensor(13.4254, device='cuda:0')</td>\n",
       "      <td>tensor(0.4878, device='cuda:0')</td>\n",
       "      <td>0.061265</td>\n",
       "      <td>1.774146e-03</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>3.387111e-05</td>\n",
       "      <td>0.062385</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.433987</td>\n",
       "      <td>253758.671875</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-2.738451e-06</td>\n",
       "      <td>4.667359e-03</td>\n",
       "      <td>-5.867240e-04</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>66.230324</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>5980.081055</td>\n",
       "      <td>60588.476562</td>\n",
       "      <td>2.213782e+10</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>448.046143</td>\n",
       "      <td>48.660442</td>\n",
       "      <td>9.990737e-06</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>2.740845</td>\n",
       "      <td>36.002350</td>\n",
       "      <td>143.984131</td>\n",
       "      <td>207.995636</td>\n",
       "      <td>5979.126465</td>\n",
       "      <td>tensor(10.7594, device='cuda:0')</td>\n",
       "      <td>tensor(0.1532, device='cuda:0')</td>\n",
       "      <td>tensor(25177.1855, device='cuda:0')</td>\n",
       "      <td>tensor(1207.6293, device='cuda:0')</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>2.038164e-05</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>8.675774e-05</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.022367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.619488</td>\n",
       "      <td>263933.625000</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-2.242682e-05</td>\n",
       "      <td>-2.347590e-01</td>\n",
       "      <td>-2.242682e+07</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>68.885559</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>4502.488770</td>\n",
       "      <td>72163.531250</td>\n",
       "      <td>3.023657e+11</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>448.057861</td>\n",
       "      <td>49.945812</td>\n",
       "      <td>-2.644935e-06</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>3.008850</td>\n",
       "      <td>36.002029</td>\n",
       "      <td>144.002167</td>\n",
       "      <td>223.992004</td>\n",
       "      <td>4501.459473</td>\n",
       "      <td>tensor(15.5357, device='cuda:0')</td>\n",
       "      <td>tensor(0.3244, device='cuda:0')</td>\n",
       "      <td>tensor(94769.0859, device='cuda:0')</td>\n",
       "      <td>tensor(1046.7028, device='cuda:0')</td>\n",
       "      <td>0.022195</td>\n",
       "      <td>4.308694e-04</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>1.637276e-04</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>40.589417</td>\n",
       "      <td>246767.109375</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-5.489941e-06</td>\n",
       "      <td>-3.485284e-02</td>\n",
       "      <td>-5.489941e+06</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>64.405540</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>6079.592773</td>\n",
       "      <td>69012.031250</td>\n",
       "      <td>5.890241e+10</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>448.046631</td>\n",
       "      <td>47.737759</td>\n",
       "      <td>-3.452895e-04</td>\n",
       "      <td>0.626836</td>\n",
       "      <td>3.239502</td>\n",
       "      <td>36.000782</td>\n",
       "      <td>128.005127</td>\n",
       "      <td>192.012756</td>\n",
       "      <td>6078.503906</td>\n",
       "      <td>tensor(4.8922, device='cuda:0')</td>\n",
       "      <td>tensor(0.2801, device='cuda:0')</td>\n",
       "      <td>tensor(31653.9648, device='cuda:0')</td>\n",
       "      <td>tensor(1424.4911, device='cuda:0')</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>1.721785e-05</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>1.154298e-05</td>\n",
       "      <td>0.022348</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>49.849182</td>\n",
       "      <td>182301.687500</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4.912959e-06</td>\n",
       "      <td>-4.510187e-02</td>\n",
       "      <td>4.912959e+06</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>89.718170</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>3657.064453</td>\n",
       "      <td>41153.359375</td>\n",
       "      <td>1.212697e+10</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>448.070312</td>\n",
       "      <td>66.892845</td>\n",
       "      <td>7.146989e-04</td>\n",
       "      <td>0.739604</td>\n",
       "      <td>3.740662</td>\n",
       "      <td>51.950928</td>\n",
       "      <td>191.978394</td>\n",
       "      <td>255.999725</td>\n",
       "      <td>3656.063477</td>\n",
       "      <td>tensor(12.0291, device='cuda:0')</td>\n",
       "      <td>tensor(0.3482, device='cuda:0')</td>\n",
       "      <td>tensor(27637.5566, device='cuda:0')</td>\n",
       "      <td>tensor(1330.9163, device='cuda:0')</td>\n",
       "      <td>0.036090</td>\n",
       "      <td>5.613678e-05</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>2.486951e-04</td>\n",
       "      <td>0.040021</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>64.376747</td>\n",
       "      <td>314651.562500</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>7.497435e-06</td>\n",
       "      <td>-3.885011e-02</td>\n",
       "      <td>7.497435e+06</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>94.827713</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>4887.658691</td>\n",
       "      <td>55091.910156</td>\n",
       "      <td>9.115122e+10</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>448.063965</td>\n",
       "      <td>73.885269</td>\n",
       "      <td>3.619854e-04</td>\n",
       "      <td>1.109558</td>\n",
       "      <td>5.497147</td>\n",
       "      <td>60.001022</td>\n",
       "      <td>191.996735</td>\n",
       "      <td>256.005188</td>\n",
       "      <td>4886.743164</td>\n",
       "      <td>tensor(9.9500, device='cuda:0')</td>\n",
       "      <td>tensor(0.0234, device='cuda:0')</td>\n",
       "      <td>tensor(46854.0781, device='cuda:0')</td>\n",
       "      <td>tensor(229.1664, device='cuda:0')</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>4.570196e-05</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>4.354915e-05</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>35.798725</td>\n",
       "      <td>21.656708</td>\n",
       "      <td>1.653009</td>\n",
       "      <td>-1.216935e-04</td>\n",
       "      <td>-9.439918e-05</td>\n",
       "      <td>-1.216935e+08</td>\n",
       "      <td>0.026427</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>1.653020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>1.166367</td>\n",
       "      <td>7.772630</td>\n",
       "      <td>3.962209e+06</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.393822</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>6.406918e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>0.060303</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>0.395233</td>\n",
       "      <td>tensor(22.3172, device='cuda:0')</td>\n",
       "      <td>tensor(0.8497, device='cuda:0')</td>\n",
       "      <td>tensor(13.3784, device='cuda:0')</td>\n",
       "      <td>tensor(0.4817, device='cuda:0')</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>5.179920e-04</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>1.451263e-04</td>\n",
       "      <td>0.062886</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.254421</td>\n",
       "      <td>258464.078125</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-9.516548e-07</td>\n",
       "      <td>-1.052500e-02</td>\n",
       "      <td>-9.516548e+05</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>67.458427</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6116.853027</td>\n",
       "      <td>77353.398438</td>\n",
       "      <td>8.408030e+10</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>448.045898</td>\n",
       "      <td>50.039043</td>\n",
       "      <td>1.521224e-04</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>2.966797</td>\n",
       "      <td>36.025391</td>\n",
       "      <td>143.990356</td>\n",
       "      <td>207.995789</td>\n",
       "      <td>6115.948242</td>\n",
       "      <td>tensor(6.6717, device='cuda:0')</td>\n",
       "      <td>tensor(0.2343, device='cuda:0')</td>\n",
       "      <td>tensor(26657.4316, device='cuda:0')</td>\n",
       "      <td>tensor(1255.6924, device='cuda:0')</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>6.360774e-05</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>1.938107e-04</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>57.487576</td>\n",
       "      <td>267196.437500</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-3.175724e-05</td>\n",
       "      <td>-1.723170e-01</td>\n",
       "      <td>-3.175724e+07</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>69.737335</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>4647.899414</td>\n",
       "      <td>54278.503906</td>\n",
       "      <td>7.853655e+10</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>50.312813</td>\n",
       "      <td>-3.153391e-04</td>\n",
       "      <td>0.618896</td>\n",
       "      <td>3.010681</td>\n",
       "      <td>36.001839</td>\n",
       "      <td>144.007507</td>\n",
       "      <td>224.003357</td>\n",
       "      <td>4646.845703</td>\n",
       "      <td>tensor(14.9229, device='cuda:0')</td>\n",
       "      <td>tensor(0.2893, device='cuda:0')</td>\n",
       "      <td>tensor(90643.4609, device='cuda:0')</td>\n",
       "      <td>tensor(965.4329, device='cuda:0')</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>5.939807e-04</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>4.253169e-04</td>\n",
       "      <td>0.022301</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>41.106983</td>\n",
       "      <td>252560.531250</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>3.281851e-07</td>\n",
       "      <td>-1.137515e-02</td>\n",
       "      <td>3.281851e+05</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>65.917618</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>6143.980957</td>\n",
       "      <td>63881.269531</td>\n",
       "      <td>3.967310e+10</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>448.038818</td>\n",
       "      <td>49.004391</td>\n",
       "      <td>2.035016e-04</td>\n",
       "      <td>0.636353</td>\n",
       "      <td>3.249995</td>\n",
       "      <td>36.007721</td>\n",
       "      <td>128.018433</td>\n",
       "      <td>207.978516</td>\n",
       "      <td>6143.013672</td>\n",
       "      <td>tensor(6.1338, device='cuda:0')</td>\n",
       "      <td>tensor(0.2918, device='cuda:0')</td>\n",
       "      <td>tensor(34523.9297, device='cuda:0')</td>\n",
       "      <td>tensor(1400.4647, device='cuda:0')</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>2.435658e-04</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>5.911770e-06</td>\n",
       "      <td>0.021914</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.294857</td>\n",
       "      <td>176369.859375</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-1.530643e-05</td>\n",
       "      <td>-1.975615e-03</td>\n",
       "      <td>-1.530643e+07</td>\n",
       "      <td>0.020815</td>\n",
       "      <td>86.798882</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>4170.007812</td>\n",
       "      <td>42843.574219</td>\n",
       "      <td>9.629481e+09</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>63.692081</td>\n",
       "      <td>-4.158668e-04</td>\n",
       "      <td>0.690430</td>\n",
       "      <td>3.494690</td>\n",
       "      <td>44.027344</td>\n",
       "      <td>176.030762</td>\n",
       "      <td>255.994659</td>\n",
       "      <td>4169.010742</td>\n",
       "      <td>tensor(10.4696, device='cuda:0')</td>\n",
       "      <td>tensor(0.3428, device='cuda:0')</td>\n",
       "      <td>tensor(20146.1777, device='cuda:0')</td>\n",
       "      <td>tensor(816.6249, device='cuda:0')</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>2.565815e-04</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>3.157993e-05</td>\n",
       "      <td>0.038368</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>51.717434</td>\n",
       "      <td>347355.125000</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-7.407287e-07</td>\n",
       "      <td>2.083170e-02</td>\n",
       "      <td>-3.555777e-05</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>104.683708</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>6716.402344</td>\n",
       "      <td>245204.984375</td>\n",
       "      <td>1.607408e+12</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>448.057129</td>\n",
       "      <td>82.612213</td>\n",
       "      <td>4.707460e-04</td>\n",
       "      <td>1.250813</td>\n",
       "      <td>6.477905</td>\n",
       "      <td>71.977783</td>\n",
       "      <td>208.000305</td>\n",
       "      <td>287.989502</td>\n",
       "      <td>6715.797852</td>\n",
       "      <td>tensor(8.6338, device='cuda:0')</td>\n",
       "      <td>tensor(0.0289, device='cuda:0')</td>\n",
       "      <td>tensor(55536.3008, device='cuda:0')</td>\n",
       "      <td>tensor(209.8562, device='cuda:0')</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>3.772899e-05</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>2.381837e-04</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>36.117199</td>\n",
       "      <td>20.357906</td>\n",
       "      <td>1.774112</td>\n",
       "      <td>-4.039209e-05</td>\n",
       "      <td>-1.072185e-04</td>\n",
       "      <td>-4.039209e+07</td>\n",
       "      <td>0.026662</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>1.774155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>1.146590</td>\n",
       "      <td>4.780324</td>\n",
       "      <td>1.094827e+05</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.361908</td>\n",
       "      <td>0.024207</td>\n",
       "      <td>3.614819e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.080185</td>\n",
       "      <td>0.437230</td>\n",
       "      <td>tensor(22.3042, device='cuda:0')</td>\n",
       "      <td>tensor(1.1528, device='cuda:0')</td>\n",
       "      <td>tensor(12.1845, device='cuda:0')</td>\n",
       "      <td>tensor(0.4646, device='cuda:0')</td>\n",
       "      <td>0.055801</td>\n",
       "      <td>2.641404e-04</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>1.201245e-04</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.344177</td>\n",
       "      <td>256965.453125</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>4.297632e-06</td>\n",
       "      <td>7.255935e-03</td>\n",
       "      <td>5.922920e-04</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>67.067284</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>5928.488281</td>\n",
       "      <td>65095.105469</td>\n",
       "      <td>6.731704e+10</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>448.049316</td>\n",
       "      <td>50.065414</td>\n",
       "      <td>3.031318e-04</td>\n",
       "      <td>0.580322</td>\n",
       "      <td>3.000080</td>\n",
       "      <td>39.988708</td>\n",
       "      <td>143.977539</td>\n",
       "      <td>207.989136</td>\n",
       "      <td>5927.549316</td>\n",
       "      <td>tensor(8.9917, device='cuda:0')</td>\n",
       "      <td>tensor(0.2110, device='cuda:0')</td>\n",
       "      <td>tensor(26562.7539, device='cuda:0')</td>\n",
       "      <td>tensor(1329.0332, device='cuda:0')</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>7.629678e-06</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>9.118368e-05</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>58.638844</td>\n",
       "      <td>274772.812500</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-4.038461e-05</td>\n",
       "      <td>-1.469817e-01</td>\n",
       "      <td>-4.038461e+07</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>71.714813</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>4685.849609</td>\n",
       "      <td>80761.898438</td>\n",
       "      <td>2.549592e+11</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>448.081543</td>\n",
       "      <td>52.161930</td>\n",
       "      <td>4.090447e-04</td>\n",
       "      <td>0.639404</td>\n",
       "      <td>3.249382</td>\n",
       "      <td>36.044189</td>\n",
       "      <td>144.021973</td>\n",
       "      <td>224.010498</td>\n",
       "      <td>4684.781250</td>\n",
       "      <td>tensor(15.8992, device='cuda:0')</td>\n",
       "      <td>tensor(0.2927, device='cuda:0')</td>\n",
       "      <td>tensor(89780.3984, device='cuda:0')</td>\n",
       "      <td>tensor(878.8092, device='cuda:0')</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>8.831140e-05</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>7.271907e-05</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>42.496319</td>\n",
       "      <td>268099.093750</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.203183e-06</td>\n",
       "      <td>4.487616e-03</td>\n",
       "      <td>2.681118e-04</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>69.973145</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>6308.760254</td>\n",
       "      <td>72835.218750</td>\n",
       "      <td>8.567623e+10</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>448.035400</td>\n",
       "      <td>52.742100</td>\n",
       "      <td>9.467788e-05</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>3.524048</td>\n",
       "      <td>40.006012</td>\n",
       "      <td>143.998444</td>\n",
       "      <td>208.000793</td>\n",
       "      <td>6307.842773</td>\n",
       "      <td>tensor(6.1287, device='cuda:0')</td>\n",
       "      <td>tensor(0.2878, device='cuda:0')</td>\n",
       "      <td>tensor(37705.6797, device='cuda:0')</td>\n",
       "      <td>tensor(1585.0227, device='cuda:0')</td>\n",
       "      <td>0.018419</td>\n",
       "      <td>2.184379e-04</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>1.689942e-04</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>43.518063</td>\n",
       "      <td>166118.187500</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-6.869784e-06</td>\n",
       "      <td>1.160942e-02</td>\n",
       "      <td>-5.917421e-04</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>81.753609</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>3817.223877</td>\n",
       "      <td>44322.226562</td>\n",
       "      <td>4.140420e+10</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>448.056152</td>\n",
       "      <td>59.618183</td>\n",
       "      <td>1.034701e-04</td>\n",
       "      <td>0.617371</td>\n",
       "      <td>3.022705</td>\n",
       "      <td>43.984619</td>\n",
       "      <td>175.991760</td>\n",
       "      <td>240.019897</td>\n",
       "      <td>3816.159912</td>\n",
       "      <td>tensor(11.3791, device='cuda:0')</td>\n",
       "      <td>tensor(0.2796, device='cuda:0')</td>\n",
       "      <td>tensor(21788.4023, device='cuda:0')</td>\n",
       "      <td>tensor(880.0981, device='cuda:0')</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>5.937259e-05</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>1.195816e-04</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>46.662914</td>\n",
       "      <td>336636.906250</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-1.299218e-06</td>\n",
       "      <td>2.403503e-02</td>\n",
       "      <td>-5.405517e-05</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>101.453522</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>7214.228027</td>\n",
       "      <td>95299.117188</td>\n",
       "      <td>8.012635e+10</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>448.049072</td>\n",
       "      <td>80.103516</td>\n",
       "      <td>1.683750e-04</td>\n",
       "      <td>1.244904</td>\n",
       "      <td>6.011108</td>\n",
       "      <td>64.009460</td>\n",
       "      <td>207.978394</td>\n",
       "      <td>256.021362</td>\n",
       "      <td>7213.776367</td>\n",
       "      <td>tensor(8.7488, device='cuda:0')</td>\n",
       "      <td>tensor(0.0289, device='cuda:0')</td>\n",
       "      <td>tensor(55452.2695, device='cuda:0')</td>\n",
       "      <td>tensor(287.8564, device='cuda:0')</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>2.697091e-04</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>1.372605e-04</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>34.743210</td>\n",
       "      <td>19.548061</td>\n",
       "      <td>1.777323</td>\n",
       "      <td>-2.811972e-05</td>\n",
       "      <td>-4.951217e-05</td>\n",
       "      <td>-2.811972e+07</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>1.777332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>1.144950</td>\n",
       "      <td>16.797567</td>\n",
       "      <td>1.917396e+07</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.356506</td>\n",
       "      <td>0.023236</td>\n",
       "      <td>5.722261e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>0.077087</td>\n",
       "      <td>0.438725</td>\n",
       "      <td>tensor(21.1496, device='cuda:0')</td>\n",
       "      <td>tensor(0.8035, device='cuda:0')</td>\n",
       "      <td>tensor(11.3195, device='cuda:0')</td>\n",
       "      <td>tensor(0.4171, device='cuda:0')</td>\n",
       "      <td>0.060555</td>\n",
       "      <td>8.225833e-05</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>2.160154e-04</td>\n",
       "      <td>0.063257</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.350349</td>\n",
       "      <td>259602.890625</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-2.246785e-06</td>\n",
       "      <td>1.121911e-02</td>\n",
       "      <td>-2.002640e-04</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>67.755661</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>5988.484863</td>\n",
       "      <td>75500.585938</td>\n",
       "      <td>2.094308e+11</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>50.332382</td>\n",
       "      <td>3.149825e-04</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>2.998650</td>\n",
       "      <td>39.977539</td>\n",
       "      <td>143.992401</td>\n",
       "      <td>207.992676</td>\n",
       "      <td>5987.518555</td>\n",
       "      <td>tensor(6.5458, device='cuda:0')</td>\n",
       "      <td>tensor(0.2855, device='cuda:0')</td>\n",
       "      <td>tensor(30401.8984, device='cuda:0')</td>\n",
       "      <td>tensor(1290.9520, device='cuda:0')</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>8.548675e-05</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>2.030478e-04</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>60.991867</td>\n",
       "      <td>277887.031250</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>-2.877171e-05</td>\n",
       "      <td>-1.678354e-01</td>\n",
       "      <td>-2.877171e+07</td>\n",
       "      <td>0.015919</td>\n",
       "      <td>72.527573</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>4556.131348</td>\n",
       "      <td>52136.453125</td>\n",
       "      <td>8.914959e+10</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>448.060791</td>\n",
       "      <td>53.017929</td>\n",
       "      <td>6.087371e-04</td>\n",
       "      <td>0.676636</td>\n",
       "      <td>3.275024</td>\n",
       "      <td>39.989685</td>\n",
       "      <td>144.148438</td>\n",
       "      <td>224.012817</td>\n",
       "      <td>4555.069336</td>\n",
       "      <td>tensor(16.7388, device='cuda:0')</td>\n",
       "      <td>tensor(0.2801, device='cuda:0')</td>\n",
       "      <td>tensor(86191.8828, device='cuda:0')</td>\n",
       "      <td>tensor(715.9442, device='cuda:0')</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>2.998451e-05</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>1.815974e-04</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>43.234421</td>\n",
       "      <td>275242.437500</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>6.647404e-06</td>\n",
       "      <td>-2.566931e-02</td>\n",
       "      <td>6.647404e+06</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>71.837524</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>6366.280273</td>\n",
       "      <td>83311.023438</td>\n",
       "      <td>2.426508e+11</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>448.036133</td>\n",
       "      <td>54.482510</td>\n",
       "      <td>3.576197e-07</td>\n",
       "      <td>0.751625</td>\n",
       "      <td>3.751640</td>\n",
       "      <td>43.987427</td>\n",
       "      <td>144.005005</td>\n",
       "      <td>208.004181</td>\n",
       "      <td>6365.253418</td>\n",
       "      <td>tensor(5.0818, device='cuda:0')</td>\n",
       "      <td>tensor(0.3004, device='cuda:0')</td>\n",
       "      <td>tensor(42098.7969, device='cuda:0')</td>\n",
       "      <td>tensor(1519.8364, device='cuda:0')</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>7.666961e-05</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>9.069940e-05</td>\n",
       "      <td>0.021762</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.597591</td>\n",
       "      <td>183532.031250</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>-1.887155e-05</td>\n",
       "      <td>5.164166e-02</td>\n",
       "      <td>-3.654328e-04</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>90.323662</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>3855.910156</td>\n",
       "      <td>38593.156250</td>\n",
       "      <td>9.370838e+09</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>448.096680</td>\n",
       "      <td>67.729317</td>\n",
       "      <td>-1.948271e-04</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>4.023926</td>\n",
       "      <td>51.974976</td>\n",
       "      <td>191.986206</td>\n",
       "      <td>256.002899</td>\n",
       "      <td>3854.888916</td>\n",
       "      <td>tensor(10.6793, device='cuda:0')</td>\n",
       "      <td>tensor(0.3140, device='cuda:0')</td>\n",
       "      <td>tensor(30547.9570, device='cuda:0')</td>\n",
       "      <td>tensor(1284.9739, device='cuda:0')</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>7.955917e-05</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>2.764150e-05</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.011913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>57.733204</td>\n",
       "      <td>339363.062500</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.106712e-06</td>\n",
       "      <td>2.848307e-02</td>\n",
       "      <td>1.090722e-04</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>102.275108</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>5878.126953</td>\n",
       "      <td>103989.742188</td>\n",
       "      <td>2.145388e+11</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>448.060059</td>\n",
       "      <td>80.500168</td>\n",
       "      <td>-2.287797e-04</td>\n",
       "      <td>1.240295</td>\n",
       "      <td>6.008118</td>\n",
       "      <td>64.011169</td>\n",
       "      <td>207.988342</td>\n",
       "      <td>287.973877</td>\n",
       "      <td>5877.293457</td>\n",
       "      <td>tensor(10.0556, device='cuda:0')</td>\n",
       "      <td>tensor(0.0296, device='cuda:0')</td>\n",
       "      <td>tensor(51285.6055, device='cuda:0')</td>\n",
       "      <td>tensor(314.9107, device='cuda:0')</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>2.804205e-05</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>4.200035e-04</td>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>33.904938</td>\n",
       "      <td>19.602224</td>\n",
       "      <td>1.729648</td>\n",
       "      <td>-1.243669e-04</td>\n",
       "      <td>-1.508405e-05</td>\n",
       "      <td>-1.243669e+08</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>1.729627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>1.153161</td>\n",
       "      <td>6.369375</td>\n",
       "      <td>1.516401e+06</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.389984</td>\n",
       "      <td>0.022817</td>\n",
       "      <td>4.758421e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.075806</td>\n",
       "      <td>0.428040</td>\n",
       "      <td>tensor(20.6954, device='cuda:0')</td>\n",
       "      <td>tensor(0.9896, device='cuda:0')</td>\n",
       "      <td>tensor(10.6801, device='cuda:0')</td>\n",
       "      <td>tensor(0.4201, device='cuda:0')</td>\n",
       "      <td>0.053434</td>\n",
       "      <td>1.885782e-04</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>2.046767e-04</td>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.071590</td>\n",
       "      <td>254212.046875</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-5.526402e-08</td>\n",
       "      <td>-4.684624e-03</td>\n",
       "      <td>-5.526402e+04</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>66.348656</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>5640.184570</td>\n",
       "      <td>84146.710938</td>\n",
       "      <td>1.713525e+11</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>448.035889</td>\n",
       "      <td>48.836674</td>\n",
       "      <td>-6.697464e-04</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>2.764221</td>\n",
       "      <td>36.002304</td>\n",
       "      <td>143.984741</td>\n",
       "      <td>207.985535</td>\n",
       "      <td>5639.177734</td>\n",
       "      <td>tensor(8.0602, device='cuda:0')</td>\n",
       "      <td>tensor(0.2775, device='cuda:0')</td>\n",
       "      <td>tensor(45431.2383, device='cuda:0')</td>\n",
       "      <td>tensor(903.4066, device='cuda:0')</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>6.019613e-05</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>7.727394e-05</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>64.227753</td>\n",
       "      <td>278233.968750</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-3.936243e-05</td>\n",
       "      <td>-2.186561e-01</td>\n",
       "      <td>-3.936243e+07</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>72.617989</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>4331.990234</td>\n",
       "      <td>46617.175781</td>\n",
       "      <td>2.411210e+10</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>448.094238</td>\n",
       "      <td>53.295658</td>\n",
       "      <td>-2.178474e-04</td>\n",
       "      <td>0.683075</td>\n",
       "      <td>3.478271</td>\n",
       "      <td>39.994385</td>\n",
       "      <td>144.045410</td>\n",
       "      <td>224.008850</td>\n",
       "      <td>4331.026855</td>\n",
       "      <td>tensor(18.9527, device='cuda:0')</td>\n",
       "      <td>tensor(0.2315, device='cuda:0')</td>\n",
       "      <td>tensor(82750.0625, device='cuda:0')</td>\n",
       "      <td>tensor(682.2212, device='cuda:0')</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>4.984610e-04</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>7.067386e-05</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>45.738163</td>\n",
       "      <td>279941.000000</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-1.128455e-06</td>\n",
       "      <td>-1.713091e-02</td>\n",
       "      <td>-1.128455e+06</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>73.063843</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>6120.513184</td>\n",
       "      <td>63511.289062</td>\n",
       "      <td>6.052358e+10</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>55.354233</td>\n",
       "      <td>-1.234664e-04</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>3.763062</td>\n",
       "      <td>43.993744</td>\n",
       "      <td>144.010803</td>\n",
       "      <td>208.019897</td>\n",
       "      <td>6119.698242</td>\n",
       "      <td>tensor(6.4444, device='cuda:0')</td>\n",
       "      <td>tensor(0.3005, device='cuda:0')</td>\n",
       "      <td>tensor(46438.2578, device='cuda:0')</td>\n",
       "      <td>tensor(516.5245, device='cuda:0')</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>4.674533e-04</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>7.333744e-05</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.971287</td>\n",
       "      <td>165510.984375</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>1.439222e-05</td>\n",
       "      <td>-1.083697e-02</td>\n",
       "      <td>1.439222e+07</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>81.454781</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>3851.665283</td>\n",
       "      <td>63072.113281</td>\n",
       "      <td>5.975606e+10</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>448.182617</td>\n",
       "      <td>62.526688</td>\n",
       "      <td>-7.203819e-05</td>\n",
       "      <td>0.901611</td>\n",
       "      <td>4.501552</td>\n",
       "      <td>48.033936</td>\n",
       "      <td>160.017578</td>\n",
       "      <td>239.981079</td>\n",
       "      <td>3850.676270</td>\n",
       "      <td>tensor(10.7383, device='cuda:0')</td>\n",
       "      <td>tensor(0.2843, device='cuda:0')</td>\n",
       "      <td>tensor(28483.9883, device='cuda:0')</td>\n",
       "      <td>tensor(1262.7197, device='cuda:0')</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>2.647378e-04</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>4.623981e-05</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>56.423298</td>\n",
       "      <td>324759.031250</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-6.326462e-06</td>\n",
       "      <td>-1.447186e-02</td>\n",
       "      <td>-6.326462e+06</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>97.873833</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>5755.760742</td>\n",
       "      <td>83934.046875</td>\n",
       "      <td>9.124578e+10</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>448.064941</td>\n",
       "      <td>75.822250</td>\n",
       "      <td>1.265295e-04</td>\n",
       "      <td>1.112183</td>\n",
       "      <td>5.495941</td>\n",
       "      <td>60.008240</td>\n",
       "      <td>192.019165</td>\n",
       "      <td>256.028564</td>\n",
       "      <td>5754.885742</td>\n",
       "      <td>tensor(10.3825, device='cuda:0')</td>\n",
       "      <td>tensor(0.0244, device='cuda:0')</td>\n",
       "      <td>tensor(51343.9414, device='cuda:0')</td>\n",
       "      <td>tensor(193.8278, device='cuda:0')</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>4.387709e-05</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>6.547107e-05</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>33.004986</td>\n",
       "      <td>20.246275</td>\n",
       "      <td>1.630176</td>\n",
       "      <td>-7.202942e-05</td>\n",
       "      <td>9.072167e-05</td>\n",
       "      <td>-7.939605e-01</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>1.630199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>1.173660</td>\n",
       "      <td>5.969302</td>\n",
       "      <td>2.051572e+05</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>-4.413895e-04</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>0.395684</td>\n",
       "      <td>tensor(19.7949, device='cuda:0')</td>\n",
       "      <td>tensor(0.8968, device='cuda:0')</td>\n",
       "      <td>tensor(10.5430, device='cuda:0')</td>\n",
       "      <td>tensor(0.1361, device='cuda:0')</td>\n",
       "      <td>0.060235</td>\n",
       "      <td>5.267344e-04</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>4.398809e-04</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.850452</td>\n",
       "      <td>248567.453125</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-1.933409e-06</td>\n",
       "      <td>7.639631e-03</td>\n",
       "      <td>-2.530763e-04</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>64.875435</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>5305.550781</td>\n",
       "      <td>52250.949219</td>\n",
       "      <td>2.228740e+10</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>448.056152</td>\n",
       "      <td>47.467190</td>\n",
       "      <td>-5.179914e-05</td>\n",
       "      <td>0.554565</td>\n",
       "      <td>2.748894</td>\n",
       "      <td>35.991272</td>\n",
       "      <td>128.015320</td>\n",
       "      <td>192.016602</td>\n",
       "      <td>5304.633789</td>\n",
       "      <td>tensor(8.3095, device='cuda:0')</td>\n",
       "      <td>tensor(0.1437, device='cuda:0')</td>\n",
       "      <td>tensor(38577.4727, device='cuda:0')</td>\n",
       "      <td>tensor(586.1177, device='cuda:0')</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>2.624532e-05</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>4.228681e-04</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>65.613007</td>\n",
       "      <td>278620.093750</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-4.827616e-05</td>\n",
       "      <td>1.218323e-01</td>\n",
       "      <td>-3.962510e-04</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>72.719002</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>4246.416016</td>\n",
       "      <td>56015.222656</td>\n",
       "      <td>6.911216e+10</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>448.079590</td>\n",
       "      <td>53.671066</td>\n",
       "      <td>-4.600205e-05</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>3.496948</td>\n",
       "      <td>40.000343</td>\n",
       "      <td>144.031738</td>\n",
       "      <td>224.004028</td>\n",
       "      <td>4245.456055</td>\n",
       "      <td>tensor(20.5483, device='cuda:0')</td>\n",
       "      <td>tensor(0.1664, device='cuda:0')</td>\n",
       "      <td>tensor(80056.2734, device='cuda:0')</td>\n",
       "      <td>tensor(558.2468, device='cuda:0')</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>1.357284e-05</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>2.884954e-04</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.656509</td>\n",
       "      <td>268330.593750</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-4.617706e-06</td>\n",
       "      <td>4.263859e-03</td>\n",
       "      <td>-1.082987e-03</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>70.033562</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>5514.793457</td>\n",
       "      <td>63015.148438</td>\n",
       "      <td>1.628906e+11</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>448.043701</td>\n",
       "      <td>53.023014</td>\n",
       "      <td>-2.049523e-04</td>\n",
       "      <td>0.740906</td>\n",
       "      <td>3.738159</td>\n",
       "      <td>40.012207</td>\n",
       "      <td>143.998077</td>\n",
       "      <td>207.997208</td>\n",
       "      <td>5513.809082</td>\n",
       "      <td>tensor(7.5036, device='cuda:0')</td>\n",
       "      <td>tensor(0.2844, device='cuda:0')</td>\n",
       "      <td>tensor(51825.0703, device='cuda:0')</td>\n",
       "      <td>tensor(799.5524, device='cuda:0')</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>1.469870e-04</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>9.215138e-05</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>42.285824</td>\n",
       "      <td>192984.609375</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>-3.834824e-06</td>\n",
       "      <td>1.003834e-01</td>\n",
       "      <td>-3.820178e-05</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>94.975632</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4563.813477</td>\n",
       "      <td>62297.203125</td>\n",
       "      <td>3.555635e+10</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>448.092285</td>\n",
       "      <td>74.100739</td>\n",
       "      <td>3.001667e-04</td>\n",
       "      <td>1.113342</td>\n",
       "      <td>5.498935</td>\n",
       "      <td>60.005157</td>\n",
       "      <td>191.996811</td>\n",
       "      <td>256.003357</td>\n",
       "      <td>4562.860840</td>\n",
       "      <td>tensor(11.9744, device='cuda:0')</td>\n",
       "      <td>tensor(0.3805, device='cuda:0')</td>\n",
       "      <td>tensor(31275.2129, device='cuda:0')</td>\n",
       "      <td>tensor(795.6398, device='cuda:0')</td>\n",
       "      <td>0.031931</td>\n",
       "      <td>1.113813e-04</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>1.448914e-04</td>\n",
       "      <td>0.040510</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>47.141296</td>\n",
       "      <td>278748.437500</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-6.660851e-06</td>\n",
       "      <td>1.602416e-02</td>\n",
       "      <td>-4.156755e-04</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>84.007454</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>5913.041504</td>\n",
       "      <td>297973.250000</td>\n",
       "      <td>2.363130e+12</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>448.046143</td>\n",
       "      <td>63.545689</td>\n",
       "      <td>3.565136e-04</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>4.491394</td>\n",
       "      <td>48.009338</td>\n",
       "      <td>175.995361</td>\n",
       "      <td>240.026001</td>\n",
       "      <td>5912.236816</td>\n",
       "      <td>tensor(11.8634, device='cuda:0')</td>\n",
       "      <td>tensor(0.0269, device='cuda:0')</td>\n",
       "      <td>tensor(66133.5000, device='cuda:0')</td>\n",
       "      <td>tensor(340.0785, device='cuda:0')</td>\n",
       "      <td>0.018997</td>\n",
       "      <td>3.463870e-04</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>1.713159e-04</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>30.243559</td>\n",
       "      <td>21.967958</td>\n",
       "      <td>1.376712</td>\n",
       "      <td>-1.165403e-04</td>\n",
       "      <td>1.126568e-04</td>\n",
       "      <td>-1.034472e+00</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>1.376727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>1.235276</td>\n",
       "      <td>8.624231</td>\n",
       "      <td>2.912710e+06</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.394775</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>4.939766e-04</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.297874</td>\n",
       "      <td>tensor(16.6159, device='cuda:0')</td>\n",
       "      <td>tensor(0.8496, device='cuda:0')</td>\n",
       "      <td>tensor(10.7000, device='cuda:0')</td>\n",
       "      <td>tensor(0.4479, device='cuda:0')</td>\n",
       "      <td>0.051078</td>\n",
       "      <td>1.191989e-05</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>2.019776e-04</td>\n",
       "      <td>0.061247</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.900597</td>\n",
       "      <td>232829.328125</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-1.224481e-07</td>\n",
       "      <td>1.516126e-02</td>\n",
       "      <td>-8.076385e-06</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>60.767826</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>4964.314941</td>\n",
       "      <td>48132.335938</td>\n",
       "      <td>2.871859e+10</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>448.206055</td>\n",
       "      <td>44.010178</td>\n",
       "      <td>1.326976e-04</td>\n",
       "      <td>0.524170</td>\n",
       "      <td>2.735413</td>\n",
       "      <td>31.995209</td>\n",
       "      <td>127.991577</td>\n",
       "      <td>192.002243</td>\n",
       "      <td>4963.339355</td>\n",
       "      <td>tensor(7.9094, device='cuda:0')</td>\n",
       "      <td>tensor(0.1819, device='cuda:0')</td>\n",
       "      <td>tensor(38388.2422, device='cuda:0')</td>\n",
       "      <td>tensor(791.0397, device='cuda:0')</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>7.031715e-05</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>2.352685e-04</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>66.756119</td>\n",
       "      <td>253401.437500</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-6.539675e-05</td>\n",
       "      <td>1.408842e-01</td>\n",
       "      <td>-4.641880e-04</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>66.136940</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>3795.928711</td>\n",
       "      <td>54383.152344</td>\n",
       "      <td>7.626670e+10</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>448.072754</td>\n",
       "      <td>48.809811</td>\n",
       "      <td>-2.693519e-04</td>\n",
       "      <td>0.635498</td>\n",
       "      <td>3.244934</td>\n",
       "      <td>36.005493</td>\n",
       "      <td>143.972412</td>\n",
       "      <td>207.995544</td>\n",
       "      <td>3795.022217</td>\n",
       "      <td>tensor(20.5914, device='cuda:0')</td>\n",
       "      <td>tensor(0.2305, device='cuda:0')</td>\n",
       "      <td>tensor(65362.0078, device='cuda:0')</td>\n",
       "      <td>tensor(486.4416, device='cuda:0')</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>1.914805e-05</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>3.346864e-04</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>48.777443</td>\n",
       "      <td>239059.500000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-2.859583e-06</td>\n",
       "      <td>-4.252552e-03</td>\n",
       "      <td>-2.859583e+06</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>62.393883</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>4901.025879</td>\n",
       "      <td>75714.164062</td>\n",
       "      <td>2.429860e+11</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>448.069824</td>\n",
       "      <td>46.818249</td>\n",
       "      <td>2.533953e-04</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>3.253448</td>\n",
       "      <td>36.003189</td>\n",
       "      <td>127.987244</td>\n",
       "      <td>191.994110</td>\n",
       "      <td>4900.058594</td>\n",
       "      <td>tensor(7.4081, device='cuda:0')</td>\n",
       "      <td>tensor(0.2352, device='cuda:0')</td>\n",
       "      <td>tensor(73035.7344, device='cuda:0')</td>\n",
       "      <td>tensor(1042.3658, device='cuda:0')</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>1.060572e-04</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>1.569453e-04</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>48.823463</td>\n",
       "      <td>166728.703125</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>1.387867e-06</td>\n",
       "      <td>5.260651e-02</td>\n",
       "      <td>2.638203e-05</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>82.054054</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>3414.929932</td>\n",
       "      <td>30536.048828</td>\n",
       "      <td>3.031742e+09</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>448.095215</td>\n",
       "      <td>62.006210</td>\n",
       "      <td>2.690325e-04</td>\n",
       "      <td>0.843506</td>\n",
       "      <td>4.031494</td>\n",
       "      <td>47.995789</td>\n",
       "      <td>175.967529</td>\n",
       "      <td>240.002502</td>\n",
       "      <td>3413.891846</td>\n",
       "      <td>tensor(12.8179, device='cuda:0')</td>\n",
       "      <td>tensor(0.3095, device='cuda:0')</td>\n",
       "      <td>tensor(26455.1523, device='cuda:0')</td>\n",
       "      <td>tensor(1135.1500, device='cuda:0')</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>4.456205e-04</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>1.171809e-04</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>59.075577</td>\n",
       "      <td>329189.125000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-3.281977e-07</td>\n",
       "      <td>-3.920203e-02</td>\n",
       "      <td>-3.281977e+05</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>99.208954</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>5572.338867</td>\n",
       "      <td>61945.824219</td>\n",
       "      <td>3.524076e+10</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>448.061035</td>\n",
       "      <td>77.599541</td>\n",
       "      <td>3.124934e-04</td>\n",
       "      <td>1.134583</td>\n",
       "      <td>5.964355</td>\n",
       "      <td>63.988464</td>\n",
       "      <td>192.023682</td>\n",
       "      <td>256.024170</td>\n",
       "      <td>5571.521973</td>\n",
       "      <td>tensor(8.5375, device='cuda:0')</td>\n",
       "      <td>tensor(0.0257, device='cuda:0')</td>\n",
       "      <td>tensor(51248.5547, device='cuda:0')</td>\n",
       "      <td>tensor(212.9493, device='cuda:0')</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>9.466882e-05</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>2.336649e-04</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.gate.weight</td>\n",
       "      <td>(256, 7168)</td>\n",
       "      <td>1835008.0</td>\n",
       "      <td>29.131956</td>\n",
       "      <td>29.370396</td>\n",
       "      <td>0.991882</td>\n",
       "      <td>-8.851806e-05</td>\n",
       "      <td>2.514182e-04</td>\n",
       "      <td>-3.520750e-01</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.991940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002488</td>\n",
       "      <td>1.421778</td>\n",
       "      <td>11.759218</td>\n",
       "      <td>2.415468e+06</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>0.530273</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>-3.187038e-03</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>0.223582</td>\n",
       "      <td>tensor(15.8844, device='cuda:0')</td>\n",
       "      <td>tensor(0.6004, device='cuda:0')</td>\n",
       "      <td>tensor(14.8305, device='cuda:0')</td>\n",
       "      <td>tensor(0.1455, device='cuda:0')</td>\n",
       "      <td>0.058314</td>\n",
       "      <td>9.905634e-06</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>1.811016e-06</td>\n",
       "      <td>0.062994</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.down_proj.weight</td>\n",
       "      <td>(7168, 2048)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>46.158073</td>\n",
       "      <td>202610.562500</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>-5.081034e-06</td>\n",
       "      <td>-2.179184e-02</td>\n",
       "      <td>-5.081034e+06</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>52.880806</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>4389.493652</td>\n",
       "      <td>47949.730469</td>\n",
       "      <td>3.665039e+10</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>448.048584</td>\n",
       "      <td>35.982563</td>\n",
       "      <td>-1.557488e-04</td>\n",
       "      <td>0.349304</td>\n",
       "      <td>1.750744</td>\n",
       "      <td>23.991455</td>\n",
       "      <td>112.002792</td>\n",
       "      <td>176.009033</td>\n",
       "      <td>4388.459473</td>\n",
       "      <td>tensor(6.6716, device='cuda:0')</td>\n",
       "      <td>tensor(0.1751, device='cuda:0')</td>\n",
       "      <td>tensor(38450.7852, device='cuda:0')</td>\n",
       "      <td>tensor(176.5273, device='cuda:0')</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>4.673662e-05</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>9.593985e-05</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.gate_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>64.730461</td>\n",
       "      <td>255341.218750</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-7.044782e-05</td>\n",
       "      <td>1.505888e-02</td>\n",
       "      <td>-4.678158e-03</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>66.643372</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>3944.684326</td>\n",
       "      <td>49669.804688</td>\n",
       "      <td>4.712193e+10</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>448.062500</td>\n",
       "      <td>49.567970</td>\n",
       "      <td>5.894285e-05</td>\n",
       "      <td>0.676636</td>\n",
       "      <td>3.275879</td>\n",
       "      <td>36.020386</td>\n",
       "      <td>143.978149</td>\n",
       "      <td>207.992828</td>\n",
       "      <td>3943.669434</td>\n",
       "      <td>tensor(20.2600, device='cuda:0')</td>\n",
       "      <td>tensor(0.1997, device='cuda:0')</td>\n",
       "      <td>tensor(71203.4219, device='cuda:0')</td>\n",
       "      <td>tensor(208.3305, device='cuda:0')</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>3.661342e-05</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>4.116225e-05</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.shared_experts.up_proj.weight</td>\n",
       "      <td>(2048, 7168)</td>\n",
       "      <td>14680064.0</td>\n",
       "      <td>50.728722</td>\n",
       "      <td>222510.703125</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>4.082678e-07</td>\n",
       "      <td>1.042032e-02</td>\n",
       "      <td>3.917998e-05</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>58.074692</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>4386.286621</td>\n",
       "      <td>63520.992188</td>\n",
       "      <td>2.883965e+11</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>448.050781</td>\n",
       "      <td>42.034321</td>\n",
       "      <td>-2.670212e-05</td>\n",
       "      <td>0.566742</td>\n",
       "      <td>2.766113</td>\n",
       "      <td>31.987305</td>\n",
       "      <td>119.986084</td>\n",
       "      <td>192.002914</td>\n",
       "      <td>4385.196289</td>\n",
       "      <td>tensor(8.7921, device='cuda:0')</td>\n",
       "      <td>tensor(0.2365, device='cuda:0')</td>\n",
       "      <td>tensor(133543.0156, device='cuda:0')</td>\n",
       "      <td>tensor(128.6453, device='cuda:0')</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>5.486513e-05</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>1.367414e-04</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_a_proj_with_mqa.weight</td>\n",
       "      <td>(576, 7168)</td>\n",
       "      <td>4128768.0</td>\n",
       "      <td>47.286278</td>\n",
       "      <td>185368.171875</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.049011e-05</td>\n",
       "      <td>2.346013e-02</td>\n",
       "      <td>4.471461e-04</td>\n",
       "      <td>0.023272</td>\n",
       "      <td>91.227325</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>3920.126709</td>\n",
       "      <td>53168.152344</td>\n",
       "      <td>4.398046e+10</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>448.095215</td>\n",
       "      <td>70.598984</td>\n",
       "      <td>2.658626e-06</td>\n",
       "      <td>1.008301</td>\n",
       "      <td>5.012756</td>\n",
       "      <td>56.009583</td>\n",
       "      <td>191.912109</td>\n",
       "      <td>255.989136</td>\n",
       "      <td>3919.112793</td>\n",
       "      <td>tensor(10.1165, device='cuda:0')</td>\n",
       "      <td>tensor(0.2669, device='cuda:0')</td>\n",
       "      <td>tensor(27195.3047, device='cuda:0')</td>\n",
       "      <td>tensor(1194.9875, device='cuda:0')</td>\n",
       "      <td>0.035558</td>\n",
       "      <td>2.869157e-04</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>2.241689e-05</td>\n",
       "      <td>0.040544</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20480, 512)</td>\n",
       "      <td>(32768, 512)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.o_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(7168, 12288)</td>\n",
       "      <td>(7168, 16384)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_a_proj.weight</td>\n",
       "      <td>(1536, 7168)</td>\n",
       "      <td>11010048.0</td>\n",
       "      <td>56.993889</td>\n",
       "      <td>261524.468750</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>4.304269e-06</td>\n",
       "      <td>-2.489731e-02</td>\n",
       "      <td>4.304268e+06</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>78.816605</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>4588.641113</td>\n",
       "      <td>50657.347656</td>\n",
       "      <td>2.971653e+10</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>448.065918</td>\n",
       "      <td>58.154953</td>\n",
       "      <td>-8.692507e-05</td>\n",
       "      <td>0.739685</td>\n",
       "      <td>3.735413</td>\n",
       "      <td>43.985229</td>\n",
       "      <td>160.017212</td>\n",
       "      <td>240.000900</td>\n",
       "      <td>4587.669434</td>\n",
       "      <td>tensor(10.0743, device='cuda:0')</td>\n",
       "      <td>tensor(0.0338, device='cuda:0')</td>\n",
       "      <td>tensor(71440.6328, device='cuda:0')</td>\n",
       "      <td>tensor(186.7096, device='cuda:0')</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>2.516703e-05</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>1.981615e-04</td>\n",
       "      <td>0.025320</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_b_proj.weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(12288, 1536)</td>\n",
       "      <td>(24576, 1536)</td>\n",
       "      <td>shape_mismatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer                                                  key  \\\n",
       "1        0                  model.layers.0.mlp.down_proj.weight   \n",
       "2        0                  model.layers.0.mlp.gate_proj.weight   \n",
       "3        0                    model.layers.0.mlp.up_proj.weight   \n",
       "6        0   model.layers.0.self_attn.kv_a_proj_with_mqa.weight   \n",
       "7        0            model.layers.0.self_attn.kv_b_proj.weight   \n",
       "8        0               model.layers.0.self_attn.o_proj.weight   \n",
       "10       0             model.layers.0.self_attn.q_a_proj.weight   \n",
       "11       0             model.layers.0.self_attn.q_b_proj.weight   \n",
       "13       1                  model.layers.1.mlp.down_proj.weight   \n",
       "14       1                  model.layers.1.mlp.gate_proj.weight   \n",
       "15       1                    model.layers.1.mlp.up_proj.weight   \n",
       "18       1   model.layers.1.self_attn.kv_a_proj_with_mqa.weight   \n",
       "19       1            model.layers.1.self_attn.kv_b_proj.weight   \n",
       "20       1               model.layers.1.self_attn.o_proj.weight   \n",
       "22       1             model.layers.1.self_attn.q_a_proj.weight   \n",
       "23       1             model.layers.1.self_attn.q_b_proj.weight   \n",
       "25       2                  model.layers.2.mlp.down_proj.weight   \n",
       "26       2                  model.layers.2.mlp.gate_proj.weight   \n",
       "27       2                    model.layers.2.mlp.up_proj.weight   \n",
       "30       2   model.layers.2.self_attn.kv_a_proj_with_mqa.weight   \n",
       "31       2            model.layers.2.self_attn.kv_b_proj.weight   \n",
       "32       2               model.layers.2.self_attn.o_proj.weight   \n",
       "34       2             model.layers.2.self_attn.q_a_proj.weight   \n",
       "35       2             model.layers.2.self_attn.q_b_proj.weight   \n",
       "38       3                       model.layers.3.mlp.gate.weight   \n",
       "39       3   model.layers.3.mlp.shared_experts.down_proj.weight   \n",
       "40       3   model.layers.3.mlp.shared_experts.gate_proj.weight   \n",
       "41       3     model.layers.3.mlp.shared_experts.up_proj.weight   \n",
       "44       3   model.layers.3.self_attn.kv_a_proj_with_mqa.weight   \n",
       "45       3            model.layers.3.self_attn.kv_b_proj.weight   \n",
       "46       3               model.layers.3.self_attn.o_proj.weight   \n",
       "48       3             model.layers.3.self_attn.q_a_proj.weight   \n",
       "49       3             model.layers.3.self_attn.q_b_proj.weight   \n",
       "52       4                       model.layers.4.mlp.gate.weight   \n",
       "53       4   model.layers.4.mlp.shared_experts.down_proj.weight   \n",
       "54       4   model.layers.4.mlp.shared_experts.gate_proj.weight   \n",
       "55       4     model.layers.4.mlp.shared_experts.up_proj.weight   \n",
       "58       4   model.layers.4.self_attn.kv_a_proj_with_mqa.weight   \n",
       "59       4            model.layers.4.self_attn.kv_b_proj.weight   \n",
       "60       4               model.layers.4.self_attn.o_proj.weight   \n",
       "62       4             model.layers.4.self_attn.q_a_proj.weight   \n",
       "63       4             model.layers.4.self_attn.q_b_proj.weight   \n",
       "66       5                       model.layers.5.mlp.gate.weight   \n",
       "67       5   model.layers.5.mlp.shared_experts.down_proj.weight   \n",
       "68       5   model.layers.5.mlp.shared_experts.gate_proj.weight   \n",
       "69       5     model.layers.5.mlp.shared_experts.up_proj.weight   \n",
       "72       5   model.layers.5.self_attn.kv_a_proj_with_mqa.weight   \n",
       "73       5            model.layers.5.self_attn.kv_b_proj.weight   \n",
       "74       5               model.layers.5.self_attn.o_proj.weight   \n",
       "76       5             model.layers.5.self_attn.q_a_proj.weight   \n",
       "77       5             model.layers.5.self_attn.q_b_proj.weight   \n",
       "80       6                       model.layers.6.mlp.gate.weight   \n",
       "81       6   model.layers.6.mlp.shared_experts.down_proj.weight   \n",
       "82       6   model.layers.6.mlp.shared_experts.gate_proj.weight   \n",
       "83       6     model.layers.6.mlp.shared_experts.up_proj.weight   \n",
       "86       6   model.layers.6.self_attn.kv_a_proj_with_mqa.weight   \n",
       "87       6            model.layers.6.self_attn.kv_b_proj.weight   \n",
       "88       6               model.layers.6.self_attn.o_proj.weight   \n",
       "90       6             model.layers.6.self_attn.q_a_proj.weight   \n",
       "91       6             model.layers.6.self_attn.q_b_proj.weight   \n",
       "94       7                       model.layers.7.mlp.gate.weight   \n",
       "95       7   model.layers.7.mlp.shared_experts.down_proj.weight   \n",
       "96       7   model.layers.7.mlp.shared_experts.gate_proj.weight   \n",
       "97       7     model.layers.7.mlp.shared_experts.up_proj.weight   \n",
       "100      7   model.layers.7.self_attn.kv_a_proj_with_mqa.weight   \n",
       "101      7            model.layers.7.self_attn.kv_b_proj.weight   \n",
       "102      7               model.layers.7.self_attn.o_proj.weight   \n",
       "104      7             model.layers.7.self_attn.q_a_proj.weight   \n",
       "105      7             model.layers.7.self_attn.q_b_proj.weight   \n",
       "108      8                       model.layers.8.mlp.gate.weight   \n",
       "109      8   model.layers.8.mlp.shared_experts.down_proj.weight   \n",
       "110      8   model.layers.8.mlp.shared_experts.gate_proj.weight   \n",
       "111      8     model.layers.8.mlp.shared_experts.up_proj.weight   \n",
       "114      8   model.layers.8.self_attn.kv_a_proj_with_mqa.weight   \n",
       "115      8            model.layers.8.self_attn.kv_b_proj.weight   \n",
       "116      8               model.layers.8.self_attn.o_proj.weight   \n",
       "118      8             model.layers.8.self_attn.q_a_proj.weight   \n",
       "119      8             model.layers.8.self_attn.q_b_proj.weight   \n",
       "122      9                       model.layers.9.mlp.gate.weight   \n",
       "123      9   model.layers.9.mlp.shared_experts.down_proj.weight   \n",
       "124      9   model.layers.9.mlp.shared_experts.gate_proj.weight   \n",
       "125      9     model.layers.9.mlp.shared_experts.up_proj.weight   \n",
       "128      9   model.layers.9.self_attn.kv_a_proj_with_mqa.weight   \n",
       "129      9            model.layers.9.self_attn.kv_b_proj.weight   \n",
       "130      9               model.layers.9.self_attn.o_proj.weight   \n",
       "132      9             model.layers.9.self_attn.q_a_proj.weight   \n",
       "133      9             model.layers.9.self_attn.q_b_proj.weight   \n",
       "136     10                      model.layers.10.mlp.gate.weight   \n",
       "137     10  model.layers.10.mlp.shared_experts.down_proj.weight   \n",
       "138     10  model.layers.10.mlp.shared_experts.gate_proj.weight   \n",
       "139     10    model.layers.10.mlp.shared_experts.up_proj.weight   \n",
       "142     10  model.layers.10.self_attn.kv_a_proj_with_mqa.weight   \n",
       "143     10           model.layers.10.self_attn.kv_b_proj.weight   \n",
       "144     10              model.layers.10.self_attn.o_proj.weight   \n",
       "146     10            model.layers.10.self_attn.q_a_proj.weight   \n",
       "147     10            model.layers.10.self_attn.q_b_proj.weight   \n",
       "150     11                      model.layers.11.mlp.gate.weight   \n",
       "151     11  model.layers.11.mlp.shared_experts.down_proj.weight   \n",
       "152     11  model.layers.11.mlp.shared_experts.gate_proj.weight   \n",
       "153     11    model.layers.11.mlp.shared_experts.up_proj.weight   \n",
       "156     11  model.layers.11.self_attn.kv_a_proj_with_mqa.weight   \n",
       "157     11           model.layers.11.self_attn.kv_b_proj.weight   \n",
       "158     11              model.layers.11.self_attn.o_proj.weight   \n",
       "160     11            model.layers.11.self_attn.q_a_proj.weight   \n",
       "161     11            model.layers.11.self_attn.q_b_proj.weight   \n",
       "164     12                      model.layers.12.mlp.gate.weight   \n",
       "165     12  model.layers.12.mlp.shared_experts.down_proj.weight   \n",
       "166     12  model.layers.12.mlp.shared_experts.gate_proj.weight   \n",
       "167     12    model.layers.12.mlp.shared_experts.up_proj.weight   \n",
       "170     12  model.layers.12.self_attn.kv_a_proj_with_mqa.weight   \n",
       "171     12           model.layers.12.self_attn.kv_b_proj.weight   \n",
       "172     12              model.layers.12.self_attn.o_proj.weight   \n",
       "174     12            model.layers.12.self_attn.q_a_proj.weight   \n",
       "175     12            model.layers.12.self_attn.q_b_proj.weight   \n",
       "178     13                      model.layers.13.mlp.gate.weight   \n",
       "179     13  model.layers.13.mlp.shared_experts.down_proj.weight   \n",
       "180     13  model.layers.13.mlp.shared_experts.gate_proj.weight   \n",
       "181     13    model.layers.13.mlp.shared_experts.up_proj.weight   \n",
       "184     13  model.layers.13.self_attn.kv_a_proj_with_mqa.weight   \n",
       "185     13           model.layers.13.self_attn.kv_b_proj.weight   \n",
       "186     13              model.layers.13.self_attn.o_proj.weight   \n",
       "188     13            model.layers.13.self_attn.q_a_proj.weight   \n",
       "189     13            model.layers.13.self_attn.q_b_proj.weight   \n",
       "192     14                      model.layers.14.mlp.gate.weight   \n",
       "193     14  model.layers.14.mlp.shared_experts.down_proj.weight   \n",
       "194     14  model.layers.14.mlp.shared_experts.gate_proj.weight   \n",
       "195     14    model.layers.14.mlp.shared_experts.up_proj.weight   \n",
       "198     14  model.layers.14.self_attn.kv_a_proj_with_mqa.weight   \n",
       "199     14           model.layers.14.self_attn.kv_b_proj.weight   \n",
       "200     14              model.layers.14.self_attn.o_proj.weight   \n",
       "202     14            model.layers.14.self_attn.q_a_proj.weight   \n",
       "203     14            model.layers.14.self_attn.q_b_proj.weight   \n",
       "206     15                      model.layers.15.mlp.gate.weight   \n",
       "207     15  model.layers.15.mlp.shared_experts.down_proj.weight   \n",
       "208     15  model.layers.15.mlp.shared_experts.gate_proj.weight   \n",
       "209     15    model.layers.15.mlp.shared_experts.up_proj.weight   \n",
       "212     15  model.layers.15.self_attn.kv_a_proj_with_mqa.weight   \n",
       "213     15           model.layers.15.self_attn.kv_b_proj.weight   \n",
       "214     15              model.layers.15.self_attn.o_proj.weight   \n",
       "216     15            model.layers.15.self_attn.q_a_proj.weight   \n",
       "217     15            model.layers.15.self_attn.q_b_proj.weight   \n",
       "220     16                      model.layers.16.mlp.gate.weight   \n",
       "221     16  model.layers.16.mlp.shared_experts.down_proj.weight   \n",
       "222     16  model.layers.16.mlp.shared_experts.gate_proj.weight   \n",
       "223     16    model.layers.16.mlp.shared_experts.up_proj.weight   \n",
       "226     16  model.layers.16.self_attn.kv_a_proj_with_mqa.weight   \n",
       "227     16           model.layers.16.self_attn.kv_b_proj.weight   \n",
       "228     16              model.layers.16.self_attn.o_proj.weight   \n",
       "230     16            model.layers.16.self_attn.q_a_proj.weight   \n",
       "231     16            model.layers.16.self_attn.q_b_proj.weight   \n",
       "234     17                      model.layers.17.mlp.gate.weight   \n",
       "235     17  model.layers.17.mlp.shared_experts.down_proj.weight   \n",
       "236     17  model.layers.17.mlp.shared_experts.gate_proj.weight   \n",
       "237     17    model.layers.17.mlp.shared_experts.up_proj.weight   \n",
       "240     17  model.layers.17.self_attn.kv_a_proj_with_mqa.weight   \n",
       "241     17           model.layers.17.self_attn.kv_b_proj.weight   \n",
       "242     17              model.layers.17.self_attn.o_proj.weight   \n",
       "244     17            model.layers.17.self_attn.q_a_proj.weight   \n",
       "245     17            model.layers.17.self_attn.q_b_proj.weight   \n",
       "248     18                      model.layers.18.mlp.gate.weight   \n",
       "249     18  model.layers.18.mlp.shared_experts.down_proj.weight   \n",
       "250     18  model.layers.18.mlp.shared_experts.gate_proj.weight   \n",
       "251     18    model.layers.18.mlp.shared_experts.up_proj.weight   \n",
       "254     18  model.layers.18.self_attn.kv_a_proj_with_mqa.weight   \n",
       "255     18           model.layers.18.self_attn.kv_b_proj.weight   \n",
       "256     18              model.layers.18.self_attn.o_proj.weight   \n",
       "258     18            model.layers.18.self_attn.q_a_proj.weight   \n",
       "259     18            model.layers.18.self_attn.q_b_proj.weight   \n",
       "262     19                      model.layers.19.mlp.gate.weight   \n",
       "263     19  model.layers.19.mlp.shared_experts.down_proj.weight   \n",
       "264     19  model.layers.19.mlp.shared_experts.gate_proj.weight   \n",
       "265     19    model.layers.19.mlp.shared_experts.up_proj.weight   \n",
       "268     19  model.layers.19.self_attn.kv_a_proj_with_mqa.weight   \n",
       "269     19           model.layers.19.self_attn.kv_b_proj.weight   \n",
       "270     19              model.layers.19.self_attn.o_proj.weight   \n",
       "272     19            model.layers.19.self_attn.q_a_proj.weight   \n",
       "273     19            model.layers.19.self_attn.q_b_proj.weight   \n",
       "276     20                      model.layers.20.mlp.gate.weight   \n",
       "277     20  model.layers.20.mlp.shared_experts.down_proj.weight   \n",
       "278     20  model.layers.20.mlp.shared_experts.gate_proj.weight   \n",
       "279     20    model.layers.20.mlp.shared_experts.up_proj.weight   \n",
       "282     20  model.layers.20.self_attn.kv_a_proj_with_mqa.weight   \n",
       "283     20           model.layers.20.self_attn.kv_b_proj.weight   \n",
       "284     20              model.layers.20.self_attn.o_proj.weight   \n",
       "286     20            model.layers.20.self_attn.q_a_proj.weight   \n",
       "287     20            model.layers.20.self_attn.q_b_proj.weight   \n",
       "290     21                      model.layers.21.mlp.gate.weight   \n",
       "291     21  model.layers.21.mlp.shared_experts.down_proj.weight   \n",
       "292     21  model.layers.21.mlp.shared_experts.gate_proj.weight   \n",
       "293     21    model.layers.21.mlp.shared_experts.up_proj.weight   \n",
       "296     21  model.layers.21.self_attn.kv_a_proj_with_mqa.weight   \n",
       "297     21           model.layers.21.self_attn.kv_b_proj.weight   \n",
       "298     21              model.layers.21.self_attn.o_proj.weight   \n",
       "300     21            model.layers.21.self_attn.q_a_proj.weight   \n",
       "301     21            model.layers.21.self_attn.q_b_proj.weight   \n",
       "304     22                      model.layers.22.mlp.gate.weight   \n",
       "305     22  model.layers.22.mlp.shared_experts.down_proj.weight   \n",
       "306     22  model.layers.22.mlp.shared_experts.gate_proj.weight   \n",
       "307     22    model.layers.22.mlp.shared_experts.up_proj.weight   \n",
       "310     22  model.layers.22.self_attn.kv_a_proj_with_mqa.weight   \n",
       "311     22           model.layers.22.self_attn.kv_b_proj.weight   \n",
       "312     22              model.layers.22.self_attn.o_proj.weight   \n",
       "314     22            model.layers.22.self_attn.q_a_proj.weight   \n",
       "315     22            model.layers.22.self_attn.q_b_proj.weight   \n",
       "318     23                      model.layers.23.mlp.gate.weight   \n",
       "319     23  model.layers.23.mlp.shared_experts.down_proj.weight   \n",
       "320     23  model.layers.23.mlp.shared_experts.gate_proj.weight   \n",
       "321     23    model.layers.23.mlp.shared_experts.up_proj.weight   \n",
       "324     23  model.layers.23.self_attn.kv_a_proj_with_mqa.weight   \n",
       "325     23           model.layers.23.self_attn.kv_b_proj.weight   \n",
       "326     23              model.layers.23.self_attn.o_proj.weight   \n",
       "328     23            model.layers.23.self_attn.q_a_proj.weight   \n",
       "329     23            model.layers.23.self_attn.q_b_proj.weight   \n",
       "332     24                      model.layers.24.mlp.gate.weight   \n",
       "333     24  model.layers.24.mlp.shared_experts.down_proj.weight   \n",
       "334     24  model.layers.24.mlp.shared_experts.gate_proj.weight   \n",
       "335     24    model.layers.24.mlp.shared_experts.up_proj.weight   \n",
       "338     24  model.layers.24.self_attn.kv_a_proj_with_mqa.weight   \n",
       "339     24           model.layers.24.self_attn.kv_b_proj.weight   \n",
       "340     24              model.layers.24.self_attn.o_proj.weight   \n",
       "342     24            model.layers.24.self_attn.q_a_proj.weight   \n",
       "343     24            model.layers.24.self_attn.q_b_proj.weight   \n",
       "346     25                      model.layers.25.mlp.gate.weight   \n",
       "347     25  model.layers.25.mlp.shared_experts.down_proj.weight   \n",
       "348     25  model.layers.25.mlp.shared_experts.gate_proj.weight   \n",
       "349     25    model.layers.25.mlp.shared_experts.up_proj.weight   \n",
       "352     25  model.layers.25.self_attn.kv_a_proj_with_mqa.weight   \n",
       "353     25           model.layers.25.self_attn.kv_b_proj.weight   \n",
       "354     25              model.layers.25.self_attn.o_proj.weight   \n",
       "356     25            model.layers.25.self_attn.q_a_proj.weight   \n",
       "357     25            model.layers.25.self_attn.q_b_proj.weight   \n",
       "360     26                      model.layers.26.mlp.gate.weight   \n",
       "361     26  model.layers.26.mlp.shared_experts.down_proj.weight   \n",
       "362     26  model.layers.26.mlp.shared_experts.gate_proj.weight   \n",
       "363     26    model.layers.26.mlp.shared_experts.up_proj.weight   \n",
       "366     26  model.layers.26.self_attn.kv_a_proj_with_mqa.weight   \n",
       "367     26           model.layers.26.self_attn.kv_b_proj.weight   \n",
       "368     26              model.layers.26.self_attn.o_proj.weight   \n",
       "370     26            model.layers.26.self_attn.q_a_proj.weight   \n",
       "371     26            model.layers.26.self_attn.q_b_proj.weight   \n",
       "374     27                      model.layers.27.mlp.gate.weight   \n",
       "375     27  model.layers.27.mlp.shared_experts.down_proj.weight   \n",
       "376     27  model.layers.27.mlp.shared_experts.gate_proj.weight   \n",
       "377     27    model.layers.27.mlp.shared_experts.up_proj.weight   \n",
       "380     27  model.layers.27.self_attn.kv_a_proj_with_mqa.weight   \n",
       "381     27           model.layers.27.self_attn.kv_b_proj.weight   \n",
       "382     27              model.layers.27.self_attn.o_proj.weight   \n",
       "384     27            model.layers.27.self_attn.q_a_proj.weight   \n",
       "385     27            model.layers.27.self_attn.q_b_proj.weight   \n",
       "388     28                      model.layers.28.mlp.gate.weight   \n",
       "389     28  model.layers.28.mlp.shared_experts.down_proj.weight   \n",
       "390     28  model.layers.28.mlp.shared_experts.gate_proj.weight   \n",
       "391     28    model.layers.28.mlp.shared_experts.up_proj.weight   \n",
       "394     28  model.layers.28.self_attn.kv_a_proj_with_mqa.weight   \n",
       "395     28           model.layers.28.self_attn.kv_b_proj.weight   \n",
       "396     28              model.layers.28.self_attn.o_proj.weight   \n",
       "398     28            model.layers.28.self_attn.q_a_proj.weight   \n",
       "399     28            model.layers.28.self_attn.q_b_proj.weight   \n",
       "402     29                      model.layers.29.mlp.gate.weight   \n",
       "403     29  model.layers.29.mlp.shared_experts.down_proj.weight   \n",
       "404     29  model.layers.29.mlp.shared_experts.gate_proj.weight   \n",
       "405     29    model.layers.29.mlp.shared_experts.up_proj.weight   \n",
       "408     29  model.layers.29.self_attn.kv_a_proj_with_mqa.weight   \n",
       "409     29           model.layers.29.self_attn.kv_b_proj.weight   \n",
       "410     29              model.layers.29.self_attn.o_proj.weight   \n",
       "412     29            model.layers.29.self_attn.q_a_proj.weight   \n",
       "413     29            model.layers.29.self_attn.q_b_proj.weight   \n",
       "416     30                      model.layers.30.mlp.gate.weight   \n",
       "417     30  model.layers.30.mlp.shared_experts.down_proj.weight   \n",
       "418     30  model.layers.30.mlp.shared_experts.gate_proj.weight   \n",
       "419     30    model.layers.30.mlp.shared_experts.up_proj.weight   \n",
       "422     30  model.layers.30.self_attn.kv_a_proj_with_mqa.weight   \n",
       "423     30           model.layers.30.self_attn.kv_b_proj.weight   \n",
       "424     30              model.layers.30.self_attn.o_proj.weight   \n",
       "426     30            model.layers.30.self_attn.q_a_proj.weight   \n",
       "427     30            model.layers.30.self_attn.q_b_proj.weight   \n",
       "430     31                      model.layers.31.mlp.gate.weight   \n",
       "431     31  model.layers.31.mlp.shared_experts.down_proj.weight   \n",
       "432     31  model.layers.31.mlp.shared_experts.gate_proj.weight   \n",
       "433     31    model.layers.31.mlp.shared_experts.up_proj.weight   \n",
       "436     31  model.layers.31.self_attn.kv_a_proj_with_mqa.weight   \n",
       "437     31           model.layers.31.self_attn.kv_b_proj.weight   \n",
       "438     31              model.layers.31.self_attn.o_proj.weight   \n",
       "440     31            model.layers.31.self_attn.q_a_proj.weight   \n",
       "441     31            model.layers.31.self_attn.q_b_proj.weight   \n",
       "444     32                      model.layers.32.mlp.gate.weight   \n",
       "445     32  model.layers.32.mlp.shared_experts.down_proj.weight   \n",
       "446     32  model.layers.32.mlp.shared_experts.gate_proj.weight   \n",
       "447     32    model.layers.32.mlp.shared_experts.up_proj.weight   \n",
       "450     32  model.layers.32.self_attn.kv_a_proj_with_mqa.weight   \n",
       "451     32           model.layers.32.self_attn.kv_b_proj.weight   \n",
       "452     32              model.layers.32.self_attn.o_proj.weight   \n",
       "454     32            model.layers.32.self_attn.q_a_proj.weight   \n",
       "455     32            model.layers.32.self_attn.q_b_proj.weight   \n",
       "458     33                      model.layers.33.mlp.gate.weight   \n",
       "459     33  model.layers.33.mlp.shared_experts.down_proj.weight   \n",
       "460     33  model.layers.33.mlp.shared_experts.gate_proj.weight   \n",
       "461     33    model.layers.33.mlp.shared_experts.up_proj.weight   \n",
       "464     33  model.layers.33.self_attn.kv_a_proj_with_mqa.weight   \n",
       "465     33           model.layers.33.self_attn.kv_b_proj.weight   \n",
       "466     33              model.layers.33.self_attn.o_proj.weight   \n",
       "468     33            model.layers.33.self_attn.q_a_proj.weight   \n",
       "469     33            model.layers.33.self_attn.q_b_proj.weight   \n",
       "472     34                      model.layers.34.mlp.gate.weight   \n",
       "473     34  model.layers.34.mlp.shared_experts.down_proj.weight   \n",
       "474     34  model.layers.34.mlp.shared_experts.gate_proj.weight   \n",
       "475     34    model.layers.34.mlp.shared_experts.up_proj.weight   \n",
       "478     34  model.layers.34.self_attn.kv_a_proj_with_mqa.weight   \n",
       "479     34           model.layers.34.self_attn.kv_b_proj.weight   \n",
       "480     34              model.layers.34.self_attn.o_proj.weight   \n",
       "482     34            model.layers.34.self_attn.q_a_proj.weight   \n",
       "483     34            model.layers.34.self_attn.q_b_proj.weight   \n",
       "486     35                      model.layers.35.mlp.gate.weight   \n",
       "487     35  model.layers.35.mlp.shared_experts.down_proj.weight   \n",
       "488     35  model.layers.35.mlp.shared_experts.gate_proj.weight   \n",
       "489     35    model.layers.35.mlp.shared_experts.up_proj.weight   \n",
       "492     35  model.layers.35.self_attn.kv_a_proj_with_mqa.weight   \n",
       "493     35           model.layers.35.self_attn.kv_b_proj.weight   \n",
       "494     35              model.layers.35.self_attn.o_proj.weight   \n",
       "496     35            model.layers.35.self_attn.q_a_proj.weight   \n",
       "497     35            model.layers.35.self_attn.q_b_proj.weight   \n",
       "500     36                      model.layers.36.mlp.gate.weight   \n",
       "501     36  model.layers.36.mlp.shared_experts.down_proj.weight   \n",
       "502     36  model.layers.36.mlp.shared_experts.gate_proj.weight   \n",
       "503     36    model.layers.36.mlp.shared_experts.up_proj.weight   \n",
       "506     36  model.layers.36.self_attn.kv_a_proj_with_mqa.weight   \n",
       "507     36           model.layers.36.self_attn.kv_b_proj.weight   \n",
       "508     36              model.layers.36.self_attn.o_proj.weight   \n",
       "510     36            model.layers.36.self_attn.q_a_proj.weight   \n",
       "511     36            model.layers.36.self_attn.q_b_proj.weight   \n",
       "514     37                      model.layers.37.mlp.gate.weight   \n",
       "515     37  model.layers.37.mlp.shared_experts.down_proj.weight   \n",
       "516     37  model.layers.37.mlp.shared_experts.gate_proj.weight   \n",
       "517     37    model.layers.37.mlp.shared_experts.up_proj.weight   \n",
       "520     37  model.layers.37.self_attn.kv_a_proj_with_mqa.weight   \n",
       "521     37           model.layers.37.self_attn.kv_b_proj.weight   \n",
       "522     37              model.layers.37.self_attn.o_proj.weight   \n",
       "524     37            model.layers.37.self_attn.q_a_proj.weight   \n",
       "525     37            model.layers.37.self_attn.q_b_proj.weight   \n",
       "528     38                      model.layers.38.mlp.gate.weight   \n",
       "529     38  model.layers.38.mlp.shared_experts.down_proj.weight   \n",
       "530     38  model.layers.38.mlp.shared_experts.gate_proj.weight   \n",
       "531     38    model.layers.38.mlp.shared_experts.up_proj.weight   \n",
       "534     38  model.layers.38.self_attn.kv_a_proj_with_mqa.weight   \n",
       "535     38           model.layers.38.self_attn.kv_b_proj.weight   \n",
       "536     38              model.layers.38.self_attn.o_proj.weight   \n",
       "538     38            model.layers.38.self_attn.q_a_proj.weight   \n",
       "539     38            model.layers.38.self_attn.q_b_proj.weight   \n",
       "542     39                      model.layers.39.mlp.gate.weight   \n",
       "543     39  model.layers.39.mlp.shared_experts.down_proj.weight   \n",
       "544     39  model.layers.39.mlp.shared_experts.gate_proj.weight   \n",
       "545     39    model.layers.39.mlp.shared_experts.up_proj.weight   \n",
       "548     39  model.layers.39.self_attn.kv_a_proj_with_mqa.weight   \n",
       "549     39           model.layers.39.self_attn.kv_b_proj.weight   \n",
       "550     39              model.layers.39.self_attn.o_proj.weight   \n",
       "552     39            model.layers.39.self_attn.q_a_proj.weight   \n",
       "553     39            model.layers.39.self_attn.q_b_proj.weight   \n",
       "556     40                      model.layers.40.mlp.gate.weight   \n",
       "557     40  model.layers.40.mlp.shared_experts.down_proj.weight   \n",
       "558     40  model.layers.40.mlp.shared_experts.gate_proj.weight   \n",
       "559     40    model.layers.40.mlp.shared_experts.up_proj.weight   \n",
       "562     40  model.layers.40.self_attn.kv_a_proj_with_mqa.weight   \n",
       "563     40           model.layers.40.self_attn.kv_b_proj.weight   \n",
       "564     40              model.layers.40.self_attn.o_proj.weight   \n",
       "566     40            model.layers.40.self_attn.q_a_proj.weight   \n",
       "567     40            model.layers.40.self_attn.q_b_proj.weight   \n",
       "570     41                      model.layers.41.mlp.gate.weight   \n",
       "571     41  model.layers.41.mlp.shared_experts.down_proj.weight   \n",
       "572     41  model.layers.41.mlp.shared_experts.gate_proj.weight   \n",
       "573     41    model.layers.41.mlp.shared_experts.up_proj.weight   \n",
       "576     41  model.layers.41.self_attn.kv_a_proj_with_mqa.weight   \n",
       "577     41           model.layers.41.self_attn.kv_b_proj.weight   \n",
       "578     41              model.layers.41.self_attn.o_proj.weight   \n",
       "580     41            model.layers.41.self_attn.q_a_proj.weight   \n",
       "581     41            model.layers.41.self_attn.q_b_proj.weight   \n",
       "584     42                      model.layers.42.mlp.gate.weight   \n",
       "585     42  model.layers.42.mlp.shared_experts.down_proj.weight   \n",
       "586     42  model.layers.42.mlp.shared_experts.gate_proj.weight   \n",
       "587     42    model.layers.42.mlp.shared_experts.up_proj.weight   \n",
       "590     42  model.layers.42.self_attn.kv_a_proj_with_mqa.weight   \n",
       "591     42           model.layers.42.self_attn.kv_b_proj.weight   \n",
       "592     42              model.layers.42.self_attn.o_proj.weight   \n",
       "594     42            model.layers.42.self_attn.q_a_proj.weight   \n",
       "595     42            model.layers.42.self_attn.q_b_proj.weight   \n",
       "598     43                      model.layers.43.mlp.gate.weight   \n",
       "599     43  model.layers.43.mlp.shared_experts.down_proj.weight   \n",
       "600     43  model.layers.43.mlp.shared_experts.gate_proj.weight   \n",
       "601     43    model.layers.43.mlp.shared_experts.up_proj.weight   \n",
       "604     43  model.layers.43.self_attn.kv_a_proj_with_mqa.weight   \n",
       "605     43           model.layers.43.self_attn.kv_b_proj.weight   \n",
       "606     43              model.layers.43.self_attn.o_proj.weight   \n",
       "608     43            model.layers.43.self_attn.q_a_proj.weight   \n",
       "609     43            model.layers.43.self_attn.q_b_proj.weight   \n",
       "612     44                      model.layers.44.mlp.gate.weight   \n",
       "613     44  model.layers.44.mlp.shared_experts.down_proj.weight   \n",
       "614     44  model.layers.44.mlp.shared_experts.gate_proj.weight   \n",
       "615     44    model.layers.44.mlp.shared_experts.up_proj.weight   \n",
       "618     44  model.layers.44.self_attn.kv_a_proj_with_mqa.weight   \n",
       "619     44           model.layers.44.self_attn.kv_b_proj.weight   \n",
       "620     44              model.layers.44.self_attn.o_proj.weight   \n",
       "622     44            model.layers.44.self_attn.q_a_proj.weight   \n",
       "623     44            model.layers.44.self_attn.q_b_proj.weight   \n",
       "626     45                      model.layers.45.mlp.gate.weight   \n",
       "627     45  model.layers.45.mlp.shared_experts.down_proj.weight   \n",
       "628     45  model.layers.45.mlp.shared_experts.gate_proj.weight   \n",
       "629     45    model.layers.45.mlp.shared_experts.up_proj.weight   \n",
       "632     45  model.layers.45.self_attn.kv_a_proj_with_mqa.weight   \n",
       "633     45           model.layers.45.self_attn.kv_b_proj.weight   \n",
       "634     45              model.layers.45.self_attn.o_proj.weight   \n",
       "636     45            model.layers.45.self_attn.q_a_proj.weight   \n",
       "637     45            model.layers.45.self_attn.q_b_proj.weight   \n",
       "640     46                      model.layers.46.mlp.gate.weight   \n",
       "641     46  model.layers.46.mlp.shared_experts.down_proj.weight   \n",
       "642     46  model.layers.46.mlp.shared_experts.gate_proj.weight   \n",
       "643     46    model.layers.46.mlp.shared_experts.up_proj.weight   \n",
       "646     46  model.layers.46.self_attn.kv_a_proj_with_mqa.weight   \n",
       "647     46           model.layers.46.self_attn.kv_b_proj.weight   \n",
       "648     46              model.layers.46.self_attn.o_proj.weight   \n",
       "650     46            model.layers.46.self_attn.q_a_proj.weight   \n",
       "651     46            model.layers.46.self_attn.q_b_proj.weight   \n",
       "654     47                      model.layers.47.mlp.gate.weight   \n",
       "655     47  model.layers.47.mlp.shared_experts.down_proj.weight   \n",
       "656     47  model.layers.47.mlp.shared_experts.gate_proj.weight   \n",
       "657     47    model.layers.47.mlp.shared_experts.up_proj.weight   \n",
       "660     47  model.layers.47.self_attn.kv_a_proj_with_mqa.weight   \n",
       "661     47           model.layers.47.self_attn.kv_b_proj.weight   \n",
       "662     47              model.layers.47.self_attn.o_proj.weight   \n",
       "664     47            model.layers.47.self_attn.q_a_proj.weight   \n",
       "665     47            model.layers.47.self_attn.q_b_proj.weight   \n",
       "668     48                      model.layers.48.mlp.gate.weight   \n",
       "669     48  model.layers.48.mlp.shared_experts.down_proj.weight   \n",
       "670     48  model.layers.48.mlp.shared_experts.gate_proj.weight   \n",
       "671     48    model.layers.48.mlp.shared_experts.up_proj.weight   \n",
       "674     48  model.layers.48.self_attn.kv_a_proj_with_mqa.weight   \n",
       "675     48           model.layers.48.self_attn.kv_b_proj.weight   \n",
       "676     48              model.layers.48.self_attn.o_proj.weight   \n",
       "678     48            model.layers.48.self_attn.q_a_proj.weight   \n",
       "679     48            model.layers.48.self_attn.q_b_proj.weight   \n",
       "682     49                      model.layers.49.mlp.gate.weight   \n",
       "683     49  model.layers.49.mlp.shared_experts.down_proj.weight   \n",
       "684     49  model.layers.49.mlp.shared_experts.gate_proj.weight   \n",
       "685     49    model.layers.49.mlp.shared_experts.up_proj.weight   \n",
       "688     49  model.layers.49.self_attn.kv_a_proj_with_mqa.weight   \n",
       "689     49           model.layers.49.self_attn.kv_b_proj.weight   \n",
       "690     49              model.layers.49.self_attn.o_proj.weight   \n",
       "692     49            model.layers.49.self_attn.q_a_proj.weight   \n",
       "693     49            model.layers.49.self_attn.q_b_proj.weight   \n",
       "696     50                      model.layers.50.mlp.gate.weight   \n",
       "697     50  model.layers.50.mlp.shared_experts.down_proj.weight   \n",
       "698     50  model.layers.50.mlp.shared_experts.gate_proj.weight   \n",
       "699     50    model.layers.50.mlp.shared_experts.up_proj.weight   \n",
       "702     50  model.layers.50.self_attn.kv_a_proj_with_mqa.weight   \n",
       "703     50           model.layers.50.self_attn.kv_b_proj.weight   \n",
       "704     50              model.layers.50.self_attn.o_proj.weight   \n",
       "706     50            model.layers.50.self_attn.q_a_proj.weight   \n",
       "707     50            model.layers.50.self_attn.q_b_proj.weight   \n",
       "710     51                      model.layers.51.mlp.gate.weight   \n",
       "711     51  model.layers.51.mlp.shared_experts.down_proj.weight   \n",
       "712     51  model.layers.51.mlp.shared_experts.gate_proj.weight   \n",
       "713     51    model.layers.51.mlp.shared_experts.up_proj.weight   \n",
       "716     51  model.layers.51.self_attn.kv_a_proj_with_mqa.weight   \n",
       "717     51           model.layers.51.self_attn.kv_b_proj.weight   \n",
       "718     51              model.layers.51.self_attn.o_proj.weight   \n",
       "720     51            model.layers.51.self_attn.q_a_proj.weight   \n",
       "721     51            model.layers.51.self_attn.q_b_proj.weight   \n",
       "724     52                      model.layers.52.mlp.gate.weight   \n",
       "725     52  model.layers.52.mlp.shared_experts.down_proj.weight   \n",
       "726     52  model.layers.52.mlp.shared_experts.gate_proj.weight   \n",
       "727     52    model.layers.52.mlp.shared_experts.up_proj.weight   \n",
       "730     52  model.layers.52.self_attn.kv_a_proj_with_mqa.weight   \n",
       "731     52           model.layers.52.self_attn.kv_b_proj.weight   \n",
       "732     52              model.layers.52.self_attn.o_proj.weight   \n",
       "734     52            model.layers.52.self_attn.q_a_proj.weight   \n",
       "735     52            model.layers.52.self_attn.q_b_proj.weight   \n",
       "738     53                      model.layers.53.mlp.gate.weight   \n",
       "739     53  model.layers.53.mlp.shared_experts.down_proj.weight   \n",
       "740     53  model.layers.53.mlp.shared_experts.gate_proj.weight   \n",
       "741     53    model.layers.53.mlp.shared_experts.up_proj.weight   \n",
       "744     53  model.layers.53.self_attn.kv_a_proj_with_mqa.weight   \n",
       "745     53           model.layers.53.self_attn.kv_b_proj.weight   \n",
       "746     53              model.layers.53.self_attn.o_proj.weight   \n",
       "748     53            model.layers.53.self_attn.q_a_proj.weight   \n",
       "749     53            model.layers.53.self_attn.q_b_proj.weight   \n",
       "752     54                      model.layers.54.mlp.gate.weight   \n",
       "753     54  model.layers.54.mlp.shared_experts.down_proj.weight   \n",
       "754     54  model.layers.54.mlp.shared_experts.gate_proj.weight   \n",
       "755     54    model.layers.54.mlp.shared_experts.up_proj.weight   \n",
       "758     54  model.layers.54.self_attn.kv_a_proj_with_mqa.weight   \n",
       "759     54           model.layers.54.self_attn.kv_b_proj.weight   \n",
       "760     54              model.layers.54.self_attn.o_proj.weight   \n",
       "762     54            model.layers.54.self_attn.q_a_proj.weight   \n",
       "763     54            model.layers.54.self_attn.q_b_proj.weight   \n",
       "766     55                      model.layers.55.mlp.gate.weight   \n",
       "767     55  model.layers.55.mlp.shared_experts.down_proj.weight   \n",
       "768     55  model.layers.55.mlp.shared_experts.gate_proj.weight   \n",
       "769     55    model.layers.55.mlp.shared_experts.up_proj.weight   \n",
       "772     55  model.layers.55.self_attn.kv_a_proj_with_mqa.weight   \n",
       "773     55           model.layers.55.self_attn.kv_b_proj.weight   \n",
       "774     55              model.layers.55.self_attn.o_proj.weight   \n",
       "776     55            model.layers.55.self_attn.q_a_proj.weight   \n",
       "777     55            model.layers.55.self_attn.q_b_proj.weight   \n",
       "780     56                      model.layers.56.mlp.gate.weight   \n",
       "781     56  model.layers.56.mlp.shared_experts.down_proj.weight   \n",
       "782     56  model.layers.56.mlp.shared_experts.gate_proj.weight   \n",
       "783     56    model.layers.56.mlp.shared_experts.up_proj.weight   \n",
       "786     56  model.layers.56.self_attn.kv_a_proj_with_mqa.weight   \n",
       "787     56           model.layers.56.self_attn.kv_b_proj.weight   \n",
       "788     56              model.layers.56.self_attn.o_proj.weight   \n",
       "790     56            model.layers.56.self_attn.q_a_proj.weight   \n",
       "791     56            model.layers.56.self_attn.q_b_proj.weight   \n",
       "794     57                      model.layers.57.mlp.gate.weight   \n",
       "795     57  model.layers.57.mlp.shared_experts.down_proj.weight   \n",
       "796     57  model.layers.57.mlp.shared_experts.gate_proj.weight   \n",
       "797     57    model.layers.57.mlp.shared_experts.up_proj.weight   \n",
       "800     57  model.layers.57.self_attn.kv_a_proj_with_mqa.weight   \n",
       "801     57           model.layers.57.self_attn.kv_b_proj.weight   \n",
       "802     57              model.layers.57.self_attn.o_proj.weight   \n",
       "804     57            model.layers.57.self_attn.q_a_proj.weight   \n",
       "805     57            model.layers.57.self_attn.q_b_proj.weight   \n",
       "808     58                      model.layers.58.mlp.gate.weight   \n",
       "809     58  model.layers.58.mlp.shared_experts.down_proj.weight   \n",
       "810     58  model.layers.58.mlp.shared_experts.gate_proj.weight   \n",
       "811     58    model.layers.58.mlp.shared_experts.up_proj.weight   \n",
       "814     58  model.layers.58.self_attn.kv_a_proj_with_mqa.weight   \n",
       "815     58           model.layers.58.self_attn.kv_b_proj.weight   \n",
       "816     58              model.layers.58.self_attn.o_proj.weight   \n",
       "818     58            model.layers.58.self_attn.q_a_proj.weight   \n",
       "819     58            model.layers.58.self_attn.q_b_proj.weight   \n",
       "822     59                      model.layers.59.mlp.gate.weight   \n",
       "823     59  model.layers.59.mlp.shared_experts.down_proj.weight   \n",
       "824     59  model.layers.59.mlp.shared_experts.gate_proj.weight   \n",
       "825     59    model.layers.59.mlp.shared_experts.up_proj.weight   \n",
       "828     59  model.layers.59.self_attn.kv_a_proj_with_mqa.weight   \n",
       "829     59           model.layers.59.self_attn.kv_b_proj.weight   \n",
       "830     59              model.layers.59.self_attn.o_proj.weight   \n",
       "832     59            model.layers.59.self_attn.q_a_proj.weight   \n",
       "833     59            model.layers.59.self_attn.q_b_proj.weight   \n",
       "836     60                      model.layers.60.mlp.gate.weight   \n",
       "837     60  model.layers.60.mlp.shared_experts.down_proj.weight   \n",
       "838     60  model.layers.60.mlp.shared_experts.gate_proj.weight   \n",
       "839     60    model.layers.60.mlp.shared_experts.up_proj.weight   \n",
       "842     60  model.layers.60.self_attn.kv_a_proj_with_mqa.weight   \n",
       "843     60           model.layers.60.self_attn.kv_b_proj.weight   \n",
       "844     60              model.layers.60.self_attn.o_proj.weight   \n",
       "846     60            model.layers.60.self_attn.q_a_proj.weight   \n",
       "847     60            model.layers.60.self_attn.q_b_proj.weight   \n",
       "\n",
       "             shape        numel     norm_a         norm_b  norm_ratio  \\\n",
       "1    (7168, 18432)  132120576.0  59.667873  428978.468750    0.000139   \n",
       "2    (18432, 7168)  132120576.0  56.593945  233500.296875    0.000242   \n",
       "3    (18432, 7168)  132120576.0  51.375027  589028.500000    0.000087   \n",
       "6      (576, 7168)    4128768.0  42.883209  143063.109375    0.000300   \n",
       "7              NaN          NaN        NaN            NaN         NaN   \n",
       "8              NaN          NaN        NaN            NaN         NaN   \n",
       "10    (1536, 7168)   11010048.0  32.806965  295782.718750    0.000111   \n",
       "11             NaN          NaN        NaN            NaN         NaN   \n",
       "13   (7168, 18432)  132120576.0  31.056589  311506.968750    0.000100   \n",
       "14   (18432, 7168)  132120576.0  46.198711  275344.031250    0.000168   \n",
       "15   (18432, 7168)  132120576.0  24.128511  398866.781250    0.000060   \n",
       "18     (576, 7168)    4128768.0  28.544937  119154.664062    0.000240   \n",
       "19             NaN          NaN        NaN            NaN         NaN   \n",
       "20             NaN          NaN        NaN            NaN         NaN   \n",
       "22    (1536, 7168)   11010048.0  17.876047  176267.359375    0.000101   \n",
       "23             NaN          NaN        NaN            NaN         NaN   \n",
       "25   (7168, 18432)  132120576.0  35.113667  253710.390625    0.000138   \n",
       "26   (18432, 7168)  132120576.0  47.933502  201596.265625    0.000238   \n",
       "27   (18432, 7168)  132120576.0  28.609304  325057.093750    0.000088   \n",
       "30     (576, 7168)    4128768.0  27.854443   98536.000000    0.000283   \n",
       "31             NaN          NaN        NaN            NaN         NaN   \n",
       "32             NaN          NaN        NaN            NaN         NaN   \n",
       "34    (1536, 7168)   11010048.0  23.909323  193261.531250    0.000124   \n",
       "35             NaN          NaN        NaN            NaN         NaN   \n",
       "38     (256, 7168)    1835008.0  29.393806      33.376320    0.880678   \n",
       "39    (7168, 2048)   14680064.0  28.635567  241520.312500    0.000119   \n",
       "40    (2048, 7168)   14680064.0  31.387489  230882.187500    0.000136   \n",
       "41    (2048, 7168)   14680064.0  25.626366  355590.343750    0.000072   \n",
       "44     (576, 7168)    4128768.0  34.273003  139565.296875    0.000246   \n",
       "45             NaN          NaN        NaN            NaN         NaN   \n",
       "46             NaN          NaN        NaN            NaN         NaN   \n",
       "48    (1536, 7168)   11010048.0  37.585987  223475.562500    0.000168   \n",
       "49             NaN          NaN        NaN            NaN         NaN   \n",
       "52     (256, 7168)    1835008.0  40.083839      38.301109    1.046545   \n",
       "53    (7168, 2048)   14680064.0  31.385395  252685.328125    0.000124   \n",
       "54    (2048, 7168)   14680064.0  53.515797  200585.921875    0.000267   \n",
       "55    (2048, 7168)   14680064.0  30.086203  340374.531250    0.000088   \n",
       "58     (576, 7168)    4128768.0  34.652184  153807.328125    0.000225   \n",
       "59             NaN          NaN        NaN            NaN         NaN   \n",
       "60             NaN          NaN        NaN            NaN         NaN   \n",
       "62    (1536, 7168)   11010048.0  29.676378  286426.500000    0.000104   \n",
       "63             NaN          NaN        NaN            NaN         NaN   \n",
       "66     (256, 7168)    1835008.0  47.636959      47.007324    1.013394   \n",
       "67    (7168, 2048)   14680064.0  32.378353  258382.609375    0.000125   \n",
       "68    (2048, 7168)   14680064.0  58.461613  204030.687500    0.000287   \n",
       "69    (2048, 7168)   14680064.0  32.674606  322552.281250    0.000101   \n",
       "72     (576, 7168)    4128768.0  39.866913  127441.625000    0.000313   \n",
       "73             NaN          NaN        NaN            NaN         NaN   \n",
       "74             NaN          NaN        NaN            NaN         NaN   \n",
       "76    (1536, 7168)   11010048.0  35.922665  268944.281250    0.000134   \n",
       "77             NaN          NaN        NaN            NaN         NaN   \n",
       "80     (256, 7168)    1835008.0  52.055973      51.258682    1.015554   \n",
       "81    (7168, 2048)   14680064.0  35.252045  265794.281250    0.000133   \n",
       "82    (2048, 7168)   14680064.0  65.565948  208179.843750    0.000315   \n",
       "83    (2048, 7168)   14680064.0  35.650501  316225.750000    0.000113   \n",
       "86     (576, 7168)    4128768.0  35.578690  165172.265625    0.000215   \n",
       "87             NaN          NaN        NaN            NaN         NaN   \n",
       "88             NaN          NaN        NaN            NaN         NaN   \n",
       "90    (1536, 7168)   11010048.0  32.842499  272285.156250    0.000121   \n",
       "91             NaN          NaN        NaN            NaN         NaN   \n",
       "94     (256, 7168)    1835008.0  62.166615      56.682781    1.096746   \n",
       "95    (7168, 2048)   14680064.0  34.187748  274685.562500    0.000124   \n",
       "96    (2048, 7168)   14680064.0  73.995186  214966.609375    0.000344   \n",
       "97    (2048, 7168)   14680064.0  36.493416  296291.062500    0.000123   \n",
       "100    (576, 7168)    4128768.0  44.163628  158275.140625    0.000279   \n",
       "101            NaN          NaN        NaN            NaN         NaN   \n",
       "102            NaN          NaN        NaN            NaN         NaN   \n",
       "104   (1536, 7168)   11010048.0  44.411427  286513.031250    0.000155   \n",
       "105            NaN          NaN        NaN            NaN         NaN   \n",
       "108    (256, 7168)    1835008.0  63.920872      52.985229    1.206390   \n",
       "109   (7168, 2048)   14680064.0  37.425797  232908.671875    0.000161   \n",
       "110   (2048, 7168)   14680064.0  83.790474  224043.687500    0.000374   \n",
       "111   (2048, 7168)   14680064.0  39.538883  287792.812500    0.000137   \n",
       "114    (576, 7168)    4128768.0  44.211086  148725.421875    0.000297   \n",
       "115            NaN          NaN        NaN            NaN         NaN   \n",
       "116            NaN          NaN        NaN            NaN         NaN   \n",
       "118   (1536, 7168)   11010048.0  43.829700  275328.781250    0.000159   \n",
       "119            NaN          NaN        NaN            NaN         NaN   \n",
       "122    (256, 7168)    1835008.0  61.512337      53.668427    1.146155   \n",
       "123   (7168, 2048)   14680064.0  40.872108  251042.640625    0.000163   \n",
       "124   (2048, 7168)   14680064.0  86.544426  211574.093750    0.000409   \n",
       "125   (2048, 7168)   14680064.0  41.083069  264269.031250    0.000155   \n",
       "128    (576, 7168)    4128768.0  43.943066  171746.765625    0.000256   \n",
       "129            NaN          NaN        NaN            NaN         NaN   \n",
       "130            NaN          NaN        NaN            NaN         NaN   \n",
       "132   (1536, 7168)   11010048.0  42.547871  322357.468750    0.000132   \n",
       "133            NaN          NaN        NaN            NaN         NaN   \n",
       "136    (256, 7168)    1835008.0  59.963379      56.496185    1.061370   \n",
       "137   (7168, 2048)   14680064.0  45.310238  263960.593750    0.000172   \n",
       "138   (2048, 7168)   14680064.0  91.581459  205267.031250    0.000446   \n",
       "139   (2048, 7168)   14680064.0  43.552773  262363.000000    0.000166   \n",
       "142    (576, 7168)    4128768.0  46.502293  165971.343750    0.000280   \n",
       "143            NaN          NaN        NaN            NaN         NaN   \n",
       "144            NaN          NaN        NaN            NaN         NaN   \n",
       "146   (1536, 7168)   11010048.0  43.622997  324044.500000    0.000135   \n",
       "147            NaN          NaN        NaN            NaN         NaN   \n",
       "150    (256, 7168)    1835008.0  61.361385      57.482117    1.067487   \n",
       "151   (7168, 2048)   14680064.0  41.967201  250408.062500    0.000168   \n",
       "152   (2048, 7168)   14680064.0  94.314461  206260.328125    0.000457   \n",
       "153   (2048, 7168)   14680064.0  42.831738  254143.609375    0.000169   \n",
       "156    (576, 7168)    4128768.0  50.810741  192736.578125    0.000264   \n",
       "157            NaN          NaN        NaN            NaN         NaN   \n",
       "158            NaN          NaN        NaN            NaN         NaN   \n",
       "160   (1536, 7168)   11010048.0  52.763145  307570.718750    0.000172   \n",
       "161            NaN          NaN        NaN            NaN         NaN   \n",
       "164    (256, 7168)    1835008.0  60.909180      55.247620    1.102476   \n",
       "165   (7168, 2048)   14680064.0  44.653931  261757.046875    0.000171   \n",
       "166   (2048, 7168)   14680064.0  88.550323  213861.343750    0.000414   \n",
       "167   (2048, 7168)   14680064.0  44.156055  254356.968750    0.000174   \n",
       "170    (576, 7168)    4128768.0  48.693699  179631.687500    0.000271   \n",
       "171            NaN          NaN        NaN            NaN         NaN   \n",
       "172            NaN          NaN        NaN            NaN         NaN   \n",
       "174   (1536, 7168)   11010048.0  47.013763  299907.625000    0.000157   \n",
       "175            NaN          NaN        NaN            NaN         NaN   \n",
       "178    (256, 7168)    1835008.0  62.685085      54.026512    1.160265   \n",
       "179   (7168, 2048)   14680064.0  42.977657  255123.500000    0.000168   \n",
       "180   (2048, 7168)   14680064.0  80.258064  197298.640625    0.000407   \n",
       "181   (2048, 7168)   14680064.0  43.370766  249163.703125    0.000174   \n",
       "184    (576, 7168)    4128768.0  50.868774  186268.890625    0.000273   \n",
       "185            NaN          NaN        NaN            NaN         NaN   \n",
       "186            NaN          NaN        NaN            NaN         NaN   \n",
       "188   (1536, 7168)   11010048.0  54.821720  303415.875000    0.000181   \n",
       "189            NaN          NaN        NaN            NaN         NaN   \n",
       "192    (256, 7168)    1835008.0  63.182152      52.010090    1.214806   \n",
       "193   (7168, 2048)   14680064.0  43.694138  253349.312500    0.000172   \n",
       "194   (2048, 7168)   14680064.0  83.070198  152293.328125    0.000545   \n",
       "195   (2048, 7168)   14680064.0  44.037579  238882.812500    0.000184   \n",
       "198    (576, 7168)    4128768.0  51.171547  189226.890625    0.000270   \n",
       "199            NaN          NaN        NaN            NaN         NaN   \n",
       "200            NaN          NaN        NaN            NaN         NaN   \n",
       "202   (1536, 7168)   11010048.0  62.171219  314810.125000    0.000197   \n",
       "203            NaN          NaN        NaN            NaN         NaN   \n",
       "206    (256, 7168)    1835008.0  63.850780      49.865566    1.280458   \n",
       "207   (7168, 2048)   14680064.0  42.938866  231562.562500    0.000185   \n",
       "208   (2048, 7168)   14680064.0  76.841179  154447.515625    0.000498   \n",
       "209   (2048, 7168)   14680064.0  42.662048  231356.515625    0.000184   \n",
       "212    (576, 7168)    4128768.0  51.585777  194538.734375    0.000265   \n",
       "213            NaN          NaN        NaN            NaN         NaN   \n",
       "214            NaN          NaN        NaN            NaN         NaN   \n",
       "216   (1536, 7168)   11010048.0  67.028961  323574.531250    0.000207   \n",
       "217            NaN          NaN        NaN            NaN         NaN   \n",
       "220    (256, 7168)    1835008.0  62.051323      51.242741    1.210929   \n",
       "221   (7168, 2048)   14680064.0  45.100792  251104.656250    0.000180   \n",
       "222   (2048, 7168)   14680064.0  75.130760  130005.640625    0.000578   \n",
       "223   (2048, 7168)   14680064.0  44.422676  231655.156250    0.000192   \n",
       "226    (576, 7168)    4128768.0  48.504116  189007.765625    0.000257   \n",
       "227            NaN          NaN        NaN            NaN         NaN   \n",
       "228            NaN          NaN        NaN            NaN         NaN   \n",
       "230   (1536, 7168)   11010048.0  59.526833  333944.687500    0.000178   \n",
       "231            NaN          NaN        NaN            NaN         NaN   \n",
       "234    (256, 7168)    1835008.0  62.750134      49.359756    1.271281   \n",
       "235   (7168, 2048)   14680064.0  42.149212  247063.156250    0.000171   \n",
       "236   (2048, 7168)   14680064.0  72.227585  181604.406250    0.000398   \n",
       "237   (2048, 7168)   14680064.0  42.069752  252705.421875    0.000166   \n",
       "240    (576, 7168)    4128768.0  52.250446  170246.734375    0.000307   \n",
       "241            NaN          NaN        NaN            NaN         NaN   \n",
       "242            NaN          NaN        NaN            NaN         NaN   \n",
       "244   (1536, 7168)   11010048.0  65.144463  321128.125000    0.000203   \n",
       "245            NaN          NaN        NaN            NaN         NaN   \n",
       "248    (256, 7168)    1835008.0  62.404762      47.435638    1.315567   \n",
       "249   (7168, 2048)   14680064.0  43.535549  240439.250000    0.000181   \n",
       "250   (2048, 7168)   14680064.0  68.102524  174105.203125    0.000391   \n",
       "251   (2048, 7168)   14680064.0  43.068176  245458.218750    0.000175   \n",
       "254    (576, 7168)    4128768.0  50.018276  186641.953125    0.000268   \n",
       "255            NaN          NaN        NaN            NaN         NaN   \n",
       "256            NaN          NaN        NaN            NaN         NaN   \n",
       "258   (1536, 7168)   11010048.0  55.811195  335747.656250    0.000166   \n",
       "259            NaN          NaN        NaN            NaN         NaN   \n",
       "262    (256, 7168)    1835008.0  63.084209      45.760281    1.378580   \n",
       "263   (7168, 2048)   14680064.0  46.389908  230632.750000    0.000201   \n",
       "264   (2048, 7168)   14680064.0  74.325966  183386.718750    0.000405   \n",
       "265   (2048, 7168)   14680064.0  46.460163  235976.156250    0.000197   \n",
       "268    (576, 7168)    4128768.0  53.282570  191723.765625    0.000278   \n",
       "269            NaN          NaN        NaN            NaN         NaN   \n",
       "270            NaN          NaN        NaN            NaN         NaN   \n",
       "272   (1536, 7168)   11010048.0  67.073479  341160.906250    0.000197   \n",
       "273            NaN          NaN        NaN            NaN         NaN   \n",
       "276    (256, 7168)    1835008.0  61.973553      46.179924    1.342002   \n",
       "277   (7168, 2048)   14680064.0  45.197800  247829.406250    0.000182   \n",
       "278   (2048, 7168)   14680064.0  70.298676  199909.265625    0.000352   \n",
       "279   (2048, 7168)   14680064.0  44.633236  251577.046875    0.000177   \n",
       "282    (576, 7168)    4128768.0  52.084736  189800.718750    0.000274   \n",
       "283            NaN          NaN        NaN            NaN         NaN   \n",
       "284            NaN          NaN        NaN            NaN         NaN   \n",
       "286   (1536, 7168)   11010048.0  58.247837  352249.687500    0.000165   \n",
       "287            NaN          NaN        NaN            NaN         NaN   \n",
       "290    (256, 7168)    1835008.0  60.863007      43.545822    1.397677   \n",
       "291   (7168, 2048)   14680064.0  47.931683  258967.203125    0.000185   \n",
       "292   (2048, 7168)   14680064.0  68.468765  223264.484375    0.000307   \n",
       "293   (2048, 7168)   14680064.0  46.949577  258003.062500    0.000182   \n",
       "296    (576, 7168)    4128768.0  50.602535  185338.343750    0.000273   \n",
       "297            NaN          NaN        NaN            NaN         NaN   \n",
       "298            NaN          NaN        NaN            NaN         NaN   \n",
       "300   (1536, 7168)   11010048.0  57.460434  349251.406250    0.000165   \n",
       "301            NaN          NaN        NaN            NaN         NaN   \n",
       "304    (256, 7168)    1835008.0  61.605721      41.730858    1.476263   \n",
       "305   (7168, 2048)   14680064.0  46.564346  237526.000000    0.000196   \n",
       "306   (2048, 7168)   14680064.0  66.990974  220415.093750    0.000304   \n",
       "307   (2048, 7168)   14680064.0  46.014114  243710.812500    0.000189   \n",
       "310    (576, 7168)    4128768.0  52.571045  178447.593750    0.000295   \n",
       "311            NaN          NaN        NaN            NaN         NaN   \n",
       "312            NaN          NaN        NaN            NaN         NaN   \n",
       "314   (1536, 7168)   11010048.0  65.445320  350310.343750    0.000187   \n",
       "315            NaN          NaN        NaN            NaN         NaN   \n",
       "318    (256, 7168)    1835008.0  61.044193      38.723587    1.576409   \n",
       "319   (7168, 2048)   14680064.0  47.011139  245694.359375    0.000191   \n",
       "320   (2048, 7168)   14680064.0  61.929295  229450.031250    0.000270   \n",
       "321   (2048, 7168)   14680064.0  46.404636  237881.484375    0.000195   \n",
       "324    (576, 7168)    4128768.0  51.397686  185549.109375    0.000277   \n",
       "325            NaN          NaN        NaN            NaN         NaN   \n",
       "326            NaN          NaN        NaN            NaN         NaN   \n",
       "328   (1536, 7168)   11010048.0  67.362633  352155.875000    0.000191   \n",
       "329            NaN          NaN        NaN            NaN         NaN   \n",
       "332    (256, 7168)    1835008.0  60.068474      37.407093    1.605804   \n",
       "333   (7168, 2048)   14680064.0  45.927448  254102.531250    0.000181   \n",
       "334   (2048, 7168)   14680064.0  60.150677  223982.171875    0.000269   \n",
       "335   (2048, 7168)   14680064.0  45.011257  229948.515625    0.000196   \n",
       "338    (576, 7168)    4128768.0  53.090969  176628.812500    0.000301   \n",
       "339            NaN          NaN        NaN            NaN         NaN   \n",
       "340            NaN          NaN        NaN            NaN         NaN   \n",
       "342   (1536, 7168)   11010048.0  75.970032  351171.062500    0.000216   \n",
       "343            NaN          NaN        NaN            NaN         NaN   \n",
       "346    (256, 7168)    1835008.0  58.858749      37.209473    1.581822   \n",
       "347   (7168, 2048)   14680064.0  43.812443  263204.593750    0.000166   \n",
       "348   (2048, 7168)   14680064.0  56.144016  209996.078125    0.000267   \n",
       "349   (2048, 7168)   14680064.0  42.932861  230937.734375    0.000186   \n",
       "352    (576, 7168)    4128768.0  52.336922  166856.593750    0.000314   \n",
       "353            NaN          NaN        NaN            NaN         NaN   \n",
       "354            NaN          NaN        NaN            NaN         NaN   \n",
       "356   (1536, 7168)   11010048.0  72.086006  349273.781250    0.000206   \n",
       "357            NaN          NaN        NaN            NaN         NaN   \n",
       "360    (256, 7168)    1835008.0  58.200573      37.173981    1.565627   \n",
       "361   (7168, 2048)   14680064.0  45.615864  265324.500000    0.000172   \n",
       "362   (2048, 7168)   14680064.0  56.633945  216835.828125    0.000261   \n",
       "363   (2048, 7168)   14680064.0  44.797127  242268.687500    0.000185   \n",
       "366    (576, 7168)    4128768.0  51.520401  177910.296875    0.000290   \n",
       "367            NaN          NaN        NaN            NaN         NaN   \n",
       "368            NaN          NaN        NaN            NaN         NaN   \n",
       "370   (1536, 7168)   11010048.0  69.948273  347354.000000    0.000201   \n",
       "371            NaN          NaN        NaN            NaN         NaN   \n",
       "374    (256, 7168)    1835008.0  57.779716      36.448174    1.585257   \n",
       "375   (7168, 2048)   14680064.0  41.154556  284785.656250    0.000145   \n",
       "376   (2048, 7168)   14680064.0  49.128021  229124.890625    0.000214   \n",
       "377   (2048, 7168)   14680064.0  40.624657  256067.140625    0.000159   \n",
       "380    (576, 7168)    4128768.0  49.640358  164400.296875    0.000302   \n",
       "381            NaN          NaN        NaN            NaN         NaN   \n",
       "382            NaN          NaN        NaN            NaN         NaN   \n",
       "384   (1536, 7168)   11010048.0  68.983093  331264.437500    0.000208   \n",
       "385            NaN          NaN        NaN            NaN         NaN   \n",
       "388    (256, 7168)    1835008.0  57.039749      35.363419    1.612959   \n",
       "389   (7168, 2048)   14680064.0  47.880848  282893.593750    0.000169   \n",
       "390   (2048, 7168)   14680064.0  56.813526  212324.312500    0.000268   \n",
       "391   (2048, 7168)   14680064.0  46.198658  254270.328125    0.000182   \n",
       "394    (576, 7168)    4128768.0  52.230282  180721.046875    0.000289   \n",
       "395            NaN          NaN        NaN            NaN         NaN   \n",
       "396            NaN          NaN        NaN            NaN         NaN   \n",
       "398   (1536, 7168)   11010048.0  72.279205  351104.250000    0.000206   \n",
       "399            NaN          NaN        NaN            NaN         NaN   \n",
       "402    (256, 7168)    1835008.0  56.890789      35.420940    1.606134   \n",
       "403   (7168, 2048)   14680064.0  47.138607  278421.906250    0.000169   \n",
       "404   (2048, 7168)   14680064.0  54.204090  229367.781250    0.000236   \n",
       "405   (2048, 7168)   14680064.0  45.840836  256352.265625    0.000179   \n",
       "408    (576, 7168)    4128768.0  52.593529  186104.609375    0.000283   \n",
       "409            NaN          NaN        NaN            NaN         NaN   \n",
       "410            NaN          NaN        NaN            NaN         NaN   \n",
       "412   (1536, 7168)   11010048.0  79.557137  344495.843750    0.000231   \n",
       "413            NaN          NaN        NaN            NaN         NaN   \n",
       "416    (256, 7168)    1835008.0  56.199585      35.525330    1.581958   \n",
       "417   (7168, 2048)   14680064.0  46.984955  279280.562500    0.000168   \n",
       "418   (2048, 7168)   14680064.0  55.816029  222334.625000    0.000251   \n",
       "419   (2048, 7168)   14680064.0  45.959114  253979.453125    0.000181   \n",
       "422    (576, 7168)    4128768.0  47.171612  186653.390625    0.000253   \n",
       "423            NaN          NaN        NaN            NaN         NaN   \n",
       "424            NaN          NaN        NaN            NaN         NaN   \n",
       "426   (1536, 7168)   11010048.0  70.334183  347517.656250    0.000202   \n",
       "427            NaN          NaN        NaN            NaN         NaN   \n",
       "430    (256, 7168)    1835008.0  54.366833      34.047428    1.596797   \n",
       "431   (7168, 2048)   14680064.0  45.985538  274074.875000    0.000168   \n",
       "432   (2048, 7168)   14680064.0  53.188286  213671.890625    0.000249   \n",
       "433   (2048, 7168)   14680064.0  45.167343  242867.578125    0.000186   \n",
       "436    (576, 7168)    4128768.0  49.067039  175714.812500    0.000279   \n",
       "437            NaN          NaN        NaN            NaN         NaN   \n",
       "438            NaN          NaN        NaN            NaN         NaN   \n",
       "440   (1536, 7168)   11010048.0  71.968002  331438.187500    0.000217   \n",
       "441            NaN          NaN        NaN            NaN         NaN   \n",
       "444    (256, 7168)    1835008.0  53.960705      33.469986    1.612212   \n",
       "445   (7168, 2048)   14680064.0  48.308689  270485.625000    0.000179   \n",
       "446   (2048, 7168)   14680064.0  54.150475  212072.375000    0.000255   \n",
       "447   (2048, 7168)   14680064.0  47.262604  241527.921875    0.000196   \n",
       "450    (576, 7168)    4128768.0  49.026100  179884.656250    0.000273   \n",
       "451            NaN          NaN        NaN            NaN         NaN   \n",
       "452            NaN          NaN        NaN            NaN         NaN   \n",
       "454   (1536, 7168)   11010048.0  74.409676  346724.875000    0.000215   \n",
       "455            NaN          NaN        NaN            NaN         NaN   \n",
       "458    (256, 7168)    1835008.0  52.822144      34.614334    1.526019   \n",
       "459   (7168, 2048)   14680064.0  49.340076  268255.343750    0.000184   \n",
       "460   (2048, 7168)   14680064.0  54.313282  248781.703125    0.000218   \n",
       "461   (2048, 7168)   14680064.0  48.547146  254547.875000    0.000191   \n",
       "464    (576, 7168)    4128768.0  52.848537  172664.937500    0.000306   \n",
       "465            NaN          NaN        NaN            NaN         NaN   \n",
       "466            NaN          NaN        NaN            NaN         NaN   \n",
       "468   (1536, 7168)   11010048.0  77.089249  348893.781250    0.000221   \n",
       "469            NaN          NaN        NaN            NaN         NaN   \n",
       "472    (256, 7168)    1835008.0  51.809036      33.058929    1.567172   \n",
       "473   (7168, 2048)   14680064.0  48.625832  274444.125000    0.000177   \n",
       "474   (2048, 7168)   14680064.0  54.440929  239390.265625    0.000227   \n",
       "475   (2048, 7168)   14680064.0  47.147461  248760.671875    0.000190   \n",
       "478    (576, 7168)    4128768.0  53.150894  147863.421875    0.000359   \n",
       "479            NaN          NaN        NaN            NaN         NaN   \n",
       "480            NaN          NaN        NaN            NaN         NaN   \n",
       "482   (1536, 7168)   11010048.0  78.304436  348700.437500    0.000225   \n",
       "483            NaN          NaN        NaN            NaN         NaN   \n",
       "486    (256, 7168)    1835008.0  51.533623      32.673985    1.577207   \n",
       "487   (7168, 2048)   14680064.0  47.569614  254154.312500    0.000187   \n",
       "488   (2048, 7168)   14680064.0  54.026478  237929.937500    0.000227   \n",
       "489   (2048, 7168)   14680064.0  47.178051  228491.671875    0.000206   \n",
       "492    (576, 7168)    4128768.0  53.218193  169141.671875    0.000315   \n",
       "493            NaN          NaN        NaN            NaN         NaN   \n",
       "494            NaN          NaN        NaN            NaN         NaN   \n",
       "496   (1536, 7168)   11010048.0  77.360214  339649.406250    0.000228   \n",
       "497            NaN          NaN        NaN            NaN         NaN   \n",
       "500    (256, 7168)    1835008.0  50.803822      33.005226    1.539266   \n",
       "501   (7168, 2048)   14680064.0  47.462849  265520.093750    0.000179   \n",
       "502   (2048, 7168)   14680064.0  55.385624  254744.312500    0.000217   \n",
       "503   (2048, 7168)   14680064.0  48.529091  250556.265625    0.000194   \n",
       "506    (576, 7168)    4128768.0  47.422222  185918.343750    0.000255   \n",
       "507            NaN          NaN        NaN            NaN         NaN   \n",
       "508            NaN          NaN        NaN            NaN         NaN   \n",
       "510   (1536, 7168)   11010048.0  64.470337  351829.625000    0.000183   \n",
       "511            NaN          NaN        NaN            NaN         NaN   \n",
       "514    (256, 7168)    1835008.0  50.808838      31.944159    1.590552   \n",
       "515   (7168, 2048)   14680064.0  46.174149  264156.875000    0.000175   \n",
       "516   (2048, 7168)   14680064.0  53.878120  238560.093750    0.000226   \n",
       "517   (2048, 7168)   14680064.0  46.584557  246313.625000    0.000189   \n",
       "520    (576, 7168)    4128768.0  50.028133  169801.312500    0.000295   \n",
       "521            NaN          NaN        NaN            NaN         NaN   \n",
       "522            NaN          NaN        NaN            NaN         NaN   \n",
       "524   (1536, 7168)   11010048.0  72.203667  349750.625000    0.000206   \n",
       "525            NaN          NaN        NaN            NaN         NaN   \n",
       "528    (256, 7168)    1835008.0  50.471760      32.046082    1.574974   \n",
       "529   (7168, 2048)   14680064.0  46.096180  251339.109375    0.000183   \n",
       "530   (2048, 7168)   14680064.0  52.693172  239392.328125    0.000220   \n",
       "531   (2048, 7168)   14680064.0  46.256454  232850.640625    0.000199   \n",
       "534    (576, 7168)    4128768.0  51.403919  161578.359375    0.000318   \n",
       "535            NaN          NaN        NaN            NaN         NaN   \n",
       "536            NaN          NaN        NaN            NaN         NaN   \n",
       "538   (1536, 7168)   11010048.0  76.326584  353690.687500    0.000216   \n",
       "539            NaN          NaN        NaN            NaN         NaN   \n",
       "542    (256, 7168)    1835008.0  50.295757      30.401682    1.654374   \n",
       "543   (7168, 2048)   14680064.0  46.349049  253563.968750    0.000183   \n",
       "544   (2048, 7168)   14680064.0  53.696072  243363.437500    0.000221   \n",
       "545   (2048, 7168)   14680064.0  47.525772  233164.468750    0.000204   \n",
       "548    (576, 7168)    4128768.0  42.421379  157419.468750    0.000269   \n",
       "549            NaN          NaN        NaN            NaN         NaN   \n",
       "550            NaN          NaN        NaN            NaN         NaN   \n",
       "552   (1536, 7168)   11010048.0  59.475895  351937.812500    0.000169   \n",
       "553            NaN          NaN        NaN            NaN         NaN   \n",
       "556    (256, 7168)    1835008.0  48.734970      30.269274    1.610048   \n",
       "557   (7168, 2048)   14680064.0  46.782246  264826.281250    0.000177   \n",
       "558   (2048, 7168)   14680064.0  52.809319  249959.890625    0.000211   \n",
       "559   (2048, 7168)   14680064.0  47.837463  246854.312500    0.000194   \n",
       "562    (576, 7168)    4128768.0  51.146156  166726.796875    0.000307   \n",
       "563            NaN          NaN        NaN            NaN         NaN   \n",
       "564            NaN          NaN        NaN            NaN         NaN   \n",
       "566   (1536, 7168)   11010048.0  77.038696  322530.968750    0.000239   \n",
       "567            NaN          NaN        NaN            NaN         NaN   \n",
       "570    (256, 7168)    1835008.0  46.998287      29.635151    1.585897   \n",
       "571   (7168, 2048)   14680064.0  45.448711  249535.968750    0.000182   \n",
       "572   (2048, 7168)   14680064.0  50.511700  247315.750000    0.000204   \n",
       "573   (2048, 7168)   14680064.0  46.237614  228836.593750    0.000202   \n",
       "576    (576, 7168)    4128768.0  50.286785  159359.562500    0.000316   \n",
       "577            NaN          NaN        NaN            NaN         NaN   \n",
       "578            NaN          NaN        NaN            NaN         NaN   \n",
       "580   (1536, 7168)   11010048.0  70.098717  354023.062500    0.000198   \n",
       "581            NaN          NaN        NaN            NaN         NaN   \n",
       "584    (256, 7168)    1835008.0  44.978374      29.709774    1.513925   \n",
       "585   (7168, 2048)   14680064.0  44.732426  246747.593750    0.000181   \n",
       "586   (2048, 7168)   14680064.0  51.111565  247076.625000    0.000207   \n",
       "587   (2048, 7168)   14680064.0  45.126278  235508.343750    0.000192   \n",
       "590    (576, 7168)    4128768.0  51.099186  176098.312500    0.000290   \n",
       "591            NaN          NaN        NaN            NaN         NaN   \n",
       "592            NaN          NaN        NaN            NaN         NaN   \n",
       "594   (1536, 7168)   11010048.0  75.349091  357103.000000    0.000211   \n",
       "595            NaN          NaN        NaN            NaN         NaN   \n",
       "598    (256, 7168)    1835008.0  44.902657      29.010998    1.547781   \n",
       "599   (7168, 2048)   14680064.0  44.755562  230694.109375    0.000194   \n",
       "600   (2048, 7168)   14680064.0  52.204166  244833.046875    0.000213   \n",
       "601   (2048, 7168)   14680064.0  44.635883  229273.031250    0.000195   \n",
       "604    (576, 7168)    4128768.0  50.237015  153083.781250    0.000328   \n",
       "605            NaN          NaN        NaN            NaN         NaN   \n",
       "606            NaN          NaN        NaN            NaN         NaN   \n",
       "608   (1536, 7168)   11010048.0  74.993248  347749.062500    0.000216   \n",
       "609            NaN          NaN        NaN            NaN         NaN   \n",
       "612    (256, 7168)    1835008.0  44.251369      28.274366    1.565070   \n",
       "613   (7168, 2048)   14680064.0  44.357864  236758.187500    0.000187   \n",
       "614   (2048, 7168)   14680064.0  53.258675  242143.906250    0.000220   \n",
       "615   (2048, 7168)   14680064.0  43.021950  233435.046875    0.000184   \n",
       "618    (576, 7168)    4128768.0  53.222435  181203.046875    0.000294   \n",
       "619            NaN          NaN        NaN            NaN         NaN   \n",
       "620            NaN          NaN        NaN            NaN         NaN   \n",
       "622   (1536, 7168)   11010048.0  73.530098  331982.937500    0.000221   \n",
       "623            NaN          NaN        NaN            NaN         NaN   \n",
       "626    (256, 7168)    1835008.0  44.192734      27.867537    1.585814   \n",
       "627   (7168, 2048)   14680064.0  43.674278  236165.750000    0.000185   \n",
       "628   (2048, 7168)   14680064.0  54.291489  239228.000000    0.000227   \n",
       "629   (2048, 7168)   14680064.0  43.223412  223178.593750    0.000194   \n",
       "632    (576, 7168)    4128768.0  45.840549  162606.562500    0.000282   \n",
       "633            NaN          NaN        NaN            NaN         NaN   \n",
       "634            NaN          NaN        NaN            NaN         NaN   \n",
       "636   (1536, 7168)   11010048.0  72.775063  346763.250000    0.000210   \n",
       "637            NaN          NaN        NaN            NaN         NaN   \n",
       "640    (256, 7168)    1835008.0  41.863281      26.720890    1.566687   \n",
       "641   (7168, 2048)   14680064.0  43.783043  240158.453125    0.000182   \n",
       "642   (2048, 7168)   14680064.0  53.768604  257880.921875    0.000209   \n",
       "643   (2048, 7168)   14680064.0  42.861973  226822.234375    0.000189   \n",
       "646    (576, 7168)    4128768.0  52.777794  144451.828125    0.000365   \n",
       "647            NaN          NaN        NaN            NaN         NaN   \n",
       "648            NaN          NaN        NaN            NaN         NaN   \n",
       "650   (1536, 7168)   11010048.0  66.715645  338362.750000    0.000197   \n",
       "651            NaN          NaN        NaN            NaN         NaN   \n",
       "654    (256, 7168)    1835008.0  40.910725      25.972263    1.575170   \n",
       "655   (7168, 2048)   14680064.0  42.287209  260490.750000    0.000162   \n",
       "656   (2048, 7168)   14680064.0  54.979279  266612.125000    0.000206   \n",
       "657   (2048, 7168)   14680064.0  41.763363  242888.062500    0.000172   \n",
       "660    (576, 7168)    4128768.0  46.789642  136687.203125    0.000342   \n",
       "661            NaN          NaN        NaN            NaN         NaN   \n",
       "662            NaN          NaN        NaN            NaN         NaN   \n",
       "664   (1536, 7168)   11010048.0  61.593723  343426.281250    0.000179   \n",
       "665            NaN          NaN        NaN            NaN         NaN   \n",
       "668    (256, 7168)    1835008.0  40.967010      25.516438    1.605515   \n",
       "669   (7168, 2048)   14680064.0  41.911053  266518.906250    0.000157   \n",
       "670   (2048, 7168)   14680064.0  55.824352  265747.937500    0.000210   \n",
       "671   (2048, 7168)   14680064.0  41.388466  241293.421875    0.000172   \n",
       "674    (576, 7168)    4128768.0  44.699005  184263.796875    0.000243   \n",
       "675            NaN          NaN        NaN            NaN         NaN   \n",
       "676            NaN          NaN        NaN            NaN         NaN   \n",
       "678   (1536, 7168)   11010048.0  54.549786  348280.156250    0.000157   \n",
       "679            NaN          NaN        NaN            NaN         NaN   \n",
       "682    (256, 7168)    1835008.0  41.393047      24.754883    1.672117   \n",
       "683   (7168, 2048)   14680064.0  41.868046  264151.750000    0.000158   \n",
       "684   (2048, 7168)   14680064.0  55.572136  269599.500000    0.000206   \n",
       "685   (2048, 7168)   14680064.0  42.009579  243532.406250    0.000173   \n",
       "688    (576, 7168)    4128768.0  43.209965  172654.687500    0.000250   \n",
       "689            NaN          NaN        NaN            NaN         NaN   \n",
       "690            NaN          NaN        NaN            NaN         NaN   \n",
       "692   (1536, 7168)   11010048.0  55.441502  345941.156250    0.000160   \n",
       "693            NaN          NaN        NaN            NaN         NaN   \n",
       "696    (256, 7168)    1835008.0  39.940376      24.357220    1.639776   \n",
       "697   (7168, 2048)   14680064.0  41.579712  258156.953125    0.000161   \n",
       "698   (2048, 7168)   14680064.0  55.334579  266024.468750    0.000208   \n",
       "699   (2048, 7168)   14680064.0  40.802856  238225.250000    0.000171   \n",
       "702    (576, 7168)    4128768.0  52.474453  162472.593750    0.000323   \n",
       "703            NaN          NaN        NaN            NaN         NaN   \n",
       "704            NaN          NaN        NaN            NaN         NaN   \n",
       "706   (1536, 7168)   11010048.0  73.557915  340124.093750    0.000216   \n",
       "707            NaN          NaN        NaN            NaN         NaN   \n",
       "710    (256, 7168)    1835008.0  39.181675      23.561365    1.662963   \n",
       "711   (7168, 2048)   14680064.0  42.402748  274071.906250    0.000155   \n",
       "712   (2048, 7168)   14680064.0  57.039303  263386.218750    0.000217   \n",
       "713   (2048, 7168)   14680064.0  41.339771  250485.078125    0.000165   \n",
       "716    (576, 7168)    4128768.0  52.515038  160357.781250    0.000327   \n",
       "717            NaN          NaN        NaN            NaN         NaN   \n",
       "718            NaN          NaN        NaN            NaN         NaN   \n",
       "720   (1536, 7168)   11010048.0  63.924370  347385.187500    0.000184   \n",
       "721            NaN          NaN        NaN            NaN         NaN   \n",
       "724    (256, 7168)    1835008.0  38.341373      23.653309    1.620973   \n",
       "725   (7168, 2048)   14680064.0  42.682983  258502.312500    0.000165   \n",
       "726   (2048, 7168)   14680064.0  56.438549  267154.718750    0.000211   \n",
       "727   (2048, 7168)   14680064.0  40.821194  253036.984375    0.000161   \n",
       "730    (576, 7168)    4128768.0  47.905533  180060.421875    0.000266   \n",
       "731            NaN          NaN        NaN            NaN         NaN   \n",
       "732            NaN          NaN        NaN            NaN         NaN   \n",
       "734   (1536, 7168)   11010048.0  64.010201  335954.250000    0.000191   \n",
       "735            NaN          NaN        NaN            NaN         NaN   \n",
       "738    (256, 7168)    1835008.0  37.370094      21.695557    1.722477   \n",
       "739   (7168, 2048)   14680064.0  42.433987  253758.671875    0.000167   \n",
       "740   (2048, 7168)   14680064.0  58.619488  263933.625000    0.000222   \n",
       "741   (2048, 7168)   14680064.0  40.589417  246767.109375    0.000164   \n",
       "744    (576, 7168)    4128768.0  49.849182  182301.687500    0.000273   \n",
       "745            NaN          NaN        NaN            NaN         NaN   \n",
       "746            NaN          NaN        NaN            NaN         NaN   \n",
       "748   (1536, 7168)   11010048.0  64.376747  314651.562500    0.000205   \n",
       "749            NaN          NaN        NaN            NaN         NaN   \n",
       "752    (256, 7168)    1835008.0  35.798725      21.656708    1.653009   \n",
       "753   (7168, 2048)   14680064.0  42.254421  258464.078125    0.000163   \n",
       "754   (2048, 7168)   14680064.0  57.487576  267196.437500    0.000215   \n",
       "755   (2048, 7168)   14680064.0  41.106983  252560.531250    0.000163   \n",
       "758    (576, 7168)    4128768.0  42.294857  176369.859375    0.000240   \n",
       "759            NaN          NaN        NaN            NaN         NaN   \n",
       "760            NaN          NaN        NaN            NaN         NaN   \n",
       "762   (1536, 7168)   11010048.0  51.717434  347355.125000    0.000149   \n",
       "763            NaN          NaN        NaN            NaN         NaN   \n",
       "766    (256, 7168)    1835008.0  36.117199      20.357906    1.774112   \n",
       "767   (7168, 2048)   14680064.0  43.344177  256965.453125    0.000169   \n",
       "768   (2048, 7168)   14680064.0  58.638844  274772.812500    0.000213   \n",
       "769   (2048, 7168)   14680064.0  42.496319  268099.093750    0.000159   \n",
       "772    (576, 7168)    4128768.0  43.518063  166118.187500    0.000262   \n",
       "773            NaN          NaN        NaN            NaN         NaN   \n",
       "774            NaN          NaN        NaN            NaN         NaN   \n",
       "776   (1536, 7168)   11010048.0  46.662914  336636.906250    0.000139   \n",
       "777            NaN          NaN        NaN            NaN         NaN   \n",
       "780    (256, 7168)    1835008.0  34.743210      19.548061    1.777323   \n",
       "781   (7168, 2048)   14680064.0  43.350349  259602.890625    0.000167   \n",
       "782   (2048, 7168)   14680064.0  60.991867  277887.031250    0.000219   \n",
       "783   (2048, 7168)   14680064.0  43.234421  275242.437500    0.000157   \n",
       "786    (576, 7168)    4128768.0  47.597591  183532.031250    0.000259   \n",
       "787            NaN          NaN        NaN            NaN         NaN   \n",
       "788            NaN          NaN        NaN            NaN         NaN   \n",
       "790   (1536, 7168)   11010048.0  57.733204  339363.062500    0.000170   \n",
       "791            NaN          NaN        NaN            NaN         NaN   \n",
       "794    (256, 7168)    1835008.0  33.904938      19.602224    1.729648   \n",
       "795   (7168, 2048)   14680064.0  45.071590  254212.046875    0.000177   \n",
       "796   (2048, 7168)   14680064.0  64.227753  278233.968750    0.000231   \n",
       "797   (2048, 7168)   14680064.0  45.738163  279941.000000    0.000163   \n",
       "800    (576, 7168)    4128768.0  42.971287  165510.984375    0.000260   \n",
       "801            NaN          NaN        NaN            NaN         NaN   \n",
       "802            NaN          NaN        NaN            NaN         NaN   \n",
       "804   (1536, 7168)   11010048.0  56.423298  324759.031250    0.000174   \n",
       "805            NaN          NaN        NaN            NaN         NaN   \n",
       "808    (256, 7168)    1835008.0  33.004986      20.246275    1.630176   \n",
       "809   (7168, 2048)   14680064.0  46.850452  248567.453125    0.000188   \n",
       "810   (2048, 7168)   14680064.0  65.613007  278620.093750    0.000235   \n",
       "811   (2048, 7168)   14680064.0  48.656509  268330.593750    0.000181   \n",
       "814    (576, 7168)    4128768.0  42.285824  192984.609375    0.000219   \n",
       "815            NaN          NaN        NaN            NaN         NaN   \n",
       "816            NaN          NaN        NaN            NaN         NaN   \n",
       "818   (1536, 7168)   11010048.0  47.141296  278748.437500    0.000169   \n",
       "819            NaN          NaN        NaN            NaN         NaN   \n",
       "822    (256, 7168)    1835008.0  30.243559      21.967958    1.376712   \n",
       "823   (7168, 2048)   14680064.0  46.900597  232829.328125    0.000201   \n",
       "824   (2048, 7168)   14680064.0  66.756119  253401.437500    0.000263   \n",
       "825   (2048, 7168)   14680064.0  48.777443  239059.500000    0.000204   \n",
       "828    (576, 7168)    4128768.0  48.823463  166728.703125    0.000293   \n",
       "829            NaN          NaN        NaN            NaN         NaN   \n",
       "830            NaN          NaN        NaN            NaN         NaN   \n",
       "832   (1536, 7168)   11010048.0  59.075577  329189.125000    0.000179   \n",
       "833            NaN          NaN        NaN            NaN         NaN   \n",
       "836    (256, 7168)    1835008.0  29.131956      29.370396    0.991882   \n",
       "837   (7168, 2048)   14680064.0  46.158073  202610.562500    0.000228   \n",
       "838   (2048, 7168)   14680064.0  64.730461  255341.218750    0.000254   \n",
       "839   (2048, 7168)   14680064.0  50.728722  222510.703125    0.000228   \n",
       "842    (576, 7168)    4128768.0  47.286278  185368.171875    0.000255   \n",
       "843            NaN          NaN        NaN            NaN         NaN   \n",
       "844            NaN          NaN        NaN            NaN         NaN   \n",
       "846   (1536, 7168)   11010048.0  56.993889  261524.468750    0.000218   \n",
       "847            NaN          NaN        NaN            NaN         NaN   \n",
       "\n",
       "           mean_a        mean_b    mean_ratio     std_a       std_b  \\\n",
       "1    1.938400e-07 -5.042707e-03  1.938400e+05  0.005191   37.320744   \n",
       "2   -1.141391e-05  2.023005e-01 -5.642058e-05  0.004924   20.313309   \n",
       "3    4.222969e-07 -3.271475e-03  4.222969e+05  0.004470   51.244949   \n",
       "6    8.415574e-06 -5.285055e-02  8.415574e+06  0.021105   70.407242   \n",
       "7             NaN           NaN           NaN       NaN         NaN   \n",
       "8             NaN           NaN           NaN       NaN         NaN   \n",
       "10   1.081290e-06 -1.848673e-02  1.081290e+06  0.009887   89.141144   \n",
       "11            NaN           NaN           NaN       NaN         NaN   \n",
       "13   1.974590e-08 -6.014036e-03  1.974590e+04  0.002702   27.100826   \n",
       "14   7.893201e-06  2.129500e-01  3.706598e-05  0.004019   23.953739   \n",
       "15  -7.624888e-08  7.651516e-03 -9.965200e-06  0.002099   34.701054   \n",
       "18  -4.458476e-08 -2.386205e-02 -4.458476e+04  0.014048   58.640915   \n",
       "19            NaN           NaN           NaN       NaN         NaN   \n",
       "20            NaN           NaN           NaN       NaN         NaN   \n",
       "22   3.607209e-07 -9.147654e-03  3.607209e+05  0.005387   53.122345   \n",
       "23            NaN           NaN           NaN       NaN         NaN   \n",
       "25   2.642451e-07 -2.943784e-04  2.642451e+05  0.003055   22.072577   \n",
       "26   3.276502e-06  9.338737e-02  3.508507e-05  0.004170   17.538445   \n",
       "27   2.105856e-07  9.443110e-04  2.230045e-04  0.002489   28.279673   \n",
       "30  -3.046824e-06 -1.653090e-02 -3.046824e+06  0.013708   48.493622   \n",
       "31            NaN           NaN           NaN       NaN         NaN   \n",
       "32            NaN           NaN           NaN       NaN         NaN   \n",
       "34  -2.569489e-06 -1.133139e-02 -2.569488e+06  0.007206   58.243946   \n",
       "35            NaN           NaN           NaN       NaN         NaN   \n",
       "38   7.770116e-05  1.165834e-04  6.664856e-01  0.021699    0.024639   \n",
       "39  -2.374483e-06 -6.645652e-03 -2.374483e+06  0.007474   63.036152   \n",
       "40   3.296047e-05  2.247492e-01  1.466545e-04  0.008192   60.259205   \n",
       "41   6.067139e-07  1.293623e-03  4.690038e-04  0.006688   92.808113   \n",
       "44   5.541524e-06  3.586704e-02  1.545019e-04  0.016867   68.685829   \n",
       "45            NaN           NaN           NaN       NaN         NaN   \n",
       "46            NaN           NaN           NaN       NaN         NaN   \n",
       "48  -1.298052e-06  1.999416e-02 -6.492158e-05  0.011327   67.349655   \n",
       "49            NaN           NaN           NaN       NaN         NaN   \n",
       "52   9.968146e-05  1.027509e-04  9.701275e-01  0.029590    0.028274   \n",
       "53   9.522834e-07 -7.535151e-03  9.522834e+05  0.008192   65.950188   \n",
       "54   3.550852e-05  2.336629e-01  1.519648e-04  0.013967   52.351864   \n",
       "55   2.896452e-08 -2.909102e-02  2.896452e+04  0.007852   88.836830   \n",
       "58  -4.588853e-06  4.405908e-02 -1.041523e-04  0.017054   75.694916   \n",
       "59            NaN           NaN           NaN       NaN         NaN   \n",
       "60            NaN           NaN           NaN       NaN         NaN   \n",
       "62   8.800778e-07  3.902343e-03  2.255255e-04  0.008944   86.321419   \n",
       "63            NaN           NaN           NaN       NaN         NaN   \n",
       "66   6.166619e-05  1.320220e-04  4.670901e-01  0.035166    0.034701   \n",
       "67   3.037285e-06  4.000738e-03  7.591810e-04  0.008451   67.437164   \n",
       "68   3.864144e-05  4.771323e-01  8.098686e-05  0.015258   53.249321   \n",
       "69  -1.867902e-07 -7.872188e-03 -1.867902e+05  0.008528   84.185272   \n",
       "72  -3.083006e-06  2.253130e-02 -1.368322e-04  0.019620   62.719273   \n",
       "73            NaN           NaN           NaN       NaN         NaN   \n",
       "74            NaN           NaN           NaN       NaN         NaN   \n",
       "76  -6.152970e-06  6.052906e-03 -1.016532e-03  0.010826   81.052742   \n",
       "77            NaN           NaN           NaN       NaN         NaN   \n",
       "80   3.220308e-05 -1.018610e-04  3.220308e+07  0.038428    0.037840   \n",
       "81   1.716296e-06 -2.312120e-02  1.716296e+06  0.009201   69.371590   \n",
       "82  -7.949048e-06  2.292349e-01 -3.467642e-05  0.017113   54.333893   \n",
       "83   4.467801e-07 -1.222656e-02  4.467801e+05  0.009305   82.534065   \n",
       "86   7.151962e-07  5.476070e-02  1.306039e-05  0.017510   81.288063   \n",
       "87            NaN           NaN           NaN       NaN         NaN   \n",
       "88            NaN           NaN           NaN       NaN         NaN   \n",
       "90  -2.548874e-06 -2.222098e-02 -2.548874e+06  0.009898   82.059593   \n",
       "91            NaN           NaN           NaN       NaN         NaN   \n",
       "94   1.989925e-04 -5.538079e-05  1.989925e+08  0.045892    0.041844   \n",
       "95   6.911815e-07 -3.381542e-03  6.911815e+05  0.008923   71.692192   \n",
       "96   5.357097e-05  1.608118e-01  3.331284e-04  0.019312   56.105476   \n",
       "97  -3.694102e-06  2.692454e-02 -1.372020e-04  0.009525   77.331161   \n",
       "100 -3.632149e-06 -5.050855e-02 -3.632149e+06  0.021735   77.893707   \n",
       "101           NaN           NaN           NaN       NaN         NaN   \n",
       "102           NaN           NaN           NaN       NaN         NaN   \n",
       "104  3.162919e-06 -2.790407e-02  3.162919e+06  0.013384   86.347496   \n",
       "105           NaN           NaN           NaN       NaN         NaN   \n",
       "108  4.126995e-04  7.247948e-05  5.694018e+00  0.047185    0.039114   \n",
       "109  1.845480e-06 -2.657622e-03  1.845480e+06  0.009768   60.788536   \n",
       "110  2.012922e-04  3.143978e-01  6.402470e-04  0.021868   58.473953   \n",
       "111  6.882189e-07  3.672514e-02  1.873972e-05  0.010320   75.113144   \n",
       "114 -2.210979e-07  2.284615e-02 -9.677687e-06  0.021758   73.193909   \n",
       "115           NaN           NaN           NaN       NaN         NaN   \n",
       "116           NaN           NaN           NaN       NaN         NaN   \n",
       "118  1.262830e-05  2.441130e-03  5.173140e-03  0.013209   82.976860   \n",
       "119           NaN           NaN           NaN       NaN         NaN   \n",
       "122  3.828389e-04  1.262108e-04  3.033328e+00  0.045408    0.039618   \n",
       "123 -7.462968e-07 -5.120226e-05 -7.462969e+05  0.010668   65.521454   \n",
       "124  2.213672e-04  2.932894e-01  7.547740e-04  0.022587   55.219490   \n",
       "125 -2.680473e-07 -9.782354e-03 -2.680473e+05  0.010723   68.973503   \n",
       "128  1.195049e-06  5.308273e-02  2.251295e-05  0.021626   84.523651   \n",
       "129           NaN           NaN           NaN       NaN         NaN   \n",
       "130           NaN           NaN           NaN       NaN         NaN   \n",
       "132  5.205086e-06  2.235255e-02  2.328632e-04  0.012823   97.150070   \n",
       "133           NaN           NaN           NaN       NaN         NaN   \n",
       "136  4.075590e-04  1.312464e-04  3.105295e+00  0.044264    0.041706   \n",
       "137 -4.547229e-06 -2.533327e-03 -4.547230e+06  0.011826   68.893005   \n",
       "138  2.173313e-04  7.173754e-02  3.029533e-03  0.023902   53.574089   \n",
       "139 -6.160434e-06  9.338681e-03 -6.596685e-04  0.011367   68.476036   \n",
       "142 -3.878666e-06  1.243844e-03 -3.118289e-03  0.022886   81.681343   \n",
       "143           NaN           NaN           NaN       NaN         NaN   \n",
       "144           NaN           NaN           NaN       NaN         NaN   \n",
       "146 -5.362010e-06 -3.328361e-02 -5.362010e+06  0.013147   97.658493   \n",
       "147           NaN           NaN           NaN       NaN         NaN   \n",
       "150  4.563871e-04  2.085474e-04  2.188409e+00  0.045295    0.042433   \n",
       "151  1.679038e-06  1.292949e-02  1.298611e-04  0.010953   65.355827   \n",
       "152  2.190171e-04  1.562747e-02  1.401488e-02  0.024615   53.833389   \n",
       "153  7.714563e-07  8.034391e-03  9.601926e-05  0.011179   66.330795   \n",
       "156  2.028491e-06 -3.845371e-02  2.028491e+06  0.025006   94.853600   \n",
       "157           NaN           NaN           NaN       NaN         NaN   \n",
       "158           NaN           NaN           NaN       NaN         NaN   \n",
       "160  8.200746e-07  4.014836e-02  2.042610e-05  0.015901   92.693726   \n",
       "161           NaN           NaN           NaN       NaN         NaN   \n",
       "164  4.544015e-04  2.422025e-04  1.876122e+00  0.044962    0.040784   \n",
       "165 -2.420139e-06  1.095472e-02 -2.209221e-04  0.011655   68.317879   \n",
       "166  1.613195e-04 -4.928809e-02  1.613195e+08  0.023111   55.817215   \n",
       "167 -1.379924e-06  5.655065e-04 -2.440156e-03  0.011525   66.386482   \n",
       "170 -2.288964e-06  9.703936e-02 -2.358800e-05  0.023964   88.404106   \n",
       "171           NaN           NaN           NaN       NaN         NaN   \n",
       "172           NaN           NaN           NaN       NaN         NaN   \n",
       "174  3.287169e-06  4.231628e-03  7.768095e-04  0.014169   90.384285   \n",
       "175           NaN           NaN           NaN       NaN         NaN   \n",
       "178  2.984306e-04  2.348996e-04  1.270460e+00  0.046274    0.039882   \n",
       "179  2.263072e-06  2.233088e-02  1.013427e-04  0.011217   66.586540   \n",
       "180  9.398915e-05  9.880558e-02  9.512535e-04  0.020947   51.494320   \n",
       "181  1.542116e-06  3.286558e-02  4.692192e-05  0.011320   65.031044   \n",
       "184  4.309190e-06  7.512900e-02  5.735721e-05  0.025035   91.670570   \n",
       "185           NaN           NaN           NaN       NaN         NaN   \n",
       "186           NaN           NaN           NaN       NaN         NaN   \n",
       "188 -1.320386e-06  1.594279e-02 -8.282024e-05  0.016522   91.441566   \n",
       "189           NaN           NaN           NaN       NaN         NaN   \n",
       "192  3.551023e-04  4.025494e-04  8.821335e-01  0.046640    0.038392   \n",
       "193 -3.134209e-06 -2.396222e-02 -3.134208e+06  0.011404   66.123482   \n",
       "194  8.412390e-05  8.334381e-02  1.009360e-03  0.021681   39.748058   \n",
       "195 -2.181807e-06 -1.616513e-02 -2.181807e+06  0.011494   62.347771   \n",
       "198 -1.168154e-05  3.427737e-02 -3.407946e-04  0.025184   93.126350   \n",
       "199           NaN           NaN           NaN       NaN         NaN   \n",
       "200           NaN           NaN           NaN       NaN         NaN   \n",
       "202  6.371345e-06 -2.448407e-03  6.371344e+06  0.018737   94.875511   \n",
       "203           NaN           NaN           NaN       NaN         NaN   \n",
       "206  1.851208e-04  3.350106e-04  5.525820e-01  0.047135    0.036810   \n",
       "207  2.060468e-06  7.649785e-03  2.693498e-04  0.011207   60.437206   \n",
       "208  4.140424e-05  7.981002e-02  5.187850e-04  0.020055   40.310303   \n",
       "209  2.608207e-06 -1.491899e-02  2.608207e+06  0.011135   60.383430   \n",
       "212 -2.157557e-05  3.859184e-03 -5.590707e-03  0.025387   95.740532   \n",
       "213           NaN           NaN           NaN       NaN         NaN   \n",
       "214           NaN           NaN           NaN       NaN         NaN   \n",
       "216  9.261754e-06  3.194254e-02  2.899505e-04  0.020201   97.516869   \n",
       "217           NaN           NaN           NaN       NaN         NaN   \n",
       "220  5.022708e-05  4.078590e-04  1.231481e-01  0.045807    0.037826   \n",
       "221 -1.771797e-06 -2.997688e-05 -1.771797e+06  0.011771   65.537636   \n",
       "222  1.298265e-05  5.368698e-02  2.418213e-04  0.019609   33.931076   \n",
       "223  5.882713e-07 -2.174682e-02  5.882714e+05  0.011594   60.461372   \n",
       "226  1.287167e-05 -2.249974e-02  1.287167e+07  0.023871   93.018517   \n",
       "227           NaN           NaN           NaN       NaN         NaN   \n",
       "228           NaN           NaN           NaN       NaN         NaN   \n",
       "230  7.903849e-07 -3.563926e-02  7.903849e+05  0.017940  100.642151   \n",
       "231           NaN           NaN           NaN       NaN         NaN   \n",
       "234  4.912720e-05  2.551288e-04  1.925584e-01  0.046323    0.036437   \n",
       "235 -1.787721e-06 -1.017821e-02 -1.787721e+06  0.011001   64.482819   \n",
       "236  1.781603e-05  1.264764e-02  1.408644e-03  0.018851   47.398262   \n",
       "237  3.127269e-06 -2.167179e-03  3.127269e+06  0.010980   65.955437   \n",
       "240  1.038563e-05 -2.859824e-02  1.038563e+07  0.025715   83.785439   \n",
       "241           NaN           NaN           NaN       NaN         NaN   \n",
       "242           NaN           NaN           NaN       NaN         NaN   \n",
       "244 -4.929692e-06 -1.455903e-02 -4.929692e+06  0.019633   96.779587   \n",
       "245           NaN           NaN           NaN       NaN         NaN   \n",
       "248 -1.113991e-06  6.144195e-05 -1.813078e-02  0.046068    0.035017   \n",
       "249  1.445487e-06 -1.753473e-04  1.445487e+06  0.011363   62.753994   \n",
       "250 -1.824098e-06 -1.665290e-02 -1.824098e+06  0.017775   45.440990   \n",
       "251  4.456436e-06 -2.655647e-02  4.456436e+06  0.011241   64.063927   \n",
       "254  9.768949e-06 -3.703205e-02  9.768949e+06  0.024616   91.854195   \n",
       "255           NaN           NaN           NaN       NaN         NaN   \n",
       "256           NaN           NaN           NaN       NaN         NaN   \n",
       "258 -1.355623e-06  6.798734e-02 -1.993935e-05  0.016820  101.185501   \n",
       "259           NaN           NaN           NaN       NaN         NaN   \n",
       "262 -1.221991e-05  1.062308e-04 -1.150317e-01  0.046570    0.033781   \n",
       "263  5.718708e-07 -1.643468e-02  5.718708e+05  0.012108   60.194527   \n",
       "264 -1.808949e-05 -8.035551e-02 -1.808949e+07  0.019399   47.863373   \n",
       "265  1.905539e-06 -1.813463e-02  1.905539e+06  0.012126   61.589142   \n",
       "268  1.245191e-05 -1.889592e-02  1.245192e+07  0.026223   94.355164   \n",
       "269           NaN           NaN           NaN       NaN         NaN   \n",
       "270           NaN           NaN           NaN       NaN         NaN   \n",
       "272  3.105785e-06  3.046496e-02  1.019461e-04  0.020214  102.816933   \n",
       "273           NaN           NaN           NaN       NaN         NaN   \n",
       "276 -5.842796e-06  2.846467e-05 -2.052648e-01  0.045750    0.034091   \n",
       "277  9.818995e-06  1.695100e-02  5.792574e-04  0.011797   64.682808   \n",
       "278  1.465653e-05 -1.079188e-01  1.465653e+07  0.018348   52.175667   \n",
       "279  2.387375e-06 -3.892486e-03  2.387375e+06  0.011649   65.660934   \n",
       "282 -6.229685e-06  7.405902e-02 -8.411784e-05  0.025633   93.408730   \n",
       "283           NaN           NaN           NaN       NaN         NaN   \n",
       "284           NaN           NaN           NaN       NaN         NaN   \n",
       "286  7.624965e-06 -1.217848e-02  7.624965e+06  0.017554  106.158806   \n",
       "287           NaN           NaN           NaN       NaN         NaN   \n",
       "290 -4.725270e-05  7.091826e-05 -6.662980e-01  0.044930    0.032146   \n",
       "291  1.960684e-06 -1.130648e-02  1.960684e+06  0.012510   67.589737   \n",
       "292 -1.311062e-05 -7.179382e-02 -1.311062e+07  0.017870   58.271381   \n",
       "293 -1.868062e-06 -6.031224e-04 -1.868062e+06  0.012254   67.338104   \n",
       "296 -1.446391e-05  5.707364e-02 -2.534253e-04  0.024904   91.212624   \n",
       "297           NaN           NaN           NaN       NaN         NaN   \n",
       "298           NaN           NaN           NaN       NaN         NaN   \n",
       "300  1.119392e-06 -2.197577e-02  1.119392e+06  0.017317  105.255188   \n",
       "301           NaN           NaN           NaN       NaN         NaN   \n",
       "304 -1.530145e-04  2.700510e-05 -5.666134e+00  0.045478    0.030806   \n",
       "305  2.318720e-06 -1.888927e-03  2.318720e+06  0.012153   61.993645   \n",
       "306 -4.016560e-06 -1.647688e-01 -4.016560e+06  0.017484   57.527512   \n",
       "307  5.867026e-06 -6.488448e-03  5.867026e+06  0.012010   63.607864   \n",
       "310  1.410764e-05 -7.414980e-02  1.410764e+07  0.025872   87.821396   \n",
       "311           NaN           NaN           NaN       NaN         NaN   \n",
       "312           NaN           NaN           NaN       NaN         NaN   \n",
       "314 -6.649078e-06 -5.937477e-02 -6.649078e+06  0.019724  105.574318   \n",
       "315           NaN           NaN           NaN       NaN         NaN   \n",
       "318 -2.331353e-04  1.089518e-07 -2.139803e+03  0.045063    0.028586   \n",
       "319  5.785107e-07 -1.659142e-02  5.785106e+05  0.012270   64.125565   \n",
       "320  1.733290e-06 -2.156630e-01  1.733290e+06  0.016163   59.885452   \n",
       "321 -1.802183e-06 -1.224682e-02 -1.802183e+06  0.012111   62.086426   \n",
       "324 -7.090073e-06  3.424453e-02 -2.070425e-04  0.025295   91.316360   \n",
       "325           NaN           NaN           NaN       NaN         NaN   \n",
       "326           NaN           NaN           NaN       NaN         NaN   \n",
       "328 -1.075843e-05  1.588381e-02 -6.773203e-04  0.020301  106.130531   \n",
       "329           NaN           NaN           NaN       NaN         NaN   \n",
       "332 -2.001737e-04  1.250116e-05 -1.601241e+01  0.044343    0.027614   \n",
       "333  2.557896e-06 -5.352998e-03  2.557896e+06  0.011987   66.320076   \n",
       "334 -5.872026e-06 -2.892585e-01 -5.872026e+06  0.015699   58.458031   \n",
       "335  3.839652e-06 -7.054937e-03  3.839652e+06  0.011748   60.015942   \n",
       "338 -9.493078e-06  3.381686e-02 -2.807202e-04  0.026128   86.926315   \n",
       "339           NaN           NaN           NaN       NaN         NaN   \n",
       "340           NaN           NaN           NaN       NaN         NaN   \n",
       "342 -8.975815e-06  9.288421e-02 -9.663446e-05  0.022895  105.833694   \n",
       "343           NaN           NaN           NaN       NaN         NaN   \n",
       "346 -2.069383e-04 -1.533429e-05 -2.069384e+08  0.043450    0.027468   \n",
       "347  4.622842e-06  1.639827e-02  2.819104e-04  0.011435   68.695694   \n",
       "348 -5.015406e-06 -3.113505e-01 -5.015406e+06  0.014653   54.807526   \n",
       "349 -3.569238e-07 -2.094859e-02 -3.569238e+05  0.011205   60.274117   \n",
       "352 -3.956973e-06  5.946008e-02 -6.654839e-05  0.025757   82.116997   \n",
       "353           NaN           NaN           NaN       NaN         NaN   \n",
       "354           NaN           NaN           NaN       NaN         NaN   \n",
       "356 -7.950891e-06  1.419720e-02 -5.600323e-04  0.021725  105.261940   \n",
       "357           NaN           NaN           NaN       NaN         NaN   \n",
       "360 -2.780234e-04  4.305819e-05 -6.456923e+00  0.042963    0.027442   \n",
       "361 -2.007923e-06 -1.622766e-02 -2.007923e+06  0.011906   69.248978   \n",
       "362 -5.254829e-06 -3.287365e-01 -5.254830e+06  0.014781   56.592617   \n",
       "363  1.348566e-06 -2.978748e-03  1.348566e+06  0.011692   63.231472   \n",
       "366  1.296716e-05 -2.945281e-03  1.296716e+07  0.025355   87.556984   \n",
       "367           NaN           NaN           NaN       NaN         NaN   \n",
       "368           NaN           NaN           NaN       NaN         NaN   \n",
       "370  8.303167e-08  5.813380e-03  1.428286e-05  0.021081  104.683365   \n",
       "371           NaN           NaN           NaN       NaN         NaN   \n",
       "374 -1.634033e-04  3.412114e-05 -4.788915e+00  0.042653    0.026906   \n",
       "375 -2.963604e-06 -3.467131e-03 -2.963604e+06  0.010741   74.328285   \n",
       "376 -2.033020e-06 -3.252713e-01 -2.033020e+06  0.012822   59.800095   \n",
       "377  1.440451e-06 -8.315486e-03  1.440451e+06  0.010603   66.832832   \n",
       "380  2.422474e-05 -2.134536e-02  2.422474e+07  0.024430   80.908165   \n",
       "381           NaN           NaN           NaN       NaN         NaN   \n",
       "382           NaN           NaN           NaN       NaN         NaN   \n",
       "384  6.848127e-06 -1.303290e-02  6.848127e+06  0.020790   99.834404   \n",
       "385           NaN           NaN           NaN       NaN         NaN   \n",
       "388 -1.894469e-04 -1.777002e-05 -1.894469e+08  0.042107    0.026106   \n",
       "389  2.965367e-06  3.939144e-02  7.527947e-05  0.012497   73.834450   \n",
       "390  1.570648e-07 -2.391088e-01  1.570648e+05  0.014828   55.415562   \n",
       "391  2.451872e-06  3.403801e-02  7.203335e-05  0.012058   66.363869   \n",
       "394 -1.555544e-05 -4.958065e-02 -1.555544e+07  0.025705   88.940269   \n",
       "395           NaN           NaN           NaN       NaN         NaN   \n",
       "396           NaN           NaN           NaN       NaN         NaN   \n",
       "398  4.962117e-06  1.478509e-02  3.356162e-04  0.021783  105.813599   \n",
       "399           NaN           NaN           NaN       NaN         NaN   \n",
       "402 -2.449994e-04  4.622344e-05 -5.300328e+00  0.041997    0.026148   \n",
       "403  6.203331e-06  7.772340e-03  7.981291e-04  0.012303   72.667374   \n",
       "404 -9.100067e-06 -3.669771e-01 -9.100068e+06  0.014147   59.863251   \n",
       "405 -3.288569e-06 -1.102681e-02 -3.288569e+06  0.011964   66.907257   \n",
       "408 -1.703942e-07  4.032629e-03 -4.225387e-05  0.025883   91.589745   \n",
       "409           NaN           NaN           NaN       NaN         NaN   \n",
       "410           NaN           NaN           NaN       NaN         NaN   \n",
       "412  4.319254e-07  3.405518e-02  1.268310e-05  0.023976  103.821999   \n",
       "413           NaN           NaN           NaN       NaN         NaN   \n",
       "416 -1.777210e-04 -7.934801e-05 -1.777210e+08  0.041487    0.026225   \n",
       "417 -2.315411e-06  5.455615e-03 -4.244088e-04  0.012263   72.891472   \n",
       "418  1.553173e-05 -2.199446e-01  1.553173e+07  0.014568   58.028320   \n",
       "419 -3.223807e-06 -4.895579e-03 -3.223807e+06  0.011995   66.287956   \n",
       "422 -2.392116e-06  4.066739e-02 -5.882148e-05  0.023215   91.859833   \n",
       "423           NaN           NaN           NaN       NaN         NaN   \n",
       "424           NaN           NaN           NaN       NaN         NaN   \n",
       "426 -3.602708e-06 -6.330750e-03 -3.602708e+06  0.021197  104.732697   \n",
       "427           NaN           NaN           NaN       NaN         NaN   \n",
       "430 -1.708427e-04 -7.752867e-05 -1.708427e+08  0.040134    0.025134   \n",
       "431  5.314093e-07  8.933453e-03  5.948532e-05  0.012002   71.532806   \n",
       "432  7.053688e-06 -2.400984e-01  7.053688e+06  0.013882   55.767273   \n",
       "433 -4.167405e-06 -9.471465e-03 -4.167405e+06  0.011789   63.387787   \n",
       "436 -6.090719e-06 -2.176526e-02 -6.090718e+06  0.024148   86.476509   \n",
       "437           NaN           NaN           NaN       NaN         NaN   \n",
       "438           NaN           NaN           NaN       NaN         NaN   \n",
       "440  5.583176e-06  4.792462e-03  1.164991e-03  0.021689   99.886757   \n",
       "441           NaN           NaN           NaN       NaN         NaN   \n",
       "444 -1.149284e-04 -3.365870e-05 -1.149284e+08  0.039834    0.024708   \n",
       "445  4.064856e-07 -1.043761e-02  4.064856e+05  0.012608   70.596008   \n",
       "446  1.142472e-05 -2.508570e-01  1.142472e+07  0.014133   55.349747   \n",
       "447 -4.910673e-06  9.193955e-03 -5.341198e-04  0.012335   63.038136   \n",
       "450  6.047038e-06 -4.908935e-02  6.047038e+06  0.024128   88.528648   \n",
       "451           NaN           NaN           NaN       NaN         NaN   \n",
       "452           NaN           NaN           NaN       NaN         NaN   \n",
       "454 -1.429682e-06  4.509106e-02 -3.170655e-05  0.022425  104.493759   \n",
       "455           NaN           NaN           NaN       NaN         NaN   \n",
       "458 -1.508373e-04  2.858262e-05 -5.277240e+00  0.038994    0.025553   \n",
       "459  5.842824e-07 -9.231600e-03  5.842824e+05  0.012878   70.013916   \n",
       "460  3.733487e-06 -3.760223e-01  3.733487e+06  0.014176   64.930260   \n",
       "461  2.896968e-06  2.988487e-03  9.693764e-04  0.012671   66.436310   \n",
       "464  3.885699e-06  6.064153e-02  6.407653e-05  0.026009   84.975517   \n",
       "465           NaN           NaN           NaN       NaN         NaN   \n",
       "466           NaN           NaN           NaN       NaN         NaN   \n",
       "468  8.868068e-06 -6.743153e-03  8.868068e+06  0.023233  105.147415   \n",
       "469           NaN           NaN           NaN       NaN         NaN   \n",
       "472 -1.320829e-04 -4.541640e-05 -1.320829e+08  0.038246    0.024404   \n",
       "473 -1.152634e-06 -1.972780e-03 -1.152634e+06  0.012691   71.629173   \n",
       "474  8.834773e-06 -2.911580e-01  8.834773e+06  0.014209   62.479534   \n",
       "475  1.993115e-06  8.235618e-03  2.420116e-04  0.012305   64.925858   \n",
       "478  3.030488e-06 -3.417383e-02  3.030488e+06  0.026158   72.769676   \n",
       "479           NaN           NaN           NaN       NaN         NaN   \n",
       "480           NaN           NaN           NaN       NaN         NaN   \n",
       "482 -1.396485e-07 -8.308860e-03 -1.396485e+05  0.023599  105.089142   \n",
       "483           NaN           NaN           NaN       NaN         NaN   \n",
       "486 -1.692496e-04  2.098504e-05 -8.065253e+00  0.038042    0.024120   \n",
       "487  4.154171e-06 -7.816254e-03  4.154171e+06  0.012416   66.333588   \n",
       "488  1.108182e-06 -2.339160e-01  1.108182e+06  0.014101   62.098629   \n",
       "489  6.086235e-07 -9.359336e-03  6.086235e+05  0.012313   59.635708   \n",
       "492  2.475617e-05 -1.117020e-01  2.475617e+07  0.026191   83.241516   \n",
       "493           NaN           NaN           NaN       NaN         NaN   \n",
       "494           NaN           NaN           NaN       NaN         NaN   \n",
       "496  7.585611e-06  4.504902e-03  1.683857e-03  0.023314  102.361404   \n",
       "497           NaN           NaN           NaN       NaN         NaN   \n",
       "500 -1.491089e-04 -1.254909e-04 -1.491089e+08  0.037504    0.024365   \n",
       "501 -3.236842e-06  1.374267e-02 -2.355323e-04  0.012388   69.300026   \n",
       "502  1.347473e-05 -2.921647e-01  1.347473e+07  0.014455   66.486938   \n",
       "503 -2.656181e-06 -2.184244e-02 -2.656181e+06  0.012666   65.394508   \n",
       "506 -3.073183e-05 -9.216955e-02 -3.073183e+07  0.023338   91.498039   \n",
       "507           NaN           NaN           NaN       NaN         NaN   \n",
       "508           NaN           NaN           NaN       NaN         NaN   \n",
       "510  8.923560e-07  1.168493e-02  7.636809e-05  0.019430  106.032204   \n",
       "511           NaN           NaN           NaN       NaN         NaN   \n",
       "514 -1.105045e-04 -1.708675e-04 -1.105045e+08  0.037508    0.023581   \n",
       "515  1.395854e-07 -2.267782e-03  1.395854e+05  0.012051   68.944221   \n",
       "516  4.846256e-06 -1.937132e-01  4.846256e+06  0.014062   62.263241   \n",
       "517 -1.477660e-06 -2.003634e-02 -1.477660e+06  0.012158   64.287193   \n",
       "520 -1.492910e-05 -3.902095e-02 -1.492910e+07  0.024621   83.566223   \n",
       "521           NaN           NaN           NaN       NaN         NaN   \n",
       "522           NaN           NaN           NaN       NaN         NaN   \n",
       "524 -4.557790e-06  5.746814e-02 -7.930986e-05  0.021760  105.405632   \n",
       "525           NaN           NaN           NaN       NaN         NaN   \n",
       "528 -1.121770e-04 -1.210259e-04 -1.121770e+08  0.037259    0.023656   \n",
       "529  5.785394e-07 -6.294029e-03  5.785394e+05  0.012031   65.598831   \n",
       "530 -2.532516e-06 -2.024581e-01 -2.532516e+06  0.013753   62.480423   \n",
       "531  4.575153e-06 -9.745409e-03  4.575152e+06  0.012073   60.773392   \n",
       "534  8.130700e-06  2.347322e-02  3.463819e-04  0.025298   79.519371   \n",
       "535           NaN           NaN           NaN       NaN         NaN   \n",
       "536           NaN           NaN           NaN       NaN         NaN   \n",
       "538  4.217153e-06 -5.704076e-03  4.217153e+06  0.023003  106.593079   \n",
       "539           NaN           NaN           NaN       NaN         NaN   \n",
       "542 -1.869524e-04 -5.243882e-05 -1.869524e+08  0.037128    0.022443   \n",
       "543 -2.036382e-06 -5.447127e-03 -2.036382e+06  0.012097   66.179512   \n",
       "544  6.955045e-06 -1.972267e-01  6.955044e+06  0.014015   63.516895   \n",
       "545  4.115060e-07 -2.233913e-03  4.115060e+05  0.012404   60.855301   \n",
       "548 -1.187304e-05  8.978627e-04 -1.322367e-02  0.020877   77.472610   \n",
       "549           NaN           NaN           NaN       NaN         NaN   \n",
       "550           NaN           NaN           NaN       NaN         NaN   \n",
       "552  2.778476e-06  4.981333e-02  5.577775e-05  0.017924  106.064796   \n",
       "553           NaN           NaN           NaN       NaN         NaN   \n",
       "556 -1.270078e-04 -1.192450e-04 -1.270078e+08  0.035977    0.022345   \n",
       "557 -2.627695e-06  5.786971e-03 -4.540709e-04  0.012210   69.118950   \n",
       "558 -6.566966e-06 -2.019484e-01 -6.566966e+06  0.013783   65.238548   \n",
       "559 -3.257190e-06 -8.360455e-03 -3.257190e+06  0.012485   64.428314   \n",
       "562  5.031710e-06  7.347168e-03  6.848503e-04  0.025171   82.053139   \n",
       "563           NaN           NaN           NaN       NaN         NaN   \n",
       "564           NaN           NaN           NaN       NaN         NaN   \n",
       "566 -3.341826e-06 -1.406137e-02 -3.341826e+06  0.023217   97.202354   \n",
       "567           NaN           NaN           NaN       NaN         NaN   \n",
       "570 -1.830576e-04 -1.751987e-04 -1.830576e+08  0.034694    0.021876   \n",
       "571 -6.396671e-07 -7.341177e-03 -6.396671e+05  0.011862   65.128220   \n",
       "572  8.624909e-06 -1.405958e-01  8.624909e+06  0.013183   64.548592   \n",
       "573  6.162876e-07 -3.677541e-02  6.162876e+05  0.012068   59.725723   \n",
       "576 -6.090324e-06 -3.130476e-02 -6.090324e+06  0.024748   78.427406   \n",
       "577           NaN           NaN           NaN       NaN         NaN   \n",
       "578           NaN           NaN           NaN       NaN         NaN   \n",
       "580 -1.144068e-05  5.585783e-02 -2.048178e-04  0.021126  106.693237   \n",
       "581           NaN           NaN           NaN       NaN         NaN   \n",
       "584 -1.210729e-04 -1.989673e-04 -1.210729e+08  0.033203    0.021931   \n",
       "585  2.206265e-06  3.226588e-02  6.837764e-05  0.011675   64.400452   \n",
       "586  5.742945e-06 -1.902667e-01  5.742945e+06  0.013340   64.486053   \n",
       "587  2.934498e-06  1.086098e-02  2.701873e-04  0.011778   61.467045   \n",
       "590  9.309763e-06 -2.666127e-02  9.309763e+06  0.025148   86.665237   \n",
       "591           NaN           NaN           NaN       NaN         NaN   \n",
       "592           NaN           NaN           NaN       NaN         NaN   \n",
       "594 -6.279362e-06  2.139048e-03 -2.935587e-03  0.022708  107.621468   \n",
       "595           NaN           NaN           NaN       NaN         NaN   \n",
       "598 -1.609426e-04 -1.404632e-04 -1.609426e+08  0.033147    0.021416   \n",
       "599  3.613284e-06 -6.485780e-03  3.613284e+06  0.011681   60.210541   \n",
       "600 -7.717815e-06 -2.031770e-01 -7.717814e+06  0.013625   63.900448   \n",
       "601  3.854368e-06  1.034002e-02  3.727620e-04  0.011650   59.839645   \n",
       "604 -3.273722e-06 -5.559136e-02 -3.273722e+06  0.024724   75.338821   \n",
       "605           NaN           NaN           NaN       NaN         NaN   \n",
       "606           NaN           NaN           NaN       NaN         NaN   \n",
       "608  8.232048e-06  3.023849e-02  2.722374e-04  0.022601  104.802429   \n",
       "609           NaN           NaN           NaN       NaN         NaN   \n",
       "612 -1.530798e-04 -1.352092e-04 -1.530798e+08  0.032667    0.020872   \n",
       "613 -4.030531e-06 -7.940068e-03 -4.030531e+06  0.011577   61.793247   \n",
       "614  2.750955e-06 -1.850301e-01  2.750955e+06  0.013900   63.198639   \n",
       "615 -1.456514e-06  1.647042e-02 -8.843213e-05  0.011229   60.925915   \n",
       "618  4.592324e-06 -4.400600e-02  4.592324e+06  0.026193   89.177483   \n",
       "619           NaN           NaN           NaN       NaN         NaN   \n",
       "620           NaN           NaN           NaN       NaN         NaN   \n",
       "622  4.888307e-06  4.533396e-03  1.078288e-03  0.022160  100.050941   \n",
       "623           NaN           NaN           NaN       NaN         NaN   \n",
       "626 -1.046044e-04 -9.810292e-05 -1.046044e+08  0.032623    0.020572   \n",
       "627  3.017280e-06  2.051894e-02  1.470485e-04  0.011399   61.638622   \n",
       "628  3.023840e-06 -6.742522e-02  3.023840e+06  0.014170   62.437828   \n",
       "629  1.261310e-06  1.738634e-02  7.254606e-05  0.011281   58.249008   \n",
       "632 -1.813067e-06 -6.622984e-02 -1.813067e+06  0.022560   80.025360   \n",
       "633           NaN           NaN           NaN       NaN         NaN   \n",
       "634           NaN           NaN           NaN       NaN         NaN   \n",
       "636  1.783787e-06 -3.087820e-02  1.783786e+06  0.021932  104.505333   \n",
       "637           NaN           NaN           NaN       NaN         NaN   \n",
       "640 -1.596463e-04 -1.207755e-04 -1.596463e+08  0.030904    0.019725   \n",
       "641 -2.821200e-06  3.617537e-03 -7.798676e-04  0.011427   62.680706   \n",
       "642 -7.959879e-06 -1.582177e-01 -7.959880e+06  0.014033   67.306038   \n",
       "643 -7.313890e-06  5.653849e-03 -1.293612e-03  0.011187   59.199986   \n",
       "646  1.207770e-06  4.197418e-02  2.877413e-05  0.025974   71.090698   \n",
       "647           NaN           NaN           NaN       NaN         NaN   \n",
       "648           NaN           NaN           NaN       NaN         NaN   \n",
       "650 -2.672746e-06  1.946198e-02 -1.373317e-04  0.020106  101.973648   \n",
       "651           NaN           NaN           NaN       NaN         NaN   \n",
       "654 -1.012390e-04 -1.808002e-04 -1.012390e+08  0.030201    0.019172   \n",
       "655  1.819590e-06  2.766303e-03  6.577697e-04  0.011037   67.987389   \n",
       "656  2.148646e-05 -2.301417e-01  2.148646e+07  0.014349   69.584663   \n",
       "657 -7.760198e-07 -1.859942e-02 -7.760198e+05  0.010900   63.393131   \n",
       "660  6.802001e-06 -2.692598e-02  6.802002e+06  0.023027   67.269402   \n",
       "661           NaN           NaN           NaN       NaN         NaN   \n",
       "662           NaN           NaN           NaN       NaN         NaN   \n",
       "664 -1.184558e-05  4.968539e-02 -2.384118e-04  0.018563  103.499649   \n",
       "665           NaN           NaN           NaN       NaN         NaN   \n",
       "668 -1.089947e-04 -1.687905e-04 -1.089947e+08  0.030242    0.018836   \n",
       "669 -5.961533e-06  6.079135e-03 -9.806550e-04  0.010939   69.560707   \n",
       "670 -6.168965e-06 -2.367010e-01 -6.168965e+06  0.014570   69.359093   \n",
       "671 -4.853365e-06  1.312750e-04 -3.697098e-02  0.010802   62.976933   \n",
       "674 -4.431110e-06 -9.210092e-02 -4.431110e+06  0.021998   90.683762   \n",
       "675           NaN           NaN           NaN       NaN         NaN   \n",
       "676           NaN           NaN           NaN       NaN         NaN   \n",
       "678  3.629224e-06 -2.747159e-02  3.629224e+06  0.016440  104.962486   \n",
       "679           NaN           NaN           NaN       NaN         NaN   \n",
       "682 -9.340945e-05 -1.160686e-04 -9.340945e+07  0.030557    0.018274   \n",
       "683  2.065495e-06 -8.322178e-03  2.065495e+06  0.010927   68.942902   \n",
       "684 -9.959461e-08 -1.904464e-01 -9.959461e+04  0.014504   70.364494   \n",
       "685  2.872873e-07 -1.776119e-02  2.872873e+05  0.010964   63.561302   \n",
       "688 -3.225490e-06  2.155166e-02 -1.496631e-04  0.021265   84.970497   \n",
       "689           NaN           NaN           NaN       NaN         NaN   \n",
       "690           NaN           NaN           NaN       NaN         NaN   \n",
       "692 -6.610821e-06 -3.157791e-03 -6.610822e+06  0.016709  104.257576   \n",
       "693           NaN           NaN           NaN       NaN         NaN   \n",
       "696 -1.819975e-04 -1.049985e-04 -1.819975e+08  0.029484    0.017980   \n",
       "697 -3.709344e-06 -3.467460e-02 -3.709344e+06  0.010852   67.378258   \n",
       "698 -2.191403e-05 -1.845903e-01 -2.191403e+07  0.014442   69.431419   \n",
       "699  7.321877e-07 -1.483387e-03  7.321878e+05  0.010649   62.176151   \n",
       "702  5.950097e-06  5.554332e-02  1.071253e-04  0.025825   79.959450   \n",
       "703           NaN           NaN           NaN       NaN         NaN   \n",
       "704           NaN           NaN           NaN       NaN         NaN   \n",
       "706 -1.052833e-05  3.655579e-02 -2.880072e-04  0.022168  102.504456   \n",
       "707           NaN           NaN           NaN       NaN         NaN   \n",
       "710 -1.531837e-04 -1.507561e-04 -1.531837e+08  0.028924    0.017393   \n",
       "711 -3.844635e-06  6.481429e-03 -5.931771e-04  0.011067   71.532028   \n",
       "712 -4.383844e-06 -2.694015e-01 -4.383844e+06  0.014887   68.742569   \n",
       "713  3.685792e-07  5.844287e-03  6.306659e-05  0.010790   65.375931   \n",
       "716  7.729338e-06 -2.947754e-02  7.729338e+06  0.025845   78.918671   \n",
       "717           NaN           NaN           NaN       NaN         NaN   \n",
       "718           NaN           NaN           NaN       NaN         NaN   \n",
       "720  3.315716e-07 -3.104924e-02  3.315717e+05  0.019265  104.692764   \n",
       "721           NaN           NaN           NaN       NaN         NaN   \n",
       "724 -1.386354e-04 -1.537078e-04 -1.386354e+08  0.028304    0.017460   \n",
       "725  1.346152e-06 -1.024971e-02  1.346152e+06  0.011140   67.468399   \n",
       "726 -2.579942e-05 -3.413542e-01 -2.579942e+07  0.014730   69.725830   \n",
       "727  1.576601e-06  3.249281e-03  4.852152e-04  0.010654   66.041969   \n",
       "730  1.503743e-05 -3.311199e-02  1.503743e+07  0.023576   88.615150   \n",
       "731           NaN           NaN           NaN       NaN         NaN   \n",
       "732           NaN           NaN           NaN       NaN         NaN   \n",
       "734  8.073707e-06 -3.664225e-02  8.073708e+06  0.019291  101.247780   \n",
       "735           NaN           NaN           NaN       NaN         NaN   \n",
       "738 -7.633631e-05 -1.765326e-04 -7.633631e+07  0.027587    0.016015   \n",
       "739 -2.738451e-06  4.667359e-03 -5.867240e-04  0.011075   66.230324   \n",
       "740 -2.242682e-05 -2.347590e-01 -2.242682e+07  0.015300   68.885559   \n",
       "741 -5.489941e-06 -3.485284e-02 -5.489941e+06  0.010594   64.405540   \n",
       "744  4.912959e-06 -4.510187e-02  4.912959e+06  0.024533   89.718170   \n",
       "745           NaN           NaN           NaN       NaN         NaN   \n",
       "746           NaN           NaN           NaN       NaN         NaN   \n",
       "748  7.497435e-06 -3.885011e-02  7.497435e+06  0.019401   94.827713   \n",
       "749           NaN           NaN           NaN       NaN         NaN   \n",
       "752 -1.216935e-04 -9.439918e-05 -1.216935e+08  0.026427    0.015987   \n",
       "753 -9.516548e-07 -1.052500e-02 -9.516548e+05  0.011028   67.458427   \n",
       "754 -3.175724e-05 -1.723170e-01 -3.175724e+07  0.015004   69.737335   \n",
       "755  3.281851e-07 -1.137515e-02  3.281851e+05  0.010729   65.917618   \n",
       "758 -1.530643e-05 -1.975615e-03 -1.530643e+07  0.020815   86.798882   \n",
       "759           NaN           NaN           NaN       NaN         NaN   \n",
       "760           NaN           NaN           NaN       NaN         NaN   \n",
       "762 -7.407287e-07  2.083170e-02 -3.555777e-05  0.015586  104.683708   \n",
       "763           NaN           NaN           NaN       NaN         NaN   \n",
       "766 -4.039209e-05 -1.072185e-04 -4.039209e+07  0.026662    0.015028   \n",
       "767  4.297632e-06  7.255935e-03  5.922920e-04  0.011313   67.067284   \n",
       "768 -4.038461e-05 -1.469817e-01 -4.038461e+07  0.015305   71.714813   \n",
       "769  1.203183e-06  4.487616e-03  2.681118e-04  0.011091   69.973145   \n",
       "772 -6.869784e-06  1.160942e-02 -5.917421e-04  0.021417   81.753609   \n",
       "773           NaN           NaN           NaN       NaN         NaN   \n",
       "774           NaN           NaN           NaN       NaN         NaN   \n",
       "776 -1.299218e-06  2.403503e-02 -5.405517e-05  0.014063  101.453522   \n",
       "777           NaN           NaN           NaN       NaN         NaN   \n",
       "780 -2.811972e-05 -4.951217e-05 -2.811972e+07  0.025648    0.014431   \n",
       "781 -2.246785e-06  1.121911e-02 -2.002640e-04  0.011314   67.755661   \n",
       "782 -2.877171e-05 -1.678354e-01 -2.877171e+07  0.015919   72.527573   \n",
       "783  6.647404e-06 -2.566931e-02  6.647404e+06  0.011284   71.837524   \n",
       "786 -1.887155e-05  5.164166e-02 -3.654328e-04  0.023425   90.323662   \n",
       "787           NaN           NaN           NaN       NaN         NaN   \n",
       "788           NaN           NaN           NaN       NaN         NaN   \n",
       "790  3.106712e-06  2.848307e-02  1.090722e-04  0.017399  102.275108   \n",
       "791           NaN           NaN           NaN       NaN         NaN   \n",
       "794 -1.243669e-04 -1.508405e-05 -1.243669e+08  0.025029    0.014471   \n",
       "795 -5.526402e-08 -4.684624e-03 -5.526402e+04  0.011764   66.348656   \n",
       "796 -3.936243e-05 -2.186561e-01 -3.936243e+07  0.016763   72.617989   \n",
       "797 -1.128455e-06 -1.713091e-02 -1.128455e+06  0.011938   73.063843   \n",
       "800  1.439222e-05 -1.083697e-02  1.439222e+07  0.021148   81.454781   \n",
       "801           NaN           NaN           NaN       NaN         NaN   \n",
       "802           NaN           NaN           NaN       NaN         NaN   \n",
       "804 -6.326462e-06 -1.447186e-02 -6.326462e+06  0.017004   97.873833   \n",
       "805           NaN           NaN           NaN       NaN         NaN   \n",
       "808 -7.202942e-05  9.072167e-05 -7.939605e-01  0.024365    0.014946   \n",
       "809 -1.933409e-06  7.639631e-03 -2.530763e-04  0.012228   64.875435   \n",
       "810 -4.827616e-05  1.218323e-01 -3.962510e-04  0.017125   72.719002   \n",
       "811 -4.617706e-06  4.263859e-03 -1.082987e-03  0.012699   70.033562   \n",
       "814 -3.834824e-06  1.003834e-01 -3.820178e-05  0.020811   94.975632   \n",
       "815           NaN           NaN           NaN       NaN         NaN   \n",
       "816           NaN           NaN           NaN       NaN         NaN   \n",
       "818 -6.660851e-06  1.602416e-02 -4.156755e-04  0.014207   84.007454   \n",
       "819           NaN           NaN           NaN       NaN         NaN   \n",
       "822 -1.165403e-04  1.126568e-04 -1.034472e+00  0.022326    0.016217   \n",
       "823 -1.224481e-07  1.516126e-02 -8.076385e-06  0.012241   60.767826   \n",
       "824 -6.539675e-05  1.408842e-01 -4.641880e-04  0.017423   66.136940   \n",
       "825 -2.859583e-06 -4.252552e-03 -2.859583e+06  0.012731   62.393883   \n",
       "828  1.387867e-06  5.260651e-02  2.638203e-05  0.024028   82.054054   \n",
       "829           NaN           NaN           NaN       NaN         NaN   \n",
       "830           NaN           NaN           NaN       NaN         NaN   \n",
       "832 -3.281977e-07 -3.920203e-02 -3.281977e+05  0.017804   99.208954   \n",
       "833           NaN           NaN           NaN       NaN         NaN   \n",
       "836 -8.851806e-05  2.514182e-04 -3.520750e-01  0.021505    0.021680   \n",
       "837 -5.081034e-06 -2.179184e-02 -5.081034e+06  0.012047   52.880806   \n",
       "838 -7.044782e-05  1.505888e-02 -4.678158e-03  0.016894   66.643372   \n",
       "839  4.082678e-07  1.042032e-02  3.917998e-05  0.013240   58.074692   \n",
       "842  1.049011e-05  2.346013e-02  4.471461e-04  0.023272   91.227325   \n",
       "843           NaN           NaN           NaN       NaN         NaN   \n",
       "844           NaN           NaN           NaN       NaN         NaN   \n",
       "846  4.304269e-06 -2.489731e-02  4.304268e+06  0.017176   78.816605   \n",
       "847           NaN           NaN           NaN       NaN         NaN   \n",
       "\n",
       "     std_ratio  zero_frac_a  zero_frac_b   cos_sim    rel_l2_err  \\\n",
       "1     0.000139          0.0     0.000047  0.000037   7189.438477   \n",
       "2     0.000242          0.0     0.000274 -0.000151   4125.888672   \n",
       "3     0.000087          0.0     0.000026 -0.000017  11465.268555   \n",
       "6     0.000300          0.0     0.000023 -0.000718   3336.111328   \n",
       "7          NaN          NaN          NaN       NaN           NaN   \n",
       "8          NaN          NaN          NaN       NaN           NaN   \n",
       "10    0.000111          0.0     0.000010  0.000173   9015.852539   \n",
       "11         NaN          NaN          NaN       NaN           NaN   \n",
       "13    0.000100          0.0     0.000067 -0.000085  10030.302734   \n",
       "14    0.000168          0.0     0.000473 -0.002543   5959.996582   \n",
       "15    0.000060          0.0     0.000058  0.000031  16530.933594   \n",
       "18    0.000240          0.0     0.000030  0.000140   4174.283691   \n",
       "19         NaN          NaN          NaN       NaN           NaN   \n",
       "20         NaN          NaN          NaN       NaN           NaN   \n",
       "22    0.000101          0.0     0.000024 -0.000554   9860.533203   \n",
       "23         NaN          NaN          NaN       NaN           NaN   \n",
       "25    0.000138          0.0     0.000084 -0.000120   7225.403320   \n",
       "26    0.000238          0.0     0.000526 -0.000183   4205.749023   \n",
       "27    0.000088          0.0     0.000063 -0.000124  11361.936523   \n",
       "30    0.000283          0.0     0.000038 -0.001011   3537.533447   \n",
       "31         NaN          NaN          NaN       NaN           NaN   \n",
       "32         NaN          NaN          NaN       NaN           NaN   \n",
       "34    0.000124          0.0     0.000021 -0.000291   8083.104004   \n",
       "35         NaN          NaN          NaN       NaN           NaN   \n",
       "38    0.880683          0.0     0.000000 -0.003374      1.515584   \n",
       "39    0.000119          0.0     0.000018  0.000154   8434.277344   \n",
       "40    0.000136          0.0     0.000024  0.007713   7355.858887   \n",
       "41    0.000072          0.0     0.000009  0.000455  13875.956055   \n",
       "44    0.000246          0.0     0.000023 -0.000964   4072.165283   \n",
       "45         NaN          NaN          NaN       NaN           NaN   \n",
       "46         NaN          NaN          NaN       NaN           NaN   \n",
       "48    0.000168          0.0     0.000015 -0.000191   5945.715332   \n",
       "49         NaN          NaN          NaN       NaN           NaN   \n",
       "52    1.046546          0.0     0.000000 -0.005643      1.387016   \n",
       "53    0.000124          0.0     0.000015  0.000191   8051.048340   \n",
       "54    0.000267          0.0     0.000026 -0.002549   3748.165527   \n",
       "55    0.000088          0.0     0.000011 -0.000021  11313.309570   \n",
       "58    0.000225          0.0     0.000016  0.000142   4438.604004   \n",
       "59         NaN          NaN          NaN       NaN           NaN   \n",
       "60         NaN          NaN          NaN       NaN           NaN   \n",
       "62    0.000104          0.0     0.000010  0.000736   9651.665039   \n",
       "63         NaN          NaN          NaN       NaN           NaN   \n",
       "66    1.013400          0.0     0.000000  0.002856      1.402891   \n",
       "67    0.000125          0.0     0.000013  0.000072   7980.104004   \n",
       "68    0.000287          0.0     0.000025  0.007981   3489.986328   \n",
       "69    0.000101          0.0     0.000010 -0.000720   9871.651367   \n",
       "72    0.000313          0.0     0.000029  0.000555   3196.676270   \n",
       "73         NaN          NaN          NaN       NaN           NaN   \n",
       "74         NaN          NaN          NaN       NaN           NaN   \n",
       "76    0.000134          0.0     0.000011  0.000123   7486.757324   \n",
       "77         NaN          NaN          NaN       NaN           NaN   \n",
       "80    1.015558          0.0     0.000000  0.001635      1.402278   \n",
       "81    0.000133          0.0     0.000015  0.000040   7539.826172   \n",
       "82    0.000315          0.0     0.000029  0.006891   3175.114746   \n",
       "83    0.000113          0.0     0.000011 -0.000596   8870.164062   \n",
       "86    0.000215          0.0     0.000015  0.000162   4642.449219   \n",
       "87         NaN          NaN          NaN       NaN           NaN   \n",
       "88         NaN          NaN          NaN       NaN           NaN   \n",
       "90    0.000121          0.0     0.000010  0.000410   8290.634766   \n",
       "91         NaN          NaN          NaN       NaN           NaN   \n",
       "94    1.096737          0.0     0.000000 -0.000217      1.353423   \n",
       "95    0.000124          0.0     0.000014  0.000423   8034.620117   \n",
       "96    0.000344          0.0     0.000029  0.002579   2905.140869   \n",
       "97    0.000123          0.0     0.000012  0.000060   8119.027832   \n",
       "100   0.000279          0.0     0.000017 -0.001061   3583.836182   \n",
       "101        NaN          NaN          NaN       NaN           NaN   \n",
       "102        NaN          NaN          NaN       NaN           NaN   \n",
       "104   0.000155          0.0     0.000011 -0.000106   6451.335938   \n",
       "105        NaN          NaN          NaN       NaN           NaN   \n",
       "108   1.206346          0.0     0.000000 -0.002334      1.300376   \n",
       "109   0.000161          0.0     0.000019  0.000129   6223.212402   \n",
       "110   0.000374          0.0     0.000029  0.002176   2673.854492   \n",
       "111   0.000137          0.0     0.000014 -0.000741   7278.729492   \n",
       "114   0.000297          0.0     0.000013  0.001199   3363.983643   \n",
       "115        NaN          NaN          NaN       NaN           NaN   \n",
       "116        NaN          NaN          NaN       NaN           NaN   \n",
       "118   0.000159          0.0     0.000012  0.000191   6281.785645   \n",
       "119        NaN          NaN          NaN       NaN           NaN   \n",
       "122   1.146120          0.0     0.000000 -0.000197      1.327242   \n",
       "123   0.000163          0.0     0.000016  0.000436   6142.150391   \n",
       "124   0.000409          0.0     0.000033  0.001613   2444.686279   \n",
       "125   0.000155          0.0     0.000016  0.000223   6432.552734   \n",
       "128   0.000256          0.0     0.000015  0.000201   3908.392822   \n",
       "129        NaN          NaN          NaN       NaN           NaN   \n",
       "130        NaN          NaN          NaN       NaN           NaN   \n",
       "132   0.000132          0.0     0.000009 -0.000427   7576.348633   \n",
       "133        NaN          NaN          NaN       NaN           NaN   \n",
       "136   1.061331          0.0     0.000000 -0.004267      1.376859   \n",
       "137   0.000172          0.0     0.000015  0.000112   5825.627930   \n",
       "138   0.000446          0.0     0.000030 -0.000207   2241.360596   \n",
       "139   0.000166          0.0     0.000014 -0.000003   6024.025879   \n",
       "142   0.000280          0.0     0.000021  0.000038   3569.100342   \n",
       "143        NaN          NaN          NaN       NaN           NaN   \n",
       "144        NaN          NaN          NaN       NaN           NaN   \n",
       "146   0.000135          0.0     0.000010  0.000364   7428.295410   \n",
       "147        NaN          NaN          NaN       NaN           NaN   \n",
       "150   1.067445          0.0     0.000000 -0.002468      1.371926   \n",
       "151   0.000168          0.0     0.000016  0.000031   5966.756348   \n",
       "152   0.000457          0.0     0.000026 -0.000050   2186.943359   \n",
       "153   0.000169          0.0     0.000018 -0.000152   5933.535156   \n",
       "156   0.000264          0.0     0.000017 -0.000145   3793.225342   \n",
       "157        NaN          NaN          NaN       NaN           NaN   \n",
       "158        NaN          NaN          NaN       NaN           NaN   \n",
       "160   0.000172          0.0     0.000011 -0.000089   5829.271973   \n",
       "161        NaN          NaN          NaN       NaN           NaN   \n",
       "164   1.102439          0.0     0.000000 -0.001725      1.351247   \n",
       "165   0.000171          0.0     0.000014  0.000285   5861.903809   \n",
       "166   0.000414          0.0     0.000026 -0.001716   2415.140869   \n",
       "167   0.000174          0.0     0.000015  0.000034   5760.409668   \n",
       "170   0.000271          0.0     0.000014  0.000435   3689.012695   \n",
       "171        NaN          NaN          NaN       NaN           NaN   \n",
       "172        NaN          NaN          NaN       NaN           NaN   \n",
       "174   0.000157          0.0     0.000011 -0.000233   6379.145020   \n",
       "175        NaN          NaN          NaN       NaN           NaN   \n",
       "178   1.160261          0.0     0.000000 -0.002876      1.322036   \n",
       "179   0.000168          0.0     0.000017  0.000095   5936.188965   \n",
       "180   0.000407          0.0     0.000031 -0.002048   2458.305176   \n",
       "181   0.000174          0.0     0.000014 -0.000086   5744.969238   \n",
       "184   0.000273          0.0     0.000013  0.000074   3661.753174   \n",
       "185        NaN          NaN          NaN       NaN           NaN   \n",
       "186        NaN          NaN          NaN       NaN           NaN   \n",
       "188   0.000181          0.0     0.000011 -0.000043   5534.592773   \n",
       "189        NaN          NaN          NaN       NaN           NaN   \n",
       "192   1.214837          0.0     0.000000 -0.003300      1.297325   \n",
       "193   0.000172          0.0     0.000017 -0.000267   5798.245605   \n",
       "194   0.000545          0.0     0.000035 -0.002147   1833.311279   \n",
       "195   0.000184          0.0     0.000017  0.000183   5424.522461   \n",
       "198   0.000270          0.0     0.000016  0.000144   3697.892822   \n",
       "199        NaN          NaN          NaN       NaN           NaN   \n",
       "200        NaN          NaN          NaN       NaN           NaN   \n",
       "202   0.000197          0.0     0.000010 -0.000231   5063.599609   \n",
       "203        NaN          NaN          NaN       NaN           NaN   \n",
       "206   1.280502          0.0     0.000000 -0.003517      1.270987   \n",
       "207   0.000185          0.0     0.000017  0.000324   5392.842773   \n",
       "208   0.000498          0.0     0.000034 -0.000964   2009.958862   \n",
       "209   0.000184          0.0     0.000020  0.000047   5423.005859   \n",
       "212   0.000265          0.0     0.000013  0.000258   3771.169922   \n",
       "213        NaN          NaN          NaN       NaN           NaN   \n",
       "214        NaN          NaN          NaN       NaN           NaN   \n",
       "216   0.000207          0.0     0.000008 -0.000266   4827.384277   \n",
       "217        NaN          NaN          NaN       NaN           NaN   \n",
       "220   1.210999          0.0     0.000000 -0.006046      1.300750   \n",
       "221   0.000180          0.0     0.000016  0.000297   5567.632812   \n",
       "222   0.000578          0.0     0.000032 -0.000995   1730.392944   \n",
       "223   0.000192          0.0     0.000018  0.000332   5214.794922   \n",
       "226   0.000257          0.0     0.000012 -0.000334   3896.737061   \n",
       "227        NaN          NaN          NaN       NaN           NaN   \n",
       "228        NaN          NaN          NaN       NaN           NaN   \n",
       "230   0.000178          0.0     0.000007 -0.000515   5609.986328   \n",
       "231        NaN          NaN          NaN       NaN           NaN   \n",
       "234   1.271312          0.0     0.000000 -0.003551      1.274495   \n",
       "235   0.000171          0.0     0.000015  0.000072   5861.631836   \n",
       "236   0.000398          0.0     0.000027 -0.001624   2514.337891   \n",
       "237   0.000166          0.0     0.000015  0.000359   6006.819824   \n",
       "240   0.000307          0.0     0.000016 -0.000256   3258.283447   \n",
       "241        NaN          NaN          NaN       NaN           NaN   \n",
       "242        NaN          NaN          NaN       NaN           NaN   \n",
       "244   0.000203          0.0     0.000010 -0.000042   4929.477539   \n",
       "245        NaN          NaN          NaN       NaN           NaN   \n",
       "248   1.315569          0.0     0.000000 -0.004603      1.258886   \n",
       "249   0.000181          0.0     0.000018  0.000224   5522.825684   \n",
       "250   0.000391          0.0     0.000029 -0.001710   2556.518311   \n",
       "251   0.000175          0.0     0.000015  0.000542   5699.294434   \n",
       "254   0.000268          0.0     0.000017  0.000758   3731.474609   \n",
       "255        NaN          NaN          NaN       NaN           NaN   \n",
       "256        NaN          NaN          NaN       NaN           NaN   \n",
       "258   0.000166          0.0     0.000010  0.000164   6015.775879   \n",
       "259        NaN          NaN          NaN       NaN           NaN   \n",
       "262   1.378587          0.0     0.000000 -0.004642      1.238110   \n",
       "263   0.000201          0.0     0.000018 -0.000071   4971.615234   \n",
       "264   0.000405          0.0     0.000028 -0.001423   2467.332031   \n",
       "265   0.000197          0.0     0.000017 -0.000435   5079.107910   \n",
       "268   0.000278          0.0     0.000017  0.000148   3598.245117   \n",
       "269        NaN          NaN          NaN       NaN           NaN   \n",
       "270        NaN          NaN          NaN       NaN           NaN   \n",
       "272   0.000197          0.0     0.000008 -0.000265   5086.375488   \n",
       "273        NaN          NaN          NaN       NaN           NaN   \n",
       "276   1.342003          0.0     0.000000 -0.004085      1.249538   \n",
       "277   0.000182          0.0     0.000016 -0.000048   5483.218750   \n",
       "278   0.000352          0.0     0.000024 -0.001544   2843.714844   \n",
       "279   0.000177          0.0     0.000018  0.000041   5636.540527   \n",
       "282   0.000274          0.0     0.000016 -0.000930   3644.076660   \n",
       "283        NaN          NaN          NaN       NaN           NaN   \n",
       "284        NaN          NaN          NaN       NaN           NaN   \n",
       "286   0.000165          0.0     0.000007 -0.000271   6047.429688   \n",
       "287        NaN          NaN          NaN       NaN           NaN   \n",
       "290   1.397680          0.0     0.000000 -0.004670      1.232308   \n",
       "291   0.000185          0.0     0.000015 -0.000056   5402.839844   \n",
       "292   0.000307          0.0     0.000021 -0.001270   3260.823730   \n",
       "293   0.000182          0.0     0.000015 -0.000012   5495.322266   \n",
       "296   0.000273          0.0     0.000015 -0.000238   3662.629883   \n",
       "297        NaN          NaN          NaN       NaN           NaN   \n",
       "298        NaN          NaN          NaN       NaN           NaN   \n",
       "300   0.000165          0.0     0.000008  0.000236   6078.119141   \n",
       "301        NaN          NaN          NaN       NaN           NaN   \n",
       "304   1.476255          0.0     0.000000 -0.005641      1.210989   \n",
       "305   0.000196          0.0     0.000018  0.000548   5101.026855   \n",
       "306   0.000304          0.0     0.000019 -0.000112   3290.221191   \n",
       "307   0.000189          0.0     0.000015  0.000020   5296.436035   \n",
       "310   0.000295          0.0     0.000017  0.000013   3394.408691   \n",
       "311        NaN          NaN          NaN       NaN           NaN   \n",
       "312        NaN          NaN          NaN       NaN           NaN   \n",
       "314   0.000187          0.0     0.000007 -0.000069   5352.717773   \n",
       "315        NaN          NaN          NaN       NaN           NaN   \n",
       "318   1.576388          0.0     0.000000 -0.005457      1.187151   \n",
       "319   0.000191          0.0     0.000017  0.000154   5226.300781   \n",
       "320   0.000270          0.0     0.000022  0.000063   3705.032227   \n",
       "321   0.000195          0.0     0.000015 -0.000244   5126.244629   \n",
       "324   0.000277          0.0     0.000014  0.000189   3610.067383   \n",
       "325        NaN          NaN          NaN       NaN           NaN   \n",
       "326        NaN          NaN          NaN       NaN           NaN   \n",
       "328   0.000191          0.0     0.000007 -0.000013   5227.763184   \n",
       "329        NaN          NaN          NaN       NaN           NaN   \n",
       "332   1.605788          0.0     0.000000 -0.009123      1.182865   \n",
       "333   0.000181          0.0     0.000018  0.000174   5532.694336   \n",
       "334   0.000269          0.0     0.000021 -0.000206   3723.685547   \n",
       "335   0.000196          0.0     0.000019 -0.000082   5108.688965   \n",
       "338   0.000301          0.0     0.000014  0.000569   3326.908203   \n",
       "339        NaN          NaN          NaN       NaN           NaN   \n",
       "340        NaN          NaN          NaN       NaN           NaN   \n",
       "342   0.000216          0.0     0.000008  0.000233   4622.494629   \n",
       "343        NaN          NaN          NaN       NaN           NaN   \n",
       "346   1.581804          0.0     0.000000 -0.006099      1.186325   \n",
       "347   0.000166          0.0     0.000015 -0.000034   6007.531250   \n",
       "348   0.000267          0.0     0.000024  0.000063   3740.311035   \n",
       "349   0.000186          0.0     0.000017  0.000060   5379.043457   \n",
       "352   0.000314          0.0     0.000016 -0.000941   3188.125244   \n",
       "353        NaN          NaN          NaN       NaN           NaN   \n",
       "354        NaN          NaN          NaN       NaN           NaN   \n",
       "356   0.000206          0.0     0.000008  0.000214   4845.236816   \n",
       "357        NaN          NaN          NaN       NaN           NaN   \n",
       "360   1.565596          0.0     0.000000 -0.005773      1.189681   \n",
       "361   0.000172          0.0     0.000016  0.000214   5816.496094   \n",
       "362   0.000261          0.0     0.000024 -0.000412   3828.726318   \n",
       "363   0.000185          0.0     0.000016 -0.000302   5408.130371   \n",
       "366   0.000290          0.0     0.000013  0.000985   3453.199951   \n",
       "367        NaN          NaN          NaN       NaN           NaN   \n",
       "368        NaN          NaN          NaN       NaN           NaN   \n",
       "370   0.000201          0.0     0.000009 -0.000011   4965.869629   \n",
       "371        NaN          NaN          NaN       NaN           NaN   \n",
       "374   1.585246          0.0     0.000000 -0.008816      1.187033   \n",
       "375   0.000145          0.0     0.000014  0.000011   6919.906738   \n",
       "376   0.000214          0.0     0.000020 -0.000359   4663.833496   \n",
       "377   0.000159          0.0     0.000016 -0.000184   6303.244629   \n",
       "380   0.000302          0.0     0.000012 -0.000787   3311.828369   \n",
       "381        NaN          NaN          NaN       NaN           NaN   \n",
       "382        NaN          NaN          NaN       NaN           NaN   \n",
       "384   0.000208          0.0     0.000008  0.000261   4802.110352   \n",
       "385        NaN          NaN          NaN       NaN           NaN   \n",
       "388   1.612943          0.0     0.000000 -0.006990      1.180271   \n",
       "389   0.000169          0.0     0.000016  0.000260   5908.282715   \n",
       "390   0.000268          0.0     0.000020 -0.000692   3737.214844   \n",
       "391   0.000182          0.0     0.000016 -0.000280   5503.847168   \n",
       "394   0.000289          0.0     0.000015 -0.000186   3460.082031   \n",
       "395        NaN          NaN          NaN       NaN           NaN   \n",
       "396        NaN          NaN          NaN       NaN           NaN   \n",
       "398   0.000206          0.0     0.000008 -0.000038   4857.611328   \n",
       "399        NaN          NaN          NaN       NaN           NaN   \n",
       "402   1.606110          0.0     0.000000 -0.005633      1.180957   \n",
       "403   0.000169          0.0     0.000014  0.000093   5906.451660   \n",
       "404   0.000236          0.0     0.000020 -0.000279   4231.559082   \n",
       "405   0.000179          0.0     0.000015 -0.000108   5592.225098   \n",
       "408   0.000283          0.0     0.000015 -0.000274   3538.546143   \n",
       "409        NaN          NaN          NaN       NaN           NaN   \n",
       "410        NaN          NaN          NaN       NaN           NaN   \n",
       "412   0.000231          0.0     0.000008 -0.000219   4330.169434   \n",
       "413        NaN          NaN          NaN       NaN           NaN   \n",
       "416   1.581951          0.0     0.000000 -0.004024      1.185189   \n",
       "417   0.000168          0.0     0.000015  0.000122   5944.042480   \n",
       "418   0.000251          0.0     0.000019 -0.000218   3983.347656   \n",
       "419   0.000181          0.0     0.000015  0.000154   5526.204590   \n",
       "422   0.000253          0.0     0.000010 -0.000117   3956.901123   \n",
       "423        NaN          NaN          NaN       NaN           NaN   \n",
       "424        NaN          NaN          NaN       NaN           NaN   \n",
       "426   0.000202          0.0     0.000007 -0.000026   4940.950195   \n",
       "427        NaN          NaN          NaN       NaN           NaN   \n",
       "430   1.596790          0.0     0.000000 -0.004181      1.182130   \n",
       "431   0.000168          0.0     0.000015  0.000165   5960.023926   \n",
       "432   0.000249          0.0     0.000022 -0.000019   4017.274170   \n",
       "433   0.000186          0.0     0.000019  0.000165   5377.061523   \n",
       "436   0.000279          0.0     0.000011 -0.000494   3581.117920   \n",
       "437        NaN          NaN          NaN       NaN           NaN   \n",
       "438        NaN          NaN          NaN       NaN           NaN   \n",
       "440   0.000217          0.0     0.000007 -0.000026   4605.354980   \n",
       "441        NaN          NaN          NaN       NaN           NaN   \n",
       "444   1.612207          0.0     0.000000 -0.001719      1.177651   \n",
       "445   0.000179          0.0     0.000016 -0.000102   5599.109375   \n",
       "446   0.000255          0.0     0.000020  0.000059   3916.353027   \n",
       "447   0.000196          0.0     0.000016  0.000302   5110.338867   \n",
       "450   0.000273          0.0     0.000017 -0.000373   3669.161621   \n",
       "451        NaN          NaN          NaN       NaN           NaN   \n",
       "452        NaN          NaN          NaN       NaN           NaN   \n",
       "454   0.000215          0.0     0.000007  0.000098   4659.674805   \n",
       "455        NaN          NaN          NaN       NaN           NaN   \n",
       "458   1.526009          0.0     0.000000 -0.005242      1.198452   \n",
       "459   0.000184          0.0     0.000016  0.000011   5436.865234   \n",
       "460   0.000218          0.0     0.000018  0.001086   4580.493652   \n",
       "461   0.000191          0.0     0.000016  0.000004   5243.312988   \n",
       "464   0.000306          0.0     0.000019  0.000208   3267.165771   \n",
       "465        NaN          NaN          NaN       NaN           NaN   \n",
       "466        NaN          NaN          NaN       NaN           NaN   \n",
       "468   0.000221          0.0     0.000008  0.000341   4525.841797   \n",
       "469        NaN          NaN          NaN       NaN           NaN   \n",
       "472   1.567166          0.0     0.000000 -0.002095      1.187365   \n",
       "473   0.000177          0.0     0.000015  0.000255   5643.998047   \n",
       "474   0.000227          0.0     0.000021  0.001027   4397.247070   \n",
       "475   0.000190          0.0     0.000016 -0.000103   5276.226562   \n",
       "478   0.000359          0.0     0.000017  0.000319   2781.955566   \n",
       "479        NaN          NaN          NaN       NaN           NaN   \n",
       "480        NaN          NaN          NaN       NaN           NaN   \n",
       "482   0.000225          0.0     0.000009 -0.000041   4453.137695   \n",
       "483        NaN          NaN          NaN       NaN           NaN   \n",
       "486   1.577191          0.0     0.000000 -0.002269      1.185274   \n",
       "487   0.000187          0.0     0.000018 -0.000021   5342.787109   \n",
       "488   0.000227          0.0     0.000019  0.001031   4403.949219   \n",
       "489   0.000206          0.0     0.000020  0.000306   4843.177246   \n",
       "492   0.000315          0.0     0.000016 -0.000188   3178.268555   \n",
       "493        NaN          NaN          NaN       NaN           NaN   \n",
       "494        NaN          NaN          NaN       NaN           NaN   \n",
       "496   0.000228          0.0     0.000007  0.000045   4390.492676   \n",
       "497        NaN          NaN          NaN       NaN           NaN   \n",
       "500   1.539274          0.0     0.000000 -0.000600      1.192828   \n",
       "501   0.000179          0.0     0.000016  0.000181   5594.271973   \n",
       "502   0.000217          0.0     0.000016  0.000470   4599.465820   \n",
       "503   0.000194          0.0     0.000015  0.000217   5163.011719   \n",
       "506   0.000255          0.0     0.000013  0.000838   3920.489258   \n",
       "507        NaN          NaN          NaN       NaN           NaN   \n",
       "508        NaN          NaN          NaN       NaN           NaN   \n",
       "510   0.000183          0.0     0.000006  0.000268   5457.231934   \n",
       "511        NaN          NaN          NaN       NaN           NaN   \n",
       "514   1.590587          0.0     0.000000  0.000968      1.180704   \n",
       "515   0.000175          0.0     0.000015 -0.000129   5720.882324   \n",
       "516   0.000226          0.0     0.000019  0.000818   4427.772461   \n",
       "517   0.000189          0.0     0.000015  0.000551   5287.452148   \n",
       "520   0.000295          0.0     0.000012 -0.000145   3394.116699   \n",
       "521        NaN          NaN          NaN       NaN           NaN   \n",
       "522        NaN          NaN          NaN       NaN           NaN   \n",
       "524   0.000206          0.0     0.000010  0.000039   4843.945312   \n",
       "525        NaN          NaN          NaN       NaN           NaN   \n",
       "528   1.574988          0.0     0.000000  0.002056      1.183439   \n",
       "529   0.000183          0.0     0.000018 -0.000085   5452.493652   \n",
       "530   0.000220          0.0     0.000018  0.000412   4543.137207   \n",
       "531   0.000199          0.0     0.000018  0.000385   5033.905762   \n",
       "534   0.000318          0.0     0.000018 -0.000653   3143.308838   \n",
       "535        NaN          NaN          NaN       NaN           NaN   \n",
       "536        NaN          NaN          NaN       NaN           NaN   \n",
       "538   0.000216          0.0     0.000007 -0.000375   4633.912598   \n",
       "539        NaN          NaN          NaN       NaN           NaN   \n",
       "542   1.654358          0.0     0.000000  0.001574      1.167676   \n",
       "543   0.000183          0.0     0.000018 -0.000362   5470.748535   \n",
       "544   0.000221          0.0     0.000019  0.001321   4532.237793   \n",
       "545   0.000204          0.0     0.000019 -0.000232   4906.063965   \n",
       "548   0.000269          0.0     0.000013 -0.000706   3710.853271   \n",
       "549        NaN          NaN          NaN       NaN           NaN   \n",
       "550        NaN          NaN          NaN       NaN           NaN   \n",
       "552   0.000169          0.0     0.000006 -0.000089   5917.318359   \n",
       "553        NaN          NaN          NaN       NaN           NaN   \n",
       "556   1.610060          0.0     0.000000  0.003676      1.175244   \n",
       "557   0.000177          0.0     0.000019  0.000333   5660.828613   \n",
       "558   0.000211          0.0     0.000015  0.000725   4733.252930   \n",
       "559   0.000194          0.0     0.000016  0.000079   5160.271973   \n",
       "562   0.000307          0.0     0.000014 -0.000041   3259.811279   \n",
       "563        NaN          NaN          NaN       NaN           NaN   \n",
       "564        NaN          NaN          NaN       NaN           NaN   \n",
       "566   0.000239          0.0     0.000008 -0.000171   4186.609863   \n",
       "567        NaN          NaN          NaN       NaN           NaN   \n",
       "570   1.585925          0.0     0.000000  0.005806      1.179102   \n",
       "571   0.000182          0.0     0.000018 -0.000151   5490.496582   \n",
       "572   0.000204          0.0     0.000018  0.001144   4896.206055   \n",
       "573   0.000202          0.0     0.000017  0.000310   4949.143555   \n",
       "576   0.000316          0.0     0.000016 -0.000069   3169.015137   \n",
       "577        NaN          NaN          NaN       NaN           NaN   \n",
       "578        NaN          NaN          NaN       NaN           NaN   \n",
       "580   0.000198          0.0     0.000007 -0.000224   5050.350586   \n",
       "581        NaN          NaN          NaN       NaN           NaN   \n",
       "584   1.513977          0.0     0.000000  0.005035      1.195682   \n",
       "585   0.000181          0.0     0.000017  0.000071   5516.079102   \n",
       "586   0.000207          0.0     0.000016  0.001009   4834.063965   \n",
       "587   0.000192          0.0     0.000015 -0.000491   5218.874512   \n",
       "590   0.000290          0.0     0.000013 -0.000227   3446.206055   \n",
       "591        NaN          NaN          NaN       NaN           NaN   \n",
       "592        NaN          NaN          NaN       NaN           NaN   \n",
       "594   0.000211          0.0     0.000008  0.000167   4739.313965   \n",
       "595        NaN          NaN          NaN       NaN           NaN   \n",
       "598   1.547796          0.0     0.000000  0.004208      1.188272   \n",
       "599   0.000194          0.0     0.000019 -0.000003   5154.535156   \n",
       "600   0.000213          0.0     0.000019  0.000669   4689.913574   \n",
       "601   0.000195          0.0     0.000017  0.000061   5136.518555   \n",
       "604   0.000328          0.0     0.000018  0.000319   3047.230957   \n",
       "605        NaN          NaN          NaN       NaN           NaN   \n",
       "606        NaN          NaN          NaN       NaN           NaN   \n",
       "608   0.000216          0.0     0.000007 -0.000178   4637.071777   \n",
       "609        NaN          NaN          NaN       NaN           NaN   \n",
       "612   1.565086          0.0     0.000000  0.004665      1.184185   \n",
       "613   0.000187          0.0     0.000018  0.000238   5337.457031   \n",
       "614   0.000220          0.0     0.000018  0.000642   4546.562500   \n",
       "615   0.000184          0.0     0.000015 -0.000131   5425.952637   \n",
       "618   0.000294          0.0     0.000009  0.000564   3404.636230   \n",
       "619        NaN          NaN          NaN       NaN           NaN   \n",
       "620        NaN          NaN          NaN       NaN           NaN   \n",
       "622   0.000221          0.0     0.000009 -0.000222   4514.926270   \n",
       "623        NaN          NaN          NaN       NaN           NaN   \n",
       "626   1.585824          0.0     0.000000  0.006671      1.178657   \n",
       "627   0.000185          0.0     0.000017  0.000258   5407.433105   \n",
       "628   0.000227          0.0     0.000019  0.000764   4406.362305   \n",
       "629   0.000194          0.0     0.000016  0.000052   5163.373047   \n",
       "632   0.000282          0.0     0.000016 -0.000565   3547.221436   \n",
       "633        NaN          NaN          NaN       NaN           NaN   \n",
       "634        NaN          NaN          NaN       NaN           NaN   \n",
       "636   0.000210          0.0     0.000009  0.000150   4764.863770   \n",
       "637        NaN          NaN          NaN       NaN           NaN   \n",
       "640   1.566696          0.0     0.000000  0.005187      1.183551   \n",
       "641   0.000182          0.0     0.000018  0.000087   5485.193359   \n",
       "642   0.000209          0.0     0.000018  0.000672   4796.124023   \n",
       "643   0.000189          0.0     0.000017 -0.000362   5291.922852   \n",
       "646   0.000365          0.0     0.000016  0.000839   2736.980469   \n",
       "647        NaN          NaN          NaN       NaN           NaN   \n",
       "648        NaN          NaN          NaN       NaN           NaN   \n",
       "650   0.000197          0.0     0.000007  0.000233   5071.715332   \n",
       "651        NaN          NaN          NaN       NaN           NaN   \n",
       "654   1.575231          0.0     0.000000  0.003836      1.182441   \n",
       "655   0.000162          0.0     0.000020 -0.000156   6160.037109   \n",
       "656   0.000206          0.0     0.000016  0.000830   4849.319824   \n",
       "657   0.000172          0.0     0.000016  0.000049   5815.816895   \n",
       "660   0.000342          0.0     0.000022 -0.000720   2921.314209   \n",
       "661        NaN          NaN          NaN       NaN           NaN   \n",
       "662        NaN          NaN          NaN       NaN           NaN   \n",
       "664   0.000179          0.0     0.000008 -0.000198   5575.669922   \n",
       "665        NaN          NaN          NaN       NaN           NaN   \n",
       "668   1.605569          0.0     0.000000  0.006847      1.174486   \n",
       "669   0.000157          0.0     0.000017 -0.000014   6359.155762   \n",
       "670   0.000210          0.0     0.000016  0.000960   4760.429199   \n",
       "671   0.000172          0.0     0.000016  0.000481   5829.967285   \n",
       "674   0.000243          0.0     0.000013 -0.000421   4122.324707   \n",
       "675        NaN          NaN          NaN       NaN           NaN   \n",
       "676        NaN          NaN          NaN       NaN           NaN   \n",
       "678   0.000157          0.0     0.000008  0.000134   6384.629395   \n",
       "679        NaN          NaN          NaN       NaN           NaN   \n",
       "682   1.672143          0.0     0.000000  0.005707      1.162253   \n",
       "683   0.000158          0.0     0.000017  0.000404   6309.149414   \n",
       "684   0.000206          0.0     0.000015  0.000945   4851.342773   \n",
       "685   0.000173          0.0     0.000015 -0.000348   5797.069336   \n",
       "688   0.000250          0.0     0.000012 -0.000336   3995.715332   \n",
       "689        NaN          NaN          NaN       NaN           NaN   \n",
       "690        NaN          NaN          NaN       NaN           NaN   \n",
       "692   0.000160          0.0     0.000007 -0.000193   6239.751465   \n",
       "693        NaN          NaN          NaN       NaN           NaN   \n",
       "696   1.639772          0.0     0.000000  0.004127      1.169132   \n",
       "697   0.000161          0.0     0.000020 -0.000066   6208.724121   \n",
       "698   0.000208          0.0     0.000017  0.001389   4807.561523   \n",
       "699   0.000171          0.0     0.000015  0.000183   5838.445801   \n",
       "702   0.000323          0.0     0.000015  0.000347   3096.222656   \n",
       "703        NaN          NaN          NaN       NaN           NaN   \n",
       "704        NaN          NaN          NaN       NaN           NaN   \n",
       "706   0.000216          0.0     0.000008  0.000242   4623.895508   \n",
       "707        NaN          NaN          NaN       NaN           NaN   \n",
       "710   1.663002          0.0     0.000000  0.004823      1.164390   \n",
       "711   0.000155          0.0     0.000018 -0.000029   6463.541016   \n",
       "712   0.000217          0.0     0.000015  0.001002   4617.626465   \n",
       "713   0.000165          0.0     0.000014  0.000040   6059.179688   \n",
       "716   0.000327          0.0     0.000011  0.000039   3053.559326   \n",
       "717        NaN          NaN          NaN       NaN           NaN   \n",
       "718        NaN          NaN          NaN       NaN           NaN   \n",
       "720   0.000184          0.0     0.000009 -0.000412   5434.315918   \n",
       "721        NaN          NaN          NaN       NaN           NaN   \n",
       "724   1.621016          0.0     0.000000  0.007234      1.171178   \n",
       "725   0.000165          0.0     0.000019  0.000159   6056.332031   \n",
       "726   0.000211          0.0     0.000015  0.000667   4733.549805   \n",
       "727   0.000161          0.0     0.000015 -0.000285   6198.667480   \n",
       "730   0.000266          0.0     0.000015 -0.000055   3758.656006   \n",
       "731        NaN          NaN          NaN       NaN           NaN   \n",
       "732        NaN          NaN          NaN       NaN           NaN   \n",
       "734   0.000191          0.0     0.000007 -0.000404   5248.449219   \n",
       "735        NaN          NaN          NaN       NaN           NaN   \n",
       "738   1.722575          0.0     0.000000  0.002225      1.155191   \n",
       "739   0.000167          0.0     0.000019 -0.000120   5980.081055   \n",
       "740   0.000222          0.0     0.000016  0.000416   4502.488770   \n",
       "741   0.000164          0.0     0.000018 -0.000301   6079.592773   \n",
       "744   0.000273          0.0     0.000016  0.000570   3657.064453   \n",
       "745        NaN          NaN          NaN       NaN           NaN   \n",
       "746        NaN          NaN          NaN       NaN           NaN   \n",
       "748   0.000205          0.0     0.000009  0.000273   4887.658691   \n",
       "749        NaN          NaN          NaN       NaN           NaN   \n",
       "752   1.653020          0.0     0.000000  0.004597      1.166367   \n",
       "753   0.000163          0.0     0.000017 -0.000031   6116.853027   \n",
       "754   0.000215          0.0     0.000016 -0.000125   4647.899414   \n",
       "755   0.000163          0.0     0.000015  0.000285   6143.980957   \n",
       "758   0.000240          0.0     0.000013 -0.000439   4170.007812   \n",
       "759        NaN          NaN          NaN       NaN           NaN   \n",
       "760        NaN          NaN          NaN       NaN           NaN   \n",
       "762   0.000149          0.0     0.000009  0.000376   6716.402344   \n",
       "763        NaN          NaN          NaN       NaN           NaN   \n",
       "766   1.774155          0.0     0.000000  0.002703      1.146590   \n",
       "767   0.000169          0.0     0.000018  0.000364   5928.488281   \n",
       "768   0.000213          0.0     0.000015  0.000512   4685.849609   \n",
       "769   0.000159          0.0     0.000012  0.000099   6308.760254   \n",
       "772   0.000262          0.0     0.000015  0.000207   3817.223877   \n",
       "773        NaN          NaN          NaN       NaN           NaN   \n",
       "774        NaN          NaN          NaN       NaN           NaN   \n",
       "776   0.000139          0.0     0.000009  0.000137   7214.228027   \n",
       "777        NaN          NaN          NaN       NaN           NaN   \n",
       "780   1.777332          0.0     0.000000  0.005028      1.144950   \n",
       "781   0.000167          0.0     0.000018  0.000184   5988.484863   \n",
       "782   0.000219          0.0     0.000014  0.000713   4556.131348   \n",
       "783   0.000157          0.0     0.000012  0.000079   6366.280273   \n",
       "786   0.000259          0.0     0.000009 -0.000221   3855.910156   \n",
       "787        NaN          NaN          NaN       NaN           NaN   \n",
       "788        NaN          NaN          NaN       NaN           NaN   \n",
       "790   0.000170          0.0     0.000009 -0.000190   5878.126953   \n",
       "791        NaN          NaN          NaN       NaN           NaN   \n",
       "794   1.729627          0.0     0.000000  0.003875      1.153161   \n",
       "795   0.000177          0.0     0.000017 -0.000533   5640.184570   \n",
       "796   0.000231          0.0     0.000014 -0.000150   4331.990234   \n",
       "797   0.000163          0.0     0.000012 -0.000221   6120.513184   \n",
       "800   0.000260          0.0     0.000012 -0.000181   3851.665283   \n",
       "801        NaN          NaN          NaN       NaN           NaN   \n",
       "802        NaN          NaN          NaN       NaN           NaN   \n",
       "804   0.000174          0.0     0.000007  0.000243   5755.760742   \n",
       "805        NaN          NaN          NaN       NaN           NaN   \n",
       "808   1.630199          0.0     0.000000 -0.000962      1.173660   \n",
       "809   0.000188          0.0     0.000016 -0.000118   5305.550781   \n",
       "810   0.000235          0.0     0.000014 -0.000051   4246.416016   \n",
       "811   0.000181          0.0     0.000013 -0.000062   5514.793457   \n",
       "814   0.000219          0.0     0.000006  0.000020   4563.813477   \n",
       "815        NaN          NaN          NaN       NaN           NaN   \n",
       "816        NaN          NaN          NaN       NaN           NaN   \n",
       "818   0.000169          0.0     0.000010  0.000336   5913.041504   \n",
       "819        NaN          NaN          NaN       NaN           NaN   \n",
       "822   1.376727          0.0     0.000000  0.001173      1.235276   \n",
       "823   0.000201          0.0     0.000018 -0.000144   4964.314941   \n",
       "824   0.000263          0.0     0.000015 -0.000200   3795.928711   \n",
       "825   0.000204          0.0     0.000015  0.000156   4901.025879   \n",
       "828   0.000293          0.0     0.000011 -0.000025   3414.929932   \n",
       "829        NaN          NaN          NaN       NaN           NaN   \n",
       "830        NaN          NaN          NaN       NaN           NaN   \n",
       "832   0.000179          0.0     0.000008  0.000515   5572.338867   \n",
       "833        NaN          NaN          NaN       NaN           NaN   \n",
       "836   0.991940          0.0     0.000000 -0.002488      1.421778   \n",
       "837   0.000228          0.0     0.000027 -0.000164   4389.493652   \n",
       "838   0.000254          0.0     0.000015  0.000134   3944.684326   \n",
       "839   0.000228          0.0     0.000016  0.000219   4386.286621   \n",
       "842   0.000255          0.0     0.000010 -0.000478   3920.126709   \n",
       "843        NaN          NaN          NaN       NaN           NaN   \n",
       "844        NaN          NaN          NaN       NaN           NaN   \n",
       "846   0.000218          0.0     0.000015 -0.000156   4588.641113   \n",
       "847        NaN          NaN          NaN       NaN           NaN   \n",
       "\n",
       "     mean_rel_diff  max_rel_diff   pearson  max_abs_diff  mean_abs_diff  \\\n",
       "1     83933.062500  6.245747e+11  0.000037    448.040527      23.491154   \n",
       "2     94711.351562  1.379779e+12 -0.000128    448.040039       6.796145   \n",
       "3    144081.312500  6.944284e+11 -0.000017    448.027222      35.005745   \n",
       "6     27890.207031  5.200393e+09 -0.000717    448.052734      47.079998   \n",
       "7              NaN           NaN       NaN           NaN            NaN   \n",
       "8              NaN           NaN       NaN           NaN            NaN   \n",
       "10   108942.070312  8.457782e+10  0.000173    448.038086      68.106529   \n",
       "11             NaN           NaN       NaN           NaN            NaN   \n",
       "13    92496.351562  2.210074e+11 -0.000085    448.031982      15.785647   \n",
       "14    80385.343750  1.901858e+11 -0.002561    448.058594       5.853664   \n",
       "15   175742.328125  9.296684e+11  0.000031    448.016846      19.753969   \n",
       "18    40850.437500  1.004120e+10  0.000140    448.053955      38.335239   \n",
       "19             NaN           NaN       NaN           NaN            NaN   \n",
       "20             NaN           NaN       NaN           NaN            NaN   \n",
       "22   125684.679688  5.753258e+10 -0.000554    448.036865      36.667000   \n",
       "23             NaN           NaN       NaN           NaN            NaN   \n",
       "25    84006.882812  5.088649e+11 -0.000120    448.042480      12.308104   \n",
       "26    78158.953125  1.039538e+12 -0.000187    448.207031       4.621072   \n",
       "27   136232.515625  9.815383e+11 -0.000124    448.032227      15.789912   \n",
       "30    48838.906250  6.926057e+10 -0.001011    448.072754      30.269457   \n",
       "31             NaN           NaN       NaN           NaN            NaN   \n",
       "32             NaN           NaN       NaN           NaN            NaN   \n",
       "34   142250.140625  5.695312e+11 -0.000291    448.025635      41.066807   \n",
       "35             NaN           NaN       NaN           NaN            NaN   \n",
       "38       13.248475  1.562718e+06 -0.003391      0.277832       0.025607   \n",
       "39   111086.609375  1.099512e+11  0.000154    448.027954      45.915237   \n",
       "40   106107.656250  4.311810e+10  0.007698    448.034912      40.476818   \n",
       "41   188024.328125  2.638828e+11  0.000455    448.029175      72.166595   \n",
       "44    44838.820312  1.610613e+10 -0.000964    448.102539      47.355137   \n",
       "45             NaN           NaN       NaN           NaN            NaN   \n",
       "46             NaN           NaN       NaN           NaN            NaN   \n",
       "48    76040.718750  1.019415e+11 -0.000191    448.040527      49.336349   \n",
       "49             NaN           NaN       NaN           NaN            NaN   \n",
       "52       10.403044  2.972342e+06 -0.005655      0.514404       0.032241   \n",
       "53   104473.632812  2.286984e+11  0.000191    448.034668      48.497044   \n",
       "54    41904.957031  1.778622e+10 -0.002561    448.047607      35.467117   \n",
       "55   123050.289062  9.657872e+10 -0.000021    448.027832      68.796997   \n",
       "58   103584.546875  2.521173e+11  0.000142    448.075684      54.851147   \n",
       "59             NaN           NaN       NaN           NaN            NaN   \n",
       "60             NaN           NaN       NaN           NaN            NaN   \n",
       "62   128580.859375  2.133381e+11  0.000736    448.054688      66.160744   \n",
       "63             NaN           NaN       NaN           NaN            NaN   \n",
       "66       10.279372  1.655645e+06  0.002850      0.581055       0.038961   \n",
       "67    83325.734375  9.926146e+10  0.000072    448.026367      49.998989   \n",
       "68    59396.566406  1.157381e+11  0.007958    448.050293      35.807480   \n",
       "69   122963.664062  2.057566e+11 -0.000720    448.029419      64.861771   \n",
       "72    26617.050781  6.568774e+09  0.000556    448.097168      42.111485   \n",
       "73             NaN           NaN       NaN           NaN            NaN   \n",
       "74             NaN           NaN       NaN           NaN            NaN   \n",
       "76    78665.507812  9.458165e+10  0.000123    448.049316      60.950573   \n",
       "77             NaN           NaN       NaN           NaN            NaN   \n",
       "80       11.150939  1.377131e+06  0.001637      0.675049       0.042596   \n",
       "81    68780.289062  1.816374e+10  0.000040    448.034180      51.997993   \n",
       "82    42008.457031  7.996448e+10  0.006893    448.094727      34.640247   \n",
       "83    96643.554688  1.178048e+11 -0.000596    448.040527      63.304726   \n",
       "86    56666.421875  6.972513e+10  0.000162    448.085449      58.334003   \n",
       "87             NaN           NaN       NaN           NaN            NaN   \n",
       "88             NaN           NaN       NaN           NaN            NaN   \n",
       "90   106324.718750  2.278781e+11  0.000410    448.031982      61.963135   \n",
       "91             NaN           NaN       NaN           NaN            NaN   \n",
       "94        8.175681  5.932172e+05 -0.000211      0.621704       0.049081   \n",
       "95    86767.773438  1.824075e+11  0.000423    448.025879      53.748817   \n",
       "96    33285.167969  2.114446e+10  0.002571    448.061279      34.820297   \n",
       "97    90334.429688  1.449906e+11  0.000060    448.033447      58.566914   \n",
       "100   28647.994141  2.987803e+09 -0.001061    448.128906      54.644348   \n",
       "101            NaN           NaN       NaN           NaN            NaN   \n",
       "102            NaN           NaN       NaN           NaN            NaN   \n",
       "104   76815.914062  1.077953e+11 -0.000106    448.043213      65.227463   \n",
       "105            NaN           NaN       NaN           NaN            NaN   \n",
       "108       7.747681  6.337558e+05 -0.002351      0.675293       0.048485   \n",
       "109   72496.890625  1.360221e+11  0.000129    448.045654      43.508984   \n",
       "110   33780.730469  2.987803e+10  0.002126    448.072754      35.894470   \n",
       "111  326736.812500  2.645441e+12 -0.000741    448.039551      56.034348   \n",
       "114   31014.486328  6.921386e+09  0.001199    448.079590      53.058487   \n",
       "115            NaN           NaN       NaN           NaN            NaN   \n",
       "116            NaN           NaN       NaN           NaN            NaN   \n",
       "118   61390.054688  2.863311e+10  0.000191    448.050293      62.451614   \n",
       "119            NaN           NaN       NaN           NaN            NaN   \n",
       "122       9.150343  1.513408e+06 -0.000224      0.627930       0.047580   \n",
       "123   94325.835938  3.845286e+11  0.000436    448.035645      47.616280   \n",
       "124   36657.710938  3.642960e+10  0.001561    448.090332      33.766823   \n",
       "125   74949.867188  1.022802e+11  0.000223    448.033447      50.510826   \n",
       "128   38092.027344  1.365288e+10  0.000201    448.082031      61.989113   \n",
       "129            NaN           NaN       NaN           NaN            NaN   \n",
       "130            NaN           NaN       NaN           NaN            NaN   \n",
       "132  113839.148438  2.542223e+11 -0.000428    448.040527      75.271484   \n",
       "133            NaN           NaN       NaN           NaN            NaN   \n",
       "136       9.255237  5.682615e+05 -0.004296      0.527039       0.048087   \n",
       "137   75546.671875  1.027581e+11  0.000112    448.046387      51.127525   \n",
       "138   46266.199219  6.871948e+10 -0.000219    448.088867      32.213394   \n",
       "139   71460.921875  3.248557e+10 -0.000002    448.050537      50.749287   \n",
       "142   33626.273438  9.111975e+09  0.000038    448.125000      59.024380   \n",
       "143            NaN           NaN       NaN           NaN            NaN   \n",
       "144            NaN           NaN       NaN           NaN            NaN   \n",
       "146   98738.742188  8.084645e+10  0.000364    448.048828      75.587151   \n",
       "147            NaN           NaN       NaN           NaN            NaN   \n",
       "150      11.144596  1.712673e+06 -0.002518      0.501953       0.049011   \n",
       "151   87873.343750  1.917753e+11  0.000031    448.042480      47.950573   \n",
       "152   36411.246094  2.824088e+10 -0.000053    448.088379      32.682415   \n",
       "153   81376.351562  1.268667e+11 -0.000152    448.038330      48.853081   \n",
       "156   37852.476562  1.453681e+10 -0.000145    448.090820      70.807175   \n",
       "157            NaN           NaN       NaN           NaN            NaN   \n",
       "158            NaN           NaN       NaN           NaN            NaN   \n",
       "160   64734.238281  4.780485e+10 -0.000089    448.048096      70.225998   \n",
       "161            NaN           NaN       NaN           NaN            NaN   \n",
       "164      14.124280  1.053342e+07 -0.001786      0.590820       0.047986   \n",
       "165   67611.867188  2.224445e+10  0.000285    448.050049      50.335476   \n",
       "166   44485.601562  1.963414e+10 -0.001710    448.085449      34.325626   \n",
       "167   63613.476562  1.636178e+10  0.000034    448.053955      48.593182   \n",
       "170   33560.445312  4.805558e+09  0.000435    448.106934      65.864243   \n",
       "171            NaN           NaN       NaN           NaN            NaN   \n",
       "172            NaN           NaN       NaN           NaN            NaN   \n",
       "174   78593.039062  6.299286e+10 -0.000233    448.057373      68.812584   \n",
       "175            NaN           NaN       NaN           NaN            NaN   \n",
       "178      10.097334  1.601146e+06 -0.002914      0.601654       0.048259   \n",
       "179   72545.148438  5.429687e+10  0.000095    448.048340      48.868233   \n",
       "180   50679.742188  5.961208e+10 -0.002057    448.101074      31.786739   \n",
       "181  137100.203125  4.317101e+11 -0.000086    448.041748      47.781593   \n",
       "184   35885.093750  9.554579e+09  0.000074    448.188477      68.483772   \n",
       "185            NaN           NaN       NaN           NaN            NaN   \n",
       "186            NaN           NaN       NaN           NaN            NaN   \n",
       "188   56591.507812  1.502065e+10 -0.000043    448.063477      68.983444   \n",
       "189            NaN           NaN       NaN           NaN            NaN   \n",
       "192       7.492600  5.786942e+05 -0.003380      0.562012       0.047714   \n",
       "193  103942.492188  4.773074e+11 -0.000267    448.169922      49.261894   \n",
       "194   60341.679688  2.532906e+11 -0.002155    448.087402      25.531776   \n",
       "195   87642.031250  3.227924e+11  0.000183    448.052979      46.309608   \n",
       "198   43932.089844  3.435974e+10  0.000144    448.087891      68.981293   \n",
       "199            NaN           NaN       NaN           NaN            NaN   \n",
       "200            NaN           NaN       NaN           NaN            NaN   \n",
       "202   56138.335938  3.546812e+10 -0.000231    448.065430      72.510666   \n",
       "203            NaN           NaN       NaN           NaN            NaN   \n",
       "206       7.658829  1.154136e+06 -0.003553      0.554688       0.047247   \n",
       "207   89205.640625  2.199023e+11  0.000324    448.041016      44.529606   \n",
       "208   34416.296875  4.678773e+10 -0.000968    448.074219      26.249416   \n",
       "209   68517.617188  4.006318e+10  0.000047    448.041016      44.436245   \n",
       "212   36770.828125  6.650272e+09  0.000258    448.105957      71.288094   \n",
       "213            NaN           NaN       NaN           NaN            NaN   \n",
       "214            NaN           NaN       NaN           NaN            NaN   \n",
       "216   57141.085938  5.961208e+10 -0.000266    448.062256      75.351212   \n",
       "217            NaN           NaN       NaN           NaN            NaN   \n",
       "220       7.540335  7.418769e+05 -0.006058      0.579712       0.046998   \n",
       "221   65712.617188  8.078044e+10  0.000297    448.046387      48.383396   \n",
       "222   38455.523438  4.754645e+10 -0.000996    448.109863      23.628176   \n",
       "223   68696.265625  1.691556e+11  0.000332    448.041992      44.068352   \n",
       "226  108091.843750  1.809323e+11 -0.000334    448.100586      69.130898   \n",
       "227            NaN           NaN       NaN           NaN            NaN   \n",
       "228            NaN           NaN       NaN           NaN            NaN   \n",
       "230   65696.726562  6.944284e+10 -0.000515    448.056396      78.484642   \n",
       "231            NaN           NaN       NaN           NaN            NaN   \n",
       "234       8.138981  2.219794e+06 -0.003558      0.552246       0.046564   \n",
       "235   83600.359375  4.386349e+10  0.000072    448.059570      48.018024   \n",
       "236   46348.429688  4.898814e+10 -0.001624    448.113281      31.664038   \n",
       "237   78606.656250  8.144531e+10  0.000359    448.051270      48.941292   \n",
       "240   32944.500000  6.170728e+09 -0.000256    448.080566      62.261913   \n",
       "241            NaN           NaN       NaN           NaN            NaN   \n",
       "242            NaN           NaN       NaN           NaN            NaN   \n",
       "244   52557.511719  1.832519e+10 -0.000042    448.070801      74.487129   \n",
       "245            NaN           NaN       NaN           NaN            NaN   \n",
       "248       7.086387  4.426945e+05 -0.004603      0.573975       0.045766   \n",
       "249   59994.035156  1.871509e+10  0.000224    448.047119      46.171185   \n",
       "250   41185.980469  3.646339e+10 -0.001710    448.090332      30.620880   \n",
       "251  114335.671875  3.021559e+11  0.000542    448.049561      47.354362   \n",
       "254   38760.339844  8.191726e+09  0.000758    448.072754      68.218445   \n",
       "255            NaN           NaN       NaN           NaN            NaN   \n",
       "256            NaN           NaN       NaN           NaN            NaN   \n",
       "258  182631.156250  1.122905e+12  0.000164    448.060791      79.014297   \n",
       "259            NaN           NaN       NaN           NaN            NaN   \n",
       "262       8.630249  3.332972e+06 -0.004641      0.630844       0.045444   \n",
       "263   60915.753906  5.286114e+10 -0.000071    448.048340      44.023239   \n",
       "264   37515.609375  1.784921e+10 -0.001425    448.105469      32.712452   \n",
       "265   69824.281250  8.457782e+10 -0.000435    448.075195      45.274456   \n",
       "268   32920.160156  5.245762e+09  0.000148    448.094727      70.256126   \n",
       "269            NaN           NaN       NaN           NaN            NaN   \n",
       "270            NaN           NaN       NaN           NaN            NaN   \n",
       "272  113385.765625  4.429687e+11 -0.000265    448.061768      80.569618   \n",
       "273            NaN           NaN       NaN           NaN            NaN   \n",
       "276       8.309877  2.365393e+06 -0.004085      0.880859       0.045063   \n",
       "277   65615.882812  5.216661e+10 -0.000049    448.055664      47.841057   \n",
       "278   45011.886719  4.302437e+10 -0.001543    448.081055      35.923420   \n",
       "279   70258.507812  1.499334e+11  0.000041    448.055664      48.812527   \n",
       "282   55398.613281  5.662721e+10 -0.000930    448.102539      69.423103   \n",
       "283            NaN           NaN       NaN           NaN            NaN   \n",
       "284            NaN           NaN       NaN           NaN            NaN   \n",
       "286  118446.406250  4.123169e+11 -0.000270    448.054443      83.965500   \n",
       "287            NaN           NaN       NaN           NaN            NaN   \n",
       "290       7.579942  1.231282e+06 -0.004667      0.709900       0.043607   \n",
       "291   94233.632812  2.393495e+11 -0.000056    448.042480      49.313259   \n",
       "292   42319.062500  3.276690e+10 -0.001270    448.080078      40.509304   \n",
       "293   59840.785156  1.381296e+10 -0.000012    448.048340      49.617111   \n",
       "296   35816.812500  6.343336e+09 -0.000238    448.077148      67.374046   \n",
       "297            NaN           NaN       NaN           NaN            NaN   \n",
       "298            NaN           NaN       NaN           NaN            NaN   \n",
       "300  110719.929688  5.929950e+11  0.000236    448.061279      82.983955   \n",
       "301            NaN           NaN       NaN           NaN            NaN   \n",
       "304       6.799035  1.167164e+06 -0.005638      0.651154       0.043359   \n",
       "305   60454.804688  3.214946e+10  0.000548    448.050781      45.218090   \n",
       "306  154464.421875  1.599290e+12 -0.000112    448.083496      40.729774   \n",
       "307   54421.101562  1.906668e+10  0.000020    448.040283      46.840004   \n",
       "310   28110.822266  3.435974e+09  0.000014    448.089355      65.355232   \n",
       "311            NaN           NaN       NaN           NaN            NaN   \n",
       "312            NaN           NaN       NaN           NaN            NaN   \n",
       "314   73483.367188  1.951796e+11 -0.000070    448.059570      83.454048   \n",
       "315            NaN           NaN       NaN           NaN            NaN   \n",
       "318       6.806275  9.437174e+05 -0.005457      0.676025       0.042139   \n",
       "319   53237.601562  1.812382e+10  0.000154    448.056885      46.886604   \n",
       "320   51236.792969  1.124501e+11  0.000064    448.072754      42.024529   \n",
       "321   56260.359375  2.159755e+10 -0.000244    448.051270      45.346439   \n",
       "324   40893.218750  1.385939e+10  0.000189    448.090820      67.768341   \n",
       "325            NaN           NaN       NaN           NaN            NaN   \n",
       "326            NaN           NaN       NaN           NaN            NaN   \n",
       "328  101440.617188  4.143087e+11 -0.000013    448.081055      84.165985   \n",
       "329            NaN           NaN       NaN           NaN            NaN   \n",
       "332       6.967912  2.037659e+06 -0.009121      0.783661       0.041236   \n",
       "333   70815.179688  1.963414e+11  0.000174    448.044189      48.983410   \n",
       "334   53367.753906  3.515880e+10 -0.000207    448.079590      40.885448   \n",
       "335   57816.910156  2.237378e+10 -0.000082    448.062988      43.369343   \n",
       "338   34240.996094  1.275805e+10  0.000569    448.092773      63.937683   \n",
       "339            NaN           NaN       NaN           NaN            NaN   \n",
       "340            NaN           NaN       NaN           NaN            NaN   \n",
       "342   47613.683594  1.869918e+10  0.000233    448.076172      83.853996   \n",
       "343            NaN           NaN       NaN           NaN            NaN   \n",
       "346       6.157388  8.881391e+05 -0.006102      0.707642       0.040536   \n",
       "347   66962.312500  7.186351e+10 -0.000034    448.048828      51.221184   \n",
       "348   50413.109375  1.537778e+11  0.000061    448.066406      37.953381   \n",
       "349   59902.082031  2.411210e+10  0.000060    448.041992      43.627922   \n",
       "352   26756.935547  2.177730e+09 -0.000941    448.085449      60.438431   \n",
       "353            NaN           NaN       NaN           NaN            NaN   \n",
       "354            NaN           NaN       NaN           NaN            NaN   \n",
       "356   73109.187500  2.407690e+11  0.000214    448.098633      83.337296   \n",
       "357            NaN           NaN       NaN           NaN            NaN   \n",
       "360      28.079277  3.535601e+07 -0.005763      0.514099       0.040127   \n",
       "361   71131.429688  1.434146e+11  0.000214    448.053711      51.775349   \n",
       "362   46579.980469  6.077703e+10 -0.000415    448.072266      39.595421   \n",
       "363   53408.792969  3.133323e+10 -0.000302    448.043457      45.956284   \n",
       "366   38679.003906  2.466853e+10  0.000985    448.123047      64.604950   \n",
       "367            NaN           NaN       NaN           NaN            NaN   \n",
       "368            NaN           NaN       NaN           NaN            NaN   \n",
       "370   79836.742188  2.945120e+11 -0.000011    448.061768      82.751930   \n",
       "371            NaN           NaN       NaN           NaN            NaN   \n",
       "374       7.955982  2.352456e+06 -0.008811      0.592773       0.039701   \n",
       "375   81858.500000  8.457782e+10  0.000011    448.039062      56.084431   \n",
       "376   55310.933594  9.407586e+10 -0.000360    448.057617      42.273369   \n",
       "377   61047.878906  5.590737e+10 -0.000184    448.044922      48.959206   \n",
       "380   30653.859375  2.627510e+09 -0.000787    448.061279      59.762985   \n",
       "381            NaN           NaN       NaN           NaN            NaN   \n",
       "382            NaN           NaN       NaN           NaN            NaN   \n",
       "384   50730.894531  2.482768e+10  0.000261    448.082520      78.443085   \n",
       "385            NaN           NaN       NaN           NaN            NaN   \n",
       "388       6.859995  1.125183e+06 -0.006993      0.520508       0.039013   \n",
       "389   86174.664062  1.115447e+11  0.000260    448.049316      55.759281   \n",
       "390   38064.398438  1.182271e+10 -0.000692    448.062500      39.028008   \n",
       "391   55380.269531  4.228891e+10 -0.000280    448.041992      48.690922   \n",
       "394   30954.318359  2.614328e+09 -0.000186    448.137695      65.849876   \n",
       "395            NaN           NaN       NaN           NaN            NaN   \n",
       "396            NaN           NaN       NaN           NaN            NaN   \n",
       "398   62119.929688  5.023150e+10 -0.000038    448.077148      83.880600   \n",
       "399            NaN           NaN       NaN           NaN            NaN   \n",
       "402      10.829238  3.797211e+06 -0.005622      0.595947       0.038860   \n",
       "403   72467.890625  8.078044e+10  0.000093    448.052979      54.839592   \n",
       "404   39594.101562  8.371916e+09 -0.000283    448.049805      42.527416   \n",
       "405   69093.937500  8.365849e+10 -0.000108    448.038330      49.193718   \n",
       "408   32983.320312  7.362801e+09 -0.000274    448.108398      68.122375   \n",
       "409            NaN           NaN       NaN           NaN            NaN   \n",
       "410            NaN           NaN       NaN           NaN            NaN   \n",
       "412   69587.335938  2.209064e+11 -0.000219    448.072266      82.181435   \n",
       "413            NaN           NaN       NaN           NaN            NaN   \n",
       "416       6.934441  7.369352e+05 -0.004038      0.479492       0.038543   \n",
       "417   60451.601562  4.606892e+10  0.000122    448.071289      54.965805   \n",
       "418   41168.976562  2.860001e+10 -0.000214    448.076172      41.206360   \n",
       "419   81316.234375  1.393747e+11  0.000154    448.040283      48.643196   \n",
       "422   38724.601562  1.120426e+10 -0.000117    448.106934      68.162651   \n",
       "423            NaN           NaN       NaN           NaN            NaN   \n",
       "424            NaN           NaN       NaN           NaN            NaN   \n",
       "426   52958.476562  2.783574e+10 -0.000026    448.076172      82.906509   \n",
       "427            NaN           NaN       NaN           NaN            NaN   \n",
       "430       8.236053  3.431704e+06 -0.004194      0.486572       0.037195   \n",
       "431   76537.062500  1.891633e+11  0.000165    448.045898      53.644447   \n",
       "432   45879.109375  6.686219e+10 -0.000017    448.050049      39.280289   \n",
       "433   56659.636719  6.108398e+10  0.000165    448.044434      46.169350   \n",
       "436   30605.884766  2.699694e+09 -0.000494    448.158203      63.707577   \n",
       "437            NaN           NaN       NaN           NaN            NaN   \n",
       "438            NaN           NaN       NaN           NaN            NaN   \n",
       "440   48379.199219  2.114446e+10 -0.000026    448.065918      78.596474   \n",
       "441            NaN           NaN       NaN           NaN            NaN   \n",
       "444       7.581616  3.099565e+06 -0.001722      0.485107       0.036806   \n",
       "445   86737.960938  2.145388e+11 -0.000102    448.042969      52.913498   \n",
       "446  106709.531250  6.066271e+11  0.000063    448.050293      39.291393   \n",
       "447   51973.976562  2.164393e+10  0.000302    448.046387      46.139214   \n",
       "450   37208.312500  5.726623e+09 -0.000373    448.118164      65.399979   \n",
       "451            NaN           NaN       NaN           NaN            NaN   \n",
       "452            NaN           NaN       NaN           NaN            NaN   \n",
       "454   67023.195312  1.444614e+11  0.000098    448.074707      82.702156   \n",
       "455            NaN           NaN       NaN           NaN            NaN   \n",
       "458       6.573598  6.546205e+05 -0.005238      0.544861       0.036671   \n",
       "459  124730.500000  1.055531e+12  0.000011    448.057861      51.854233   \n",
       "460   42255.625000  1.075609e+10  0.001087    448.058594      46.975239   \n",
       "461   53005.238281  2.699694e+10  0.000004    448.058350      48.525593   \n",
       "464   31396.652344  1.327913e+10  0.000208    448.151367      62.332523   \n",
       "465            NaN           NaN       NaN           NaN            NaN   \n",
       "466            NaN           NaN       NaN           NaN            NaN   \n",
       "468   44827.691406  2.439745e+10  0.000341    448.077148      83.261055   \n",
       "469            NaN           NaN       NaN           NaN            NaN   \n",
       "472       6.077863  4.487540e+05 -0.002101      0.521851       0.035628   \n",
       "473   76338.273438  1.815707e+11  0.000255    448.057617      53.525856   \n",
       "474   74510.414062  2.679013e+11  0.001030    448.051514      44.431938   \n",
       "475   76995.984375  2.403304e+11 -0.000103    448.044434      47.508385   \n",
       "478   27765.283203  7.150003e+09  0.000319    448.124512      52.785561   \n",
       "479            NaN           NaN       NaN           NaN            NaN   \n",
       "480            NaN           NaN       NaN           NaN            NaN   \n",
       "482   70075.609375  1.736071e+11 -0.000041    448.075684      83.240868   \n",
       "483            NaN           NaN       NaN           NaN            NaN   \n",
       "486       6.299329  3.625386e+05 -0.002265      0.488525       0.035434   \n",
       "487   59439.398438  5.235770e+10 -0.000021    448.159180      48.815750   \n",
       "488   45753.617188  2.174175e+10  0.001031    448.072754      44.380424   \n",
       "489   55582.941406  8.737841e+10  0.000306    448.058105      42.723488   \n",
       "492   28743.703125  4.393026e+09 -0.000187    448.109863      60.987366   \n",
       "493            NaN           NaN       NaN           NaN            NaN   \n",
       "494            NaN           NaN       NaN           NaN            NaN   \n",
       "496   51387.316406  3.824388e+10  0.000045    448.066406      80.860954   \n",
       "497            NaN           NaN       NaN           NaN            NaN   \n",
       "500       5.917994  6.260166e+05 -0.000620      0.553589       0.035180   \n",
       "501   61939.054688  7.910156e+10  0.000181    448.038330      52.318501   \n",
       "502   50886.019531  2.876629e+10  0.000474    448.041748      48.241295   \n",
       "503   46956.445312  1.863579e+10  0.000217    448.052734      48.439747   \n",
       "506   40093.097656  6.544712e+09  0.000836    448.156250      67.872482   \n",
       "507            NaN           NaN       NaN           NaN            NaN   \n",
       "508            NaN           NaN       NaN           NaN            NaN   \n",
       "510   64612.523438  5.957945e+10  0.000268    448.066406      84.026520   \n",
       "511            NaN           NaN       NaN           NaN            NaN   \n",
       "514       6.530527  4.013059e+05  0.000946      0.411194       0.034828   \n",
       "515   62654.824219  2.617885e+10 -0.000129    448.039795      52.007900   \n",
       "516   51412.230469  1.355562e+11  0.000819    448.049316      45.252541   \n",
       "517   65662.820312  9.213785e+10  0.000551    448.042236      47.736370   \n",
       "520   37682.843750  2.256460e+10 -0.000145    448.126953      61.171196   \n",
       "521            NaN           NaN       NaN           NaN            NaN   \n",
       "522            NaN           NaN       NaN           NaN            NaN   \n",
       "524   63310.359375  1.183331e+11  0.000039    448.069336      83.316315   \n",
       "525            NaN           NaN       NaN           NaN            NaN   \n",
       "528       6.977399  1.141552e+06  0.002040      0.456177       0.034657   \n",
       "529   66814.710938  5.871179e+10 -0.000085    448.052979      48.993149   \n",
       "530   48758.203125  9.995561e+10  0.000411    448.042725      44.963810   \n",
       "531   50613.683594  3.616815e+10  0.000385    448.051758      44.308361   \n",
       "534   27983.072266  5.655924e+09 -0.000653    448.196289      57.879272   \n",
       "535            NaN           NaN       NaN           NaN            NaN   \n",
       "536            NaN           NaN       NaN           NaN            NaN   \n",
       "538   54179.046875  6.663707e+10 -0.000375    448.077148      84.452888   \n",
       "539            NaN           NaN       NaN           NaN            NaN   \n",
       "542       5.328950  2.070192e+05  0.001562      0.461042       0.034095   \n",
       "543   74789.625000  2.152890e+11 -0.000362    448.037109      49.486153   \n",
       "544   46713.707031  5.320217e+10  0.001322    448.056641      45.890270   \n",
       "545   57213.574219  7.374773e+10 -0.000232    448.043213      44.357609   \n",
       "548   67299.632812  1.499334e+11 -0.000706    448.242188      55.413795   \n",
       "549            NaN           NaN       NaN           NaN            NaN   \n",
       "550            NaN           NaN       NaN           NaN            NaN   \n",
       "552  139264.093750  4.833018e+11 -0.000089    448.061035      84.174171   \n",
       "553            NaN           NaN       NaN           NaN            NaN   \n",
       "556       8.325297  1.611370e+06  0.003657      0.440552       0.033292   \n",
       "557  324381.187500  3.728145e+12  0.000333    448.034668      52.028522   \n",
       "558   62941.453125  1.232211e+11  0.000723    448.049072      47.894119   \n",
       "559   53996.414062  7.365149e+10  0.000079    448.044678      47.846733   \n",
       "562   33941.050781  9.817069e+09 -0.000041    448.096680      59.874821   \n",
       "563            NaN           NaN       NaN           NaN            NaN   \n",
       "564            NaN           NaN       NaN           NaN            NaN   \n",
       "566   75614.359375  2.513169e+11 -0.000171    448.079590      76.485435   \n",
       "567            NaN           NaN       NaN           NaN            NaN   \n",
       "570      10.375254  6.325101e+06  0.005764      0.389709       0.032201   \n",
       "571   50347.285156  1.914572e+10 -0.000151    448.043457      48.936752   \n",
       "572   68080.296875  2.229424e+11  0.001146    448.040039      47.032265   \n",
       "573   58560.859375  1.293543e+11  0.000310    448.038574      44.166080   \n",
       "576   27479.613281  3.939333e+09 -0.000069    448.134766      56.279320   \n",
       "577            NaN           NaN       NaN           NaN            NaN   \n",
       "578            NaN           NaN       NaN           NaN            NaN   \n",
       "580   53393.441406  2.617885e+10 -0.000224    448.069336      84.626434   \n",
       "581            NaN           NaN       NaN           NaN            NaN   \n",
       "584       7.656887  1.653523e+06  0.005002      0.377197       0.031232   \n",
       "585   51380.972656  1.018066e+10  0.000071    448.039795      48.669384   \n",
       "586   49648.539062  2.733592e+10  0.001010    448.082520      46.914322   \n",
       "587   52574.664062  5.497558e+10 -0.000491    448.041260      45.833378   \n",
       "590   64964.792969  1.332741e+11 -0.000227    448.138672      63.714077   \n",
       "591            NaN           NaN       NaN           NaN            NaN   \n",
       "592            NaN           NaN       NaN           NaN            NaN   \n",
       "594   49000.750000  1.627567e+10  0.000167    448.077148      85.509880   \n",
       "595            NaN           NaN       NaN           NaN            NaN   \n",
       "598       7.097365  2.189672e+06  0.004176      0.434937       0.030982   \n",
       "599   49732.816406  2.210074e+10 -0.000003    448.051758      44.747868   \n",
       "600   42603.464844  1.460704e+10  0.000668    448.042725      46.344582   \n",
       "601   52229.101562  4.363142e+10  0.000061    448.037354      44.284389   \n",
       "604   25103.058594  3.011611e+09  0.000319    448.259766      53.972969   \n",
       "605            NaN           NaN       NaN           NaN            NaN   \n",
       "606            NaN           NaN       NaN           NaN            NaN   \n",
       "608   45390.710938  1.458536e+10 -0.000178    448.070801      83.016846   \n",
       "609            NaN           NaN       NaN           NaN            NaN   \n",
       "612       6.926130  2.296250e+06  0.004635      0.449829       0.030453   \n",
       "613   63366.921875  7.761259e+10  0.000238    448.036865      46.188362   \n",
       "614   42753.277344  2.568952e+10  0.000643    448.041748      46.005123   \n",
       "615   53935.484375  4.557561e+10 -0.000131    448.037598      45.269539   \n",
       "618  164057.468750  4.113281e+11  0.000564    448.130859      66.646599   \n",
       "619            NaN           NaN       NaN           NaN            NaN   \n",
       "620            NaN           NaN       NaN           NaN            NaN   \n",
       "622   47570.929688  1.121951e+10 -0.000222    448.075684      78.170517   \n",
       "623            NaN           NaN       NaN           NaN            NaN   \n",
       "626       6.962451  1.811176e+06  0.006656      0.486694       0.030317   \n",
       "627   56981.671875  8.298201e+10  0.000257    448.041016      46.059299   \n",
       "628   46007.796875  4.133502e+10  0.000765    448.063477      45.025131   \n",
       "629   48538.796875  1.991869e+10  0.000052    448.037354      43.076241   \n",
       "632   37411.636719  2.664015e+10 -0.000565    448.135742      57.219238   \n",
       "633            NaN           NaN       NaN           NaN            NaN   \n",
       "634            NaN           NaN       NaN           NaN            NaN   \n",
       "636   45184.449219  1.257064e+10  0.000150    448.085449      82.734909   \n",
       "637            NaN           NaN       NaN           NaN            NaN   \n",
       "640       7.063575  2.130708e+06  0.005155      0.442139       0.028849   \n",
       "641   69517.117188  1.324713e+11  0.000087    448.059814      46.030537   \n",
       "642   48101.644531  3.012361e+10  0.000670    448.057373      48.837246   \n",
       "643   52456.207031  1.682926e+10 -0.000362    448.038818      43.042099   \n",
       "646   23214.568359  3.817749e+09  0.000839    448.077148      51.204514   \n",
       "647            NaN           NaN       NaN           NaN            NaN   \n",
       "648            NaN           NaN       NaN           NaN            NaN   \n",
       "650   54636.542969  1.917753e+10  0.000233    448.073730      80.585632   \n",
       "651            NaN           NaN       NaN           NaN            NaN   \n",
       "654      14.109981  1.452872e+07  0.003805      0.458252       0.028205   \n",
       "655   69636.281250  1.699728e+11 -0.000156    448.039795      50.225204   \n",
       "656   48564.054688  2.987803e+10  0.000835    448.063477      50.489311   \n",
       "657   60397.398438  4.474757e+10  0.000049    448.040771      46.630215   \n",
       "660   28729.501953  1.627567e+10 -0.000720    448.094727      47.985260   \n",
       "661            NaN           NaN       NaN           NaN            NaN   \n",
       "662            NaN           NaN       NaN           NaN            NaN   \n",
       "664   72250.726562  7.156584e+10 -0.000197    448.057129      81.831963   \n",
       "665            NaN           NaN       NaN           NaN            NaN   \n",
       "668       8.580814  2.498458e+06  0.006815      0.382812       0.028055   \n",
       "669   82208.375000  3.190293e+11 -0.000014    448.044678      51.970615   \n",
       "670   46493.609375  8.975605e+10  0.000958    448.061279      50.315189   \n",
       "671   65039.093750  6.214631e+10  0.000481    448.044434      46.345890   \n",
       "674   40340.566406  1.304800e+10 -0.000421    448.097656      66.549110   \n",
       "675            NaN           NaN       NaN           NaN            NaN   \n",
       "676            NaN           NaN       NaN           NaN            NaN   \n",
       "678   76075.992188  3.123613e+10  0.000134    448.061768      83.202171   \n",
       "679            NaN           NaN       NaN           NaN            NaN   \n",
       "682       4.913018  1.075075e+05  0.005687      0.497725       0.028072   \n",
       "683   68588.726562  6.731704e+10  0.000404    448.050293      51.094738   \n",
       "684   59792.234375  5.577233e+10  0.000945    448.049805      51.351974   \n",
       "685  157433.500000  1.297784e+12 -0.000348    448.033936      46.773361   \n",
       "688   56327.046875  3.509080e+10 -0.000336    448.077637      62.526688   \n",
       "689            NaN           NaN       NaN           NaN            NaN   \n",
       "690            NaN           NaN       NaN           NaN            NaN   \n",
       "692   85830.742188  7.156584e+10 -0.000193    448.078613      82.545204   \n",
       "693            NaN           NaN       NaN           NaN            NaN   \n",
       "696      12.287910  1.018355e+07  0.004091      0.515320       0.027217   \n",
       "697   59561.312500  2.342709e+10 -0.000066    448.036865      49.717842   \n",
       "698   55200.367188  5.186376e+10  0.001385    448.045898      50.322086   \n",
       "699  123184.773438  8.747496e+11  0.000183    448.036377      45.715626   \n",
       "702   29731.494141  1.278502e+10  0.000347    448.141602      57.190922   \n",
       "703            NaN           NaN       NaN           NaN            NaN   \n",
       "704            NaN           NaN       NaN           NaN            NaN   \n",
       "706   53108.781250  7.186351e+10  0.000242    448.081055      81.018059   \n",
       "707            NaN           NaN       NaN           NaN            NaN   \n",
       "710       7.146149  1.054305e+06  0.004777      0.406006       0.026646   \n",
       "711  116853.351562  4.435005e+11 -0.000029    448.032959      53.563866   \n",
       "712   46510.121094  2.350930e+10  0.001001    448.064453      49.847744   \n",
       "713   67946.906250  5.235770e+10  0.000040    448.050781      48.745476   \n",
       "716   40286.941406  4.106060e+10  0.000039    448.089844      58.321678   \n",
       "717            NaN           NaN       NaN           NaN            NaN   \n",
       "718            NaN           NaN       NaN           NaN            NaN   \n",
       "720   55110.109375  1.520062e+10 -0.000412    448.083496      82.653221   \n",
       "721            NaN           NaN       NaN           NaN            NaN   \n",
       "724       5.952379  5.672131e+05  0.007191      0.416016       0.026215   \n",
       "725   65280.046875  7.036875e+10  0.000159    448.035400      49.505333   \n",
       "726   67106.992188  1.851809e+11  0.000658    448.052246      50.594616   \n",
       "727   72974.531250  7.635498e+10 -0.000285    448.035889      48.948296   \n",
       "730   43898.667969  1.727804e+10 -0.000054    448.126953      65.467949   \n",
       "731            NaN           NaN       NaN           NaN            NaN   \n",
       "732            NaN           NaN       NaN           NaN            NaN   \n",
       "734   60099.574219  7.093623e+10 -0.000404    448.055908      79.793724   \n",
       "735            NaN           NaN       NaN           NaN            NaN   \n",
       "738       5.608924  3.359505e+05  0.002194      0.529297       0.025217   \n",
       "739   60588.476562  2.213782e+10 -0.000120    448.046143      48.660442   \n",
       "740   72163.531250  3.023657e+11  0.000411    448.057861      49.945812   \n",
       "741   69012.031250  5.890241e+10 -0.000301    448.046631      47.737759   \n",
       "744   41153.359375  1.212697e+10  0.000570    448.070312      66.892845   \n",
       "745            NaN           NaN       NaN           NaN            NaN   \n",
       "746            NaN           NaN       NaN           NaN            NaN   \n",
       "748   55091.910156  9.115122e+10  0.000273    448.063965      73.885269   \n",
       "749            NaN           NaN       NaN           NaN            NaN   \n",
       "752       7.772630  3.962209e+06  0.004570      0.393822       0.024376   \n",
       "753   77353.398438  8.408030e+10 -0.000031    448.045898      50.039043   \n",
       "754   54278.503906  7.853655e+10 -0.000130    448.060791      50.312813   \n",
       "755   63881.269531  3.967310e+10  0.000285    448.038818      49.004391   \n",
       "758   42843.574219  9.629481e+09 -0.000439    448.065918      63.692081   \n",
       "759            NaN           NaN       NaN           NaN            NaN   \n",
       "760            NaN           NaN       NaN           NaN            NaN   \n",
       "762  245204.984375  1.607408e+12  0.000376    448.057129      82.612213   \n",
       "763            NaN           NaN       NaN           NaN            NaN   \n",
       "766       4.780324  1.094827e+05  0.002693      0.361908       0.024207   \n",
       "767   65095.105469  6.731704e+10  0.000364    448.049316      50.065414   \n",
       "768   80761.898438  2.549592e+11  0.000507    448.081543      52.161930   \n",
       "769   72835.218750  8.567623e+10  0.000099    448.035400      52.742100   \n",
       "772   44322.226562  4.140420e+10  0.000207    448.056152      59.618183   \n",
       "773            NaN           NaN       NaN           NaN            NaN   \n",
       "774            NaN           NaN       NaN           NaN            NaN   \n",
       "776   95299.117188  8.012635e+10  0.000137    448.049072      80.103516   \n",
       "777            NaN           NaN       NaN           NaN            NaN   \n",
       "780      16.797567  1.917396e+07  0.005024      0.356506       0.023236   \n",
       "781   75500.585938  2.094308e+11  0.000184    448.043701      50.332382   \n",
       "782   52136.453125  8.914959e+10  0.000709    448.060791      53.017929   \n",
       "783   83311.023438  2.426508e+11  0.000079    448.036133      54.482510   \n",
       "786   38593.156250  9.370838e+09 -0.000221    448.096680      67.729317   \n",
       "787            NaN           NaN       NaN           NaN            NaN   \n",
       "788            NaN           NaN       NaN           NaN            NaN   \n",
       "790  103989.742188  2.145388e+11 -0.000190    448.060059      80.500168   \n",
       "791            NaN           NaN       NaN           NaN            NaN   \n",
       "794       6.369375  1.516401e+06  0.003870      0.389984       0.022817   \n",
       "795   84146.710938  1.713525e+11 -0.000533    448.035889      48.836674   \n",
       "796   46617.175781  2.411210e+10 -0.000157    448.094238      53.295658   \n",
       "797   63511.289062  6.052358e+10 -0.000221    448.043701      55.354233   \n",
       "800   63072.113281  5.975606e+10 -0.000181    448.182617      62.526688   \n",
       "801            NaN           NaN       NaN           NaN            NaN   \n",
       "802            NaN           NaN       NaN           NaN            NaN   \n",
       "804   83934.046875  9.124578e+10  0.000243    448.064941      75.822250   \n",
       "805            NaN           NaN       NaN           NaN            NaN   \n",
       "808       5.969302  2.051572e+05 -0.000944      0.325684       0.022564   \n",
       "809   52250.949219  2.228740e+10 -0.000118    448.056152      47.467190   \n",
       "810   56015.222656  6.911216e+10 -0.000046    448.079590      53.671066   \n",
       "811   63015.148438  1.628906e+11 -0.000062    448.043701      53.023014   \n",
       "814   62297.203125  3.555635e+10  0.000020    448.092285      74.100739   \n",
       "815            NaN           NaN       NaN           NaN            NaN   \n",
       "816            NaN           NaN       NaN           NaN            NaN   \n",
       "818  297973.250000  2.363130e+12  0.000336    448.046143      63.545689   \n",
       "819            NaN           NaN       NaN           NaN            NaN   \n",
       "822       8.624231  2.912710e+06  0.001209      0.394775       0.021599   \n",
       "823   48132.335938  2.871859e+10 -0.000144    448.206055      44.010178   \n",
       "824   54383.152344  7.626670e+10 -0.000192    448.072754      48.809811   \n",
       "825   75714.164062  2.429860e+11  0.000156    448.069824      46.818249   \n",
       "828   30536.048828  3.031742e+09 -0.000025    448.095215      62.006210   \n",
       "829            NaN           NaN       NaN           NaN            NaN   \n",
       "830            NaN           NaN       NaN           NaN            NaN   \n",
       "832   61945.824219  3.524076e+10  0.000515    448.061035      77.599541   \n",
       "833            NaN           NaN       NaN           NaN            NaN   \n",
       "836      11.759218  2.415468e+06 -0.002441      0.530273       0.023758   \n",
       "837   47949.730469  3.665039e+10 -0.000164    448.048584      35.982563   \n",
       "838   49669.804688  4.712193e+10  0.000134    448.062500      49.567970   \n",
       "839   63520.992188  2.883965e+11  0.000219    448.050781      42.034321   \n",
       "842   53168.152344  4.398046e+10 -0.000478    448.095215      70.598984   \n",
       "843            NaN           NaN       NaN           NaN            NaN   \n",
       "844            NaN           NaN       NaN           NaN            NaN   \n",
       "846   50657.347656  2.971653e+10 -0.000156    448.065918      58.154953   \n",
       "847            NaN           NaN       NaN           NaN            NaN   \n",
       "\n",
       "         spearman  q01_abs_diff  q05_abs_diff  q50_abs_diff  q95_abs_diff  \\\n",
       "1   -6.912752e-06      0.207336      1.003906     13.997543     80.000687   \n",
       "2   -2.233854e-03      0.035805      0.186165      2.499613     23.998825   \n",
       "3    1.957554e-05      0.376633      1.876915     23.983521    111.997208   \n",
       "6   -8.733455e-04      0.450989      2.255432     27.993683    160.000259   \n",
       "7             NaN           NaN           NaN           NaN           NaN   \n",
       "8             NaN           NaN           NaN           NaN           NaN   \n",
       "10  -2.073852e-05      0.940406      4.515320     52.008484    176.012634   \n",
       "11            NaN           NaN           NaN           NaN           NaN   \n",
       "13  -8.367174e-05      0.142975      0.748177      9.001137     52.000927   \n",
       "14  -4.157898e-03      0.020668      0.102169      1.375315     17.999088   \n",
       "15   8.872247e-05      0.171158      0.872360     10.002838     72.000519   \n",
       "18   3.593929e-05      0.347580      1.748683     23.976929    127.997711   \n",
       "19            NaN           NaN           NaN           NaN           NaN   \n",
       "20            NaN           NaN           NaN           NaN           NaN   \n",
       "22  -5.945576e-04      0.406069      1.999565     24.006989    111.999786   \n",
       "23            NaN           NaN           NaN           NaN           NaN   \n",
       "25   3.585698e-05      0.115158      0.563599      7.004242     39.999340   \n",
       "26  -2.001503e-03      0.018661      0.093677      1.249559     15.999390   \n",
       "27  -6.906464e-05      0.155973      0.752869      9.000614     52.000919   \n",
       "30  -1.181142e-03      0.276855      1.376617     17.991028    104.005463   \n",
       "31            NaN           NaN           NaN           NaN           NaN   \n",
       "32            NaN           NaN           NaN           NaN           NaN   \n",
       "34  -5.489405e-04      0.488159      2.496185     28.007050    120.005280   \n",
       "35            NaN           NaN           NaN           NaN           NaN   \n",
       "38  -3.804966e-03      0.000366      0.001923      0.020859      0.065674   \n",
       "39   2.101869e-04      0.570087      2.995636     32.006226    128.003174   \n",
       "40  -3.379034e-03      0.409973      2.003235     26.005737    127.991394   \n",
       "41   3.838496e-04      1.007935      5.490479     59.993073    191.994324   \n",
       "44  -9.473588e-04      0.484375      2.491821     30.020508    144.023438   \n",
       "45            NaN           NaN           NaN           NaN           NaN   \n",
       "46            NaN           NaN           NaN           NaN           NaN   \n",
       "48  -1.592607e-04      0.629211      3.240967     36.002991    143.994354   \n",
       "49            NaN           NaN           NaN           NaN           NaN   \n",
       "52  -4.600448e-03      0.000488      0.002441      0.026611      0.081299   \n",
       "53   3.059335e-04      0.623932      3.016235     35.999348    143.989685   \n",
       "54  -7.591132e-03      0.379333      1.878891     23.997864    104.023315   \n",
       "55  -9.841732e-05      0.998769      5.001511     55.997406    176.004272   \n",
       "58   2.915825e-04      0.569122      2.974731     39.991089    160.002487   \n",
       "59            NaN           NaN           NaN           NaN           NaN   \n",
       "60            NaN           NaN           NaN           NaN           NaN   \n",
       "62   7.446480e-04      0.933838      4.505768     52.001846    175.999649   \n",
       "63            NaN           NaN           NaN           NaN           NaN   \n",
       "66   3.035732e-03      0.000610      0.002991      0.032471      0.097168   \n",
       "67   1.949253e-04      0.635193      3.250435     36.008972    143.994904   \n",
       "68   3.278170e-03      0.373726      1.872040     23.996719    111.992462   \n",
       "69  -6.318197e-04      0.935623      4.508240     51.999256    175.991150   \n",
       "72   7.890060e-04      0.415527      2.018799     26.019531    143.984955   \n",
       "73            NaN           NaN           NaN           NaN           NaN   \n",
       "74            NaN           NaN           NaN           NaN           NaN   \n",
       "76   3.757286e-05      0.811775      4.000033     47.989502    160.019287   \n",
       "77            NaN           NaN           NaN           NaN           NaN   \n",
       "80   1.835468e-03      0.000671      0.003296      0.035553      0.105957   \n",
       "81  -1.342449e-05      0.686539      3.494934     39.998970    143.998383   \n",
       "82   3.572013e-03      0.338318      1.726318     21.988647    112.004150   \n",
       "83  -5.896445e-04      0.918457      4.501740     51.987183    160.014648   \n",
       "86   2.724180e-05      0.632538      3.237610     40.003754    176.001343   \n",
       "87            NaN           NaN           NaN           NaN           NaN   \n",
       "88            NaN           NaN           NaN           NaN           NaN   \n",
       "90   3.921397e-04      0.833496      4.010559     47.998489    175.985352   \n",
       "91            NaN           NaN           NaN           NaN           NaN   \n",
       "94  -3.559407e-04      0.000732      0.003784      0.040955      0.122314   \n",
       "95   5.208848e-04      0.704590      3.508240     40.007050    144.005157   \n",
       "96  -1.786743e-03      0.329346      1.632996     20.013794    119.993774   \n",
       "97   1.396643e-04      0.806244      3.994720     44.012390    159.997574   \n",
       "100 -8.211295e-04      0.527466      2.732056     36.001358    175.983154   \n",
       "101           NaN           NaN           NaN           NaN           NaN   \n",
       "102           NaN           NaN           NaN           NaN           NaN   \n",
       "104 -1.600708e-04      0.875127      4.491943     51.966553    176.005432   \n",
       "105           NaN           NaN           NaN           NaN           NaN   \n",
       "108 -1.099915e-03      0.000732      0.003754      0.040474      0.120850   \n",
       "109  1.693380e-04      0.490967      2.497208     31.980713    127.994049   \n",
       "110 -1.253507e-03      0.335999      1.660400     20.009705    127.996002   \n",
       "111 -5.232000e-04      0.746902      3.745941     43.991028    159.990540   \n",
       "114  1.029713e-03      0.623327      3.216797     36.137207    159.985657   \n",
       "115           NaN           NaN           NaN           NaN           NaN   \n",
       "116           NaN           NaN           NaN           NaN           NaN   \n",
       "118  4.300878e-04      0.850277      4.020264     47.998512    175.991638   \n",
       "119           NaN           NaN           NaN           NaN           NaN   \n",
       "122  8.339830e-04      0.000732      0.003662      0.039650      0.118652   \n",
       "123  3.318621e-04      0.571205      2.990845     35.993347    128.019531   \n",
       "124 -3.190789e-04      0.333740      1.635498     19.997711    120.000870   \n",
       "125  2.795917e-04      0.621231      3.011292     36.010742    143.999207   \n",
       "128  3.512416e-04      0.514893      2.721191     44.042236    176.005432   \n",
       "129           NaN           NaN           NaN           NaN           NaN   \n",
       "130           NaN           NaN           NaN           NaN           NaN   \n",
       "132 -6.341565e-04      1.105835      5.493256     60.002914    192.009827   \n",
       "133           NaN           NaN           NaN           NaN           NaN   \n",
       "136 -2.849257e-03      0.000732      0.003723      0.040039      0.119873   \n",
       "137  2.469720e-04      0.671936      3.255890     39.991577    143.996109   \n",
       "138  2.221519e-04      0.326538      1.627747     19.988403    112.002502   \n",
       "139 -7.098765e-05      0.632996      3.247665     39.987732    143.994507   \n",
       "142  1.225635e-04      0.536621      2.743713     43.968994    175.995392   \n",
       "143           NaN           NaN           NaN           NaN           NaN   \n",
       "144           NaN           NaN           NaN           NaN           NaN   \n",
       "146  3.544447e-04      1.106934      5.491821     60.003540    192.013794   \n",
       "147           NaN           NaN           NaN           NaN           NaN   \n",
       "150 -1.191945e-03      0.000732      0.003784      0.040771      0.122314   \n",
       "151 -1.841962e-04      0.612549      3.001550     36.000183    128.007629   \n",
       "152  6.006173e-04      0.340088      1.700195     19.997894    112.004181   \n",
       "153 -9.829581e-06      0.617920      3.005066     36.004578    128.024780   \n",
       "156 -3.470240e-04      0.587402      2.997269     55.970459    192.017090   \n",
       "157           NaN           NaN           NaN           NaN           NaN   \n",
       "158           NaN           NaN           NaN           NaN           NaN   \n",
       "160 -8.608949e-05      0.888306      4.499134     52.032227    191.998734   \n",
       "161           NaN           NaN           NaN           NaN           NaN   \n",
       "164 -1.109093e-03      0.000732      0.003662      0.040039      0.119385   \n",
       "165  1.039982e-05      0.658813      3.253235     39.986267    143.991516   \n",
       "166 -6.342654e-04      0.359253      1.772827     21.949707    119.996979   \n",
       "167  1.552255e-04      0.619751      3.006042     36.002228    128.022827   \n",
       "170  3.001177e-04      0.628906      3.230469     51.960938    176.037842   \n",
       "171           NaN           NaN           NaN           NaN           NaN   \n",
       "172           NaN           NaN           NaN           NaN           NaN   \n",
       "174 -2.605715e-04      0.936611      4.515076     52.014038    191.983521   \n",
       "175           NaN           NaN           NaN           NaN           NaN   \n",
       "178 -2.003028e-03      0.000732      0.003712      0.040192      0.120361   \n",
       "179 -9.275613e-05      0.624369      3.232300     36.006989    128.011536   \n",
       "180 -8.464399e-04      0.337982      1.656738     19.997437    104.005585   \n",
       "181 -6.801366e-05      0.620422      3.008301     36.000195    128.005127   \n",
       "184  4.107679e-04      0.619507      3.217285     52.008484    191.992615   \n",
       "185           NaN           NaN           NaN           NaN           NaN   \n",
       "186           NaN           NaN           NaN           NaN           NaN   \n",
       "188 -1.252155e-04      0.880859      4.496109     52.004486    191.994751   \n",
       "189           NaN           NaN           NaN           NaN           NaN   \n",
       "192 -2.543100e-03      0.000732      0.003662      0.039706      0.118896   \n",
       "193 -1.668757e-04      0.567585      2.988892     36.024536    128.008850   \n",
       "194 -1.006113e-03      0.294250      1.496918     17.990234     72.002457   \n",
       "195  4.099178e-04      0.616943      3.004120     35.994324    127.995575   \n",
       "198  1.938382e-04      0.607259      3.019043     51.998413    192.010559   \n",
       "199           NaN           NaN           NaN           NaN           NaN   \n",
       "200           NaN           NaN           NaN           NaN           NaN   \n",
       "202 -2.761971e-04      0.952332      4.978561     56.007233    192.006836   \n",
       "203           NaN           NaN           NaN           NaN           NaN   \n",
       "206 -2.689425e-03      0.000732      0.003662      0.039324      0.117676   \n",
       "207  3.690844e-04      0.560165      2.753052     32.012451    120.006836   \n",
       "208 -8.827740e-04      0.307098      1.506195     17.998337     72.027344   \n",
       "209  1.883693e-04      0.563178      2.758484     32.004517    127.978271   \n",
       "212  1.848901e-04      0.623456      3.222778     55.962402    192.034424   \n",
       "213           NaN           NaN           NaN           NaN           NaN   \n",
       "214           NaN           NaN           NaN           NaN           NaN   \n",
       "216 -1.204373e-06      1.020264      5.461426     60.001373    192.020996   \n",
       "217           NaN           NaN           NaN           NaN           NaN   \n",
       "220 -5.781804e-03      0.000732      0.003662      0.039230      0.116943   \n",
       "221  2.285991e-04      0.565744      2.978027     36.000435    128.027222   \n",
       "222 -5.342925e-04      0.292969      1.493958     17.973511     64.004578   \n",
       "223  2.352858e-04      0.552856      2.747253     31.996460    127.993500   \n",
       "226 -4.219027e-04      0.634135      3.242462     52.002319    192.006134   \n",
       "227           NaN           NaN           NaN           NaN           NaN   \n",
       "228           NaN           NaN           NaN           NaN           NaN   \n",
       "230 -3.994679e-04      1.128547      5.526367     63.991028    207.982300   \n",
       "231           NaN           NaN           NaN           NaN           NaN   \n",
       "234 -3.055236e-03      0.000732      0.003655      0.038818      0.115967   \n",
       "235  3.088471e-04      0.629456      3.245850     36.007324    127.998901   \n",
       "236 -8.246223e-04      0.369293      1.865723     21.994659     95.987976   \n",
       "237  3.948596e-04      0.630859      3.244995     36.005676    128.016357   \n",
       "240 -3.090911e-04      0.568420      2.970825     47.990540    175.990295   \n",
       "241           NaN           NaN           NaN           NaN           NaN   \n",
       "242           NaN           NaN           NaN           NaN           NaN   \n",
       "244  1.362136e-04      0.996406      5.004059     59.988464    192.015503   \n",
       "245           NaN           NaN           NaN           NaN           NaN   \n",
       "248 -3.929820e-03      0.000732      0.003540      0.038177      0.113892   \n",
       "249  1.870972e-04      0.556641      2.750587     35.991638    127.995972   \n",
       "250 -6.035906e-04      0.361694      1.772949     21.965332     88.005005   \n",
       "251  3.372317e-04      0.614807      3.001030     35.996933    128.004608   \n",
       "254  7.925935e-04      0.640869      3.250557     51.990417    191.998032   \n",
       "255           NaN           NaN           NaN           NaN           NaN   \n",
       "256           NaN           NaN           NaN           NaN           NaN   \n",
       "258  3.621618e-04      1.133606      5.972412     63.995483    207.987122   \n",
       "259           NaN           NaN           NaN           NaN           NaN   \n",
       "262 -4.209928e-03      0.000732      0.003510      0.037842      0.113037   \n",
       "263 -1.658506e-04      0.527100      2.743347     32.004303    120.006378   \n",
       "264 -1.095551e-03      0.383545      1.889160     22.010559     95.999458   \n",
       "265 -4.907714e-04      0.568390      2.983276     32.012329    127.993652   \n",
       "268  1.060141e-04      0.630615      3.245422     52.023926    192.017212   \n",
       "269           NaN           NaN           NaN           NaN           NaN   \n",
       "270           NaN           NaN           NaN           NaN           NaN   \n",
       "272 -3.955459e-04      1.205078      5.996490     64.007874    207.994110   \n",
       "273           NaN           NaN           NaN           NaN           NaN   \n",
       "276 -3.411457e-03      0.000732      0.003433      0.037598      0.112061   \n",
       "277  1.265548e-04      0.578735      2.997284     36.004364    128.001801   \n",
       "278 -8.924748e-04      0.424988      2.035645     24.034180    104.005585   \n",
       "279 -2.093344e-04      0.632385      3.247543     36.006805    128.010742   \n",
       "282 -5.787857e-04      0.672485      3.324707     52.001808    192.010925   \n",
       "283           NaN           NaN           NaN           NaN           NaN   \n",
       "284           NaN           NaN           NaN           NaN           NaN   \n",
       "286 -2.292487e-04      1.261597      6.494751     71.989197    208.006378   \n",
       "287           NaN           NaN           NaN           NaN           NaN   \n",
       "290 -3.491116e-03      0.000679      0.003357      0.036316      0.108643   \n",
       "291 -1.862604e-04      0.618286      3.007172     36.006104    143.991577   \n",
       "292 -9.134573e-04      0.459961      2.256592     27.996506    120.006439   \n",
       "293 -1.027135e-04      0.634949      3.249195     36.008301    143.990601   \n",
       "296 -3.494063e-04      0.582845      2.994274     51.965332    191.995544   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "298           NaN           NaN           NaN           NaN           NaN   \n",
       "300  2.064742e-04      1.252747      6.475098     71.977539    208.003937   \n",
       "301           NaN           NaN           NaN           NaN           NaN   \n",
       "304 -4.214777e-03      0.000671      0.003357      0.036011      0.108215   \n",
       "305  5.208935e-04      0.554871      2.748199     32.011597    127.994049   \n",
       "306 -4.129802e-04      0.482666      2.490784     28.013306    119.999237   \n",
       "307 -1.056472e-04      0.617981      3.005493     35.992767    128.002899   \n",
       "310 -9.170552e-05      0.674968      3.474365     48.023193    176.031982   \n",
       "311           NaN           NaN           NaN           NaN           NaN   \n",
       "312           NaN           NaN           NaN           NaN           NaN   \n",
       "314  7.091999e-05      1.261597      6.491272     71.983521    208.004395   \n",
       "315           NaN           NaN           NaN           NaN           NaN   \n",
       "318 -4.461233e-03      0.000645      0.003242      0.035095      0.104980   \n",
       "319  2.620186e-04      0.561195      2.756317     35.993256    128.003708   \n",
       "320  3.742337e-06      0.476196      2.484131     28.022461    127.988831   \n",
       "321 -1.868989e-04      0.569519      2.988403     32.010132    127.996765   \n",
       "324  3.919393e-04      0.680461      3.486267     51.973633    191.995636   \n",
       "325           NaN           NaN           NaN           NaN           NaN   \n",
       "326           NaN           NaN           NaN           NaN           NaN   \n",
       "328 -8.860804e-05      1.282471      6.501228     71.991333    208.005585   \n",
       "329           NaN           NaN           NaN           NaN           NaN   \n",
       "332 -8.587734e-03      0.000610      0.003174      0.034241      0.102905   \n",
       "333  1.331191e-04      0.573914      2.993988     36.006317    143.959229   \n",
       "334 -1.275543e-04      0.458862      2.255890     27.998032    120.027466   \n",
       "335 -7.604867e-05      0.546936      2.742432     31.986145    127.987976   \n",
       "338  5.589550e-04      0.666138      3.280273     47.973511    176.037109   \n",
       "339           NaN           NaN           NaN           NaN           NaN   \n",
       "340           NaN           NaN           NaN           NaN           NaN   \n",
       "342  2.126476e-04      1.277466      6.499177     71.986572    208.004944   \n",
       "343           NaN           NaN           NaN           NaN           NaN   \n",
       "346 -5.414727e-03      0.000610      0.003159      0.033691      0.101074   \n",
       "347  1.382830e-05      0.623573      3.222900     39.994354    143.994781   \n",
       "348  1.617814e-04      0.422852      2.031128     25.992981    119.971191   \n",
       "349  1.329182e-04      0.550537      2.745544     31.989929    127.991577   \n",
       "352 -9.862677e-04      0.664551      3.271606     44.004913    175.987488   \n",
       "353           NaN           NaN           NaN           NaN           NaN   \n",
       "354           NaN           NaN           NaN           NaN           NaN   \n",
       "356  4.009024e-04      1.265503      6.492493     71.983154    208.001678   \n",
       "357           NaN           NaN           NaN           NaN           NaN   \n",
       "360 -4.877809e-03      0.000610      0.003113      0.033279      0.100220   \n",
       "361  2.043054e-04      0.626462      3.240356     39.998238    143.996628   \n",
       "362  9.823422e-05      0.442596      2.246964     26.025879    120.000984   \n",
       "363 -3.414328e-04      0.564034      2.760315     32.007812    128.006714   \n",
       "366  7.026309e-04      0.673584      3.460938     47.991333    176.046631   \n",
       "367           NaN           NaN           NaN           NaN           NaN   \n",
       "368           NaN           NaN           NaN           NaN           NaN   \n",
       "370 -9.464523e-05      1.259033      6.485718     71.975708    207.999298   \n",
       "371           NaN           NaN           NaN           NaN           NaN   \n",
       "374 -8.011762e-03      0.000610      0.003052      0.032898      0.099243   \n",
       "375  1.824292e-04      0.683960      3.493866     43.997589    144.019775   \n",
       "376 -6.983956e-04      0.469565      2.267334     29.979492    127.993225   \n",
       "377  1.930326e-06      0.617432      3.005371     35.999245    143.993927   \n",
       "380 -7.713508e-04      0.665161      3.274902     44.002380    175.961182   \n",
       "381           NaN           NaN           NaN           NaN           NaN   \n",
       "382           NaN           NaN           NaN           NaN           NaN   \n",
       "384  2.769766e-04      1.207520      5.993988     63.997574    192.032715   \n",
       "385           NaN           NaN           NaN           NaN           NaN   \n",
       "388 -6.854678e-03      0.000610      0.002991      0.032349      0.097412   \n",
       "389  4.105823e-04      0.684433      3.492798     43.996429    144.014587   \n",
       "390 -6.908864e-04      0.451454      2.251640     27.957520    119.983276   \n",
       "391 -1.330027e-04      0.620636      3.010559     35.998871    143.989746   \n",
       "394 -1.032151e-04      0.685664      3.489563     48.012695    191.972290   \n",
       "395           NaN           NaN           NaN           NaN           NaN   \n",
       "396           NaN           NaN           NaN           NaN           NaN   \n",
       "398  2.170406e-05      1.282227      6.500224     71.988464    208.004089   \n",
       "399           NaN           NaN           NaN           NaN           NaN   \n",
       "402 -4.465818e-03      0.000610      0.002934      0.032166      0.097107   \n",
       "403 -4.564773e-06      0.682007      3.488647     43.990662    144.007568   \n",
       "404 -9.614210e-05      0.483643      2.491272     29.993164    127.991882   \n",
       "405 -8.202424e-05      0.624697      3.223511     36.002594    143.991821   \n",
       "408 -1.174289e-04      0.719971      3.526123     51.981445    191.997528   \n",
       "409           NaN           NaN           NaN           NaN           NaN   \n",
       "410           NaN           NaN           NaN           NaN           NaN   \n",
       "412 -1.277678e-04      1.263855      6.480957     71.966553    207.990601   \n",
       "413           NaN           NaN           NaN           NaN           NaN   \n",
       "416 -3.889156e-03      0.000610      0.002930      0.031937      0.096313   \n",
       "417 -1.055490e-04      0.668457      3.262573     43.989807    144.009399   \n",
       "418 -2.697963e-04      0.479248      2.485840     28.020142    120.012390   \n",
       "419  5.542580e-06      0.612976      3.004028     35.998398    143.988342   \n",
       "422  1.360824e-04      0.721802      3.668144     51.974609    192.001785   \n",
       "423           NaN           NaN           NaN           NaN           NaN   \n",
       "424           NaN           NaN           NaN           NaN           NaN   \n",
       "426 -6.393679e-05      1.258545      6.489685     71.979492    207.998367   \n",
       "427           NaN           NaN           NaN           NaN           NaN   \n",
       "430 -3.039527e-03      0.000565      0.002869      0.030830      0.092896   \n",
       "431 -1.450413e-05      0.628754      3.246826     40.012817    144.003555   \n",
       "432 -2.074025e-04      0.444611      2.246552     27.978882    119.991455   \n",
       "433  2.426678e-04      0.565247      2.765137     32.015625    128.004211   \n",
       "436 -4.979322e-04      0.673218      3.286133     47.974609    176.025757   \n",
       "437           NaN           NaN           NaN           NaN           NaN   \n",
       "438           NaN           NaN           NaN           NaN           NaN   \n",
       "440  1.050658e-04      1.209961      5.997131     64.000008    192.031250   \n",
       "441           NaN           NaN           NaN           NaN           NaN   \n",
       "444 -1.364358e-03      0.000549      0.002808      0.030518      0.091797   \n",
       "445  2.298434e-05      0.622879      3.233643     40.007080    143.999985   \n",
       "446 -7.743487e-05      0.460754      2.257935     27.991882    119.977173   \n",
       "447  3.565793e-04      0.571045      2.984863     35.966553    128.001205   \n",
       "450 -1.855232e-04      0.660522      3.263916     48.004364    191.969849   \n",
       "451           NaN           NaN           NaN           NaN           NaN   \n",
       "452           NaN           NaN           NaN           NaN           NaN   \n",
       "454  1.101691e-04      1.261719      6.485657     71.975464    207.997055   \n",
       "455           NaN           NaN           NaN           NaN           NaN   \n",
       "458 -4.668207e-03      0.000549      0.002808      0.030457      0.091309   \n",
       "459  2.746141e-05      0.618427      3.012268     39.995605    143.999695   \n",
       "460  5.735542e-04      0.558792      2.754822     32.014160    143.977051   \n",
       "461 -5.084596e-05      0.617065      3.007172     35.997879    143.986267   \n",
       "464  8.414559e-05      0.581787      2.988281     44.045654    176.010742   \n",
       "465           NaN           NaN           NaN           NaN           NaN   \n",
       "466           NaN           NaN           NaN           NaN           NaN   \n",
       "468  3.946591e-04      1.266602      6.493195     71.980835    208.000824   \n",
       "469           NaN           NaN           NaN           NaN           NaN   \n",
       "472 -1.161391e-03      0.000534      0.002686      0.029602      0.088745   \n",
       "473  4.596278e-05      0.623199      3.237793     40.012573    144.003281   \n",
       "474  7.626922e-04      0.492065      2.499317     30.018188    128.008423   \n",
       "475 -1.157660e-04      0.610718      3.002182     35.993134    128.012451   \n",
       "478  2.040821e-04      0.602783      3.005890     36.035889    159.971313   \n",
       "479           NaN           NaN           NaN           NaN           NaN   \n",
       "480           NaN           NaN           NaN           NaN           NaN   \n",
       "482  5.324460e-05      1.266479      6.491821     71.980591    208.000214   \n",
       "483           NaN           NaN           NaN           NaN           NaN   \n",
       "486 -1.705085e-03      0.000549      0.002716      0.029480      0.088135   \n",
       "487 -2.073805e-04      0.555023      2.754578     36.006866    128.018677   \n",
       "488  5.241273e-04      0.500254      2.507050     31.976440    128.003845   \n",
       "489  3.337132e-04      0.502991      2.509155     30.007202    127.977539   \n",
       "492 -1.598460e-04      0.655762      3.261292     44.003860    176.000885   \n",
       "493           NaN           NaN           NaN           NaN           NaN   \n",
       "494           NaN           NaN           NaN           NaN           NaN   \n",
       "496  6.449795e-05      1.247299      6.033691     64.027588    207.979248   \n",
       "497           NaN           NaN           NaN           NaN           NaN   \n",
       "500  2.500160e-04      0.000519      0.002686      0.029297      0.087555   \n",
       "501  3.122127e-04      0.626183      3.246338     40.010071    143.990540   \n",
       "502  3.567025e-04      0.575989      2.988342     35.986511    143.991516   \n",
       "503  1.253908e-04      0.629395      3.240234     36.003799    128.012878   \n",
       "506  6.362249e-04      0.797241      3.980713     48.024414    192.001892   \n",
       "507           NaN           NaN           NaN           NaN           NaN   \n",
       "508           NaN           NaN           NaN           NaN           NaN   \n",
       "510  2.146558e-04      1.274536      6.499390     71.990662    208.004761   \n",
       "511           NaN           NaN           NaN           NaN           NaN   \n",
       "514  1.486029e-03      0.000508      0.002686      0.029022      0.086670   \n",
       "515 -3.376304e-04      0.610962      3.008484     40.004211    143.992798   \n",
       "516  6.383160e-04      0.556610      2.752640     32.003006    128.000900   \n",
       "517  6.608267e-04      0.620056      3.009399     35.999550    128.007019   \n",
       "520  2.381159e-04      0.667358      3.280151     43.994263    176.003540   \n",
       "521           NaN           NaN           NaN           NaN           NaN   \n",
       "522           NaN           NaN           NaN           NaN           NaN   \n",
       "524 -7.628865e-05      1.262846      6.489075     71.980103    208.004089   \n",
       "525           NaN           NaN           NaN           NaN           NaN   \n",
       "528  2.814621e-03      0.000488      0.002686      0.028809      0.086182   \n",
       "529  1.676418e-05      0.556915      2.761780     36.015503    128.010010   \n",
       "530  6.734787e-05      0.517822      2.731812     31.994019    128.004547   \n",
       "531  5.938404e-04      0.554260      2.748375     31.997894    127.991211   \n",
       "534 -6.406042e-04      0.614685      3.025146     40.012573    160.071289   \n",
       "535           NaN           NaN           NaN           NaN           NaN   \n",
       "536           NaN           NaN           NaN           NaN           NaN   \n",
       "538 -2.786990e-04      1.284668      6.504669     71.990234    208.010986   \n",
       "539           NaN           NaN           NaN           NaN           NaN   \n",
       "542  2.463521e-03      0.000488      0.002625      0.028381      0.084930   \n",
       "543 -4.554685e-04      0.561890      2.984741     39.986206    128.009094   \n",
       "544  1.008127e-03      0.548523      2.744934     32.002930    128.011230   \n",
       "545 -2.295087e-04      0.558771      2.752243     32.000149    127.988220   \n",
       "548 -8.030227e-04      0.594971      2.994995     36.044434    160.031982   \n",
       "549           NaN           NaN           NaN           NaN           NaN   \n",
       "550           NaN           NaN           NaN           NaN           NaN   \n",
       "552 -1.307745e-04      1.285645      6.502768     71.993652    208.003372   \n",
       "553           NaN           NaN           NaN           NaN           NaN   \n",
       "556  5.005906e-03      0.000488      0.002563      0.027771      0.082764   \n",
       "557  3.012657e-04      0.567902      2.994263     40.003403    143.994476   \n",
       "558  5.587788e-04      0.602173      2.998399     35.994904    128.019897   \n",
       "559  1.614659e-04      0.621674      3.016968     36.000328    128.007935   \n",
       "562  9.044335e-05      0.726318      3.595703     43.978394    175.999115   \n",
       "563           NaN           NaN           NaN           NaN           NaN   \n",
       "564           NaN           NaN           NaN           NaN           NaN   \n",
       "566 -3.062702e-04      1.142822      5.977295     63.982422    192.005890   \n",
       "567           NaN           NaN           NaN           NaN           NaN   \n",
       "570  6.643293e-03      0.000488      0.002480      0.026825      0.080078   \n",
       "571 -1.968005e-04      0.556549      2.762268     39.982788    128.003357   \n",
       "572  9.940417e-04      0.570557      2.982788     35.979248    128.014954   \n",
       "573  4.640776e-04      0.570679      2.984436     32.007996    120.009033   \n",
       "576  3.306607e-04      0.625412      3.045898     39.979614    175.965820   \n",
       "577           NaN           NaN           NaN           NaN           NaN   \n",
       "578           NaN           NaN           NaN           NaN           NaN   \n",
       "580 -1.208794e-04      1.297607      6.506775     71.993256    208.009338   \n",
       "581           NaN           NaN           NaN           NaN           NaN   \n",
       "584  5.908003e-03      0.000488      0.002441      0.026001      0.077759   \n",
       "585  6.766855e-05      0.552368      2.757599     39.984375    127.999840   \n",
       "586  9.604982e-04      0.565582      2.768921     35.968750    128.014160   \n",
       "587 -5.040774e-04      0.614357      3.003098     35.991760    127.986755   \n",
       "590 -5.134047e-05      0.688517      3.487366     47.945068    176.030762   \n",
       "591           NaN           NaN           NaN           NaN           NaN   \n",
       "592           NaN           NaN           NaN           NaN           NaN   \n",
       "594  1.197895e-04      1.354370      6.522461     71.999550    208.015747   \n",
       "595           NaN           NaN           NaN           NaN           NaN   \n",
       "598  5.312983e-03      0.000488      0.002384      0.025757      0.077026   \n",
       "599  2.549679e-05      0.499810      2.513611     35.989014    120.001884   \n",
       "600  1.381631e-04      0.557392      2.752533     32.012573    128.010315   \n",
       "601  3.172052e-04      0.574463      2.993896     32.012329    120.004944   \n",
       "604  5.291823e-04      0.583089      2.977539     36.021851    160.009460   \n",
       "605           NaN           NaN           NaN           NaN           NaN   \n",
       "606           NaN           NaN           NaN           NaN           NaN   \n",
       "608 -1.836349e-04      1.264893      6.490601     71.980103    207.997803   \n",
       "609           NaN           NaN           NaN           NaN           NaN   \n",
       "612  6.259082e-03      0.000488      0.002319      0.025391      0.075684   \n",
       "613  2.676618e-04      0.503769      2.739807     36.001610    120.012207   \n",
       "614  2.948609e-04      0.564148      2.762280     32.014038    128.004333   \n",
       "615 -6.348122e-05      0.617126      3.005371     35.988525    120.015137   \n",
       "618  4.083858e-04      0.842651      4.032227     48.025513    191.978149   \n",
       "619           NaN           NaN           NaN           NaN           NaN   \n",
       "620           NaN           NaN           NaN           NaN           NaN   \n",
       "622 -1.743136e-04      1.139343      5.971436     63.988464    207.962891   \n",
       "623           NaN           NaN           NaN           NaN           NaN   \n",
       "626  8.104665e-03      0.000488      0.002319      0.025330      0.075241   \n",
       "627  1.109678e-04      0.495667      2.511902     35.997787    127.983398   \n",
       "628  6.357791e-04      0.547546      2.744202     31.998016    128.001678   \n",
       "629  1.679831e-05      0.564117      2.759705     31.999149    119.997650   \n",
       "632 -9.910561e-04      0.635498      3.244751     39.982056    175.993958   \n",
       "633           NaN           NaN           NaN           NaN           NaN   \n",
       "634           NaN           NaN           NaN           NaN           NaN   \n",
       "636 -1.828451e-05      1.264648      6.486694     71.976807    207.996353   \n",
       "637           NaN           NaN           NaN           NaN           NaN   \n",
       "640  5.721314e-03      0.000465      0.002258      0.024097      0.071442   \n",
       "641  1.993600e-04      0.507660      2.739319     35.991455    127.993927   \n",
       "642  4.556970e-04      0.579468      2.993408     35.995239    143.993561   \n",
       "643 -3.289511e-04      0.556610      2.750534     31.993134    120.004333   \n",
       "646  6.761709e-04      0.581055      2.983276     36.001892    144.049561   \n",
       "647           NaN           NaN           NaN           NaN           NaN   \n",
       "648           NaN           NaN           NaN           NaN           NaN   \n",
       "650  3.964597e-04      1.244110      6.029785     64.021484    207.976685   \n",
       "651           NaN           NaN           NaN           NaN           NaN   \n",
       "654  4.338760e-03      0.000458      0.002197      0.023560      0.069824   \n",
       "655 -1.212179e-04      0.516602      2.749714     39.973511    143.992279   \n",
       "656  6.598887e-04      0.614563      3.006714     36.004059    144.005737   \n",
       "657 -2.742977e-05      0.616882      3.003830     35.991699    128.001282   \n",
       "660 -6.119655e-04      0.474365      2.467285     32.010681    143.998413   \n",
       "661           NaN           NaN           NaN           NaN           NaN   \n",
       "662           NaN           NaN           NaN           NaN           NaN   \n",
       "664  1.884710e-06      1.253776      6.474609     71.963623    207.992218   \n",
       "665           NaN           NaN           NaN           NaN           NaN   \n",
       "668  8.459683e-03      0.000427      0.002197      0.023491      0.069458   \n",
       "669 -1.642748e-04      0.559769      2.989624     40.000893    143.997330   \n",
       "670  7.506667e-04      0.612183      3.003387     36.003143    144.004578   \n",
       "671  3.700178e-04      0.613525      3.002823     35.989441    127.999931   \n",
       "674 -3.216275e-04      0.693319      3.495403     47.993896    191.999619   \n",
       "675           NaN           NaN           NaN           NaN           NaN   \n",
       "676           NaN           NaN           NaN           NaN           NaN   \n",
       "678  1.685682e-04      1.264465      6.495850     71.988403    207.998962   \n",
       "679           NaN           NaN           NaN           NaN           NaN   \n",
       "682  6.839227e-03      0.000427      0.002197      0.023519      0.069397   \n",
       "683  4.490079e-04      0.521317      2.753357     39.991760    143.997162   \n",
       "684  7.915903e-04      0.630280      3.238525     36.014771    144.008667   \n",
       "685 -4.251097e-04      0.620972      3.007544     35.992798    128.002625   \n",
       "688 -4.013054e-05      0.690928      3.497015     44.019165    176.009155   \n",
       "689           NaN           NaN           NaN           NaN           NaN   \n",
       "690           NaN           NaN           NaN           NaN           NaN   \n",
       "692 -1.167669e-04      1.255890      6.488159     71.981812    207.996201   \n",
       "693           NaN           NaN           NaN           NaN           NaN   \n",
       "696  5.296745e-03      0.000427      0.002102      0.022797      0.067383   \n",
       "697 -1.167812e-04      0.517456      2.748688     36.012329    143.991028   \n",
       "698  1.110060e-03      0.610413      3.004761     36.002411    144.005402   \n",
       "699  2.584271e-04      0.605957      2.998970     35.983398    127.995636   \n",
       "702  3.464538e-04      0.636658      3.230347     39.986267    175.991638   \n",
       "703           NaN           NaN           NaN           NaN           NaN   \n",
       "704           NaN           NaN           NaN           NaN           NaN   \n",
       "706  2.196512e-04      1.249262      6.046143     64.031738    207.981079   \n",
       "707           NaN           NaN           NaN           NaN           NaN   \n",
       "710  6.245933e-03      0.000427      0.002075      0.022339      0.065796   \n",
       "711  4.448465e-05      0.559662      2.993866     40.010132    144.004913   \n",
       "712  9.679577e-04      0.607666      3.001869     36.001144    144.001587   \n",
       "713  1.663517e-05      0.645874      3.253784     36.008606    128.009705   \n",
       "716 -1.388629e-04      0.687287      3.481445     43.978149    160.019897   \n",
       "717           NaN           NaN           NaN           NaN           NaN   \n",
       "718           NaN           NaN           NaN           NaN           NaN   \n",
       "720 -6.724389e-04      1.256500      6.479736     71.973999    208.000305   \n",
       "721           NaN           NaN           NaN           NaN           NaN   \n",
       "724  8.420032e-03      0.000424      0.002045      0.021973      0.064800   \n",
       "725  7.916406e-05      0.513367      2.745636     36.005402    143.993927   \n",
       "726  6.921013e-04      0.624485      3.031494     36.005768    144.006348   \n",
       "727 -2.343239e-04      0.631744      3.246155     36.006409    128.019897   \n",
       "730 -1.291276e-04      0.723022      3.531738     47.992218    191.977051   \n",
       "731           NaN           NaN           NaN           NaN           NaN   \n",
       "732           NaN           NaN           NaN           NaN           NaN   \n",
       "734 -4.726739e-04      1.237000      6.007996     64.009338    207.970581   \n",
       "735           NaN           NaN           NaN           NaN           NaN   \n",
       "738  4.248821e-03      0.000381      0.001953      0.021164      0.062225   \n",
       "739  9.990737e-06      0.503708      2.740845     36.002350    143.984131   \n",
       "740 -2.644935e-06      0.616882      3.008850     36.002029    144.002167   \n",
       "741 -3.452895e-04      0.626836      3.239502     36.000782    128.005127   \n",
       "744  7.146989e-04      0.739604      3.740662     51.950928    191.978394   \n",
       "745           NaN           NaN           NaN           NaN           NaN   \n",
       "746           NaN           NaN           NaN           NaN           NaN   \n",
       "748  3.619854e-04      1.109558      5.497147     60.001022    191.996735   \n",
       "749           NaN           NaN           NaN           NaN           NaN   \n",
       "752  6.406918e-03      0.000366      0.001892      0.020386      0.060303   \n",
       "753  1.521224e-04      0.563644      2.966797     36.025391    143.990356   \n",
       "754 -3.153391e-04      0.618896      3.010681     36.001839    144.007507   \n",
       "755  2.035016e-04      0.636353      3.249995     36.007721    128.018433   \n",
       "758 -4.158668e-04      0.690430      3.494690     44.027344    176.030762   \n",
       "759           NaN           NaN           NaN           NaN           NaN   \n",
       "760           NaN           NaN           NaN           NaN           NaN   \n",
       "762  4.707460e-04      1.250813      6.477905     71.977783    208.000305   \n",
       "763           NaN           NaN           NaN           NaN           NaN   \n",
       "766  3.614819e-03      0.000366      0.001892      0.020304      0.059814   \n",
       "767  3.031318e-04      0.580322      3.000080     39.988708    143.977539   \n",
       "768  4.090447e-04      0.639404      3.249382     36.044189    144.021973   \n",
       "769  9.467788e-05      0.736816      3.524048     40.006012    143.998444   \n",
       "772  1.034701e-04      0.617371      3.022705     43.984619    175.991760   \n",
       "773           NaN           NaN           NaN           NaN           NaN   \n",
       "774           NaN           NaN           NaN           NaN           NaN   \n",
       "776  1.683750e-04      1.244904      6.011108     64.009460    207.978394   \n",
       "777           NaN           NaN           NaN           NaN           NaN   \n",
       "780  5.722261e-03      0.000366      0.001823      0.019470      0.057434   \n",
       "781  3.149825e-04      0.581421      2.998650     39.977539    143.992401   \n",
       "782  6.087371e-04      0.676636      3.275024     39.989685    144.148438   \n",
       "783  3.576197e-07      0.751625      3.751640     43.987427    144.005005   \n",
       "786 -1.948271e-04      0.839844      4.023926     51.974976    191.986206   \n",
       "787           NaN           NaN           NaN           NaN           NaN   \n",
       "788           NaN           NaN           NaN           NaN           NaN   \n",
       "790 -2.287797e-04      1.240295      6.008118     64.011169    207.988342   \n",
       "791           NaN           NaN           NaN           NaN           NaN   \n",
       "794  4.758421e-03      0.000366      0.001770      0.019104      0.056396   \n",
       "795 -6.697464e-04      0.563644      2.764221     36.002304    143.984741   \n",
       "796 -2.178474e-04      0.683075      3.478271     39.994385    144.045410   \n",
       "797 -1.234664e-04      0.761780      3.763062     43.993744    144.010803   \n",
       "800 -7.203819e-05      0.901611      4.501552     48.033936    160.017578   \n",
       "801           NaN           NaN           NaN           NaN           NaN   \n",
       "802           NaN           NaN           NaN           NaN           NaN   \n",
       "804  1.265295e-04      1.112183      5.495941     60.008240    192.019165   \n",
       "805           NaN           NaN           NaN           NaN           NaN   \n",
       "808 -4.413895e-04      0.000366      0.001766      0.018860      0.055847   \n",
       "809 -5.179914e-05      0.554565      2.748894     35.991272    128.015320   \n",
       "810 -4.600205e-05      0.692657      3.496948     40.000343    144.031738   \n",
       "811 -2.049523e-04      0.740906      3.738159     40.012207    143.998077   \n",
       "814  3.001667e-04      1.113342      5.498935     60.005157    191.996811   \n",
       "815           NaN           NaN           NaN           NaN           NaN   \n",
       "816           NaN           NaN           NaN           NaN           NaN   \n",
       "818  3.565136e-04      0.874409      4.491394     48.009338    175.995361   \n",
       "819           NaN           NaN           NaN           NaN           NaN   \n",
       "822  4.939766e-04      0.000336      0.001672      0.017944      0.053589   \n",
       "823  1.326976e-04      0.524170      2.735413     31.995209    127.991577   \n",
       "824 -2.693519e-04      0.635498      3.244934     36.005493    143.972412   \n",
       "825  2.533953e-04      0.643799      3.253448     36.003189    127.987244   \n",
       "828  2.690325e-04      0.843506      4.031494     47.995789    175.967529   \n",
       "829           NaN           NaN           NaN           NaN           NaN   \n",
       "830           NaN           NaN           NaN           NaN           NaN   \n",
       "832  3.124934e-04      1.134583      5.964355     63.988464    192.023682   \n",
       "833           NaN           NaN           NaN           NaN           NaN   \n",
       "836 -3.187038e-03      0.000366      0.001801      0.019516      0.059937   \n",
       "837 -1.557488e-04      0.349304      1.750744     23.991455    112.002792   \n",
       "838  5.894285e-05      0.676636      3.275879     36.020386    143.978149   \n",
       "839 -2.670212e-05      0.566742      2.766113     31.987305    119.986084   \n",
       "842  2.658626e-06      1.008301      5.012756     56.009583    191.912109   \n",
       "843           NaN           NaN           NaN           NaN           NaN   \n",
       "844           NaN           NaN           NaN           NaN           NaN   \n",
       "846 -8.692507e-05      0.739685      3.735413     43.985229    160.017212   \n",
       "847           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     q99_abs_diff  spec_rel_l2_err                        spec_a_max  \\\n",
       "1      143.996338      7188.874512  tensor(10.6355, device='cuda:0')   \n",
       "2       79.999825      4124.767578  tensor(42.7907, device='cuda:0')   \n",
       "3      176.000168     11464.057617   tensor(9.5120, device='cuda:0')   \n",
       "6      239.989075      3335.079834  tensor(10.8030, device='cuda:0')   \n",
       "7             NaN              NaN                               NaN   \n",
       "8             NaN              NaN                               NaN   \n",
       "10     255.995758      9015.641602  tensor(13.7596, device='cuda:0')   \n",
       "11            NaN              NaN                               NaN   \n",
       "13     104.000656     10030.518555  tensor(14.0962, device='cuda:0')   \n",
       "14     111.999542      5958.773926  tensor(39.3205, device='cuda:0')   \n",
       "15     143.999527     16530.671875   tensor(8.9352, device='cuda:0')   \n",
       "18     208.010315      4173.245117   tensor(8.2266, device='cuda:0')   \n",
       "19            NaN              NaN                               NaN   \n",
       "20            NaN              NaN                               NaN   \n",
       "22     176.004730      9860.308594   tensor(7.4074, device='cuda:0')   \n",
       "23            NaN              NaN                               NaN   \n",
       "25      87.996933      7226.452637  tensor(15.4160, device='cuda:0')   \n",
       "26      71.999466      4203.634766  tensor(36.6742, device='cuda:0')   \n",
       "27     112.000687     11360.679688   tensor(9.6203, device='cuda:0')   \n",
       "30     191.986572      3536.529297   tensor(9.8898, device='cuda:0')   \n",
       "31            NaN              NaN                               NaN   \n",
       "32            NaN              NaN                               NaN   \n",
       "34     192.003342      8082.446777   tensor(7.6048, device='cuda:0')   \n",
       "35            NaN              NaN                               NaN   \n",
       "38       0.091064         0.250704  tensor(10.6866, device='cuda:0')   \n",
       "39     192.008850      8433.610352   tensor(8.8674, device='cuda:0')   \n",
       "40     223.995483      7353.974121  tensor(25.5352, device='cuda:0')   \n",
       "41     255.998505     13875.400391   tensor(5.3848, device='cuda:0')   \n",
       "44     224.016846      4071.075928  tensor(11.2872, device='cuda:0')   \n",
       "45            NaN              NaN                               NaN   \n",
       "46            NaN              NaN                               NaN   \n",
       "48     208.007111      5945.157715   tensor(5.8989, device='cuda:0')   \n",
       "49            NaN              NaN                               NaN   \n",
       "52       0.111084         0.065179  tensor(18.2650, device='cuda:0')   \n",
       "53     207.994507      8050.613770   tensor(6.2823, device='cuda:0')   \n",
       "54     176.067383      3748.627930  tensor(50.2790, device='cuda:0')   \n",
       "55     255.986877     11313.096680   tensor(4.1486, device='cuda:0')   \n",
       "58     239.970703      4437.705078   tensor(7.6429, device='cuda:0')   \n",
       "59            NaN              NaN                               NaN   \n",
       "60            NaN              NaN                               NaN   \n",
       "62     240.010193      9650.624023   tensor(7.6605, device='cuda:0')   \n",
       "63            NaN              NaN                               NaN   \n",
       "66       0.131348         0.062820  tensor(20.6921, device='cuda:0')   \n",
       "67     207.996582      7979.346191   tensor(5.5833, device='cuda:0')   \n",
       "68     191.994537      3490.273682  tensor(53.9900, device='cuda:0')   \n",
       "69     239.998718      9870.957031   tensor(3.6562, device='cuda:0')   \n",
       "72     223.992340      3195.761475   tensor(7.4591, device='cuda:0')   \n",
       "73            NaN              NaN                               NaN   \n",
       "74            NaN              NaN                               NaN   \n",
       "76     240.001343      7486.018555   tensor(7.4348, device='cuda:0')   \n",
       "77            NaN              NaN                               NaN   \n",
       "80       0.143066         0.134935  tensor(21.5354, device='cuda:0')   \n",
       "81     207.999298      7539.156738   tensor(6.2277, device='cuda:0')   \n",
       "82     208.000977      3174.354004  tensor(59.3648, device='cuda:0')   \n",
       "83     239.997330      8869.392578   tensor(3.4186, device='cuda:0')   \n",
       "86     255.988953      4641.583496   tensor(8.6704, device='cuda:0')   \n",
       "87            NaN              NaN                               NaN   \n",
       "88            NaN              NaN                               NaN   \n",
       "90     240.002960      8290.015625   tensor(8.0057, device='cuda:0')   \n",
       "91            NaN              NaN                               NaN   \n",
       "94       0.165039         0.113337  tensor(29.2355, device='cuda:0')   \n",
       "95     208.012329      8033.922363   tensor(5.3051, device='cuda:0')   \n",
       "96     223.989624      2904.607422  tensor(68.4619, device='cuda:0')   \n",
       "97     224.006592      8118.274414   tensor(3.3527, device='cuda:0')   \n",
       "100    240.047607      3582.825928   tensor(7.8193, device='cuda:0')   \n",
       "101           NaN              NaN                               NaN   \n",
       "102           NaN              NaN                               NaN   \n",
       "104    255.989624      6450.762207   tensor(7.2695, device='cuda:0')   \n",
       "105           NaN              NaN                               NaN   \n",
       "108      0.163086         0.182524  tensor(30.0838, device='cuda:0')   \n",
       "109    192.008850      6222.487305   tensor(4.5972, device='cuda:0')   \n",
       "110    224.015503      2672.982910  tensor(77.3653, device='cuda:0')   \n",
       "111    224.013000      7278.065430   tensor(3.2951, device='cuda:0')   \n",
       "114    224.022705      3363.019775   tensor(7.9007, device='cuda:0')   \n",
       "115           NaN              NaN                               NaN   \n",
       "116           NaN              NaN                               NaN   \n",
       "118    240.016113      6281.029297   tensor(7.2231, device='cuda:0')   \n",
       "119           NaN              NaN                               NaN   \n",
       "122      0.160400         0.140180  tensor(30.2342, device='cuda:0')   \n",
       "123    208.003082      6141.354492   tensor(4.7362, device='cuda:0')   \n",
       "124    223.992004      2443.913330  tensor(79.9523, device='cuda:0')   \n",
       "125    223.983276      6431.841797   tensor(2.9016, device='cuda:0')   \n",
       "128    240.064941      3907.441895   tensor(8.9111, device='cuda:0')   \n",
       "129           NaN              NaN                               NaN   \n",
       "130           NaN              NaN                               NaN   \n",
       "132    256.013733      7575.843262   tensor(6.7645, device='cuda:0')   \n",
       "133           NaN              NaN                               NaN   \n",
       "136      0.163010         0.099659  tensor(31.0215, device='cuda:0')   \n",
       "137    208.006927      5825.145508   tensor(5.2519, device='cuda:0')   \n",
       "138    224.000320      2240.567139  tensor(84.5384, device='cuda:0')   \n",
       "139    208.005646      6023.332520   tensor(3.1104, device='cuda:0')   \n",
       "142    255.968506      3568.109131   tensor(8.8456, device='cuda:0')   \n",
       "143           NaN              NaN                               NaN   \n",
       "144           NaN              NaN                               NaN   \n",
       "146    256.017578      7427.973145   tensor(8.3540, device='cuda:0')   \n",
       "147           NaN              NaN                               NaN   \n",
       "150      0.166016         0.103013  tensor(32.5306, device='cuda:0')   \n",
       "151    208.000015      5965.989746   tensor(4.3905, device='cuda:0')   \n",
       "152    224.000977      2186.717773  tensor(87.7969, device='cuda:0')   \n",
       "153    207.999374      5932.769043   tensor(2.9041, device='cuda:0')   \n",
       "156    256.023560      3792.199707   tensor(9.5055, device='cuda:0')   \n",
       "157           NaN              NaN                               NaN   \n",
       "158           NaN              NaN                               NaN   \n",
       "160    256.008057      5828.459961   tensor(9.0627, device='cuda:0')   \n",
       "161           NaN              NaN                               NaN   \n",
       "164      0.161865         0.114990  tensor(32.7956, device='cuda:0')   \n",
       "165    223.994385      5861.134766   tensor(4.6922, device='cuda:0')   \n",
       "166    224.009094      2414.261230  tensor(80.0076, device='cuda:0')   \n",
       "167    208.008850      5759.628906   tensor(3.0871, device='cuda:0')   \n",
       "170    255.989197      3687.999512   tensor(9.6809, device='cuda:0')   \n",
       "171           NaN              NaN                               NaN   \n",
       "172           NaN              NaN                               NaN   \n",
       "174    256.000092      6378.625488   tensor(7.8997, device='cuda:0')   \n",
       "175           NaN              NaN                               NaN   \n",
       "178      0.162964         0.148590  tensor(34.3094, device='cuda:0')   \n",
       "179    223.966553      5935.464355   tensor(5.1420, device='cuda:0')   \n",
       "180    208.006439      2457.090332  tensor(69.9281, device='cuda:0')   \n",
       "181    207.999573      5744.305664   tensor(3.1006, device='cuda:0')   \n",
       "184    256.006226      3660.708008   tensor(8.8461, device='cuda:0')   \n",
       "185           NaN              NaN                               NaN   \n",
       "186           NaN              NaN                               NaN   \n",
       "188    256.007629      5533.782227   tensor(9.2524, device='cuda:0')   \n",
       "189           NaN              NaN                               NaN   \n",
       "192      0.161591         0.184687  tensor(35.1854, device='cuda:0')   \n",
       "193    192.010742      5797.519531   tensor(5.1990, device='cuda:0')   \n",
       "194    159.990173      1832.239746  tensor(73.2654, device='cuda:0')   \n",
       "195    191.996231      5423.809570   tensor(3.3358, device='cuda:0')   \n",
       "198    256.025513      3696.920654   tensor(9.7541, device='cuda:0')   \n",
       "199           NaN              NaN                               NaN   \n",
       "200           NaN              NaN                               NaN   \n",
       "202    256.015137      5062.698730   tensor(8.2211, device='cuda:0')   \n",
       "203           NaN              NaN                               NaN   \n",
       "206      0.159729         0.222280  tensor(35.2729, device='cuda:0')   \n",
       "207    191.990845      5391.880859   tensor(5.1456, device='cuda:0')   \n",
       "208    159.937012      2009.329468  tensor(65.6767, device='cuda:0')   \n",
       "209    191.986328      5422.176270   tensor(3.1881, device='cuda:0')   \n",
       "212    256.044678      3770.162354   tensor(9.7458, device='cuda:0')   \n",
       "213           NaN              NaN                               NaN   \n",
       "214           NaN              NaN                               NaN   \n",
       "216    256.025513      4826.617676   tensor(8.8077, device='cuda:0')   \n",
       "217           NaN              NaN                               NaN   \n",
       "220      0.158447         0.179377  tensor(34.8382, device='cuda:0')   \n",
       "221    192.014282      5567.040039   tensor(5.0391, device='cuda:0')   \n",
       "222    104.011292      1729.790527  tensor(62.4396, device='cuda:0')   \n",
       "223    191.994934      5214.052734   tensor(2.9875, device='cuda:0')   \n",
       "226    256.014648      3895.725586   tensor(7.9838, device='cuda:0')   \n",
       "227           NaN              NaN                               NaN   \n",
       "228           NaN              NaN                               NaN   \n",
       "230    287.971436      5609.116211   tensor(8.4884, device='cuda:0')   \n",
       "231           NaN              NaN                               NaN   \n",
       "234      0.157227         0.215808  tensor(35.2901, device='cuda:0')   \n",
       "235    207.968506      5860.645996   tensor(5.2692, device='cuda:0')   \n",
       "236    175.998718      2513.658447  tensor(60.2398, device='cuda:0')   \n",
       "237    207.982422      6005.924316   tensor(3.2789, device='cuda:0')   \n",
       "240    240.007263      3257.300537   tensor(9.2863, device='cuda:0')   \n",
       "241           NaN              NaN                               NaN   \n",
       "242           NaN              NaN                               NaN   \n",
       "244    256.021118      4928.490234  tensor(10.0527, device='cuda:0')   \n",
       "245           NaN              NaN                               NaN   \n",
       "248      0.154053         0.243457  tensor(35.2985, device='cuda:0')   \n",
       "249    192.002701      5522.009766   tensor(5.7537, device='cuda:0')   \n",
       "250    160.004303      2555.861328  tensor(55.2427, device='cuda:0')   \n",
       "251    192.005432      5698.498535   tensor(3.3285, device='cuda:0')   \n",
       "254    256.009949      3730.482666   tensor(9.7517, device='cuda:0')   \n",
       "255           NaN              NaN                               NaN   \n",
       "256           NaN              NaN                               NaN   \n",
       "258    287.977295      6015.132324   tensor(8.9557, device='cuda:0')   \n",
       "259           NaN              NaN                               NaN   \n",
       "262      0.153564         0.276404  tensor(34.6667, device='cuda:0')   \n",
       "263    191.998077      4970.740723   tensor(5.7697, device='cuda:0')   \n",
       "264    160.028320      2466.726562  tensor(62.3582, device='cuda:0')   \n",
       "265    191.998138      5078.368652   tensor(3.4392, device='cuda:0')   \n",
       "268    256.026123      3597.247070   tensor(9.0024, device='cuda:0')   \n",
       "269           NaN              NaN                               NaN   \n",
       "270           NaN              NaN                               NaN   \n",
       "272    287.981934      5085.660156   tensor(9.8001, device='cuda:0')   \n",
       "273           NaN              NaN                               NaN   \n",
       "276      0.152100         0.257446  tensor(35.0667, device='cuda:0')   \n",
       "277    207.991699      5482.394043   tensor(6.1783, device='cuda:0')   \n",
       "278    176.023193      2842.921387  tensor(55.7006, device='cuda:0')   \n",
       "279    207.953613      5635.711426   tensor(3.4504, device='cuda:0')   \n",
       "282    256.019531      3643.032227  tensor(10.0985, device='cuda:0')   \n",
       "283           NaN              NaN                               NaN   \n",
       "284           NaN              NaN                               NaN   \n",
       "286    287.992310      6047.041504   tensor(8.7619, device='cuda:0')   \n",
       "287           NaN              NaN                               NaN   \n",
       "290      0.147583         0.287414  tensor(34.0958, device='cuda:0')   \n",
       "291    223.992554      5402.047363   tensor(7.2430, device='cuda:0')   \n",
       "292    192.013550      3260.158447  tensor(52.5615, device='cuda:0')   \n",
       "293    208.004974      5494.527344   tensor(4.5010, device='cuda:0')   \n",
       "296    256.009705      3661.629395   tensor(9.3704, device='cuda:0')   \n",
       "297           NaN              NaN                               NaN   \n",
       "298           NaN              NaN                               NaN   \n",
       "300    287.991150      6077.812500   tensor(9.5468, device='cuda:0')   \n",
       "301           NaN              NaN                               NaN   \n",
       "304      0.147339         0.324428  tensor(35.0970, device='cuda:0')   \n",
       "305    192.008179      5100.184082   tensor(7.1026, device='cuda:0')   \n",
       "306    191.995178      3289.649902  tensor(49.3033, device='cuda:0')   \n",
       "307    192.010803      5295.571777   tensor(3.8287, device='cuda:0')   \n",
       "310    255.986328      3393.353027   tensor(9.2986, device='cuda:0')   \n",
       "311           NaN              NaN                               NaN   \n",
       "312           NaN              NaN                               NaN   \n",
       "314    287.989746      5352.112305   tensor(9.9913, device='cuda:0')   \n",
       "315           NaN              NaN                               NaN   \n",
       "318      0.142822         0.366428  tensor(35.0660, device='cuda:0')   \n",
       "319    207.991394      5225.451660   tensor(7.7590, device='cuda:0')   \n",
       "320    192.015442      3704.261963  tensor(42.5599, device='cuda:0')   \n",
       "321    192.007874      5125.369141   tensor(3.8526, device='cuda:0')   \n",
       "324    256.010437      3609.004150   tensor(8.9584, device='cuda:0')   \n",
       "325           NaN              NaN                               NaN   \n",
       "326           NaN              NaN                               NaN   \n",
       "328    287.988403      5227.149414   tensor(8.8887, device='cuda:0')   \n",
       "329           NaN              NaN                               NaN   \n",
       "332      0.140625         0.377728  tensor(34.5209, device='cuda:0')   \n",
       "333    207.990845      5531.844727   tensor(7.1540, device='cuda:0')   \n",
       "334    192.003601      3722.689941  tensor(40.0021, device='cuda:0')   \n",
       "335    191.999283      5107.795410   tensor(4.1000, device='cuda:0')   \n",
       "338    255.991211      3325.903809   tensor(9.0232, device='cuda:0')   \n",
       "339           NaN              NaN                               NaN   \n",
       "340           NaN              NaN                               NaN   \n",
       "342    287.985779      4621.634277   tensor(9.7990, device='cuda:0')   \n",
       "343           NaN              NaN                               NaN   \n",
       "346      0.138062         0.368356  tensor(34.1422, device='cuda:0')   \n",
       "347    207.997833      6006.755371   tensor(7.7261, device='cuda:0')   \n",
       "348    191.924805      3739.360107  tensor(33.1355, device='cuda:0')   \n",
       "349    191.999146      5378.153320   tensor(4.0144, device='cuda:0')   \n",
       "352    240.024902      3187.085205   tensor(8.6951, device='cuda:0')   \n",
       "353           NaN              NaN                               NaN   \n",
       "354           NaN              NaN                               NaN   \n",
       "356    287.985107      4844.363770   tensor(9.5217, device='cuda:0')   \n",
       "357           NaN              NaN                               NaN   \n",
       "360      0.137451         0.362165  tensor(33.0655, device='cuda:0')   \n",
       "361    207.998383      5815.586914   tensor(7.2302, device='cuda:0')   \n",
       "362    191.988953      3827.705811  tensor(33.1488, device='cuda:0')   \n",
       "363    192.013916      5407.208984   tensor(4.4266, device='cuda:0')   \n",
       "366    255.992615      3452.196289   tensor(8.3758, device='cuda:0')   \n",
       "367           NaN              NaN                               NaN   \n",
       "368           NaN              NaN                               NaN   \n",
       "370    287.983643      4965.174805   tensor(9.8549, device='cuda:0')   \n",
       "371           NaN              NaN                               NaN   \n",
       "374      0.136475         0.369740  tensor(33.8981, device='cuda:0')   \n",
       "375    223.986206      6919.095215   tensor(7.0887, device='cuda:0')   \n",
       "376    192.003677      4662.889160  tensor(19.3714, device='cuda:0')   \n",
       "377    207.998749      6302.318359   tensor(3.8445, device='cuda:0')   \n",
       "380    240.003448      3310.805420   tensor(8.8982, device='cuda:0')   \n",
       "381           NaN              NaN                               NaN   \n",
       "382           NaN              NaN                               NaN   \n",
       "384    256.023438      4801.417480   tensor(9.1859, device='cuda:0')   \n",
       "385           NaN              NaN                               NaN   \n",
       "388      0.133423         0.380730  tensor(32.8058, device='cuda:0')   \n",
       "389    223.977173      5907.347168   tensor(6.9771, device='cuda:0')   \n",
       "390    176.018311      3736.301514  tensor(32.0362, device='cuda:0')   \n",
       "391    207.995758      5502.916504   tensor(6.1927, device='cuda:0')   \n",
       "394    255.999542      3459.086670   tensor(7.8490, device='cuda:0')   \n",
       "395           NaN              NaN                               NaN   \n",
       "396           NaN              NaN                               NaN   \n",
       "398    287.986694      4856.841797  tensor(11.3470, device='cuda:0')   \n",
       "399           NaN              NaN                               NaN   \n",
       "402      0.133789         0.377681  tensor(33.5202, device='cuda:0')   \n",
       "403    208.014832      5905.577148   tensor(6.5437, device='cuda:0')   \n",
       "404    192.003510      4230.649414  tensor(25.9776, device='cuda:0')   \n",
       "405    207.997772      5591.329590   tensor(4.6236, device='cuda:0')   \n",
       "408    256.011292      3537.553711   tensor(8.9488, device='cuda:0')   \n",
       "409           NaN              NaN                               NaN   \n",
       "410           NaN              NaN                               NaN   \n",
       "412    287.968018      4329.193359  tensor(10.5468, device='cuda:0')   \n",
       "413           NaN              NaN                               NaN   \n",
       "416      0.132568         0.368324  tensor(33.2472, device='cuda:0')   \n",
       "417    208.012390      5943.116699   tensor(6.9730, device='cuda:0')   \n",
       "418    191.995361      3982.486084  tensor(25.8032, device='cuda:0')   \n",
       "419    207.992432      5525.297363   tensor(4.9741, device='cuda:0')   \n",
       "422    256.014282      3955.901123   tensor(8.3059, device='cuda:0')   \n",
       "423           NaN              NaN                               NaN   \n",
       "424           NaN              NaN                               NaN   \n",
       "426    287.980591      4940.126465   tensor(9.8437, device='cuda:0')   \n",
       "427           NaN              NaN                               NaN   \n",
       "430      0.127930         0.375026  tensor(31.9272, device='cuda:0')   \n",
       "431    208.011047      5959.095215   tensor(7.8461, device='cuda:0')   \n",
       "432    176.019653      4016.382324  tensor(24.5433, device='cuda:0')   \n",
       "433    192.015625      5376.119141   tensor(4.7539, device='cuda:0')   \n",
       "436    255.984680      3580.065430   tensor(8.1744, device='cuda:0')   \n",
       "437           NaN              NaN                               NaN   \n",
       "438           NaN              NaN                               NaN   \n",
       "440    256.021973      4604.652832   tensor(9.5801, device='cuda:0')   \n",
       "441           NaN              NaN                               NaN   \n",
       "444      0.125977         0.381333  tensor(31.3766, device='cuda:0')   \n",
       "445    208.004059      5598.126465   tensor(7.7607, device='cuda:0')   \n",
       "446    176.010315      3915.739746  tensor(26.6882, device='cuda:0')   \n",
       "447    192.008362      5109.399414   tensor(5.6837, device='cuda:0')   \n",
       "450    255.994751      3668.151367   tensor(8.2013, device='cuda:0')   \n",
       "451           NaN              NaN                               NaN   \n",
       "452           NaN              NaN                               NaN   \n",
       "454    287.977539      4658.727051  tensor(11.5208, device='cuda:0')   \n",
       "455           NaN              NaN                               NaN   \n",
       "458      0.125244         0.347193  tensor(31.0485, device='cuda:0')   \n",
       "459    208.039307      5435.884766   tensor(7.9644, device='cuda:0')   \n",
       "460    207.990723      4579.685547  tensor(26.8722, device='cuda:0')   \n",
       "461    208.003204      5242.381348   tensor(5.4867, device='cuda:0')   \n",
       "464    255.972412      3266.143555   tensor(8.9086, device='cuda:0')   \n",
       "465           NaN              NaN                               NaN   \n",
       "466           NaN              NaN                               NaN   \n",
       "468    287.981689      4524.863281  tensor(11.6431, device='cuda:0')   \n",
       "469           NaN              NaN                               NaN   \n",
       "472      0.121582         0.364697  tensor(30.8367, device='cuda:0')   \n",
       "473    223.985962      5643.068359   tensor(8.3418, device='cuda:0')   \n",
       "474    207.977051      4396.266602  tensor(25.4881, device='cuda:0')   \n",
       "475    207.992279      5275.293945   tensor(5.2782, device='cuda:0')   \n",
       "478    224.009644      2780.947510   tensor(9.3380, device='cuda:0')   \n",
       "479           NaN              NaN                               NaN   \n",
       "480           NaN              NaN                               NaN   \n",
       "482    287.979736      4452.117676  tensor(11.5594, device='cuda:0')   \n",
       "483           NaN              NaN                               NaN   \n",
       "486      0.120117         0.367555  tensor(31.0071, device='cuda:0')   \n",
       "487    207.999466      5341.897461   tensor(7.7318, device='cuda:0')   \n",
       "488    192.018799      4402.905762  tensor(23.6224, device='cuda:0')   \n",
       "489    192.002441      4842.175781   tensor(4.7177, device='cuda:0')   \n",
       "492    255.961670      3177.235840   tensor(8.8309, device='cuda:0')   \n",
       "493           NaN              NaN                               NaN   \n",
       "494           NaN              NaN                               NaN   \n",
       "496    256.057861      4389.505371  tensor(11.2047, device='cuda:0')   \n",
       "497           NaN              NaN                               NaN   \n",
       "500      0.119385         0.351707  tensor(30.7420, device='cuda:0')   \n",
       "501    207.996735      5593.243652   tensor(8.2205, device='cuda:0')   \n",
       "502    208.000931      4598.679199  tensor(24.5210, device='cuda:0')   \n",
       "503    192.026733      5162.035156   tensor(4.9976, device='cuda:0')   \n",
       "506    256.016235      3919.500244   tensor(9.8191, device='cuda:0')   \n",
       "507           NaN              NaN                               NaN   \n",
       "508           NaN              NaN                               NaN   \n",
       "510    287.989929      5456.511719   tensor(9.6462, device='cuda:0')   \n",
       "511           NaN              NaN                               NaN   \n",
       "514      0.118042         0.374111  tensor(30.6554, device='cuda:0')   \n",
       "515    192.032715      5719.911621   tensor(7.8940, device='cuda:0')   \n",
       "516    192.006592      4426.887207  tensor(20.2097, device='cuda:0')   \n",
       "517    192.003510      5286.512207   tensor(5.2806, device='cuda:0')   \n",
       "520    255.916626      3393.037842   tensor(9.4039, device='cuda:0')   \n",
       "521           NaN              NaN                               NaN   \n",
       "522           NaN              NaN                               NaN   \n",
       "524    287.987915      4842.937500  tensor(10.1458, device='cuda:0')   \n",
       "525           NaN              NaN                               NaN   \n",
       "528      0.117554         0.367954  tensor(30.5340, device='cuda:0')   \n",
       "529    192.006805      5451.593262   tensor(7.8431, device='cuda:0')   \n",
       "530    192.015137      4542.125488  tensor(15.9921, device='cuda:0')   \n",
       "531    191.993317      5032.910645   tensor(4.8418, device='cuda:0')   \n",
       "534    239.993317      3142.317871   tensor(9.3497, device='cuda:0')   \n",
       "535           NaN              NaN                               NaN   \n",
       "536           NaN              NaN                               NaN   \n",
       "538    287.990723      4632.876953  tensor(10.6944, device='cuda:0')   \n",
       "539           NaN              NaN                               NaN   \n",
       "542      0.115723         0.398269  tensor(30.3129, device='cuda:0')   \n",
       "543    192.027710      5469.806152   tensor(8.6974, device='cuda:0')   \n",
       "544    192.023438      4531.298828  tensor(19.2652, device='cuda:0')   \n",
       "545    191.997543      4905.114746   tensor(5.4738, device='cuda:0')   \n",
       "548    240.004547      3709.876953   tensor(9.3570, device='cuda:0')   \n",
       "549           NaN              NaN                               NaN   \n",
       "550           NaN              NaN                               NaN   \n",
       "552    287.989502      5916.671875   tensor(9.3080, device='cuda:0')   \n",
       "553           NaN              NaN                               NaN   \n",
       "556      0.112549         0.382855  tensor(29.5503, device='cuda:0')   \n",
       "557    207.986816      5659.797363   tensor(8.8600, device='cuda:0')   \n",
       "558    207.981934      4732.380371  tensor(16.9001, device='cuda:0')   \n",
       "559    192.004944      5159.297363   tensor(5.2259, device='cuda:0')   \n",
       "562    255.977539      3258.782959   tensor(9.1720, device='cuda:0')   \n",
       "563           NaN              NaN                               NaN   \n",
       "564           NaN              NaN                               NaN   \n",
       "566    256.007019      4185.813965  tensor(11.0167, device='cuda:0')   \n",
       "567           NaN              NaN                               NaN   \n",
       "570      0.108887         0.374974  tensor(27.9507, device='cuda:0')   \n",
       "571    192.002640      5489.632324   tensor(8.2664, device='cuda:0')   \n",
       "572    207.982422      4895.223145  tensor(11.1369, device='cuda:0')   \n",
       "573    176.014404      4948.210449   tensor(5.2527, device='cuda:0')   \n",
       "576    240.018433      3167.979004  tensor(10.8628, device='cuda:0')   \n",
       "577           NaN              NaN                               NaN   \n",
       "578           NaN              NaN                               NaN   \n",
       "580    287.990234      5049.261719   tensor(9.6763, device='cuda:0')   \n",
       "581           NaN              NaN                               NaN   \n",
       "584      0.105713         0.345376  tensor(27.0305, device='cuda:0')   \n",
       "585    191.991821      5515.283691   tensor(8.7346, device='cuda:0')   \n",
       "586    207.983398      4833.089844  tensor(10.7964, device='cuda:0')   \n",
       "587    176.021729      5217.956543   tensor(5.2192, device='cuda:0')   \n",
       "590    255.991089      3445.195557   tensor(9.6691, device='cuda:0')   \n",
       "591           NaN              NaN                               NaN   \n",
       "592           NaN              NaN                               NaN   \n",
       "594    287.992126      4738.358398  tensor(12.3372, device='cuda:0')   \n",
       "595           NaN              NaN                               NaN   \n",
       "598      0.104614         0.357792  tensor(27.0423, device='cuda:0')   \n",
       "599    176.017578      5153.592773   tensor(9.4703, device='cuda:0')   \n",
       "600    207.972290      4688.925781  tensor(14.1837, device='cuda:0')   \n",
       "601    176.023560      5135.521484   tensor(5.1143, device='cuda:0')   \n",
       "604    239.980225      3046.197510   tensor(9.4088, device='cuda:0')   \n",
       "605           NaN              NaN                               NaN   \n",
       "606           NaN              NaN                               NaN   \n",
       "608    287.978760      4636.120605  tensor(13.3010, device='cuda:0')   \n",
       "609           NaN              NaN                               NaN   \n",
       "612      0.102539         0.364463  tensor(27.0885, device='cuda:0')   \n",
       "613    191.991943      5336.548340   tensor(9.5175, device='cuda:0')   \n",
       "614    192.015991      4545.520020  tensor(13.3592, device='cuda:0')   \n",
       "615    191.987915      5425.009766   tensor(5.4077, device='cuda:0')   \n",
       "618    256.001831      3403.637939   tensor(9.9451, device='cuda:0')   \n",
       "619           NaN              NaN                               NaN   \n",
       "620           NaN              NaN                               NaN   \n",
       "622    287.953369      4513.942383  tensor(12.9504, device='cuda:0')   \n",
       "623           NaN              NaN                               NaN   \n",
       "626      0.101807         0.371823  tensor(27.2751, device='cuda:0')   \n",
       "627    176.021484      5406.568359  tensor(10.5140, device='cuda:0')   \n",
       "628    192.020508      4405.319336  tensor(13.9726, device='cuda:0')   \n",
       "629    176.002441      5162.484863   tensor(5.2357, device='cuda:0')   \n",
       "632    255.963623      3546.243408   tensor(9.6800, device='cuda:0')   \n",
       "633           NaN              NaN                               NaN   \n",
       "634           NaN              NaN                               NaN   \n",
       "636    287.978394      4763.919434  tensor(11.4444, device='cuda:0')   \n",
       "637           NaN              NaN                               NaN   \n",
       "640      0.096436         0.363396  tensor(26.1319, device='cuda:0')   \n",
       "641    192.010864      5484.255859  tensor(10.0300, device='cuda:0')   \n",
       "642    208.013306      4794.982422  tensor(15.9509, device='cuda:0')   \n",
       "643    191.995575      5290.937500   tensor(4.6399, device='cuda:0')   \n",
       "646    223.999252      2736.013428   tensor(9.0613, device='cuda:0')   \n",
       "647           NaN              NaN                               NaN   \n",
       "648           NaN              NaN                               NaN   \n",
       "650    256.035645      5071.012207  tensor(15.6541, device='cuda:0')   \n",
       "651           NaN              NaN                               NaN   \n",
       "654      0.093994         0.366468  tensor(25.7136, device='cuda:0')   \n",
       "655    208.003357      6159.307617   tensor(9.3290, device='cuda:0')   \n",
       "656    223.991211      4848.220703  tensor(12.2271, device='cuda:0')   \n",
       "657    192.011719      5814.898438   tensor(4.7878, device='cuda:0')   \n",
       "660    208.005554      2920.317627  tensor(10.4902, device='cuda:0')   \n",
       "661           NaN              NaN                               NaN   \n",
       "662           NaN              NaN                               NaN   \n",
       "664    287.976318      5574.845703  tensor(10.6947, device='cuda:0')   \n",
       "665           NaN              NaN                               NaN   \n",
       "668      0.093323         0.378215  tensor(25.9593, device='cuda:0')   \n",
       "669    208.004883      6358.343262   tensor(8.8961, device='cuda:0')   \n",
       "670    223.988892      4759.201172  tensor(12.5823, device='cuda:0')   \n",
       "671    192.007690      5828.971680   tensor(4.3793, device='cuda:0')   \n",
       "674    256.011230      4121.309082  tensor(10.0276, device='cuda:0')   \n",
       "675           NaN              NaN                               NaN   \n",
       "676           NaN              NaN                               NaN   \n",
       "678    287.985840      6383.861816  tensor(10.4516, device='cuda:0')   \n",
       "679           NaN              NaN                               NaN   \n",
       "682      0.093384         0.402669  tensor(25.8360, device='cuda:0')   \n",
       "683    208.006226      6308.447754  tensor(10.8229, device='cuda:0')   \n",
       "684    223.993042      4850.221191  tensor(12.2919, device='cuda:0')   \n",
       "685    192.015991      5796.203125   tensor(5.8122, device='cuda:0')   \n",
       "688    255.982788      3994.631348  tensor(10.3821, device='cuda:0')   \n",
       "689           NaN              NaN                               NaN   \n",
       "690           NaN              NaN                               NaN   \n",
       "692    287.983276      6239.253418   tensor(9.9172, device='cuda:0')   \n",
       "693           NaN              NaN                               NaN   \n",
       "696      0.090515         0.390967  tensor(24.8836, device='cuda:0')   \n",
       "697    208.000671      6207.842285   tensor(9.2425, device='cuda:0')   \n",
       "698    223.991272      4806.309570  tensor(13.4124, device='cuda:0')   \n",
       "699    192.005768      5837.430664   tensor(4.0343, device='cuda:0')   \n",
       "702    255.967529      3095.226562   tensor(9.1672, device='cuda:0')   \n",
       "703           NaN              NaN                               NaN   \n",
       "704           NaN              NaN                               NaN   \n",
       "706    256.065918      4623.017090  tensor(14.2350, device='cuda:0')   \n",
       "707           NaN              NaN                               NaN   \n",
       "710      0.088257         0.399446  tensor(24.8240, device='cuda:0')   \n",
       "711    208.011780      6462.721680  tensor(11.1681, device='cuda:0')   \n",
       "712    223.986389      4616.555664  tensor(14.4037, device='cuda:0')   \n",
       "713    192.014893      6058.180664   tensor(5.4343, device='cuda:0')   \n",
       "716    239.973022      3052.552490  tensor(11.8999, device='cuda:0')   \n",
       "717           NaN              NaN                               NaN   \n",
       "718           NaN              NaN                               NaN   \n",
       "720    287.987549      5433.369141  tensor(11.1134, device='cuda:0')   \n",
       "721           NaN              NaN                               NaN   \n",
       "724      0.086914         0.383349  tensor(24.0870, device='cuda:0')   \n",
       "725    208.001312      6055.370117  tensor(10.2170, device='cuda:0')   \n",
       "726    223.996689      4732.395020  tensor(14.1978, device='cuda:0')   \n",
       "727    207.990601      6197.644531   tensor(4.2513, device='cuda:0')   \n",
       "730    255.996140      3757.696045  tensor(10.3536, device='cuda:0')   \n",
       "731           NaN              NaN                               NaN   \n",
       "732           NaN              NaN                               NaN   \n",
       "734    256.032715      5247.531250  tensor(11.8242, device='cuda:0')   \n",
       "735           NaN              NaN                               NaN   \n",
       "738      0.083496         0.420014  tensor(23.2654, device='cuda:0')   \n",
       "739    207.995636      5979.126465  tensor(10.7594, device='cuda:0')   \n",
       "740    223.992004      4501.459473  tensor(15.5357, device='cuda:0')   \n",
       "741    192.012756      6078.503906   tensor(4.8922, device='cuda:0')   \n",
       "744    255.999725      3656.063477  tensor(12.0291, device='cuda:0')   \n",
       "745           NaN              NaN                               NaN   \n",
       "746           NaN              NaN                               NaN   \n",
       "748    256.005188      4886.743164   tensor(9.9500, device='cuda:0')   \n",
       "749           NaN              NaN                               NaN   \n",
       "752      0.081055         0.395233  tensor(22.3172, device='cuda:0')   \n",
       "753    207.995789      6115.948242   tensor(6.6717, device='cuda:0')   \n",
       "754    224.003357      4646.845703  tensor(14.9229, device='cuda:0')   \n",
       "755    207.978516      6143.013672   tensor(6.1338, device='cuda:0')   \n",
       "758    255.994659      4169.010742  tensor(10.4696, device='cuda:0')   \n",
       "759           NaN              NaN                               NaN   \n",
       "760           NaN              NaN                               NaN   \n",
       "762    287.989502      6715.797852   tensor(8.6338, device='cuda:0')   \n",
       "763           NaN              NaN                               NaN   \n",
       "766      0.080185         0.437230  tensor(22.3042, device='cuda:0')   \n",
       "767    207.989136      5927.549316   tensor(8.9917, device='cuda:0')   \n",
       "768    224.010498      4684.781250  tensor(15.8992, device='cuda:0')   \n",
       "769    208.000793      6307.842773   tensor(6.1287, device='cuda:0')   \n",
       "772    240.019897      3816.159912  tensor(11.3791, device='cuda:0')   \n",
       "773           NaN              NaN                               NaN   \n",
       "774           NaN              NaN                               NaN   \n",
       "776    256.021362      7213.776367   tensor(8.7488, device='cuda:0')   \n",
       "777           NaN              NaN                               NaN   \n",
       "780      0.077087         0.438725  tensor(21.1496, device='cuda:0')   \n",
       "781    207.992676      5987.518555   tensor(6.5458, device='cuda:0')   \n",
       "782    224.012817      4555.069336  tensor(16.7388, device='cuda:0')   \n",
       "783    208.004181      6365.253418   tensor(5.0818, device='cuda:0')   \n",
       "786    256.002899      3854.888916  tensor(10.6793, device='cuda:0')   \n",
       "787           NaN              NaN                               NaN   \n",
       "788           NaN              NaN                               NaN   \n",
       "790    287.973877      5877.293457  tensor(10.0556, device='cuda:0')   \n",
       "791           NaN              NaN                               NaN   \n",
       "794      0.075806         0.428040  tensor(20.6954, device='cuda:0')   \n",
       "795    207.985535      5639.177734   tensor(8.0602, device='cuda:0')   \n",
       "796    224.008850      4331.026855  tensor(18.9527, device='cuda:0')   \n",
       "797    208.019897      6119.698242   tensor(6.4444, device='cuda:0')   \n",
       "800    239.981079      3850.676270  tensor(10.7383, device='cuda:0')   \n",
       "801           NaN              NaN                               NaN   \n",
       "802           NaN              NaN                               NaN   \n",
       "804    256.028564      5754.885742  tensor(10.3825, device='cuda:0')   \n",
       "805           NaN              NaN                               NaN   \n",
       "808      0.075439         0.395684  tensor(19.7949, device='cuda:0')   \n",
       "809    192.016602      5304.633789   tensor(8.3095, device='cuda:0')   \n",
       "810    224.004028      4245.456055  tensor(20.5483, device='cuda:0')   \n",
       "811    207.997208      5513.809082   tensor(7.5036, device='cuda:0')   \n",
       "814    256.003357      4562.860840  tensor(11.9744, device='cuda:0')   \n",
       "815           NaN              NaN                               NaN   \n",
       "816           NaN              NaN                               NaN   \n",
       "818    240.026001      5912.236816  tensor(11.8634, device='cuda:0')   \n",
       "819           NaN              NaN                               NaN   \n",
       "822      0.073364         0.297874  tensor(16.6159, device='cuda:0')   \n",
       "823    192.002243      4963.339355   tensor(7.9094, device='cuda:0')   \n",
       "824    207.995544      3795.022217  tensor(20.5914, device='cuda:0')   \n",
       "825    191.994110      4900.058594   tensor(7.4081, device='cuda:0')   \n",
       "828    240.002502      3413.891846  tensor(12.8179, device='cuda:0')   \n",
       "829           NaN              NaN                               NaN   \n",
       "830           NaN              NaN                               NaN   \n",
       "832    256.024170      5571.521973   tensor(8.5375, device='cuda:0')   \n",
       "833           NaN              NaN                               NaN   \n",
       "836      0.083862         0.223582  tensor(15.8844, device='cuda:0')   \n",
       "837    176.009033      4388.459473   tensor(6.6716, device='cuda:0')   \n",
       "838    207.992828      3943.669434  tensor(20.2600, device='cuda:0')   \n",
       "839    192.002914      4385.196289   tensor(8.7921, device='cuda:0')   \n",
       "842    255.989136      3919.112793  tensor(10.1165, device='cuda:0')   \n",
       "843           NaN              NaN                               NaN   \n",
       "844           NaN              NaN                               NaN   \n",
       "846    240.000900      4587.669434  tensor(10.0743, device='cuda:0')   \n",
       "847           NaN              NaN                               NaN   \n",
       "\n",
       "                          spec_a_min                            spec_b_max  \\\n",
       "1    tensor(0.0307, device='cuda:0')   tensor(88471.5312, device='cuda:0')   \n",
       "2    tensor(0.0222, device='cuda:0')  tensor(172167.4219, device='cuda:0')   \n",
       "3    tensor(0.0260, device='cuda:0')  tensor(171213.8281, device='cuda:0')   \n",
       "6    tensor(0.3528, device='cuda:0')   tensor(24165.8203, device='cuda:0')   \n",
       "7                                NaN                                   NaN   \n",
       "8                                NaN                                   NaN   \n",
       "10   tensor(0.0613, device='cuda:0')   tensor(49268.8477, device='cuda:0')   \n",
       "11                               NaN                                   NaN   \n",
       "13   tensor(0.0196, device='cuda:0')  tensor(152488.9688, device='cuda:0')   \n",
       "14   tensor(0.0202, device='cuda:0')  tensor(243742.2188, device='cuda:0')   \n",
       "15   tensor(0.0173, device='cuda:0')  tensor(183980.1406, device='cuda:0')   \n",
       "18   tensor(0.1509, device='cuda:0')   tensor(18662.9473, device='cuda:0')   \n",
       "19                               NaN                                   NaN   \n",
       "20                               NaN                                   NaN   \n",
       "22   tensor(0.0243, device='cuda:0')   tensor(35550.9570, device='cuda:0')   \n",
       "23                               NaN                                   NaN   \n",
       "25   tensor(0.0190, device='cuda:0')   tensor(84441.4688, device='cuda:0')   \n",
       "26   tensor(0.0205, device='cuda:0')  tensor(140462.8750, device='cuda:0')   \n",
       "27   tensor(0.0193, device='cuda:0')  tensor(109925.6328, device='cuda:0')   \n",
       "30   tensor(0.2098, device='cuda:0')   tensor(23450.2578, device='cuda:0')   \n",
       "31                               NaN                                   NaN   \n",
       "32                               NaN                                   NaN   \n",
       "34   tensor(0.0309, device='cuda:0')   tensor(42056.8438, device='cuda:0')   \n",
       "35                               NaN                                   NaN   \n",
       "38   tensor(0.3523, device='cuda:0')      tensor(17.3292, device='cuda:0')   \n",
       "39   tensor(0.0510, device='cuda:0')   tensor(25072.1465, device='cuda:0')   \n",
       "40   tensor(0.0300, device='cuda:0')  tensor(208050.1562, device='cuda:0')   \n",
       "41   tensor(0.0481, device='cuda:0')   tensor(32384.3535, device='cuda:0')   \n",
       "44   tensor(0.1793, device='cuda:0')   tensor(19336.4766, device='cuda:0')   \n",
       "45                               NaN                                   NaN   \n",
       "46                               NaN                                   NaN   \n",
       "48   tensor(0.0289, device='cuda:0')   tensor(42202.8633, device='cuda:0')   \n",
       "49                               NaN                                   NaN   \n",
       "52   tensor(0.7453, device='cuda:0')      tensor(18.6203, device='cuda:0')   \n",
       "53   tensor(0.0831, device='cuda:0')   tensor(22417.9316, device='cuda:0')   \n",
       "54   tensor(0.0472, device='cuda:0')  tensor(161259.3125, device='cuda:0')   \n",
       "55   tensor(0.0846, device='cuda:0')   tensor(27389.6152, device='cuda:0')   \n",
       "58   tensor(0.2280, device='cuda:0')   tensor(18042.6191, device='cuda:0')   \n",
       "59                               NaN                                   NaN   \n",
       "60                               NaN                                   NaN   \n",
       "62   tensor(0.0321, device='cuda:0')   tensor(35294.6602, device='cuda:0')   \n",
       "63                               NaN                                   NaN   \n",
       "66   tensor(0.9284, device='cuda:0')      tensor(22.3953, device='cuda:0')   \n",
       "67   tensor(0.0977, device='cuda:0')   tensor(20716.1113, device='cuda:0')   \n",
       "68   tensor(0.0620, device='cuda:0')  tensor(173785.4688, device='cuda:0')   \n",
       "69   tensor(0.1020, device='cuda:0')   tensor(25935.9727, device='cuda:0')   \n",
       "72   tensor(0.2666, device='cuda:0')   tensor(15341.8379, device='cuda:0')   \n",
       "73                               NaN                                   NaN   \n",
       "74                               NaN                                   NaN   \n",
       "76   tensor(0.0354, device='cuda:0')   tensor(32484.7441, device='cuda:0')   \n",
       "77                               NaN                                   NaN   \n",
       "80   tensor(1.1733, device='cuda:0')      tensor(27.1338, device='cuda:0')   \n",
       "81   tensor(0.1143, device='cuda:0')   tensor(18087.9453, device='cuda:0')   \n",
       "82   tensor(0.0794, device='cuda:0')  tensor(182581.6094, device='cuda:0')   \n",
       "83   tensor(0.1222, device='cuda:0')   tensor(23857.4258, device='cuda:0')   \n",
       "86   tensor(0.2414, device='cuda:0')   tensor(16534.1836, device='cuda:0')   \n",
       "87                               NaN                                   NaN   \n",
       "88                               NaN                                   NaN   \n",
       "90   tensor(0.0351, device='cuda:0')   tensor(38157.2656, device='cuda:0')   \n",
       "91                               NaN                                   NaN   \n",
       "94   tensor(1.4342, device='cuda:0')      tensor(29.4863, device='cuda:0')   \n",
       "95   tensor(0.1301, device='cuda:0')   tensor(18387.5215, device='cuda:0')   \n",
       "96   tensor(0.1037, device='cuda:0')  tensor(190385.5625, device='cuda:0')   \n",
       "97   tensor(0.1451, device='cuda:0')   tensor(17994.7598, device='cuda:0')   \n",
       "100  tensor(0.3029, device='cuda:0')   tensor(16278.3340, device='cuda:0')   \n",
       "101                              NaN                                   NaN   \n",
       "102                              NaN                                   NaN   \n",
       "104  tensor(0.0344, device='cuda:0')   tensor(34993.1016, device='cuda:0')   \n",
       "105                              NaN                                   NaN   \n",
       "108  tensor(1.4665, device='cuda:0')      tensor(27.6877, device='cuda:0')   \n",
       "109  tensor(0.1704, device='cuda:0')   tensor(15784.7109, device='cuda:0')   \n",
       "110  tensor(0.1586, device='cuda:0')  tensor(196888.1406, device='cuda:0')   \n",
       "111  tensor(0.1850, device='cuda:0')   tensor(17395.1250, device='cuda:0')   \n",
       "114  tensor(0.3347, device='cuda:0')   tensor(19525.2109, device='cuda:0')   \n",
       "115                              NaN                                   NaN   \n",
       "116                              NaN                                   NaN   \n",
       "118  tensor(0.0369, device='cuda:0')   tensor(43522.4688, device='cuda:0')   \n",
       "119                              NaN                                   NaN   \n",
       "122  tensor(0.9594, device='cuda:0')      tensor(27.9796, device='cuda:0')   \n",
       "123  tensor(0.2347, device='cuda:0')   tensor(14637.7373, device='cuda:0')   \n",
       "124  tensor(0.2264, device='cuda:0')  tensor(179836.4219, device='cuda:0')   \n",
       "125  tensor(0.2492, device='cuda:0')   tensor(15065.3594, device='cuda:0')   \n",
       "128  tensor(0.3376, device='cuda:0')   tensor(16353.3037, device='cuda:0')   \n",
       "129                              NaN                                   NaN   \n",
       "130                              NaN                                   NaN   \n",
       "132  tensor(0.0392, device='cuda:0')   tensor(32399.7051, device='cuda:0')   \n",
       "133                              NaN                                   NaN   \n",
       "136  tensor(1.4224, device='cuda:0')      tensor(31.8564, device='cuda:0')   \n",
       "137  tensor(0.2631, device='cuda:0')   tensor(16205.9287, device='cuda:0')   \n",
       "138  tensor(0.2769, device='cuda:0')  tensor(174247.9844, device='cuda:0')   \n",
       "139  tensor(0.2709, device='cuda:0')   tensor(15159.9688, device='cuda:0')   \n",
       "142  tensor(0.3235, device='cuda:0')   tensor(15920.2061, device='cuda:0')   \n",
       "143                              NaN                                   NaN   \n",
       "144                              NaN                                   NaN   \n",
       "146  tensor(0.0357, device='cuda:0')   tensor(32033.4043, device='cuda:0')   \n",
       "147                              NaN                                   NaN   \n",
       "150  tensor(1.5274, device='cuda:0')      tensor(31.8147, device='cuda:0')   \n",
       "151  tensor(0.2790, device='cuda:0')   tensor(15349.4199, device='cuda:0')   \n",
       "152  tensor(0.2807, device='cuda:0')  tensor(171196.5312, device='cuda:0')   \n",
       "153  tensor(0.2855, device='cuda:0')   tensor(14481.7334, device='cuda:0')   \n",
       "156  tensor(0.3141, device='cuda:0')   tensor(17867.8242, device='cuda:0')   \n",
       "157                              NaN                                   NaN   \n",
       "158                              NaN                                   NaN   \n",
       "160  tensor(0.0346, device='cuda:0')   tensor(31358.3262, device='cuda:0')   \n",
       "161                              NaN                                   NaN   \n",
       "164  tensor(1.4570, device='cuda:0')      tensor(31.5748, device='cuda:0')   \n",
       "165  tensor(0.2851, device='cuda:0')   tensor(15713.1016, device='cuda:0')   \n",
       "166  tensor(0.2964, device='cuda:0')  tensor(177511.2344, device='cuda:0')   \n",
       "167  tensor(0.2907, device='cuda:0')   tensor(14483.9434, device='cuda:0')   \n",
       "170  tensor(0.4493, device='cuda:0')   tensor(19733.8086, device='cuda:0')   \n",
       "171                              NaN                                   NaN   \n",
       "172                              NaN                                   NaN   \n",
       "174  tensor(0.0375, device='cuda:0')   tensor(32678.3418, device='cuda:0')   \n",
       "175                              NaN                                   NaN   \n",
       "178  tensor(1.4869, device='cuda:0')      tensor(30.9469, device='cuda:0')   \n",
       "179  tensor(0.2822, device='cuda:0')   tensor(15097.4561, device='cuda:0')   \n",
       "180  tensor(0.3015, device='cuda:0')  tensor(157167.2812, device='cuda:0')   \n",
       "181  tensor(0.2961, device='cuda:0')   tensor(14406.3359, device='cuda:0')   \n",
       "184  tensor(0.3148, device='cuda:0')   tensor(18407.6309, device='cuda:0')   \n",
       "185                              NaN                                   NaN   \n",
       "186                              NaN                                   NaN   \n",
       "188  tensor(0.0359, device='cuda:0')   tensor(32452.8301, device='cuda:0')   \n",
       "189                              NaN                                   NaN   \n",
       "192  tensor(1.7850, device='cuda:0')      tensor(30.4998, device='cuda:0')   \n",
       "193  tensor(0.2842, device='cuda:0')   tensor(19167.4121, device='cuda:0')   \n",
       "194  tensor(0.3051, device='cuda:0')  tensor(102054.1328, device='cuda:0')   \n",
       "195  tensor(0.2981, device='cuda:0')   tensor(16865.2500, device='cuda:0')   \n",
       "198  tensor(0.3067, device='cuda:0')   tensor(15866.1582, device='cuda:0')   \n",
       "199                              NaN                                   NaN   \n",
       "200                              NaN                                   NaN   \n",
       "202  tensor(0.0328, device='cuda:0')   tensor(29469.3066, device='cuda:0')   \n",
       "203                              NaN                                   NaN   \n",
       "206  tensor(1.7216, device='cuda:0')      tensor(28.7350, device='cuda:0')   \n",
       "207  tensor(0.2394, device='cuda:0')   tensor(15627.5420, device='cuda:0')   \n",
       "208  tensor(0.3097, device='cuda:0')   tensor(98299.5859, device='cuda:0')   \n",
       "209  tensor(0.2954, device='cuda:0')   tensor(14303.2695, device='cuda:0')   \n",
       "212  tensor(0.3408, device='cuda:0')   tensor(17169.6426, device='cuda:0')   \n",
       "213                              NaN                                   NaN   \n",
       "214                              NaN                                   NaN   \n",
       "216  tensor(0.0213, device='cuda:0')   tensor(30561.5840, device='cuda:0')   \n",
       "217                              NaN                                   NaN   \n",
       "220  tensor(1.2862, device='cuda:0')      tensor(30.3641, device='cuda:0')   \n",
       "221  tensor(0.2663, device='cuda:0')   tensor(26416.4805, device='cuda:0')   \n",
       "222  tensor(0.3165, device='cuda:0')   tensor(56517.0039, device='cuda:0')   \n",
       "223  tensor(0.2978, device='cuda:0')   tensor(13671.3311, device='cuda:0')   \n",
       "226  tensor(0.2766, device='cuda:0')   tensor(17774.9434, device='cuda:0')   \n",
       "227                              NaN                                   NaN   \n",
       "228                              NaN                                   NaN   \n",
       "230  tensor(0.0258, device='cuda:0')   tensor(27875.1953, device='cuda:0')   \n",
       "231                              NaN                                   NaN   \n",
       "234  tensor(1.4422, device='cuda:0')      tensor(27.1107, device='cuda:0')   \n",
       "235  tensor(0.2936, device='cuda:0')   tensor(20189.6152, device='cuda:0')   \n",
       "236  tensor(0.3184, device='cuda:0')  tensor(115457.6406, device='cuda:0')   \n",
       "237  tensor(0.3085, device='cuda:0')   tensor(13867.5547, device='cuda:0')   \n",
       "240  tensor(0.2852, device='cuda:0')   tensor(15599.6973, device='cuda:0')   \n",
       "241                              NaN                                   NaN   \n",
       "242                              NaN                                   NaN   \n",
       "244  tensor(0.0268, device='cuda:0')   tensor(32874.7734, device='cuda:0')   \n",
       "245                              NaN                                   NaN   \n",
       "248  tensor(1.8774, device='cuda:0')      tensor(26.0717, device='cuda:0')   \n",
       "249  tensor(0.2922, device='cuda:0')   tensor(18232.0234, device='cuda:0')   \n",
       "250  tensor(0.3185, device='cuda:0')  tensor(102982.2969, device='cuda:0')   \n",
       "251  tensor(0.3107, device='cuda:0')   tensor(15044.6943, device='cuda:0')   \n",
       "254  tensor(0.2779, device='cuda:0')   tensor(18978.3945, device='cuda:0')   \n",
       "255                              NaN                                   NaN   \n",
       "256                              NaN                                   NaN   \n",
       "258  tensor(0.0354, device='cuda:0')   tensor(26093.2520, device='cuda:0')   \n",
       "259                              NaN                                   NaN   \n",
       "262  tensor(1.3730, device='cuda:0')      tensor(25.0578, device='cuda:0')   \n",
       "263  tensor(0.2989, device='cuda:0')   tensor(16192.5449, device='cuda:0')   \n",
       "264  tensor(0.3244, device='cuda:0')  tensor(107664.1719, device='cuda:0')   \n",
       "265  tensor(0.3141, device='cuda:0')   tensor(14081.6943, device='cuda:0')   \n",
       "268  tensor(0.2656, device='cuda:0')   tensor(16797.7227, device='cuda:0')   \n",
       "269                              NaN                                   NaN   \n",
       "270                              NaN                                   NaN   \n",
       "272  tensor(0.0248, device='cuda:0')   tensor(31485.7852, device='cuda:0')   \n",
       "273                              NaN                                   NaN   \n",
       "276  tensor(1.7887, device='cuda:0')      tensor(25.2752, device='cuda:0')   \n",
       "277  tensor(0.2644, device='cuda:0')   tensor(19561.3613, device='cuda:0')   \n",
       "278  tensor(0.3296, device='cuda:0')  tensor(122954.3828, device='cuda:0')   \n",
       "279  tensor(0.3134, device='cuda:0')   tensor(15990.5225, device='cuda:0')   \n",
       "282  tensor(0.3279, device='cuda:0')   tensor(16415.3613, device='cuda:0')   \n",
       "283                              NaN                                   NaN   \n",
       "284                              NaN                                   NaN   \n",
       "286  tensor(0.0283, device='cuda:0')   tensor(35729.4570, device='cuda:0')   \n",
       "287                              NaN                                   NaN   \n",
       "290  tensor(1.6073, device='cuda:0')      tensor(23.0769, device='cuda:0')   \n",
       "291  tensor(0.2892, device='cuda:0')   tensor(17627.8613, device='cuda:0')   \n",
       "292  tensor(0.3353, device='cuda:0')  tensor(137620.5469, device='cuda:0')   \n",
       "293  tensor(0.3151, device='cuda:0')   tensor(15610.8281, device='cuda:0')   \n",
       "296  tensor(0.3820, device='cuda:0')   tensor(14346.7393, device='cuda:0')   \n",
       "297                              NaN                                   NaN   \n",
       "298                              NaN                                   NaN   \n",
       "300  tensor(0.0369, device='cuda:0')   tensor(36449.0430, device='cuda:0')   \n",
       "301                              NaN                                   NaN   \n",
       "304  tensor(1.3668, device='cuda:0')      tensor(22.7419, device='cuda:0')   \n",
       "305  tensor(0.2615, device='cuda:0')   tensor(15760.3555, device='cuda:0')   \n",
       "306  tensor(0.3401, device='cuda:0')  tensor(114131.9844, device='cuda:0')   \n",
       "307  tensor(0.3118, device='cuda:0')   tensor(18768.5391, device='cuda:0')   \n",
       "310  tensor(0.2067, device='cuda:0')   tensor(17803.4785, device='cuda:0')   \n",
       "311                              NaN                                   NaN   \n",
       "312                              NaN                                   NaN   \n",
       "314  tensor(0.0299, device='cuda:0')   tensor(32157.2461, device='cuda:0')   \n",
       "315                              NaN                                   NaN   \n",
       "318  tensor(1.7004, device='cuda:0')      tensor(21.5537, device='cuda:0')   \n",
       "319  tensor(0.1619, device='cuda:0')   tensor(17626.8984, device='cuda:0')   \n",
       "320  tensor(0.3218, device='cuda:0')  tensor(122437.1953, device='cuda:0')   \n",
       "321  tensor(0.3003, device='cuda:0')   tensor(18192.6016, device='cuda:0')   \n",
       "324  tensor(0.3000, device='cuda:0')   tensor(14206.6006, device='cuda:0')   \n",
       "325                              NaN                                   NaN   \n",
       "326                              NaN                                   NaN   \n",
       "328  tensor(0.0258, device='cuda:0')   tensor(32481.4766, device='cuda:0')   \n",
       "329                              NaN                                   NaN   \n",
       "332  tensor(1.6631, device='cuda:0')      tensor(21.5754, device='cuda:0')   \n",
       "333  tensor(0.2712, device='cuda:0')   tensor(22022.6387, device='cuda:0')   \n",
       "334  tensor(0.3187, device='cuda:0')  tensor(108499.3672, device='cuda:0')   \n",
       "335  tensor(0.2955, device='cuda:0')   tensor(18150.1934, device='cuda:0')   \n",
       "338  tensor(0.3400, device='cuda:0')   tensor(13768.9824, device='cuda:0')   \n",
       "339                              NaN                                   NaN   \n",
       "340                              NaN                                   NaN   \n",
       "342  tensor(0.0232, device='cuda:0')   tensor(37914.6758, device='cuda:0')   \n",
       "343                              NaN                                   NaN   \n",
       "346  tensor(1.4320, device='cuda:0')      tensor(21.7181, device='cuda:0')   \n",
       "347  tensor(0.2662, device='cuda:0')   tensor(21057.7773, device='cuda:0')   \n",
       "348  tensor(0.3207, device='cuda:0')   tensor(97272.2812, device='cuda:0')   \n",
       "349  tensor(0.2964, device='cuda:0')   tensor(19661.4785, device='cuda:0')   \n",
       "352  tensor(0.2638, device='cuda:0')   tensor(16902.2070, device='cuda:0')   \n",
       "353                              NaN                                   NaN   \n",
       "354                              NaN                                   NaN   \n",
       "356  tensor(0.0202, device='cuda:0')   tensor(33030.1836, device='cuda:0')   \n",
       "357                              NaN                                   NaN   \n",
       "360  tensor(1.2455, device='cuda:0')      tensor(21.8570, device='cuda:0')   \n",
       "361  tensor(0.2594, device='cuda:0')   tensor(22312.5020, device='cuda:0')   \n",
       "362  tensor(0.3260, device='cuda:0')   tensor(92865.7578, device='cuda:0')   \n",
       "363  tensor(0.2900, device='cuda:0')   tensor(20410.8105, device='cuda:0')   \n",
       "366  tensor(0.3543, device='cuda:0')   tensor(15081.3223, device='cuda:0')   \n",
       "367                              NaN                                   NaN   \n",
       "368                              NaN                                   NaN   \n",
       "370  tensor(0.0190, device='cuda:0')   tensor(36330.3047, device='cuda:0')   \n",
       "371                              NaN                                   NaN   \n",
       "374  tensor(1.3409, device='cuda:0')      tensor(21.7236, device='cuda:0')   \n",
       "375  tensor(0.2641, device='cuda:0')   tensor(26344.2734, device='cuda:0')   \n",
       "376  tensor(0.3050, device='cuda:0')   tensor(92487.5469, device='cuda:0')   \n",
       "377  tensor(0.2880, device='cuda:0')   tensor(20570.0273, device='cuda:0')   \n",
       "380  tensor(0.2005, device='cuda:0')   tensor(16094.1943, device='cuda:0')   \n",
       "381                              NaN                                   NaN   \n",
       "382                              NaN                                   NaN   \n",
       "384  tensor(0.0265, device='cuda:0')   tensor(37772.8008, device='cuda:0')   \n",
       "385                              NaN                                   NaN   \n",
       "388  tensor(1.4807, device='cuda:0')      tensor(20.9985, device='cuda:0')   \n",
       "389  tensor(0.2654, device='cuda:0')   tensor(24798.3457, device='cuda:0')   \n",
       "390  tensor(0.2799, device='cuda:0')   tensor(92835.1875, device='cuda:0')   \n",
       "391  tensor(0.2799, device='cuda:0')   tensor(19403.6621, device='cuda:0')   \n",
       "394  tensor(0.3846, device='cuda:0')   tensor(15609.6777, device='cuda:0')   \n",
       "395                              NaN                                   NaN   \n",
       "396                              NaN                                   NaN   \n",
       "398  tensor(0.0156, device='cuda:0')   tensor(38582.8047, device='cuda:0')   \n",
       "399                              NaN                                   NaN   \n",
       "402  tensor(1.4655, device='cuda:0')      tensor(21.0717, device='cuda:0')   \n",
       "403  tensor(0.2510, device='cuda:0')   tensor(25753.0391, device='cuda:0')   \n",
       "404  tensor(0.3056, device='cuda:0')   tensor(94814.4688, device='cuda:0')   \n",
       "405  tensor(0.2892, device='cuda:0')   tensor(20008.4414, device='cuda:0')   \n",
       "408  tensor(0.3111, device='cuda:0')   tensor(17005.9180, device='cuda:0')   \n",
       "409                              NaN                                   NaN   \n",
       "410                              NaN                                   NaN   \n",
       "412  tensor(0.0298, device='cuda:0')   tensor(39697.4688, device='cuda:0')   \n",
       "413                              NaN                                   NaN   \n",
       "416  tensor(1.4521, device='cuda:0')      tensor(21.4225, device='cuda:0')   \n",
       "417  tensor(0.1612, device='cuda:0')   tensor(22748.5547, device='cuda:0')   \n",
       "418  tensor(0.3102, device='cuda:0')   tensor(75260.8750, device='cuda:0')   \n",
       "419  tensor(0.2806, device='cuda:0')   tensor(20831.9355, device='cuda:0')   \n",
       "422  tensor(0.3105, device='cuda:0')   tensor(16569.9727, device='cuda:0')   \n",
       "423                              NaN                                   NaN   \n",
       "424                              NaN                                   NaN   \n",
       "426  tensor(0.0248, device='cuda:0')   tensor(40878.7461, device='cuda:0')   \n",
       "427                              NaN                                   NaN   \n",
       "430  tensor(1.3381, device='cuda:0')      tensor(20.8508, device='cuda:0')   \n",
       "431  tensor(0.2417, device='cuda:0')   tensor(24869.6250, device='cuda:0')   \n",
       "432  tensor(0.2591, device='cuda:0')   tensor(85930.2031, device='cuda:0')   \n",
       "433  tensor(0.2822, device='cuda:0')   tensor(19412.5586, device='cuda:0')   \n",
       "436  tensor(0.3243, device='cuda:0')   tensor(15031.0605, device='cuda:0')   \n",
       "437                              NaN                                   NaN   \n",
       "438                              NaN                                   NaN   \n",
       "440  tensor(0.0247, device='cuda:0')   tensor(41463.4297, device='cuda:0')   \n",
       "441                              NaN                                   NaN   \n",
       "444  tensor(1.6840, device='cuda:0')      tensor(20.4495, device='cuda:0')   \n",
       "445  tensor(0.2507, device='cuda:0')   tensor(22602.1641, device='cuda:0')   \n",
       "446  tensor(0.2607, device='cuda:0')   tensor(78950.4062, device='cuda:0')   \n",
       "447  tensor(0.2861, device='cuda:0')   tensor(19598.0859, device='cuda:0')   \n",
       "450  tensor(0.4124, device='cuda:0')   tensor(16082.4844, device='cuda:0')   \n",
       "451                              NaN                                   NaN   \n",
       "452                              NaN                                   NaN   \n",
       "454  tensor(0.0165, device='cuda:0')   tensor(44130.3750, device='cuda:0')   \n",
       "455                              NaN                                   NaN   \n",
       "458  tensor(1.3195, device='cuda:0')      tensor(21.6039, device='cuda:0')   \n",
       "459  tensor(0.2851, device='cuda:0')   tensor(25319.5820, device='cuda:0')   \n",
       "460  tensor(0.3012, device='cuda:0')  tensor(109519.3672, device='cuda:0')   \n",
       "461  tensor(0.3040, device='cuda:0')   tensor(17943.7246, device='cuda:0')   \n",
       "464  tensor(0.4214, device='cuda:0')   tensor(17713.7090, device='cuda:0')   \n",
       "465                              NaN                                   NaN   \n",
       "466                              NaN                                   NaN   \n",
       "468  tensor(0.0258, device='cuda:0')   tensor(54859.1641, device='cuda:0')   \n",
       "469                              NaN                                   NaN   \n",
       "472  tensor(1.4435, device='cuda:0')      tensor(20.9987, device='cuda:0')   \n",
       "473  tensor(0.2791, device='cuda:0')   tensor(21950.3672, device='cuda:0')   \n",
       "474  tensor(0.3221, device='cuda:0')  tensor(102203.7969, device='cuda:0')   \n",
       "475  tensor(0.3044, device='cuda:0')   tensor(19079.1465, device='cuda:0')   \n",
       "478  tensor(0.3615, device='cuda:0')   tensor(17846.7578, device='cuda:0')   \n",
       "479                              NaN                                   NaN   \n",
       "480                              NaN                                   NaN   \n",
       "482  tensor(0.0239, device='cuda:0')   tensor(45552.4492, device='cuda:0')   \n",
       "483                              NaN                                   NaN   \n",
       "486  tensor(1.1022, device='cuda:0')      tensor(20.6515, device='cuda:0')   \n",
       "487  tensor(0.2756, device='cuda:0')   tensor(21309.0898, device='cuda:0')   \n",
       "488  tensor(0.3393, device='cuda:0')  tensor(105968.6094, device='cuda:0')   \n",
       "489  tensor(0.3142, device='cuda:0')   tensor(19481.6309, device='cuda:0')   \n",
       "492  tensor(0.4307, device='cuda:0')   tensor(15784.6787, device='cuda:0')   \n",
       "493                              NaN                                   NaN   \n",
       "494                              NaN                                   NaN   \n",
       "496  tensor(0.0299, device='cuda:0')   tensor(45610.8125, device='cuda:0')   \n",
       "497                              NaN                                   NaN   \n",
       "500  tensor(1.4473, device='cuda:0')      tensor(20.8635, device='cuda:0')   \n",
       "501  tensor(0.2710, device='cuda:0')   tensor(24616.9980, device='cuda:0')   \n",
       "502  tensor(0.3342, device='cuda:0')   tensor(92334.0156, device='cuda:0')   \n",
       "503  tensor(0.3143, device='cuda:0')   tensor(20366.8379, device='cuda:0')   \n",
       "506  tensor(0.3555, device='cuda:0')   tensor(19095.9648, device='cuda:0')   \n",
       "507                              NaN                                   NaN   \n",
       "508                              NaN                                   NaN   \n",
       "510  tensor(0.0229, device='cuda:0')   tensor(43043.5156, device='cuda:0')   \n",
       "511                              NaN                                   NaN   \n",
       "514  tensor(1.3334, device='cuda:0')      tensor(20.5411, device='cuda:0')   \n",
       "515  tensor(0.2603, device='cuda:0')   tensor(24254.5488, device='cuda:0')   \n",
       "516  tensor(0.3261, device='cuda:0')   tensor(73135.3438, device='cuda:0')   \n",
       "517  tensor(0.3108, device='cuda:0')   tensor(19982.7285, device='cuda:0')   \n",
       "520  tensor(0.3712, device='cuda:0')   tensor(19466.7344, device='cuda:0')   \n",
       "521                              NaN                                   NaN   \n",
       "522                              NaN                                   NaN   \n",
       "524  tensor(0.0212, device='cuda:0')   tensor(46309.8164, device='cuda:0')   \n",
       "525                              NaN                                   NaN   \n",
       "528  tensor(1.2833, device='cuda:0')      tensor(20.7299, device='cuda:0')   \n",
       "529  tensor(0.2399, device='cuda:0')   tensor(23762.0703, device='cuda:0')   \n",
       "530  tensor(0.3381, device='cuda:0')   tensor(76717.7969, device='cuda:0')   \n",
       "531  tensor(0.3159, device='cuda:0')   tensor(20962.4082, device='cuda:0')   \n",
       "534  tensor(0.2544, device='cuda:0')   tensor(17588.1055, device='cuda:0')   \n",
       "535                              NaN                                   NaN   \n",
       "536                              NaN                                   NaN   \n",
       "538  tensor(0.0301, device='cuda:0')   tensor(52806.1328, device='cuda:0')   \n",
       "539                              NaN                                   NaN   \n",
       "542  tensor(1.1106, device='cuda:0')      tensor(19.6710, device='cuda:0')   \n",
       "543  tensor(0.2094, device='cuda:0')   tensor(22790.2734, device='cuda:0')   \n",
       "544  tensor(0.2950, device='cuda:0')   tensor(84984.8125, device='cuda:0')   \n",
       "545  tensor(0.3121, device='cuda:0')   tensor(21954.1309, device='cuda:0')   \n",
       "548  tensor(0.2769, device='cuda:0')   tensor(16871.9629, device='cuda:0')   \n",
       "549                              NaN                                   NaN   \n",
       "550                              NaN                                   NaN   \n",
       "552  tensor(0.0179, device='cuda:0')   tensor(51658.1523, device='cuda:0')   \n",
       "553                              NaN                                   NaN   \n",
       "556  tensor(1.3230, device='cuda:0')      tensor(19.8980, device='cuda:0')   \n",
       "557  tensor(0.2617, device='cuda:0')   tensor(30910.1953, device='cuda:0')   \n",
       "558  tensor(0.2382, device='cuda:0')   tensor(73778.8125, device='cuda:0')   \n",
       "559  tensor(0.3069, device='cuda:0')   tensor(25220.7832, device='cuda:0')   \n",
       "562  tensor(0.2863, device='cuda:0')   tensor(18499.2578, device='cuda:0')   \n",
       "563                              NaN                                   NaN   \n",
       "564                              NaN                                   NaN   \n",
       "566  tensor(0.0281, device='cuda:0')   tensor(44953.9258, device='cuda:0')   \n",
       "567                              NaN                                   NaN   \n",
       "570  tensor(1.3222, device='cuda:0')      tensor(19.4090, device='cuda:0')   \n",
       "571  tensor(0.2334, device='cuda:0')   tensor(20308.2109, device='cuda:0')   \n",
       "572  tensor(0.2497, device='cuda:0')   tensor(79543.6953, device='cuda:0')   \n",
       "573  tensor(0.2922, device='cuda:0')   tensor(21952.1660, device='cuda:0')   \n",
       "576  tensor(0.3276, device='cuda:0')   tensor(18994.0117, device='cuda:0')   \n",
       "577                              NaN                                   NaN   \n",
       "578                              NaN                                   NaN   \n",
       "580  tensor(0.0168, device='cuda:0')   tensor(53809.4688, device='cuda:0')   \n",
       "581                              NaN                                   NaN   \n",
       "584  tensor(0.9609, device='cuda:0')      tensor(19.6104, device='cuda:0')   \n",
       "585  tensor(0.2270, device='cuda:0')   tensor(21879.9336, device='cuda:0')   \n",
       "586  tensor(0.2880, device='cuda:0')   tensor(75548.2031, device='cuda:0')   \n",
       "587  tensor(0.2907, device='cuda:0')   tensor(26675.1309, device='cuda:0')   \n",
       "590  tensor(0.3248, device='cuda:0')   tensor(22065.8965, device='cuda:0')   \n",
       "591                              NaN                                   NaN   \n",
       "592                              NaN                                   NaN   \n",
       "594  tensor(0.0255, device='cuda:0')   tensor(46765.5938, device='cuda:0')   \n",
       "595                              NaN                                   NaN   \n",
       "598  tensor(1.2050, device='cuda:0')      tensor(18.9062, device='cuda:0')   \n",
       "599  tensor(0.2036, device='cuda:0')   tensor(22988.7910, device='cuda:0')   \n",
       "600  tensor(0.3058, device='cuda:0')   tensor(82311.7031, device='cuda:0')   \n",
       "601  tensor(0.3024, device='cuda:0')   tensor(21297.1660, device='cuda:0')   \n",
       "604  tensor(0.4393, device='cuda:0')   tensor(16195.7930, device='cuda:0')   \n",
       "605                              NaN                                   NaN   \n",
       "606                              NaN                                   NaN   \n",
       "608  tensor(0.0292, device='cuda:0')   tensor(53386.8672, device='cuda:0')   \n",
       "609                              NaN                                   NaN   \n",
       "612  tensor(1.2248, device='cuda:0')      tensor(18.6180, device='cuda:0')   \n",
       "613  tensor(0.2913, device='cuda:0')   tensor(20778.1074, device='cuda:0')   \n",
       "614  tensor(0.3128, device='cuda:0')   tensor(81746.3516, device='cuda:0')   \n",
       "615  tensor(0.3113, device='cuda:0')   tensor(27444.8730, device='cuda:0')   \n",
       "618  tensor(0.3609, device='cuda:0')   tensor(24378.1270, device='cuda:0')   \n",
       "619                              NaN                                   NaN   \n",
       "620                              NaN                                   NaN   \n",
       "622  tensor(0.0187, device='cuda:0')   tensor(42568.5820, device='cuda:0')   \n",
       "623                              NaN                                   NaN   \n",
       "626  tensor(1.2664, device='cuda:0')      tensor(18.2832, device='cuda:0')   \n",
       "627  tensor(0.2537, device='cuda:0')   tensor(22587.2969, device='cuda:0')   \n",
       "628  tensor(0.3166, device='cuda:0')   tensor(72609.0625, device='cuda:0')   \n",
       "629  tensor(0.3117, device='cuda:0')   tensor(32460.4492, device='cuda:0')   \n",
       "632  tensor(0.2917, device='cuda:0')   tensor(23673.7500, device='cuda:0')   \n",
       "633                              NaN                                   NaN   \n",
       "634                              NaN                                   NaN   \n",
       "636  tensor(0.0303, device='cuda:0')   tensor(52744.7344, device='cuda:0')   \n",
       "637                              NaN                                   NaN   \n",
       "640  tensor(1.2379, device='cuda:0')      tensor(17.5274, device='cuda:0')   \n",
       "641  tensor(0.2771, device='cuda:0')   tensor(18962.4277, device='cuda:0')   \n",
       "642  tensor(0.3263, device='cuda:0')  tensor(106246.4297, device='cuda:0')   \n",
       "643  tensor(0.3127, device='cuda:0')   tensor(25293.5605, device='cuda:0')   \n",
       "646  tensor(0.4277, device='cuda:0')   tensor(18433.9844, device='cuda:0')   \n",
       "647                              NaN                                   NaN   \n",
       "648                              NaN                                   NaN   \n",
       "650  tensor(0.0278, device='cuda:0')   tensor(52921.0703, device='cuda:0')   \n",
       "651                              NaN                                   NaN   \n",
       "654  tensor(1.0957, device='cuda:0')      tensor(17.0027, device='cuda:0')   \n",
       "655  tensor(0.2280, device='cuda:0')   tensor(19675.5352, device='cuda:0')   \n",
       "656  tensor(0.3242, device='cuda:0')  tensor(111574.5156, device='cuda:0')   \n",
       "657  tensor(0.3095, device='cuda:0')   tensor(27845.4316, device='cuda:0')   \n",
       "660  tensor(0.2597, device='cuda:0')   tensor(18796.9766, device='cuda:0')   \n",
       "661                              NaN                                   NaN   \n",
       "662                              NaN                                   NaN   \n",
       "664  tensor(0.0209, device='cuda:0')   tensor(51019.8320, device='cuda:0')   \n",
       "665                              NaN                                   NaN   \n",
       "668  tensor(1.2159, device='cuda:0')      tensor(16.7475, device='cuda:0')   \n",
       "669  tensor(0.2667, device='cuda:0')   tensor(21914.2793, device='cuda:0')   \n",
       "670  tensor(0.3174, device='cuda:0')  tensor(111422.4453, device='cuda:0')   \n",
       "671  tensor(0.3074, device='cuda:0')   tensor(29768.1719, device='cuda:0')   \n",
       "674  tensor(0.2170, device='cuda:0')   tensor(21571.7891, device='cuda:0')   \n",
       "675                              NaN                                   NaN   \n",
       "676                              NaN                                   NaN   \n",
       "678  tensor(0.0182, device='cuda:0')   tensor(55123.1797, device='cuda:0')   \n",
       "679                              NaN                                   NaN   \n",
       "682  tensor(1.2207, device='cuda:0')      tensor(15.9157, device='cuda:0')   \n",
       "683  tensor(0.2358, device='cuda:0')   tensor(22331.1562, device='cuda:0')   \n",
       "684  tensor(0.3040, device='cuda:0')  tensor(113972.4375, device='cuda:0')   \n",
       "685  tensor(0.3093, device='cuda:0')   tensor(33630.3906, device='cuda:0')   \n",
       "688  tensor(0.4347, device='cuda:0')   tensor(25700.1016, device='cuda:0')   \n",
       "689                              NaN                                   NaN   \n",
       "690                              NaN                                   NaN   \n",
       "692  tensor(0.0333, device='cuda:0')   tensor(55082.1211, device='cuda:0')   \n",
       "693                              NaN                                   NaN   \n",
       "696  tensor(0.8439, device='cuda:0')      tensor(15.7200, device='cuda:0')   \n",
       "697  tensor(0.2751, device='cuda:0')   tensor(20928.5957, device='cuda:0')   \n",
       "698  tensor(0.3350, device='cuda:0')  tensor(113269.5703, device='cuda:0')   \n",
       "699  tensor(0.3159, device='cuda:0')   tensor(30227.0391, device='cuda:0')   \n",
       "702  tensor(0.3530, device='cuda:0')   tensor(19608.1230, device='cuda:0')   \n",
       "703                              NaN                                   NaN   \n",
       "704                              NaN                                   NaN   \n",
       "706  tensor(0.0285, device='cuda:0')   tensor(52513.4023, device='cuda:0')   \n",
       "707                              NaN                                   NaN   \n",
       "710  tensor(1.1101, device='cuda:0')      tensor(15.3637, device='cuda:0')   \n",
       "711  tensor(0.2780, device='cuda:0')   tensor(25004.5664, device='cuda:0')   \n",
       "712  tensor(0.3481, device='cuda:0')  tensor(101810.4688, device='cuda:0')   \n",
       "713  tensor(0.3239, device='cuda:0')   tensor(33316.6367, device='cuda:0')   \n",
       "716  tensor(0.2808, device='cuda:0')   tensor(29434.5645, device='cuda:0')   \n",
       "717                              NaN                                   NaN   \n",
       "718                              NaN                                   NaN   \n",
       "720  tensor(0.0179, device='cuda:0')   tensor(51368.3398, device='cuda:0')   \n",
       "721                              NaN                                   NaN   \n",
       "724  tensor(0.9062, device='cuda:0')      tensor(15.0024, device='cuda:0')   \n",
       "725  tensor(0.3027, device='cuda:0')   tensor(26607.0176, device='cuda:0')   \n",
       "726  tensor(0.3566, device='cuda:0')  tensor(100312.7344, device='cuda:0')   \n",
       "727  tensor(0.3159, device='cuda:0')   tensor(33053.0625, device='cuda:0')   \n",
       "730  tensor(0.3800, device='cuda:0')   tensor(27422.1973, device='cuda:0')   \n",
       "731                              NaN                                   NaN   \n",
       "732                              NaN                                   NaN   \n",
       "734  tensor(0.0261, device='cuda:0')   tensor(51599.6406, device='cuda:0')   \n",
       "735                              NaN                                   NaN   \n",
       "738  tensor(1.1133, device='cuda:0')      tensor(13.4254, device='cuda:0')   \n",
       "739  tensor(0.1532, device='cuda:0')   tensor(25177.1855, device='cuda:0')   \n",
       "740  tensor(0.3244, device='cuda:0')   tensor(94769.0859, device='cuda:0')   \n",
       "741  tensor(0.2801, device='cuda:0')   tensor(31653.9648, device='cuda:0')   \n",
       "744  tensor(0.3482, device='cuda:0')   tensor(27637.5566, device='cuda:0')   \n",
       "745                              NaN                                   NaN   \n",
       "746                              NaN                                   NaN   \n",
       "748  tensor(0.0234, device='cuda:0')   tensor(46854.0781, device='cuda:0')   \n",
       "749                              NaN                                   NaN   \n",
       "752  tensor(0.8497, device='cuda:0')      tensor(13.3784, device='cuda:0')   \n",
       "753  tensor(0.2343, device='cuda:0')   tensor(26657.4316, device='cuda:0')   \n",
       "754  tensor(0.2893, device='cuda:0')   tensor(90643.4609, device='cuda:0')   \n",
       "755  tensor(0.2918, device='cuda:0')   tensor(34523.9297, device='cuda:0')   \n",
       "758  tensor(0.3428, device='cuda:0')   tensor(20146.1777, device='cuda:0')   \n",
       "759                              NaN                                   NaN   \n",
       "760                              NaN                                   NaN   \n",
       "762  tensor(0.0289, device='cuda:0')   tensor(55536.3008, device='cuda:0')   \n",
       "763                              NaN                                   NaN   \n",
       "766  tensor(1.1528, device='cuda:0')      tensor(12.1845, device='cuda:0')   \n",
       "767  tensor(0.2110, device='cuda:0')   tensor(26562.7539, device='cuda:0')   \n",
       "768  tensor(0.2927, device='cuda:0')   tensor(89780.3984, device='cuda:0')   \n",
       "769  tensor(0.2878, device='cuda:0')   tensor(37705.6797, device='cuda:0')   \n",
       "772  tensor(0.2796, device='cuda:0')   tensor(21788.4023, device='cuda:0')   \n",
       "773                              NaN                                   NaN   \n",
       "774                              NaN                                   NaN   \n",
       "776  tensor(0.0289, device='cuda:0')   tensor(55452.2695, device='cuda:0')   \n",
       "777                              NaN                                   NaN   \n",
       "780  tensor(0.8035, device='cuda:0')      tensor(11.3195, device='cuda:0')   \n",
       "781  tensor(0.2855, device='cuda:0')   tensor(30401.8984, device='cuda:0')   \n",
       "782  tensor(0.2801, device='cuda:0')   tensor(86191.8828, device='cuda:0')   \n",
       "783  tensor(0.3004, device='cuda:0')   tensor(42098.7969, device='cuda:0')   \n",
       "786  tensor(0.3140, device='cuda:0')   tensor(30547.9570, device='cuda:0')   \n",
       "787                              NaN                                   NaN   \n",
       "788                              NaN                                   NaN   \n",
       "790  tensor(0.0296, device='cuda:0')   tensor(51285.6055, device='cuda:0')   \n",
       "791                              NaN                                   NaN   \n",
       "794  tensor(0.9896, device='cuda:0')      tensor(10.6801, device='cuda:0')   \n",
       "795  tensor(0.2775, device='cuda:0')   tensor(45431.2383, device='cuda:0')   \n",
       "796  tensor(0.2315, device='cuda:0')   tensor(82750.0625, device='cuda:0')   \n",
       "797  tensor(0.3005, device='cuda:0')   tensor(46438.2578, device='cuda:0')   \n",
       "800  tensor(0.2843, device='cuda:0')   tensor(28483.9883, device='cuda:0')   \n",
       "801                              NaN                                   NaN   \n",
       "802                              NaN                                   NaN   \n",
       "804  tensor(0.0244, device='cuda:0')   tensor(51343.9414, device='cuda:0')   \n",
       "805                              NaN                                   NaN   \n",
       "808  tensor(0.8968, device='cuda:0')      tensor(10.5430, device='cuda:0')   \n",
       "809  tensor(0.1437, device='cuda:0')   tensor(38577.4727, device='cuda:0')   \n",
       "810  tensor(0.1664, device='cuda:0')   tensor(80056.2734, device='cuda:0')   \n",
       "811  tensor(0.2844, device='cuda:0')   tensor(51825.0703, device='cuda:0')   \n",
       "814  tensor(0.3805, device='cuda:0')   tensor(31275.2129, device='cuda:0')   \n",
       "815                              NaN                                   NaN   \n",
       "816                              NaN                                   NaN   \n",
       "818  tensor(0.0269, device='cuda:0')   tensor(66133.5000, device='cuda:0')   \n",
       "819                              NaN                                   NaN   \n",
       "822  tensor(0.8496, device='cuda:0')      tensor(10.7000, device='cuda:0')   \n",
       "823  tensor(0.1819, device='cuda:0')   tensor(38388.2422, device='cuda:0')   \n",
       "824  tensor(0.2305, device='cuda:0')   tensor(65362.0078, device='cuda:0')   \n",
       "825  tensor(0.2352, device='cuda:0')   tensor(73035.7344, device='cuda:0')   \n",
       "828  tensor(0.3095, device='cuda:0')   tensor(26455.1523, device='cuda:0')   \n",
       "829                              NaN                                   NaN   \n",
       "830                              NaN                                   NaN   \n",
       "832  tensor(0.0257, device='cuda:0')   tensor(51248.5547, device='cuda:0')   \n",
       "833                              NaN                                   NaN   \n",
       "836  tensor(0.6004, device='cuda:0')      tensor(14.8305, device='cuda:0')   \n",
       "837  tensor(0.1751, device='cuda:0')   tensor(38450.7852, device='cuda:0')   \n",
       "838  tensor(0.1997, device='cuda:0')   tensor(71203.4219, device='cuda:0')   \n",
       "839  tensor(0.2365, device='cuda:0')  tensor(133543.0156, device='cuda:0')   \n",
       "842  tensor(0.2669, device='cuda:0')   tensor(27195.3047, device='cuda:0')   \n",
       "843                              NaN                                   NaN   \n",
       "844                              NaN                                   NaN   \n",
       "846  tensor(0.0338, device='cuda:0')   tensor(71440.6328, device='cuda:0')   \n",
       "847                              NaN                                   NaN   \n",
       "\n",
       "                             spec_b_min  spec_topk_u_cos_mean  \\\n",
       "1     tensor(123.8643, device='cuda:0')              0.009858   \n",
       "2      tensor(14.0500, device='cuda:0')              0.011980   \n",
       "3     tensor(193.5397, device='cuda:0')              0.005732   \n",
       "6     tensor(349.4814, device='cuda:0')              0.034686   \n",
       "7                                   NaN                   NaN   \n",
       "8                                   NaN                   NaN   \n",
       "10    tensor(448.7613, device='cuda:0')              0.020428   \n",
       "11                                  NaN                   NaN   \n",
       "13     tensor(54.7479, device='cuda:0')              0.009657   \n",
       "14     tensor(14.6983, device='cuda:0')              0.011400   \n",
       "15     tensor(92.7970, device='cuda:0')              0.004700   \n",
       "18    tensor(459.6478, device='cuda:0')              0.031373   \n",
       "19                                  NaN                   NaN   \n",
       "20                                  NaN                   NaN   \n",
       "22    tensor(142.0708, device='cuda:0')              0.021420   \n",
       "23                                  NaN                   NaN   \n",
       "25     tensor(54.8235, device='cuda:0')              0.008878   \n",
       "26     tensor(14.2677, device='cuda:0')              0.012118   \n",
       "27     tensor(82.5646, device='cuda:0')              0.006619   \n",
       "30    tensor(299.2184, device='cuda:0')              0.034930   \n",
       "31                                  NaN                   NaN   \n",
       "32                                  NaN                   NaN   \n",
       "34    tensor(189.9186, device='cuda:0')              0.021700   \n",
       "35                                  NaN                   NaN   \n",
       "38      tensor(0.6943, device='cuda:0')              0.052490   \n",
       "39    tensor(734.4297, device='cuda:0')              0.009379   \n",
       "40    tensor(317.1217, device='cuda:0')              0.023236   \n",
       "41   tensor(1131.4620, device='cuda:0')              0.019030   \n",
       "44    tensor(493.9148, device='cuda:0')              0.028789   \n",
       "45                                  NaN                   NaN   \n",
       "46                                  NaN                   NaN   \n",
       "48    tensor(268.7662, device='cuda:0')              0.020213   \n",
       "49                                  NaN                   NaN   \n",
       "52      tensor(0.8897, device='cuda:0')              0.061384   \n",
       "53   tensor(1011.9544, device='cuda:0')              0.008529   \n",
       "54    tensor(336.0762, device='cuda:0')              0.023238   \n",
       "55   tensor(1417.6627, device='cuda:0')              0.019178   \n",
       "58    tensor(811.0349, device='cuda:0')              0.034204   \n",
       "59                                  NaN                   NaN   \n",
       "60                                  NaN                   NaN   \n",
       "62    tensor(138.7651, device='cuda:0')              0.019057   \n",
       "63                                  NaN                   NaN   \n",
       "66      tensor(1.1303, device='cuda:0')              0.060588   \n",
       "67   tensor(1176.4631, device='cuda:0')              0.009212   \n",
       "68    tensor(307.6887, device='cuda:0')              0.024255   \n",
       "69   tensor(1433.1211, device='cuda:0')              0.017506   \n",
       "72    tensor(684.1966, device='cuda:0')              0.030119   \n",
       "73                                  NaN                   NaN   \n",
       "74                                  NaN                   NaN   \n",
       "76    tensor(295.7480, device='cuda:0')              0.020558   \n",
       "77                                  NaN                   NaN   \n",
       "80      tensor(1.3835, device='cuda:0')              0.057435   \n",
       "81   tensor(1691.2562, device='cuda:0')              0.008484   \n",
       "82    tensor(457.8208, device='cuda:0')              0.021233   \n",
       "83   tensor(1973.3673, device='cuda:0')              0.018294   \n",
       "86    tensor(974.3234, device='cuda:0')              0.033464   \n",
       "87                                  NaN                   NaN   \n",
       "88                                  NaN                   NaN   \n",
       "90    tensor(212.2912, device='cuda:0')              0.020843   \n",
       "91                                  NaN                   NaN   \n",
       "94      tensor(1.5054, device='cuda:0')              0.050679   \n",
       "95   tensor(1795.1691, device='cuda:0')              0.009855   \n",
       "96    tensor(548.3376, device='cuda:0')              0.023331   \n",
       "97   tensor(2252.2698, device='cuda:0')              0.018230   \n",
       "100  tensor(1032.4326, device='cuda:0')              0.032385   \n",
       "101                                 NaN                   NaN   \n",
       "102                                 NaN                   NaN   \n",
       "104   tensor(240.6645, device='cuda:0')              0.018368   \n",
       "105                                 NaN                   NaN   \n",
       "108     tensor(1.3173, device='cuda:0')              0.055703   \n",
       "109  tensor(1117.1893, device='cuda:0')              0.008836   \n",
       "110   tensor(727.8314, device='cuda:0')              0.020648   \n",
       "111  tensor(1791.0648, device='cuda:0')              0.017679   \n",
       "114   tensor(701.4940, device='cuda:0')              0.034952   \n",
       "115                                 NaN                   NaN   \n",
       "116                                 NaN                   NaN   \n",
       "118   tensor(175.2891, device='cuda:0')              0.020584   \n",
       "119                                 NaN                   NaN   \n",
       "122     tensor(1.2535, device='cuda:0')              0.060233   \n",
       "123  tensor(1790.4146, device='cuda:0')              0.009286   \n",
       "124   tensor(828.9401, device='cuda:0')              0.019958   \n",
       "125  tensor(1970.3135, device='cuda:0')              0.016321   \n",
       "128  tensor(1192.0713, device='cuda:0')              0.037490   \n",
       "129                                 NaN                   NaN   \n",
       "130                                 NaN                   NaN   \n",
       "132   tensor(183.3855, device='cuda:0')              0.018340   \n",
       "133                                 NaN                   NaN   \n",
       "136     tensor(1.5520, device='cuda:0')              0.059070   \n",
       "137  tensor(2026.8906, device='cuda:0')              0.008964   \n",
       "138   tensor(896.1336, device='cuda:0')              0.018471   \n",
       "139  tensor(2129.5164, device='cuda:0')              0.018753   \n",
       "142  tensor(1197.1150, device='cuda:0')              0.031686   \n",
       "143                                 NaN                   NaN   \n",
       "144                                 NaN                   NaN   \n",
       "146   tensor(256.6241, device='cuda:0')              0.020768   \n",
       "147                                 NaN                   NaN   \n",
       "150     tensor(1.6265, device='cuda:0')              0.059861   \n",
       "151  tensor(1880.5460, device='cuda:0')              0.009668   \n",
       "152   tensor(929.4828, device='cuda:0')              0.018252   \n",
       "153  tensor(1779.7095, device='cuda:0')              0.016646   \n",
       "156  tensor(1105.7489, device='cuda:0')              0.029149   \n",
       "157                                 NaN                   NaN   \n",
       "158                                 NaN                   NaN   \n",
       "160   tensor(115.6161, device='cuda:0')              0.019574   \n",
       "161                                 NaN                   NaN   \n",
       "164     tensor(1.5206, device='cuda:0')              0.058849   \n",
       "165  tensor(1916.7957, device='cuda:0')              0.010405   \n",
       "166  tensor(1006.9933, device='cuda:0')              0.019685   \n",
       "167  tensor(1965.0605, device='cuda:0')              0.018247   \n",
       "170   tensor(988.1455, device='cuda:0')              0.036253   \n",
       "171                                 NaN                   NaN   \n",
       "172                                 NaN                   NaN   \n",
       "174   tensor(300.1672, device='cuda:0')              0.018672   \n",
       "175                                 NaN                   NaN   \n",
       "178     tensor(1.5001, device='cuda:0')              0.054921   \n",
       "179  tensor(1847.8428, device='cuda:0')              0.009487   \n",
       "180   tensor(980.4156, device='cuda:0')              0.018317   \n",
       "181  tensor(1940.9368, device='cuda:0')              0.016222   \n",
       "184  tensor(1166.3866, device='cuda:0')              0.037458   \n",
       "185                                 NaN                   NaN   \n",
       "186                                 NaN                   NaN   \n",
       "188   tensor(218.6425, device='cuda:0')              0.021687   \n",
       "189                                 NaN                   NaN   \n",
       "192     tensor(1.0434, device='cuda:0')              0.056231   \n",
       "193  tensor(1216.9896, device='cuda:0')              0.008841   \n",
       "194   tensor(920.8010, device='cuda:0')              0.020180   \n",
       "195  tensor(1912.5502, device='cuda:0')              0.017517   \n",
       "198  tensor(1095.8082, device='cuda:0')              0.037729   \n",
       "199                                 NaN                   NaN   \n",
       "200                                 NaN                   NaN   \n",
       "202   tensor(217.2288, device='cuda:0')              0.017864   \n",
       "203                                 NaN                   NaN   \n",
       "206     tensor(1.0092, device='cuda:0')              0.056154   \n",
       "207  tensor(1616.5973, device='cuda:0')              0.009738   \n",
       "208   tensor(926.6945, device='cuda:0')              0.017695   \n",
       "209  tensor(1833.2781, device='cuda:0')              0.015459   \n",
       "212  tensor(1218.4589, device='cuda:0')              0.032655   \n",
       "213                                 NaN                   NaN   \n",
       "214                                 NaN                   NaN   \n",
       "216   tensor(148.3328, device='cuda:0')              0.020467   \n",
       "217                                 NaN                   NaN   \n",
       "220     tensor(1.2814, device='cuda:0')              0.056924   \n",
       "221  tensor(1835.0660, device='cuda:0')              0.009111   \n",
       "222   tensor(709.9133, device='cuda:0')              0.020365   \n",
       "223  tensor(1862.6338, device='cuda:0')              0.016793   \n",
       "226  tensor(1060.8881, device='cuda:0')              0.032469   \n",
       "227                                 NaN                   NaN   \n",
       "228                                 NaN                   NaN   \n",
       "230   tensor(245.6241, device='cuda:0')              0.021531   \n",
       "231                                 NaN                   NaN   \n",
       "234     tensor(0.9067, device='cuda:0')              0.052852   \n",
       "235  tensor(1538.2830, device='cuda:0')              0.010404   \n",
       "236  tensor(1075.5168, device='cuda:0')              0.018606   \n",
       "237  tensor(1974.4187, device='cuda:0')              0.018359   \n",
       "240  tensor(1491.3947, device='cuda:0')              0.033979   \n",
       "241                                 NaN                   NaN   \n",
       "242                                 NaN                   NaN   \n",
       "244   tensor(118.4166, device='cuda:0')              0.018672   \n",
       "245                                 NaN                   NaN   \n",
       "248     tensor(1.1170, device='cuda:0')              0.051986   \n",
       "249  tensor(1471.2906, device='cuda:0')              0.009075   \n",
       "250  tensor(1028.6125, device='cuda:0')              0.019666   \n",
       "251  tensor(1861.3116, device='cuda:0')              0.015712   \n",
       "254   tensor(901.4807, device='cuda:0')              0.036349   \n",
       "255                                 NaN                   NaN   \n",
       "256                                 NaN                   NaN   \n",
       "258   tensor(333.1879, device='cuda:0')              0.018761   \n",
       "259                                 NaN                   NaN   \n",
       "262     tensor(1.0984, device='cuda:0')              0.055092   \n",
       "263  tensor(1354.5665, device='cuda:0')              0.009436   \n",
       "264  tensor(1081.9030, device='cuda:0')              0.018326   \n",
       "265  tensor(1777.1334, device='cuda:0')              0.018734   \n",
       "268  tensor(1195.6292, device='cuda:0')              0.030921   \n",
       "269                                 NaN                   NaN   \n",
       "270                                 NaN                   NaN   \n",
       "272   tensor(188.1636, device='cuda:0')              0.020754   \n",
       "273                                 NaN                   NaN   \n",
       "276     tensor(1.0226, device='cuda:0')              0.058086   \n",
       "277  tensor(1344.3741, device='cuda:0')              0.010581   \n",
       "278   tensor(920.9156, device='cuda:0')              0.017288   \n",
       "279  tensor(1514.9631, device='cuda:0')              0.015927   \n",
       "282  tensor(1050.2319, device='cuda:0')              0.034801   \n",
       "283                                 NaN                   NaN   \n",
       "284                                 NaN                   NaN   \n",
       "286   tensor(207.2476, device='cuda:0')              0.021953   \n",
       "287                                 NaN                   NaN   \n",
       "290     tensor(0.8903, device='cuda:0')              0.058708   \n",
       "291  tensor(1171.0211, device='cuda:0')              0.009365   \n",
       "292  tensor(1012.3903, device='cuda:0')              0.019430   \n",
       "293  tensor(1610.6716, device='cuda:0')              0.016775   \n",
       "296  tensor(1192.5704, device='cuda:0')              0.037548   \n",
       "297                                 NaN                   NaN   \n",
       "298                                 NaN                   NaN   \n",
       "300   tensor(210.6368, device='cuda:0')              0.020258   \n",
       "301                                 NaN                   NaN   \n",
       "304     tensor(1.0490, device='cuda:0')              0.054744   \n",
       "305   tensor(926.3517, device='cuda:0')              0.008859   \n",
       "306  tensor(1015.9985, device='cuda:0')              0.020339   \n",
       "307  tensor(1365.4669, device='cuda:0')              0.019378   \n",
       "310  tensor(1042.3430, device='cuda:0')              0.036258   \n",
       "311                                 NaN                   NaN   \n",
       "312                                 NaN                   NaN   \n",
       "314   tensor(266.4430, device='cuda:0')              0.020226   \n",
       "315                                 NaN                   NaN   \n",
       "318     tensor(0.8511, device='cuda:0')              0.053567   \n",
       "319  tensor(1101.2554, device='cuda:0')              0.009180   \n",
       "320  tensor(1090.6274, device='cuda:0')              0.018863   \n",
       "321  tensor(1252.9811, device='cuda:0')              0.017855   \n",
       "324  tensor(1083.7571, device='cuda:0')              0.033890   \n",
       "325                                 NaN                   NaN   \n",
       "326                                 NaN                   NaN   \n",
       "328   tensor(350.3239, device='cuda:0')              0.018027   \n",
       "329                                 NaN                   NaN   \n",
       "332     tensor(0.5796, device='cuda:0')              0.056543   \n",
       "333  tensor(1115.9261, device='cuda:0')              0.010351   \n",
       "334  tensor(1099.7976, device='cuda:0')              0.018725   \n",
       "335  tensor(1265.5392, device='cuda:0')              0.017558   \n",
       "338   tensor(681.5680, device='cuda:0')              0.036253   \n",
       "339                                 NaN                   NaN   \n",
       "340                                 NaN                   NaN   \n",
       "342   tensor(326.1928, device='cuda:0')              0.021769   \n",
       "343                                 NaN                   NaN   \n",
       "346     tensor(0.5242, device='cuda:0')              0.060098   \n",
       "347  tensor(1094.6136, device='cuda:0')              0.009092   \n",
       "348   tensor(859.8816, device='cuda:0')              0.020504   \n",
       "349  tensor(1283.7434, device='cuda:0')              0.018288   \n",
       "352   tensor(914.3749, device='cuda:0')              0.033887   \n",
       "353                                 NaN                   NaN   \n",
       "354                                 NaN                   NaN   \n",
       "356   tensor(336.4664, device='cuda:0')              0.019291   \n",
       "357                                 NaN                   NaN   \n",
       "360     tensor(0.8358, device='cuda:0')              0.060369   \n",
       "361  tensor(1257.2622, device='cuda:0')              0.008828   \n",
       "362   tensor(908.4090, device='cuda:0')              0.019819   \n",
       "363  tensor(1364.3462, device='cuda:0')              0.018020   \n",
       "366   tensor(730.5581, device='cuda:0')              0.037116   \n",
       "367                                 NaN                   NaN   \n",
       "368                                 NaN                   NaN   \n",
       "370   tensor(542.9551, device='cuda:0')              0.018961   \n",
       "371                                 NaN                   NaN   \n",
       "374     tensor(0.5479, device='cuda:0')              0.054753   \n",
       "375  tensor(1134.4048, device='cuda:0')              0.009180   \n",
       "376   tensor(913.3782, device='cuda:0')              0.020757   \n",
       "377  tensor(1336.8438, device='cuda:0')              0.017752   \n",
       "380   tensor(734.1368, device='cuda:0')              0.032147   \n",
       "381                                 NaN                   NaN   \n",
       "382                                 NaN                   NaN   \n",
       "384   tensor(512.9623, device='cuda:0')              0.019349   \n",
       "385                                 NaN                   NaN   \n",
       "388     tensor(0.7559, device='cuda:0')              0.061572   \n",
       "389  tensor(1460.1954, device='cuda:0')              0.009132   \n",
       "390   tensor(795.9445, device='cuda:0')              0.021818   \n",
       "391  tensor(1267.0066, device='cuda:0')              0.017620   \n",
       "394   tensor(884.9722, device='cuda:0')              0.037256   \n",
       "395                                 NaN                   NaN   \n",
       "396                                 NaN                   NaN   \n",
       "398   tensor(606.1862, device='cuda:0')              0.019921   \n",
       "399                                 NaN                   NaN   \n",
       "402     tensor(0.8710, device='cuda:0')              0.058088   \n",
       "403  tensor(1490.7745, device='cuda:0')              0.009460   \n",
       "404   tensor(915.3406, device='cuda:0')              0.023896   \n",
       "405  tensor(1421.3143, device='cuda:0')              0.017506   \n",
       "408   tensor(825.5083, device='cuda:0')              0.033500   \n",
       "409                                 NaN                   NaN   \n",
       "410                                 NaN                   NaN   \n",
       "412   tensor(515.2435, device='cuda:0')              0.020079   \n",
       "413                                 NaN                   NaN   \n",
       "416     tensor(0.6377, device='cuda:0')              0.060003   \n",
       "417  tensor(1350.3138, device='cuda:0')              0.010027   \n",
       "418   tensor(983.3224, device='cuda:0')              0.024433   \n",
       "419  tensor(1428.4304, device='cuda:0')              0.018452   \n",
       "422   tensor(844.2772, device='cuda:0')              0.032912   \n",
       "423                                 NaN                   NaN   \n",
       "424                                 NaN                   NaN   \n",
       "426   tensor(328.3351, device='cuda:0')              0.020317   \n",
       "427                                 NaN                   NaN   \n",
       "430     tensor(0.5326, device='cuda:0')              0.057099   \n",
       "431  tensor(1201.0504, device='cuda:0')              0.009488   \n",
       "432   tensor(875.6617, device='cuda:0')              0.021611   \n",
       "433  tensor(1275.1847, device='cuda:0')              0.018927   \n",
       "436   tensor(778.5264, device='cuda:0')              0.034739   \n",
       "437                                 NaN                   NaN   \n",
       "438                                 NaN                   NaN   \n",
       "440   tensor(382.4539, device='cuda:0')              0.018741   \n",
       "441                                 NaN                   NaN   \n",
       "444     tensor(0.6083, device='cuda:0')              0.053367   \n",
       "445  tensor(1530.0123, device='cuda:0')              0.009655   \n",
       "446   tensor(884.8000, device='cuda:0')              0.023104   \n",
       "447  tensor(1365.5833, device='cuda:0')              0.016535   \n",
       "450   tensor(850.0392, device='cuda:0')              0.033253   \n",
       "451                                 NaN                   NaN   \n",
       "452                                 NaN                   NaN   \n",
       "454   tensor(448.6319, device='cuda:0')              0.021628   \n",
       "455                                 NaN                   NaN   \n",
       "458     tensor(0.5621, device='cuda:0')              0.058072   \n",
       "459  tensor(1087.7020, device='cuda:0')              0.008224   \n",
       "460  tensor(1267.0739, device='cuda:0')              0.023341   \n",
       "461  tensor(1398.8707, device='cuda:0')              0.016476   \n",
       "464   tensor(926.3890, device='cuda:0')              0.034343   \n",
       "465                                 NaN                   NaN   \n",
       "466                                 NaN                   NaN   \n",
       "468   tensor(281.6629, device='cuda:0')              0.018554   \n",
       "469                                 NaN                   NaN   \n",
       "472     tensor(0.3963, device='cuda:0')              0.056675   \n",
       "473  tensor(1301.0970, device='cuda:0')              0.009679   \n",
       "474  tensor(1203.6633, device='cuda:0')              0.022332   \n",
       "475  tensor(1319.6487, device='cuda:0')              0.017651   \n",
       "478  tensor(1214.6302, device='cuda:0')              0.042080   \n",
       "479                                 NaN                   NaN   \n",
       "480                                 NaN                   NaN   \n",
       "482   tensor(316.4215, device='cuda:0')              0.021652   \n",
       "483                                 NaN                   NaN   \n",
       "486     tensor(0.3777, device='cuda:0')              0.058767   \n",
       "487  tensor(1291.6893, device='cuda:0')              0.008011   \n",
       "488  tensor(1047.5306, device='cuda:0')              0.024240   \n",
       "489  tensor(1279.8574, device='cuda:0')              0.018822   \n",
       "492  tensor(1131.8569, device='cuda:0')              0.036469   \n",
       "493                                 NaN                   NaN   \n",
       "494                                 NaN                   NaN   \n",
       "496   tensor(348.9747, device='cuda:0')              0.021805   \n",
       "497                                 NaN                   NaN   \n",
       "500     tensor(0.5605, device='cuda:0')              0.050157   \n",
       "501  tensor(1253.4230, device='cuda:0')              0.009592   \n",
       "502  tensor(1105.7457, device='cuda:0')              0.022781   \n",
       "503  tensor(1485.3699, device='cuda:0')              0.017387   \n",
       "506   tensor(798.4045, device='cuda:0')              0.031350   \n",
       "507                                 NaN                   NaN   \n",
       "508                                 NaN                   NaN   \n",
       "510   tensor(334.8853, device='cuda:0')              0.019658   \n",
       "511                                 NaN                   NaN   \n",
       "514     tensor(0.2907, device='cuda:0')              0.057409   \n",
       "515  tensor(1199.3651, device='cuda:0')              0.009943   \n",
       "516  tensor(1246.8788, device='cuda:0')              0.024083   \n",
       "517  tensor(1357.3019, device='cuda:0')              0.018314   \n",
       "520   tensor(705.0221, device='cuda:0')              0.034346   \n",
       "521                                 NaN                   NaN   \n",
       "522                                 NaN                   NaN   \n",
       "524   tensor(289.7812, device='cuda:0')              0.021286   \n",
       "525                                 NaN                   NaN   \n",
       "528     tensor(0.4193, device='cuda:0')              0.065414   \n",
       "529  tensor(1360.1426, device='cuda:0')              0.009270   \n",
       "530  tensor(1092.5890, device='cuda:0')              0.025629   \n",
       "531  tensor(1209.2291, device='cuda:0')              0.015611   \n",
       "534  tensor(1076.2759, device='cuda:0')              0.032116   \n",
       "535                                 NaN                   NaN   \n",
       "536                                 NaN                   NaN   \n",
       "538   tensor(352.6909, device='cuda:0')              0.020622   \n",
       "539                                 NaN                   NaN   \n",
       "542     tensor(0.3133, device='cuda:0')              0.054745   \n",
       "543  tensor(1302.4084, device='cuda:0')              0.009048   \n",
       "544  tensor(1116.7582, device='cuda:0')              0.022096   \n",
       "545  tensor(1331.0073, device='cuda:0')              0.019636   \n",
       "548  tensor(1119.1906, device='cuda:0')              0.034292   \n",
       "549                                 NaN                   NaN   \n",
       "550                                 NaN                   NaN   \n",
       "552   tensor(479.7096, device='cuda:0')              0.018561   \n",
       "553                                 NaN                   NaN   \n",
       "556     tensor(0.3129, device='cuda:0')              0.055726   \n",
       "557  tensor(1336.4958, device='cuda:0')              0.010527   \n",
       "558  tensor(1321.6344, device='cuda:0')              0.021741   \n",
       "559  tensor(1410.1320, device='cuda:0')              0.017817   \n",
       "562   tensor(948.2445, device='cuda:0')              0.029919   \n",
       "563                                 NaN                   NaN   \n",
       "564                                 NaN                   NaN   \n",
       "566   tensor(399.7122, device='cuda:0')              0.018542   \n",
       "567                                 NaN                   NaN   \n",
       "570     tensor(0.6169, device='cuda:0')              0.056536   \n",
       "571  tensor(1423.6157, device='cuda:0')              0.009573   \n",
       "572  tensor(1148.2297, device='cuda:0')              0.023126   \n",
       "573  tensor(1366.4347, device='cuda:0')              0.016123   \n",
       "576   tensor(980.2805, device='cuda:0')              0.030863   \n",
       "577                                 NaN                   NaN   \n",
       "578                                 NaN                   NaN   \n",
       "580   tensor(281.6903, device='cuda:0')              0.019164   \n",
       "581                                 NaN                   NaN   \n",
       "584     tensor(0.7785, device='cuda:0')              0.057986   \n",
       "585  tensor(1451.9927, device='cuda:0')              0.010943   \n",
       "586   tensor(995.4772, device='cuda:0')              0.023047   \n",
       "587  tensor(1549.4810, device='cuda:0')              0.015795   \n",
       "590  tensor(1180.8955, device='cuda:0')              0.034803   \n",
       "591                                 NaN                   NaN   \n",
       "592                                 NaN                   NaN   \n",
       "594   tensor(479.8380, device='cuda:0')              0.021566   \n",
       "595                                 NaN                   NaN   \n",
       "598     tensor(0.7413, device='cuda:0')              0.056541   \n",
       "599  tensor(1329.7961, device='cuda:0')              0.010056   \n",
       "600  tensor(1160.0485, device='cuda:0')              0.024044   \n",
       "601  tensor(1401.2380, device='cuda:0')              0.018315   \n",
       "604   tensor(915.5868, device='cuda:0')              0.037992   \n",
       "605                                 NaN                   NaN   \n",
       "606                                 NaN                   NaN   \n",
       "608   tensor(447.5946, device='cuda:0')              0.021227   \n",
       "609                                 NaN                   NaN   \n",
       "612     tensor(0.6161, device='cuda:0')              0.052854   \n",
       "613  tensor(1325.4924, device='cuda:0')              0.009665   \n",
       "614   tensor(968.7919, device='cuda:0')              0.024499   \n",
       "615  tensor(1330.8536, device='cuda:0')              0.020119   \n",
       "618   tensor(717.0118, device='cuda:0')              0.033497   \n",
       "619                                 NaN                   NaN   \n",
       "620                                 NaN                   NaN   \n",
       "622   tensor(192.1265, device='cuda:0')              0.021018   \n",
       "623                                 NaN                   NaN   \n",
       "626     tensor(0.4598, device='cuda:0')              0.063964   \n",
       "627  tensor(1243.1486, device='cuda:0')              0.009211   \n",
       "628  tensor(1066.7689, device='cuda:0')              0.023203   \n",
       "629  tensor(1261.4333, device='cuda:0')              0.018788   \n",
       "632  tensor(1276.4473, device='cuda:0')              0.038879   \n",
       "633                                 NaN                   NaN   \n",
       "634                                 NaN                   NaN   \n",
       "636   tensor(281.4563, device='cuda:0')              0.023660   \n",
       "637                                 NaN                   NaN   \n",
       "640     tensor(0.6244, device='cuda:0')              0.058605   \n",
       "641  tensor(1216.6095, device='cuda:0')              0.009485   \n",
       "642  tensor(1193.6700, device='cuda:0')              0.022841   \n",
       "643  tensor(1307.9918, device='cuda:0')              0.017715   \n",
       "646   tensor(835.9100, device='cuda:0')              0.033485   \n",
       "647                                 NaN                   NaN   \n",
       "648                                 NaN                   NaN   \n",
       "650   tensor(287.5673, device='cuda:0')              0.019480   \n",
       "651                                 NaN                   NaN   \n",
       "654     tensor(0.6454, device='cuda:0')              0.057581   \n",
       "655  tensor(1432.4521, device='cuda:0')              0.009470   \n",
       "656  tensor(1224.0015, device='cuda:0')              0.023511   \n",
       "657  tensor(1474.0465, device='cuda:0')              0.017577   \n",
       "660   tensor(986.0127, device='cuda:0')              0.038973   \n",
       "661                                 NaN                   NaN   \n",
       "662                                 NaN                   NaN   \n",
       "664   tensor(425.2454, device='cuda:0')              0.022472   \n",
       "665                                 NaN                   NaN   \n",
       "668     tensor(0.6265, device='cuda:0')              0.049300   \n",
       "669  tensor(1514.9797, device='cuda:0')              0.009734   \n",
       "670   tensor(925.5266, device='cuda:0')              0.024306   \n",
       "671  tensor(1483.9000, device='cuda:0')              0.017942   \n",
       "674   tensor(802.8763, device='cuda:0')              0.035519   \n",
       "675                                 NaN                   NaN   \n",
       "676                                 NaN                   NaN   \n",
       "678   tensor(302.8674, device='cuda:0')              0.020723   \n",
       "679                                 NaN                   NaN   \n",
       "682     tensor(0.6022, device='cuda:0')              0.057833   \n",
       "683  tensor(1222.7699, device='cuda:0')              0.009021   \n",
       "684  tensor(1106.0845, device='cuda:0')              0.023341   \n",
       "685  tensor(1413.1527, device='cuda:0')              0.018218   \n",
       "688  tensor(1030.2719, device='cuda:0')              0.028479   \n",
       "689                                 NaN                   NaN   \n",
       "690                                 NaN                   NaN   \n",
       "692   tensor(277.5867, device='cuda:0')              0.022478   \n",
       "693                                 NaN                   NaN   \n",
       "696     tensor(0.6150, device='cuda:0')              0.054628   \n",
       "697  tensor(1156.3484, device='cuda:0')              0.009614   \n",
       "698   tensor(759.3851, device='cuda:0')              0.021289   \n",
       "699  tensor(1434.9103, device='cuda:0')              0.020795   \n",
       "702   tensor(944.1569, device='cuda:0')              0.034502   \n",
       "703                                 NaN                   NaN   \n",
       "704                                 NaN                   NaN   \n",
       "706   tensor(301.4102, device='cuda:0')              0.023728   \n",
       "707                                 NaN                   NaN   \n",
       "710     tensor(0.5136, device='cuda:0')              0.060453   \n",
       "711  tensor(1187.7864, device='cuda:0')              0.008800   \n",
       "712   tensor(958.1579, device='cuda:0')              0.022771   \n",
       "713  tensor(1547.9927, device='cuda:0')              0.015974   \n",
       "716   tensor(890.7657, device='cuda:0')              0.043087   \n",
       "717                                 NaN                   NaN   \n",
       "718                                 NaN                   NaN   \n",
       "720   tensor(306.4969, device='cuda:0')              0.020646   \n",
       "721                                 NaN                   NaN   \n",
       "724     tensor(0.6519, device='cuda:0')              0.055274   \n",
       "725   tensor(836.8721, device='cuda:0')              0.009524   \n",
       "726  tensor(1080.0212, device='cuda:0')              0.021744   \n",
       "727  tensor(1500.3104, device='cuda:0')              0.016491   \n",
       "730   tensor(904.6476, device='cuda:0')              0.032327   \n",
       "731                                 NaN                   NaN   \n",
       "732                                 NaN                   NaN   \n",
       "734   tensor(254.6298, device='cuda:0')              0.019736   \n",
       "735                                 NaN                   NaN   \n",
       "738     tensor(0.4878, device='cuda:0')              0.061265   \n",
       "739  tensor(1207.6293, device='cuda:0')              0.009604   \n",
       "740  tensor(1046.7028, device='cuda:0')              0.022195   \n",
       "741  tensor(1424.4911, device='cuda:0')              0.018351   \n",
       "744  tensor(1330.9163, device='cuda:0')              0.036090   \n",
       "745                                 NaN                   NaN   \n",
       "746                                 NaN                   NaN   \n",
       "748   tensor(229.1664, device='cuda:0')              0.018460   \n",
       "749                                 NaN                   NaN   \n",
       "752     tensor(0.4817, device='cuda:0')              0.056800   \n",
       "753  tensor(1255.6924, device='cuda:0')              0.008952   \n",
       "754   tensor(965.4329, device='cuda:0')              0.022573   \n",
       "755  tensor(1400.4647, device='cuda:0')              0.018156   \n",
       "758   tensor(816.6249, device='cuda:0')              0.028331   \n",
       "759                                 NaN                   NaN   \n",
       "760                                 NaN                   NaN   \n",
       "762   tensor(209.8562, device='cuda:0')              0.018221   \n",
       "763                                 NaN                   NaN   \n",
       "766     tensor(0.4646, device='cuda:0')              0.055801   \n",
       "767  tensor(1329.0332, device='cuda:0')              0.010085   \n",
       "768   tensor(878.8092, device='cuda:0')              0.022778   \n",
       "769  tensor(1585.0227, device='cuda:0')              0.018419   \n",
       "772   tensor(880.0981, device='cuda:0')              0.031593   \n",
       "773                                 NaN                   NaN   \n",
       "774                                 NaN                   NaN   \n",
       "776   tensor(287.8564, device='cuda:0')              0.020174   \n",
       "777                                 NaN                   NaN   \n",
       "780     tensor(0.4171, device='cuda:0')              0.060555   \n",
       "781  tensor(1290.9520, device='cuda:0')              0.009396   \n",
       "782   tensor(715.9442, device='cuda:0')              0.021087   \n",
       "783  tensor(1519.8364, device='cuda:0')              0.017972   \n",
       "786  tensor(1284.9739, device='cuda:0')              0.030963   \n",
       "787                                 NaN                   NaN   \n",
       "788                                 NaN                   NaN   \n",
       "790   tensor(314.9107, device='cuda:0')              0.019055   \n",
       "791                                 NaN                   NaN   \n",
       "794     tensor(0.4201, device='cuda:0')              0.053434   \n",
       "795   tensor(903.4066, device='cuda:0')              0.009721   \n",
       "796   tensor(682.2212, device='cuda:0')              0.023708   \n",
       "797   tensor(516.5245, device='cuda:0')              0.020112   \n",
       "800  tensor(1262.7197, device='cuda:0')              0.034648   \n",
       "801                                 NaN                   NaN   \n",
       "802                                 NaN                   NaN   \n",
       "804   tensor(193.8278, device='cuda:0')              0.019795   \n",
       "805                                 NaN                   NaN   \n",
       "808     tensor(0.1361, device='cuda:0')              0.060235   \n",
       "809   tensor(586.1177, device='cuda:0')              0.008666   \n",
       "810   tensor(558.2468, device='cuda:0')              0.023041   \n",
       "811   tensor(799.5524, device='cuda:0')              0.018768   \n",
       "814   tensor(795.6398, device='cuda:0')              0.031931   \n",
       "815                                 NaN                   NaN   \n",
       "816                                 NaN                   NaN   \n",
       "818   tensor(340.0785, device='cuda:0')              0.018997   \n",
       "819                                 NaN                   NaN   \n",
       "822     tensor(0.4479, device='cuda:0')              0.051078   \n",
       "823   tensor(791.0397, device='cuda:0')              0.009505   \n",
       "824   tensor(486.4416, device='cuda:0')              0.021038   \n",
       "825  tensor(1042.3658, device='cuda:0')              0.015664   \n",
       "828  tensor(1135.1500, device='cuda:0')              0.041457   \n",
       "829                                 NaN                   NaN   \n",
       "830                                 NaN                   NaN   \n",
       "832   tensor(212.9493, device='cuda:0')              0.020493   \n",
       "833                                 NaN                   NaN   \n",
       "836     tensor(0.1455, device='cuda:0')              0.058314   \n",
       "837   tensor(176.5273, device='cuda:0')              0.009358   \n",
       "838   tensor(208.3305, device='cuda:0')              0.020965   \n",
       "839   tensor(128.6453, device='cuda:0')              0.016444   \n",
       "842  tensor(1194.9875, device='cuda:0')              0.035558   \n",
       "843                                 NaN                   NaN   \n",
       "844                                 NaN                   NaN   \n",
       "846   tensor(186.7096, device='cuda:0')              0.020782   \n",
       "847                                 NaN                   NaN   \n",
       "\n",
       "     spec_topk_u_cos_min  spec_topk_v_cos_mean  spec_topk_v_cos_min  \\\n",
       "1           2.135959e-05              0.006279         8.940118e-05   \n",
       "2           1.085157e-05              0.009933         6.676973e-05   \n",
       "3           7.110900e-05              0.008338         2.253988e-04   \n",
       "6           3.276460e-04              0.010963         1.366049e-05   \n",
       "7                    NaN                   NaN                  NaN   \n",
       "8                    NaN                   NaN                  NaN   \n",
       "10          3.701173e-04              0.009279         1.076259e-04   \n",
       "11                   NaN                   NaN                  NaN   \n",
       "13          2.635098e-05              0.005309         2.208141e-05   \n",
       "14          2.853623e-05              0.009340         9.212323e-05   \n",
       "15          2.599603e-05              0.010238         8.757383e-05   \n",
       "18          3.778761e-05              0.009502         1.464497e-05   \n",
       "19                   NaN                   NaN                  NaN   \n",
       "20                   NaN                   NaN                  NaN   \n",
       "22          4.508418e-04              0.009537         1.584741e-05   \n",
       "23                   NaN                   NaN                  NaN   \n",
       "25          1.097677e-04              0.006395         3.087616e-05   \n",
       "26          2.442019e-06              0.008370         1.423434e-04   \n",
       "27          1.657797e-04              0.008757         3.409907e-05   \n",
       "30          3.163759e-04              0.008852         8.393408e-05   \n",
       "31                   NaN                   NaN                  NaN   \n",
       "32                   NaN                   NaN                  NaN   \n",
       "34          1.052731e-04              0.009288         1.998310e-05   \n",
       "35                   NaN                   NaN                  NaN   \n",
       "38          2.375107e-03              0.009253         1.735121e-04   \n",
       "39          1.157948e-04              0.016306         3.225813e-05   \n",
       "40          3.001294e-05              0.009082         6.010657e-05   \n",
       "41          1.416251e-03              0.009417         1.322419e-04   \n",
       "44          3.697004e-04              0.008603         1.054758e-04   \n",
       "45                   NaN                   NaN                  NaN   \n",
       "46                   NaN                   NaN                  NaN   \n",
       "48          2.149240e-04              0.009391         4.613798e-06   \n",
       "49                   NaN                   NaN                  NaN   \n",
       "52          6.467307e-04              0.010052         2.562767e-04   \n",
       "53          7.492003e-05              0.018766         2.823336e-04   \n",
       "54          1.302439e-04              0.009005         9.551667e-05   \n",
       "55          2.775257e-04              0.009316         6.161588e-06   \n",
       "58          1.780987e-05              0.010234         6.047131e-05   \n",
       "59                   NaN                   NaN                  NaN   \n",
       "60                   NaN                   NaN                  NaN   \n",
       "62          4.665591e-05              0.009012         3.330892e-05   \n",
       "63                   NaN                   NaN                  NaN   \n",
       "66          5.232801e-04              0.009613         9.767702e-05   \n",
       "67          2.122949e-06              0.016597         2.944023e-04   \n",
       "68          6.432866e-05              0.009283         2.406337e-05   \n",
       "69          2.067901e-04              0.008557         5.233132e-05   \n",
       "72          1.895294e-04              0.008172         1.491961e-05   \n",
       "73                   NaN                   NaN                  NaN   \n",
       "74                   NaN                   NaN                  NaN   \n",
       "76          8.571552e-04              0.008851         7.961850e-05   \n",
       "77                   NaN                   NaN                  NaN   \n",
       "80          3.428339e-04              0.010306         1.212706e-04   \n",
       "81          2.478153e-05              0.016637         2.363533e-05   \n",
       "82          9.256021e-05              0.010505         1.226376e-04   \n",
       "83          5.425171e-04              0.010056         1.882706e-04   \n",
       "86          2.147381e-04              0.010304         3.603280e-04   \n",
       "87                   NaN                   NaN                  NaN   \n",
       "88                   NaN                   NaN                  NaN   \n",
       "90          9.200790e-05              0.009675         1.176521e-05   \n",
       "91                   NaN                   NaN                  NaN   \n",
       "94          6.354765e-05              0.009383         1.136579e-04   \n",
       "95          8.888672e-05              0.015708         7.636492e-05   \n",
       "96          5.034434e-04              0.009411         1.137765e-04   \n",
       "97          1.923553e-04              0.009575         8.513871e-05   \n",
       "100         1.081334e-04              0.009014         6.582138e-05   \n",
       "101                  NaN                   NaN                  NaN   \n",
       "102                  NaN                   NaN                  NaN   \n",
       "104         5.254057e-04              0.011221         9.408009e-05   \n",
       "105                  NaN                   NaN                  NaN   \n",
       "108         8.076369e-04              0.009610         9.113410e-05   \n",
       "109         1.346304e-04              0.018719         6.900202e-04   \n",
       "110         6.705386e-05              0.008304         3.321376e-05   \n",
       "111         3.042362e-04              0.009788         1.139945e-04   \n",
       "114         1.025921e-04              0.009666         3.514080e-06   \n",
       "115                  NaN                   NaN                  NaN   \n",
       "116                  NaN                   NaN                  NaN   \n",
       "118         2.691646e-04              0.010884         7.940549e-05   \n",
       "119                  NaN                   NaN                  NaN   \n",
       "122         7.667489e-04              0.009610         1.277797e-04   \n",
       "123         2.256520e-04              0.017010         5.387106e-06   \n",
       "124         7.612236e-05              0.009496         3.374169e-04   \n",
       "125         5.873727e-04              0.008551         4.488669e-05   \n",
       "128         4.360771e-04              0.008713         3.108490e-05   \n",
       "129                  NaN                   NaN                  NaN   \n",
       "130                  NaN                   NaN                  NaN   \n",
       "132         5.730405e-04              0.008997         3.684941e-05   \n",
       "133                  NaN                   NaN                  NaN   \n",
       "136         7.475888e-04              0.008561         2.245625e-05   \n",
       "137         1.118059e-04              0.016552         3.188674e-04   \n",
       "138         1.968195e-04              0.008572         3.507027e-05   \n",
       "139         3.450912e-04              0.008696         7.936008e-05   \n",
       "142         4.101652e-04              0.009139         1.561108e-06   \n",
       "143                  NaN                   NaN                  NaN   \n",
       "144                  NaN                   NaN                  NaN   \n",
       "146         9.337109e-05              0.008707         3.924416e-05   \n",
       "147                  NaN                   NaN                  NaN   \n",
       "150         9.776780e-04              0.009666         2.670465e-05   \n",
       "151         2.409700e-04              0.016766         1.344823e-05   \n",
       "152         3.744127e-05              0.009561         1.574015e-04   \n",
       "153         1.365797e-04              0.009754         6.072643e-05   \n",
       "156         2.214524e-04              0.010020         5.137134e-06   \n",
       "157                  NaN                   NaN                  NaN   \n",
       "158                  NaN                   NaN                  NaN   \n",
       "160         8.701634e-06              0.009633         1.715627e-05   \n",
       "161                  NaN                   NaN                  NaN   \n",
       "164         1.813016e-04              0.010098         5.757692e-05   \n",
       "165         2.814135e-04              0.018651         2.380415e-04   \n",
       "166         2.180625e-04              0.008882         3.035114e-05   \n",
       "167         1.663378e-04              0.009845         5.675370e-05   \n",
       "170         3.266752e-04              0.009120         1.183076e-04   \n",
       "171                  NaN                   NaN                  NaN   \n",
       "172                  NaN                   NaN                  NaN   \n",
       "174         2.058231e-04              0.009999         9.691253e-05   \n",
       "175                  NaN                   NaN                  NaN   \n",
       "178         4.291588e-04              0.009158         4.455452e-05   \n",
       "179         9.094416e-06              0.017325         4.463206e-05   \n",
       "180         2.312965e-04              0.010131         2.254441e-05   \n",
       "181         6.163601e-05              0.009133         2.254407e-05   \n",
       "184         5.678153e-04              0.008450         2.449809e-05   \n",
       "185                  NaN                   NaN                  NaN   \n",
       "186                  NaN                   NaN                  NaN   \n",
       "188         1.322738e-04              0.009715         3.932869e-05   \n",
       "189                  NaN                   NaN                  NaN   \n",
       "192         8.062422e-04              0.008598         6.801846e-05   \n",
       "193         6.068109e-06              0.016658         4.098071e-04   \n",
       "194         4.372881e-04              0.010397         2.298953e-04   \n",
       "195         4.675386e-05              0.009148         1.215996e-04   \n",
       "198         8.237747e-05              0.008915         7.996759e-05   \n",
       "199                  NaN                   NaN                  NaN   \n",
       "200                  NaN                   NaN                  NaN   \n",
       "202         1.257130e-03              0.009166         9.863065e-05   \n",
       "203                  NaN                   NaN                  NaN   \n",
       "206         1.166427e-03              0.009959         8.060056e-05   \n",
       "207         6.592246e-05              0.018207         6.505140e-04   \n",
       "208         1.392960e-04              0.009966         4.151587e-05   \n",
       "209         1.670447e-04              0.009272         1.486905e-04   \n",
       "212         2.093654e-04              0.009091         7.862057e-05   \n",
       "213                  NaN                   NaN                  NaN   \n",
       "214                  NaN                   NaN                  NaN   \n",
       "216         4.107460e-05              0.009084         1.082079e-04   \n",
       "217                  NaN                   NaN                  NaN   \n",
       "220         1.763348e-03              0.010408         5.293634e-05   \n",
       "221         1.819824e-04              0.018294         3.795329e-05   \n",
       "222         5.585758e-04              0.009165         3.116904e-05   \n",
       "223         6.165392e-04              0.008592         1.563807e-06   \n",
       "226         1.585503e-04              0.009009         8.236145e-05   \n",
       "227                  NaN                   NaN                  NaN   \n",
       "228                  NaN                   NaN                  NaN   \n",
       "230         1.680081e-04              0.009942         4.294467e-06   \n",
       "231                  NaN                   NaN                  NaN   \n",
       "234         1.666386e-03              0.009207         1.330105e-04   \n",
       "235         2.258347e-04              0.018782         4.459386e-04   \n",
       "236         7.672733e-06              0.009371         2.643484e-04   \n",
       "237         3.160204e-04              0.009109         7.972325e-05   \n",
       "240         1.174607e-03              0.008979         4.496304e-05   \n",
       "241                  NaN                   NaN                  NaN   \n",
       "242                  NaN                   NaN                  NaN   \n",
       "244         1.493023e-04              0.009489         8.747861e-05   \n",
       "245                  NaN                   NaN                  NaN   \n",
       "248         4.706438e-04              0.009594         2.697046e-05   \n",
       "249         5.950281e-05              0.017753         2.524187e-04   \n",
       "250         1.306992e-04              0.009659         6.721320e-06   \n",
       "251         2.388387e-05              0.009351         7.444618e-05   \n",
       "254         6.165561e-05              0.010202         5.563757e-05   \n",
       "255                  NaN                   NaN                  NaN   \n",
       "256                  NaN                   NaN                  NaN   \n",
       "258         2.578904e-04              0.008560         3.315162e-05   \n",
       "259                  NaN                   NaN                  NaN   \n",
       "262         8.172798e-04              0.009180         4.815317e-05   \n",
       "263         3.720384e-04              0.017004         3.154096e-04   \n",
       "264         4.921704e-05              0.009337         2.676544e-05   \n",
       "265         2.238143e-04              0.010022         2.883684e-05   \n",
       "268         3.202272e-04              0.007919         1.087242e-04   \n",
       "269                  NaN                   NaN                  NaN   \n",
       "270                  NaN                   NaN                  NaN   \n",
       "272         4.116604e-04              0.010507         1.002822e-04   \n",
       "273                  NaN                   NaN                  NaN   \n",
       "276         9.619877e-04              0.009387         5.926202e-05   \n",
       "277         2.105567e-04              0.019896         3.937582e-05   \n",
       "278         2.575951e-05              0.008844         1.066473e-05   \n",
       "279         4.330596e-04              0.009877         5.852825e-06   \n",
       "282         4.140799e-04              0.009770         6.365346e-05   \n",
       "283                  NaN                   NaN                  NaN   \n",
       "284                  NaN                   NaN                  NaN   \n",
       "286         2.713648e-04              0.008596         1.451743e-04   \n",
       "287                  NaN                   NaN                  NaN   \n",
       "290         1.043467e-03              0.009641         5.744134e-05   \n",
       "291         2.085403e-04              0.017969         1.132557e-05   \n",
       "292         5.128735e-04              0.009914         2.521355e-04   \n",
       "293         1.189172e-04              0.009981         3.211034e-05   \n",
       "296         4.928890e-04              0.010299         1.853030e-04   \n",
       "297                  NaN                   NaN                  NaN   \n",
       "298                  NaN                   NaN                  NaN   \n",
       "300         9.473615e-05              0.009296         1.113752e-04   \n",
       "301                  NaN                   NaN                  NaN   \n",
       "304         1.035609e-03              0.009305         7.382348e-05   \n",
       "305         3.911988e-05              0.017899         4.389784e-04   \n",
       "306         6.489080e-04              0.008362         3.023008e-05   \n",
       "307         6.410672e-05              0.008328         1.923737e-05   \n",
       "310         2.195175e-04              0.009423         2.140864e-04   \n",
       "311                  NaN                   NaN                  NaN   \n",
       "312                  NaN                   NaN                  NaN   \n",
       "314         6.731620e-05              0.010013         5.585853e-06   \n",
       "315                  NaN                   NaN                  NaN   \n",
       "318         2.362516e-04              0.009886         2.061941e-04   \n",
       "319         1.345080e-04              0.016963         6.055955e-04   \n",
       "320         5.235159e-04              0.009827         6.713955e-05   \n",
       "321         1.100783e-04              0.008977         1.756690e-04   \n",
       "324         6.738935e-04              0.009168         2.472647e-05   \n",
       "325                  NaN                   NaN                  NaN   \n",
       "326                  NaN                   NaN                  NaN   \n",
       "328         3.983682e-04              0.010898         9.850290e-05   \n",
       "329                  NaN                   NaN                  NaN   \n",
       "332         1.236015e-04              0.008714         1.455596e-05   \n",
       "333         4.795391e-05              0.016194         1.886502e-04   \n",
       "334         1.938065e-04              0.009127         2.137514e-06   \n",
       "335         1.016326e-04              0.009624         7.439352e-05   \n",
       "338         9.789478e-06              0.008468         8.082546e-05   \n",
       "339                  NaN                   NaN                  NaN   \n",
       "340                  NaN                   NaN                  NaN   \n",
       "342         2.266864e-04              0.008797         1.312394e-04   \n",
       "343                  NaN                   NaN                  NaN   \n",
       "346         8.696014e-04              0.010326         1.375237e-04   \n",
       "347         1.458897e-04              0.018369         2.088620e-04   \n",
       "348         2.934152e-04              0.009949         2.580496e-05   \n",
       "349         4.725865e-04              0.009484         4.861219e-05   \n",
       "352         1.048039e-04              0.009352         4.796919e-08   \n",
       "353                  NaN                   NaN                  NaN   \n",
       "354                  NaN                   NaN                  NaN   \n",
       "356         1.179662e-04              0.009413         3.701523e-04   \n",
       "357                  NaN                   NaN                  NaN   \n",
       "360         7.401875e-04              0.009582         6.787359e-05   \n",
       "361         3.501372e-04              0.017289         7.452597e-05   \n",
       "362         7.254230e-05              0.008535         7.073116e-05   \n",
       "363         1.122044e-05              0.009780         1.972930e-05   \n",
       "366         2.482850e-04              0.009020         4.530067e-05   \n",
       "367                  NaN                   NaN                  NaN   \n",
       "368                  NaN                   NaN                  NaN   \n",
       "370         5.231717e-04              0.008846         8.569611e-05   \n",
       "371                  NaN                   NaN                  NaN   \n",
       "374         1.802947e-04              0.009935         2.327667e-04   \n",
       "375         2.241372e-05              0.020291         7.626469e-05   \n",
       "376         1.989583e-05              0.009358         2.860786e-04   \n",
       "377         3.539885e-05              0.009298         3.778445e-06   \n",
       "380         5.572631e-04              0.009097         2.131149e-04   \n",
       "381                  NaN                   NaN                  NaN   \n",
       "382                  NaN                   NaN                  NaN   \n",
       "384         2.082170e-04              0.010743         4.899863e-04   \n",
       "385                  NaN                   NaN                  NaN   \n",
       "388         6.797977e-04              0.010201         7.364851e-06   \n",
       "389         1.012004e-04              0.017238         1.879230e-04   \n",
       "390         7.000451e-04              0.009234         6.398346e-06   \n",
       "391         1.961612e-04              0.009489         2.848488e-05   \n",
       "394         2.988074e-05              0.010424         3.133365e-05   \n",
       "395                  NaN                   NaN                  NaN   \n",
       "396                  NaN                   NaN                  NaN   \n",
       "398         1.169605e-04              0.009264         1.888735e-04   \n",
       "399                  NaN                   NaN                  NaN   \n",
       "402         1.342546e-03              0.008676         8.502888e-06   \n",
       "403         2.336063e-04              0.017281         9.816625e-05   \n",
       "404         1.576220e-04              0.008623         1.726403e-05   \n",
       "405         3.429909e-04              0.010260         8.180193e-05   \n",
       "408         1.612856e-04              0.008811         1.171612e-05   \n",
       "409                  NaN                   NaN                  NaN   \n",
       "410                  NaN                   NaN                  NaN   \n",
       "412         7.954473e-05              0.008566         1.686784e-05   \n",
       "413                  NaN                   NaN                  NaN   \n",
       "416         1.779902e-04              0.008857         3.891367e-05   \n",
       "417         6.554968e-05              0.016692         1.957595e-06   \n",
       "418         4.780053e-04              0.008899         1.693933e-04   \n",
       "419         3.790357e-04              0.009220         4.092219e-05   \n",
       "422         4.317692e-04              0.009616         3.053472e-05   \n",
       "423                  NaN                   NaN                  NaN   \n",
       "424                  NaN                   NaN                  NaN   \n",
       "426         6.041315e-04              0.009769         9.956510e-05   \n",
       "427                  NaN                   NaN                  NaN   \n",
       "430         1.674190e-03              0.010095         6.675431e-05   \n",
       "431         1.246531e-05              0.018140         7.349366e-05   \n",
       "432         2.234755e-05              0.008070         1.520225e-04   \n",
       "433         2.383912e-04              0.008627         3.007845e-05   \n",
       "436         2.476494e-04              0.009853         3.619543e-04   \n",
       "437                  NaN                   NaN                  NaN   \n",
       "438                  NaN                   NaN                  NaN   \n",
       "440         3.489057e-04              0.010008         8.914230e-06   \n",
       "441                  NaN                   NaN                  NaN   \n",
       "444         1.221055e-03              0.009261         3.587130e-05   \n",
       "445         1.858424e-05              0.016505         3.743844e-06   \n",
       "446         2.739299e-04              0.009059         1.415235e-06   \n",
       "447         9.091378e-05              0.009020         4.929966e-05   \n",
       "450         4.768497e-04              0.009275         1.044966e-04   \n",
       "451                  NaN                   NaN                  NaN   \n",
       "452                  NaN                   NaN                  NaN   \n",
       "454         3.123549e-04              0.009969         4.293425e-05   \n",
       "455                  NaN                   NaN                  NaN   \n",
       "458         3.284667e-05              0.010438         3.695511e-05   \n",
       "459         9.026210e-05              0.017743         2.592006e-04   \n",
       "460         1.378335e-04              0.009348         6.259223e-06   \n",
       "461         2.627929e-04              0.009886         4.313570e-04   \n",
       "464         5.474986e-06              0.009949         2.161141e-05   \n",
       "465                  NaN                   NaN                  NaN   \n",
       "466                  NaN                   NaN                  NaN   \n",
       "468         3.717479e-04              0.009551         4.853477e-05   \n",
       "469                  NaN                   NaN                  NaN   \n",
       "472         1.105872e-04              0.008756         6.255870e-05   \n",
       "473         1.144439e-04              0.017535         6.975065e-04   \n",
       "474         4.013958e-06              0.009807         2.151840e-04   \n",
       "475         2.875610e-04              0.009345         1.397024e-05   \n",
       "478         3.052537e-04              0.009068         6.151332e-05   \n",
       "479                  NaN                   NaN                  NaN   \n",
       "480                  NaN                   NaN                  NaN   \n",
       "482         1.465922e-05              0.009745         1.189756e-04   \n",
       "483                  NaN                   NaN                  NaN   \n",
       "486         1.564323e-03              0.010123         1.970843e-04   \n",
       "487         1.032477e-04              0.018236         1.456863e-03   \n",
       "488         6.860213e-05              0.009031         1.491076e-04   \n",
       "489         1.116475e-05              0.009156         1.435868e-04   \n",
       "492         6.160758e-04              0.009225         1.750136e-04   \n",
       "493                  NaN                   NaN                  NaN   \n",
       "494                  NaN                   NaN                  NaN   \n",
       "496         1.423036e-04              0.010053         2.797982e-06   \n",
       "497                  NaN                   NaN                  NaN   \n",
       "500         4.935949e-04              0.010295         2.167753e-06   \n",
       "501         8.316412e-05              0.017073         1.333827e-04   \n",
       "502         1.356602e-04              0.009506         3.103687e-05   \n",
       "503         3.373288e-04              0.009060         4.629541e-04   \n",
       "506         3.573753e-04              0.008443         1.106731e-04   \n",
       "507                  NaN                   NaN                  NaN   \n",
       "508                  NaN                   NaN                  NaN   \n",
       "510         3.069484e-04              0.009470         5.258771e-04   \n",
       "511                  NaN                   NaN                  NaN   \n",
       "514         1.334565e-03              0.008668         1.420775e-05   \n",
       "515         1.121841e-04              0.018723         1.029048e-04   \n",
       "516         1.766246e-04              0.010005         3.234378e-04   \n",
       "517         4.324293e-05              0.010008         2.710708e-05   \n",
       "520         1.214469e-03              0.010499         2.946670e-04   \n",
       "521                  NaN                   NaN                  NaN   \n",
       "522                  NaN                   NaN                  NaN   \n",
       "524         7.614162e-05              0.008607         3.801834e-06   \n",
       "525                  NaN                   NaN                  NaN   \n",
       "528         5.260390e-04              0.009222         9.123966e-06   \n",
       "529         4.566670e-04              0.017501         8.976113e-05   \n",
       "530         1.057993e-04              0.009184         8.403857e-05   \n",
       "531         9.331973e-07              0.009474         7.001583e-05   \n",
       "534         1.803401e-05              0.009307         4.866677e-06   \n",
       "535                  NaN                   NaN                  NaN   \n",
       "536                  NaN                   NaN                  NaN   \n",
       "538         8.258442e-05              0.009521         6.039991e-06   \n",
       "539                  NaN                   NaN                  NaN   \n",
       "542         8.008681e-06              0.009206         4.347075e-05   \n",
       "543         1.377258e-04              0.017156         2.029782e-04   \n",
       "544         1.531428e-04              0.009083         2.363928e-05   \n",
       "545         7.180075e-06              0.008796         1.331261e-04   \n",
       "548         3.613753e-04              0.010481         1.812131e-04   \n",
       "549                  NaN                   NaN                  NaN   \n",
       "550                  NaN                   NaN                  NaN   \n",
       "552         3.492055e-06              0.009123         8.367666e-06   \n",
       "553                  NaN                   NaN                  NaN   \n",
       "556         1.865421e-03              0.009630         4.815899e-05   \n",
       "557         1.361835e-04              0.013802         2.090650e-05   \n",
       "558         1.317952e-04              0.008127         1.202472e-05   \n",
       "559         4.377767e-05              0.010894         7.652361e-05   \n",
       "562         7.101535e-05              0.008990         5.823203e-05   \n",
       "563                  NaN                   NaN                  NaN   \n",
       "564                  NaN                   NaN                  NaN   \n",
       "566         1.269445e-06              0.010426         7.778249e-05   \n",
       "567                  NaN                   NaN                  NaN   \n",
       "570         3.782972e-04              0.009427         2.704759e-05   \n",
       "571         1.216412e-04              0.016799         1.477298e-04   \n",
       "572         9.051003e-05              0.010412         1.755327e-04   \n",
       "573         5.166910e-05              0.009680         9.950191e-05   \n",
       "576         1.160460e-04              0.009404         3.991327e-04   \n",
       "577                  NaN                   NaN                  NaN   \n",
       "578                  NaN                   NaN                  NaN   \n",
       "580         2.149590e-04              0.009362         9.193044e-05   \n",
       "581                  NaN                   NaN                  NaN   \n",
       "584         3.523288e-04              0.008634         8.720708e-05   \n",
       "585         1.730547e-04              0.019279         2.765036e-04   \n",
       "586         3.799311e-04              0.008206         1.342423e-04   \n",
       "587         6.752423e-05              0.010532         2.721646e-05   \n",
       "590         5.432271e-04              0.010137         2.948637e-05   \n",
       "591                  NaN                   NaN                  NaN   \n",
       "592                  NaN                   NaN                  NaN   \n",
       "594         1.419322e-04              0.009308         8.247992e-06   \n",
       "595                  NaN                   NaN                  NaN   \n",
       "598         1.004842e-03              0.010061         1.812365e-04   \n",
       "599         1.123857e-04              0.018523         8.091390e-05   \n",
       "600         2.854981e-05              0.009744         1.477597e-04   \n",
       "601         9.541544e-05              0.009243         2.904060e-05   \n",
       "604         4.503957e-04              0.008846         1.045981e-04   \n",
       "605                  NaN                   NaN                  NaN   \n",
       "606                  NaN                   NaN                  NaN   \n",
       "608         2.759859e-04              0.008991         8.263963e-06   \n",
       "609                  NaN                   NaN                  NaN   \n",
       "612         6.950810e-05              0.010188         7.106597e-05   \n",
       "613         1.305350e-04              0.020611         1.012218e-05   \n",
       "614         8.711897e-05              0.008794         7.416218e-05   \n",
       "615         1.998075e-04              0.008606         4.316019e-04   \n",
       "618         2.381118e-04              0.010073         3.034903e-04   \n",
       "619                  NaN                   NaN                  NaN   \n",
       "620                  NaN                   NaN                  NaN   \n",
       "622         4.981756e-04              0.010395         6.747567e-05   \n",
       "623                  NaN                   NaN                  NaN   \n",
       "626         3.340774e-04              0.009200         9.322339e-05   \n",
       "627         2.248128e-05              0.015068         1.169399e-04   \n",
       "628         3.024366e-04              0.009703         1.462776e-04   \n",
       "629         1.653466e-04              0.010035         8.155032e-06   \n",
       "632         5.601079e-04              0.009366         1.224874e-04   \n",
       "633                  NaN                   NaN                  NaN   \n",
       "634                  NaN                   NaN                  NaN   \n",
       "636         4.030979e-04              0.009943         5.648262e-05   \n",
       "637                  NaN                   NaN                  NaN   \n",
       "640         2.931666e-04              0.009981         4.330691e-05   \n",
       "641         3.706485e-05              0.017427         3.214202e-05   \n",
       "642         5.098538e-04              0.009485         3.034041e-05   \n",
       "643         1.902691e-07              0.009516         9.553224e-06   \n",
       "646         8.734912e-05              0.009547         7.414701e-05   \n",
       "647                  NaN                   NaN                  NaN   \n",
       "648                  NaN                   NaN                  NaN   \n",
       "650         6.230515e-06              0.009494         4.414003e-05   \n",
       "651                  NaN                   NaN                  NaN   \n",
       "654         6.670345e-04              0.009444         2.948388e-05   \n",
       "655         1.416054e-04              0.017783         2.205350e-04   \n",
       "656         3.551633e-04              0.009779         2.138221e-05   \n",
       "657         1.970258e-05              0.009355         1.771758e-05   \n",
       "660         1.280727e-04              0.009752         3.891859e-05   \n",
       "661                  NaN                   NaN                  NaN   \n",
       "662                  NaN                   NaN                  NaN   \n",
       "664         2.304637e-04              0.009816         3.246274e-06   \n",
       "665                  NaN                   NaN                  NaN   \n",
       "668         1.151491e-04              0.009662         3.919038e-05   \n",
       "669         1.614827e-04              0.017414         2.200030e-05   \n",
       "670         2.325664e-04              0.009236         6.317366e-07   \n",
       "671         8.328965e-04              0.009660         2.317139e-04   \n",
       "674         4.844767e-04              0.009666         6.252765e-05   \n",
       "675                  NaN                   NaN                  NaN   \n",
       "676                  NaN                   NaN                  NaN   \n",
       "678         9.033222e-04              0.009600         9.525313e-05   \n",
       "679                  NaN                   NaN                  NaN   \n",
       "682         4.030301e-04              0.009005         1.404873e-04   \n",
       "683         4.750127e-05              0.018995         4.457620e-05   \n",
       "684         1.244578e-04              0.009176         9.054493e-05   \n",
       "685         4.012492e-05              0.009711         2.180876e-04   \n",
       "688         6.470664e-05              0.008645         7.817513e-05   \n",
       "689                  NaN                   NaN                  NaN   \n",
       "690                  NaN                   NaN                  NaN   \n",
       "692         2.531880e-04              0.009149         2.241857e-05   \n",
       "693                  NaN                   NaN                  NaN   \n",
       "696         4.109248e-04              0.010400         3.294628e-06   \n",
       "697         5.248255e-05              0.019402         1.739248e-04   \n",
       "698         1.790393e-04              0.010133         2.128836e-04   \n",
       "699         7.465455e-05              0.009542         1.317907e-04   \n",
       "702         2.514485e-04              0.009781         1.390895e-04   \n",
       "703                  NaN                   NaN                  NaN   \n",
       "704                  NaN                   NaN                  NaN   \n",
       "706         5.901469e-04              0.009583         4.513282e-04   \n",
       "707                  NaN                   NaN                  NaN   \n",
       "710         4.498538e-04              0.009167         1.654910e-04   \n",
       "711         6.036117e-05              0.016890         4.774121e-04   \n",
       "712         3.292871e-05              0.009561         7.031342e-05   \n",
       "713         2.817766e-04              0.010924         1.944273e-04   \n",
       "716         3.120405e-04              0.009044         1.038434e-04   \n",
       "717                  NaN                   NaN                  NaN   \n",
       "718                  NaN                   NaN                  NaN   \n",
       "720         5.141289e-04              0.008436         4.274285e-05   \n",
       "721                  NaN                   NaN                  NaN   \n",
       "724         3.831508e-05              0.010296         3.229414e-06   \n",
       "725         9.331518e-05              0.018001         2.683627e-05   \n",
       "726         8.919198e-05              0.008943         4.383679e-05   \n",
       "727         1.194930e-04              0.009968         1.317188e-04   \n",
       "730         7.373513e-05              0.008962         9.850677e-05   \n",
       "731                  NaN                   NaN                  NaN   \n",
       "732                  NaN                   NaN                  NaN   \n",
       "734         5.098921e-04              0.009598         1.534616e-04   \n",
       "735                  NaN                   NaN                  NaN   \n",
       "738         1.774146e-03              0.008767         3.387111e-05   \n",
       "739         2.038164e-05              0.017128         8.675774e-05   \n",
       "740         4.308694e-04              0.009334         1.637276e-04   \n",
       "741         1.721785e-05              0.009903         1.154298e-05   \n",
       "744         5.613678e-05              0.008828         2.486951e-04   \n",
       "745                  NaN                   NaN                  NaN   \n",
       "746                  NaN                   NaN                  NaN   \n",
       "748         4.570196e-05              0.009248         4.354915e-05   \n",
       "749                  NaN                   NaN                  NaN   \n",
       "752         5.179920e-04              0.009354         1.451263e-04   \n",
       "753         6.360774e-05              0.018053         1.938107e-04   \n",
       "754         5.939807e-04              0.009305         4.253169e-04   \n",
       "755         2.435658e-04              0.009176         5.911770e-06   \n",
       "758         2.565815e-04              0.009491         3.157993e-05   \n",
       "759                  NaN                   NaN                  NaN   \n",
       "760                  NaN                   NaN                  NaN   \n",
       "762         3.772899e-05              0.009662         2.381837e-04   \n",
       "763                  NaN                   NaN                  NaN   \n",
       "766         2.641404e-04              0.010326         1.201245e-04   \n",
       "767         7.629678e-06              0.017181         9.118368e-05   \n",
       "768         8.831140e-05              0.007995         7.271907e-05   \n",
       "769         2.184379e-04              0.009447         1.689942e-04   \n",
       "772         5.937259e-05              0.009694         1.195816e-04   \n",
       "773                  NaN                   NaN                  NaN   \n",
       "774                  NaN                   NaN                  NaN   \n",
       "776         2.697091e-04              0.009244         1.372605e-04   \n",
       "777                  NaN                   NaN                  NaN   \n",
       "780         8.225833e-05              0.009095         2.160154e-04   \n",
       "781         8.548675e-05              0.017373         2.030478e-04   \n",
       "782         2.998451e-05              0.008638         1.815974e-04   \n",
       "783         7.666961e-05              0.010538         9.069940e-05   \n",
       "786         7.955917e-05              0.009864         2.764150e-05   \n",
       "787                  NaN                   NaN                  NaN   \n",
       "788                  NaN                   NaN                  NaN   \n",
       "790         2.804205e-05              0.010424         4.200035e-04   \n",
       "791                  NaN                   NaN                  NaN   \n",
       "794         1.885782e-04              0.009381         2.046767e-04   \n",
       "795         6.019613e-05              0.017881         7.727394e-05   \n",
       "796         4.984610e-04              0.009794         7.067386e-05   \n",
       "797         4.674533e-04              0.010032         7.333744e-05   \n",
       "800         2.647378e-04              0.009611         4.623981e-05   \n",
       "801                  NaN                   NaN                  NaN   \n",
       "802                  NaN                   NaN                  NaN   \n",
       "804         4.387709e-05              0.009822         6.547107e-05   \n",
       "805                  NaN                   NaN                  NaN   \n",
       "808         5.267344e-04              0.010066         4.398809e-04   \n",
       "809         2.624532e-05              0.019060         4.228681e-04   \n",
       "810         1.357284e-05              0.009258         2.884954e-04   \n",
       "811         1.469870e-04              0.010015         9.215138e-05   \n",
       "814         1.113813e-04              0.008349         1.448914e-04   \n",
       "815                  NaN                   NaN                  NaN   \n",
       "816                  NaN                   NaN                  NaN   \n",
       "818         3.463870e-04              0.010033         1.713159e-04   \n",
       "819                  NaN                   NaN                  NaN   \n",
       "822         1.191989e-05              0.009188         2.019776e-04   \n",
       "823         7.031715e-05              0.015669         2.352685e-04   \n",
       "824         1.914805e-05              0.008934         3.346864e-04   \n",
       "825         1.060572e-04              0.010596         1.569453e-04   \n",
       "828         4.456205e-04              0.009220         1.171809e-04   \n",
       "829                  NaN                   NaN                  NaN   \n",
       "830                  NaN                   NaN                  NaN   \n",
       "832         9.466882e-05              0.009677         2.336649e-04   \n",
       "833                  NaN                   NaN                  NaN   \n",
       "836         9.905634e-06              0.009731         1.811016e-06   \n",
       "837         4.673662e-05              0.017346         9.593985e-05   \n",
       "838         3.661342e-05              0.009747         4.116225e-05   \n",
       "839         5.486513e-05              0.009666         1.367414e-04   \n",
       "842         2.869157e-04              0.009894         2.241689e-05   \n",
       "843                  NaN                   NaN                  NaN   \n",
       "844                  NaN                   NaN                  NaN   \n",
       "846         2.516703e-05              0.009953         1.981615e-04   \n",
       "847                  NaN                   NaN                  NaN   \n",
       "\n",
       "     spec_subspace_overlap_u  spec_subspace_overlap_v        shape_a  \\\n",
       "1                   0.011917                 0.007174            NaN   \n",
       "2                   0.009958                 0.011808            NaN   \n",
       "3                   0.007190                 0.011946            NaN   \n",
       "6                   0.040606                 0.011874            NaN   \n",
       "7                        NaN                      NaN   (20480, 512)   \n",
       "8                        NaN                      NaN  (7168, 12288)   \n",
       "10                  0.025462                 0.011806            NaN   \n",
       "11                       NaN                      NaN  (12288, 1536)   \n",
       "13                  0.011796                 0.006596            NaN   \n",
       "14                  0.009154                 0.011891            NaN   \n",
       "15                  0.006312                 0.011855            NaN   \n",
       "18                  0.042643                 0.011806            NaN   \n",
       "19                       NaN                      NaN   (20480, 512)   \n",
       "20                       NaN                      NaN  (7168, 12288)   \n",
       "22                  0.025408                 0.011713            NaN   \n",
       "23                       NaN                      NaN  (12288, 1536)   \n",
       "25                  0.011824                 0.008569            NaN   \n",
       "26                  0.010751                 0.011821            NaN   \n",
       "27                  0.008386                 0.011729            NaN   \n",
       "30                  0.045957                 0.011777            NaN   \n",
       "31                       NaN                      NaN   (20480, 512)   \n",
       "32                       NaN                      NaN  (7168, 12288)   \n",
       "34                  0.025313                 0.011837            NaN   \n",
       "35                       NaN                      NaN  (12288, 1536)   \n",
       "38                  0.063449                 0.011868            NaN   \n",
       "39                  0.011770                 0.022368            NaN   \n",
       "40                  0.021871                 0.011835            NaN   \n",
       "41                  0.022202                 0.011697            NaN   \n",
       "44                  0.043251                 0.011756            NaN   \n",
       "45                       NaN                      NaN   (20480, 512)   \n",
       "46                       NaN                      NaN  (7168, 12288)   \n",
       "48                  0.025574                 0.011804            NaN   \n",
       "49                       NaN                      NaN  (12288, 1536)   \n",
       "52                  0.062927                 0.011883            NaN   \n",
       "53                  0.011747                 0.022105            NaN   \n",
       "54                  0.023036                 0.011735            NaN   \n",
       "55                  0.022183                 0.011721            NaN   \n",
       "58                  0.042516                 0.011831            NaN   \n",
       "59                       NaN                      NaN   (20480, 512)   \n",
       "60                       NaN                      NaN  (7168, 12288)   \n",
       "62                  0.025471                 0.011654            NaN   \n",
       "63                       NaN                      NaN  (12288, 1536)   \n",
       "66                  0.062512                 0.011886            NaN   \n",
       "67                  0.011735                 0.022372            NaN   \n",
       "68                  0.025065                 0.011946            NaN   \n",
       "69                  0.022481                 0.011891            NaN   \n",
       "72                  0.043641                 0.011704            NaN   \n",
       "73                       NaN                      NaN   (20480, 512)   \n",
       "74                       NaN                      NaN  (7168, 12288)   \n",
       "76                  0.025509                 0.011747            NaN   \n",
       "77                       NaN                      NaN  (12288, 1536)   \n",
       "80                  0.062596                 0.011804            NaN   \n",
       "81                  0.011772                 0.021546            NaN   \n",
       "82                  0.022496                 0.011900            NaN   \n",
       "83                  0.022151                 0.011839            NaN   \n",
       "86                  0.041454                 0.011931            NaN   \n",
       "87                       NaN                      NaN   (20480, 512)   \n",
       "88                       NaN                      NaN  (7168, 12288)   \n",
       "90                  0.025444                 0.011716            NaN   \n",
       "91                       NaN                      NaN  (12288, 1536)   \n",
       "94                  0.063360                 0.011765            NaN   \n",
       "95                  0.011792                 0.022062            NaN   \n",
       "96                  0.022128                 0.011814            NaN   \n",
       "97                  0.022226                 0.011840            NaN   \n",
       "100                 0.041827                 0.011800            NaN   \n",
       "101                      NaN                      NaN   (20480, 512)   \n",
       "102                      NaN                      NaN  (7168, 12288)   \n",
       "104                 0.025547                 0.011783            NaN   \n",
       "105                      NaN                      NaN  (12288, 1536)   \n",
       "108                 0.061747                 0.011808            NaN   \n",
       "109                 0.011814                 0.022340            NaN   \n",
       "110                 0.022713                 0.011915            NaN   \n",
       "111                 0.022323                 0.011744            NaN   \n",
       "114                 0.040179                 0.011849            NaN   \n",
       "115                      NaN                      NaN   (20480, 512)   \n",
       "116                      NaN                      NaN  (7168, 12288)   \n",
       "118                 0.025403                 0.011828            NaN   \n",
       "119                      NaN                      NaN  (12288, 1536)   \n",
       "122                 0.062641                 0.011820            NaN   \n",
       "123                 0.011905                 0.022165            NaN   \n",
       "124                 0.022661                 0.011788            NaN   \n",
       "125                 0.022014                 0.011796            NaN   \n",
       "128                 0.041528                 0.011838            NaN   \n",
       "129                      NaN                      NaN   (20480, 512)   \n",
       "130                      NaN                      NaN  (7168, 12288)   \n",
       "132                 0.025645                 0.011815            NaN   \n",
       "133                      NaN                      NaN  (12288, 1536)   \n",
       "136                 0.063095                 0.011992            NaN   \n",
       "137                 0.011867                 0.021368            NaN   \n",
       "138                 0.021582                 0.011873            NaN   \n",
       "139                 0.021837                 0.011791            NaN   \n",
       "142                 0.040662                 0.011803            NaN   \n",
       "143                      NaN                      NaN   (20480, 512)   \n",
       "144                      NaN                      NaN  (7168, 12288)   \n",
       "146                 0.025516                 0.011802            NaN   \n",
       "147                      NaN                      NaN  (12288, 1536)   \n",
       "150                 0.062497                 0.011787            NaN   \n",
       "151                 0.011792                 0.021636            NaN   \n",
       "152                 0.021960                 0.011853            NaN   \n",
       "153                 0.021793                 0.011696            NaN   \n",
       "156                 0.039519                 0.011800            NaN   \n",
       "157                      NaN                      NaN   (20480, 512)   \n",
       "158                      NaN                      NaN  (7168, 12288)   \n",
       "160                 0.025393                 0.011933            NaN   \n",
       "161                      NaN                      NaN  (12288, 1536)   \n",
       "164                 0.062286                 0.011768            NaN   \n",
       "165                 0.011882                 0.022975            NaN   \n",
       "166                 0.022636                 0.011830            NaN   \n",
       "167                 0.022731                 0.011903            NaN   \n",
       "170                 0.041915                 0.011761            NaN   \n",
       "171                      NaN                      NaN   (20480, 512)   \n",
       "172                      NaN                      NaN  (7168, 12288)   \n",
       "174                 0.025385                 0.011953            NaN   \n",
       "175                      NaN                      NaN  (12288, 1536)   \n",
       "178                 0.062748                 0.011780            NaN   \n",
       "179                 0.011775                 0.022120            NaN   \n",
       "180                 0.021538                 0.011866            NaN   \n",
       "181                 0.021905                 0.011881            NaN   \n",
       "184                 0.041439                 0.011801            NaN   \n",
       "185                      NaN                      NaN   (20480, 512)   \n",
       "186                      NaN                      NaN  (7168, 12288)   \n",
       "188                 0.025488                 0.011761            NaN   \n",
       "189                      NaN                      NaN  (12288, 1536)   \n",
       "192                 0.062661                 0.011873            NaN   \n",
       "193                 0.011764                 0.023114            NaN   \n",
       "194                 0.022548                 0.011811            NaN   \n",
       "195                 0.023404                 0.011836            NaN   \n",
       "198                 0.040536                 0.011933            NaN   \n",
       "199                      NaN                      NaN   (20480, 512)   \n",
       "200                      NaN                      NaN  (7168, 12288)   \n",
       "202                 0.025368                 0.011932            NaN   \n",
       "203                      NaN                      NaN  (12288, 1536)   \n",
       "206                 0.061841                 0.011795            NaN   \n",
       "207                 0.011818                 0.020896            NaN   \n",
       "208                 0.021794                 0.011798            NaN   \n",
       "209                 0.020529                 0.011691            NaN   \n",
       "212                 0.041586                 0.011838            NaN   \n",
       "213                      NaN                      NaN   (20480, 512)   \n",
       "214                      NaN                      NaN  (7168, 12288)   \n",
       "216                 0.025478                 0.011818            NaN   \n",
       "217                      NaN                      NaN  (12288, 1536)   \n",
       "220                 0.061881                 0.011839            NaN   \n",
       "221                 0.011761                 0.021889            NaN   \n",
       "222                 0.022472                 0.011850            NaN   \n",
       "223                 0.021744                 0.011739            NaN   \n",
       "226                 0.040690                 0.011758            NaN   \n",
       "227                      NaN                      NaN   (20480, 512)   \n",
       "228                      NaN                      NaN  (7168, 12288)   \n",
       "230                 0.025590                 0.011827            NaN   \n",
       "231                      NaN                      NaN  (12288, 1536)   \n",
       "234                 0.062817                 0.011938            NaN   \n",
       "235                 0.011836                 0.022098            NaN   \n",
       "236                 0.022006                 0.011766            NaN   \n",
       "237                 0.021479                 0.011789            NaN   \n",
       "240                 0.042373                 0.011759            NaN   \n",
       "241                      NaN                      NaN   (20480, 512)   \n",
       "242                      NaN                      NaN  (7168, 12288)   \n",
       "244                 0.025384                 0.011745            NaN   \n",
       "245                      NaN                      NaN  (12288, 1536)   \n",
       "248                 0.061548                 0.011770            NaN   \n",
       "249                 0.011725                 0.021146            NaN   \n",
       "250                 0.022921                 0.011758            NaN   \n",
       "251                 0.021799                 0.011716            NaN   \n",
       "254                 0.040442                 0.011839            NaN   \n",
       "255                      NaN                      NaN   (20480, 512)   \n",
       "256                      NaN                      NaN  (7168, 12288)   \n",
       "258                 0.025435                 0.011764            NaN   \n",
       "259                      NaN                      NaN  (12288, 1536)   \n",
       "262                 0.061647                 0.011821            NaN   \n",
       "263                 0.011814                 0.024147            NaN   \n",
       "264                 0.022770                 0.011766            NaN   \n",
       "265                 0.024102                 0.011785            NaN   \n",
       "268                 0.040506                 0.011839            NaN   \n",
       "269                      NaN                      NaN   (20480, 512)   \n",
       "270                      NaN                      NaN  (7168, 12288)   \n",
       "272                 0.025544                 0.011752            NaN   \n",
       "273                      NaN                      NaN  (12288, 1536)   \n",
       "276                 0.062130                 0.011701            NaN   \n",
       "277                 0.011711                 0.022844            NaN   \n",
       "278                 0.022607                 0.011753            NaN   \n",
       "279                 0.022503                 0.011795            NaN   \n",
       "282                 0.039439                 0.011883            NaN   \n",
       "283                      NaN                      NaN   (20480, 512)   \n",
       "284                      NaN                      NaN  (7168, 12288)   \n",
       "286                 0.025384                 0.011813            NaN   \n",
       "287                      NaN                      NaN  (12288, 1536)   \n",
       "290                 0.062316                 0.011766            NaN   \n",
       "291                 0.011842                 0.021200            NaN   \n",
       "292                 0.022589                 0.011776            NaN   \n",
       "293                 0.021352                 0.011792            NaN   \n",
       "296                 0.040653                 0.011863            NaN   \n",
       "297                      NaN                      NaN   (20480, 512)   \n",
       "298                      NaN                      NaN  (7168, 12288)   \n",
       "300                 0.025710                 0.011880            NaN   \n",
       "301                      NaN                      NaN  (12288, 1536)   \n",
       "304                 0.062710                 0.011802            NaN   \n",
       "305                 0.011820                 0.022273            NaN   \n",
       "306                 0.022346                 0.011895            NaN   \n",
       "307                 0.021738                 0.011815            NaN   \n",
       "310                 0.040916                 0.011882            NaN   \n",
       "311                      NaN                      NaN   (20480, 512)   \n",
       "312                      NaN                      NaN  (7168, 12288)   \n",
       "314                 0.025731                 0.011795            NaN   \n",
       "315                      NaN                      NaN  (12288, 1536)   \n",
       "318                 0.062238                 0.011875            NaN   \n",
       "319                 0.011894                 0.021005            NaN   \n",
       "320                 0.023261                 0.011767            NaN   \n",
       "321                 0.021686                 0.011816            NaN   \n",
       "324                 0.040639                 0.011844            NaN   \n",
       "325                      NaN                      NaN   (20480, 512)   \n",
       "326                      NaN                      NaN  (7168, 12288)   \n",
       "328                 0.025529                 0.011763            NaN   \n",
       "329                      NaN                      NaN  (12288, 1536)   \n",
       "332                 0.063082                 0.011682            NaN   \n",
       "333                 0.011889                 0.021187            NaN   \n",
       "334                 0.022722                 0.011740            NaN   \n",
       "335                 0.021243                 0.011810            NaN   \n",
       "338                 0.040950                 0.011865            NaN   \n",
       "339                      NaN                      NaN   (20480, 512)   \n",
       "340                      NaN                      NaN  (7168, 12288)   \n",
       "342                 0.025622                 0.011814            NaN   \n",
       "343                      NaN                      NaN  (12288, 1536)   \n",
       "346                 0.061856                 0.011833            NaN   \n",
       "347                 0.011670                 0.021291            NaN   \n",
       "348                 0.023551                 0.011844            NaN   \n",
       "349                 0.020975                 0.011722            NaN   \n",
       "352                 0.040652                 0.011755            NaN   \n",
       "353                      NaN                      NaN   (20480, 512)   \n",
       "354                      NaN                      NaN  (7168, 12288)   \n",
       "356                 0.025676                 0.011615            NaN   \n",
       "357                      NaN                      NaN  (12288, 1536)   \n",
       "360                 0.061895                 0.011809            NaN   \n",
       "361                 0.011894                 0.022064            NaN   \n",
       "362                 0.022958                 0.011788            NaN   \n",
       "363                 0.021794                 0.011876            NaN   \n",
       "366                 0.041162                 0.011762            NaN   \n",
       "367                      NaN                      NaN   (20480, 512)   \n",
       "368                      NaN                      NaN  (7168, 12288)   \n",
       "370                 0.025329                 0.011848            NaN   \n",
       "371                      NaN                      NaN  (12288, 1536)   \n",
       "374                 0.062583                 0.011795            NaN   \n",
       "375                 0.011706                 0.022284            NaN   \n",
       "376                 0.022844                 0.011671            NaN   \n",
       "377                 0.022432                 0.011685            NaN   \n",
       "380                 0.041204                 0.011783            NaN   \n",
       "381                      NaN                      NaN   (20480, 512)   \n",
       "382                      NaN                      NaN  (7168, 12288)   \n",
       "384                 0.025476                 0.011858            NaN   \n",
       "385                      NaN                      NaN  (12288, 1536)   \n",
       "388                 0.061732                 0.011900            NaN   \n",
       "389                 0.011848                 0.022201            NaN   \n",
       "390                 0.022763                 0.011732            NaN   \n",
       "391                 0.022203                 0.011775            NaN   \n",
       "394                 0.041362                 0.011775            NaN   \n",
       "395                      NaN                      NaN   (20480, 512)   \n",
       "396                      NaN                      NaN  (7168, 12288)   \n",
       "398                 0.025670                 0.011658            NaN   \n",
       "399                      NaN                      NaN  (12288, 1536)   \n",
       "402                 0.062384                 0.011772            NaN   \n",
       "403                 0.011851                 0.021950            NaN   \n",
       "404                 0.023023                 0.011795            NaN   \n",
       "405                 0.022352                 0.011681            NaN   \n",
       "408                 0.041057                 0.011865            NaN   \n",
       "409                      NaN                      NaN   (20480, 512)   \n",
       "410                      NaN                      NaN  (7168, 12288)   \n",
       "412                 0.025587                 0.011754            NaN   \n",
       "413                      NaN                      NaN  (12288, 1536)   \n",
       "416                 0.062968                 0.011768            NaN   \n",
       "417                 0.011876                 0.022129            NaN   \n",
       "418                 0.022738                 0.011696            NaN   \n",
       "419                 0.022067                 0.011649            NaN   \n",
       "422                 0.040312                 0.011805            NaN   \n",
       "423                      NaN                      NaN   (20480, 512)   \n",
       "424                      NaN                      NaN  (7168, 12288)   \n",
       "426                 0.025578                 0.011830            NaN   \n",
       "427                      NaN                      NaN  (12288, 1536)   \n",
       "430                 0.063660                 0.011859            NaN   \n",
       "431                 0.011886                 0.022523            NaN   \n",
       "432                 0.022886                 0.011799            NaN   \n",
       "433                 0.022164                 0.011733            NaN   \n",
       "436                 0.039963                 0.011837            NaN   \n",
       "437                      NaN                      NaN   (20480, 512)   \n",
       "438                      NaN                      NaN  (7168, 12288)   \n",
       "440                 0.025382                 0.011772            NaN   \n",
       "441                      NaN                      NaN  (12288, 1536)   \n",
       "444                 0.063182                 0.011753            NaN   \n",
       "445                 0.011716                 0.021282            NaN   \n",
       "446                 0.023220                 0.011807            NaN   \n",
       "447                 0.021089                 0.011680            NaN   \n",
       "450                 0.040387                 0.011856            NaN   \n",
       "451                      NaN                      NaN   (20480, 512)   \n",
       "452                      NaN                      NaN  (7168, 12288)   \n",
       "454                 0.025348                 0.011776            NaN   \n",
       "455                      NaN                      NaN  (12288, 1536)   \n",
       "458                 0.062743                 0.011854            NaN   \n",
       "459                 0.011741                 0.022656            NaN   \n",
       "460                 0.022680                 0.011754            NaN   \n",
       "461                 0.022588                 0.011646            NaN   \n",
       "464                 0.041099                 0.011797            NaN   \n",
       "465                      NaN                      NaN   (20480, 512)   \n",
       "466                      NaN                      NaN  (7168, 12288)   \n",
       "468                 0.025499                 0.011803            NaN   \n",
       "469                      NaN                      NaN  (12288, 1536)   \n",
       "472                 0.062063                 0.011860            NaN   \n",
       "473                 0.011711                 0.022615            NaN   \n",
       "474                 0.023110                 0.011756            NaN   \n",
       "475                 0.022269                 0.011751            NaN   \n",
       "478                 0.042071                 0.011847            NaN   \n",
       "479                      NaN                      NaN   (20480, 512)   \n",
       "480                      NaN                      NaN  (7168, 12288)   \n",
       "482                 0.025549                 0.011786            NaN   \n",
       "483                      NaN                      NaN  (12288, 1536)   \n",
       "486                 0.061691                 0.011825            NaN   \n",
       "487                 0.011877                 0.022451            NaN   \n",
       "488                 0.023248                 0.011633            NaN   \n",
       "489                 0.022589                 0.011778            NaN   \n",
       "492                 0.041136                 0.011795            NaN   \n",
       "493                      NaN                      NaN   (20480, 512)   \n",
       "494                      NaN                      NaN  (7168, 12288)   \n",
       "496                 0.025642                 0.011777            NaN   \n",
       "497                      NaN                      NaN  (12288, 1536)   \n",
       "500                 0.062527                 0.011783            NaN   \n",
       "501                 0.011715                 0.021596            NaN   \n",
       "502                 0.022985                 0.011831            NaN   \n",
       "503                 0.021903                 0.011733            NaN   \n",
       "506                 0.040488                 0.011631            NaN   \n",
       "507                      NaN                      NaN   (20480, 512)   \n",
       "508                      NaN                      NaN  (7168, 12288)   \n",
       "510                 0.025773                 0.011824            NaN   \n",
       "511                      NaN                      NaN  (12288, 1536)   \n",
       "514                 0.062548                 0.011854            NaN   \n",
       "515                 0.011845                 0.022055            NaN   \n",
       "516                 0.023141                 0.011789            NaN   \n",
       "517                 0.022454                 0.011772            NaN   \n",
       "520                 0.040505                 0.011890            NaN   \n",
       "521                      NaN                      NaN   (20480, 512)   \n",
       "522                      NaN                      NaN  (7168, 12288)   \n",
       "524                 0.025315                 0.011768            NaN   \n",
       "525                      NaN                      NaN  (12288, 1536)   \n",
       "528                 0.062587                 0.011865            NaN   \n",
       "529                 0.011854                 0.022029            NaN   \n",
       "530                 0.022860                 0.011693            NaN   \n",
       "531                 0.021927                 0.011793            NaN   \n",
       "534                 0.040598                 0.011837            NaN   \n",
       "535                      NaN                      NaN   (20480, 512)   \n",
       "536                      NaN                      NaN  (7168, 12288)   \n",
       "538                 0.025434                 0.011743            NaN   \n",
       "539                      NaN                      NaN  (12288, 1536)   \n",
       "542                 0.063557                 0.011759            NaN   \n",
       "543                 0.011890                 0.022085            NaN   \n",
       "544                 0.022795                 0.011705            NaN   \n",
       "545                 0.022036                 0.011708            NaN   \n",
       "548                 0.041799                 0.011892            NaN   \n",
       "549                      NaN                      NaN   (20480, 512)   \n",
       "550                      NaN                      NaN  (7168, 12288)   \n",
       "552                 0.025450                 0.011780            NaN   \n",
       "553                      NaN                      NaN  (12288, 1536)   \n",
       "556                 0.062191                 0.011840            NaN   \n",
       "557                 0.011699                 0.021954            NaN   \n",
       "558                 0.022663                 0.011811            NaN   \n",
       "559                 0.021980                 0.011698            NaN   \n",
       "562                 0.040188                 0.011757            NaN   \n",
       "563                      NaN                      NaN   (20480, 512)   \n",
       "564                      NaN                      NaN  (7168, 12288)   \n",
       "566                 0.025596                 0.011809            NaN   \n",
       "567                      NaN                      NaN  (12288, 1536)   \n",
       "570                 0.062060                 0.011879            NaN   \n",
       "571                 0.011866                 0.022237            NaN   \n",
       "572                 0.023252                 0.011705            NaN   \n",
       "573                 0.021890                 0.011671            NaN   \n",
       "576                 0.038760                 0.011811            NaN   \n",
       "577                      NaN                      NaN   (20480, 512)   \n",
       "578                      NaN                      NaN  (7168, 12288)   \n",
       "580                 0.025640                 0.011763            NaN   \n",
       "581                      NaN                      NaN  (12288, 1536)   \n",
       "584                 0.062748                 0.011738            NaN   \n",
       "585                 0.011821                 0.022209            NaN   \n",
       "586                 0.022839                 0.011851            NaN   \n",
       "587                 0.021974                 0.011753            NaN   \n",
       "590                 0.041255                 0.011776            NaN   \n",
       "591                      NaN                      NaN   (20480, 512)   \n",
       "592                      NaN                      NaN  (7168, 12288)   \n",
       "594                 0.025442                 0.011804            NaN   \n",
       "595                      NaN                      NaN  (12288, 1536)   \n",
       "598                 0.062926                 0.011827            NaN   \n",
       "599                 0.011760                 0.021814            NaN   \n",
       "600                 0.022964                 0.011771            NaN   \n",
       "601                 0.022187                 0.011697            NaN   \n",
       "604                 0.041797                 0.011715            NaN   \n",
       "605                      NaN                      NaN   (20480, 512)   \n",
       "606                      NaN                      NaN  (7168, 12288)   \n",
       "608                 0.025527                 0.011733            NaN   \n",
       "609                      NaN                      NaN  (12288, 1536)   \n",
       "612                 0.062554                 0.011818            NaN   \n",
       "613                 0.011930                 0.022872            NaN   \n",
       "614                 0.023227                 0.011807            NaN   \n",
       "615                 0.023246                 0.011728            NaN   \n",
       "618                 0.040007                 0.011767            NaN   \n",
       "619                      NaN                      NaN   (20480, 512)   \n",
       "620                      NaN                      NaN  (7168, 12288)   \n",
       "622                 0.025364                 0.011801            NaN   \n",
       "623                      NaN                      NaN  (12288, 1536)   \n",
       "626                 0.063870                 0.011831            NaN   \n",
       "627                 0.011923                 0.023137            NaN   \n",
       "628                 0.022902                 0.011896            NaN   \n",
       "629                 0.022534                 0.011668            NaN   \n",
       "632                 0.042009                 0.011726            NaN   \n",
       "633                      NaN                      NaN   (20480, 512)   \n",
       "634                      NaN                      NaN  (7168, 12288)   \n",
       "636                 0.025441                 0.011729            NaN   \n",
       "637                      NaN                      NaN  (12288, 1536)   \n",
       "640                 0.062128                 0.011825            NaN   \n",
       "641                 0.011910                 0.021159            NaN   \n",
       "642                 0.023728                 0.011895            NaN   \n",
       "643                 0.021490                 0.011797            NaN   \n",
       "646                 0.042115                 0.011879            NaN   \n",
       "647                      NaN                      NaN   (20480, 512)   \n",
       "648                      NaN                      NaN  (7168, 12288)   \n",
       "650                 0.025397                 0.011741            NaN   \n",
       "651                      NaN                      NaN  (12288, 1536)   \n",
       "654                 0.062853                 0.011909            NaN   \n",
       "655                 0.011790                 0.022037            NaN   \n",
       "656                 0.022764                 0.011837            NaN   \n",
       "657                 0.021803                 0.011750            NaN   \n",
       "660                 0.041840                 0.011895            NaN   \n",
       "661                      NaN                      NaN   (20480, 512)   \n",
       "662                      NaN                      NaN  (7168, 12288)   \n",
       "664                 0.025564                 0.011791            NaN   \n",
       "665                      NaN                      NaN  (12288, 1536)   \n",
       "668                 0.062957                 0.011883            NaN   \n",
       "669                 0.011789                 0.021876            NaN   \n",
       "670                 0.023243                 0.011795            NaN   \n",
       "671                 0.022259                 0.011740            NaN   \n",
       "674                 0.040529                 0.011811            NaN   \n",
       "675                      NaN                      NaN   (20480, 512)   \n",
       "676                      NaN                      NaN  (7168, 12288)   \n",
       "678                 0.025647                 0.011862            NaN   \n",
       "679                      NaN                      NaN  (12288, 1536)   \n",
       "682                 0.062070                 0.011881            NaN   \n",
       "683                 0.011703                 0.022161            NaN   \n",
       "684                 0.022956                 0.011777            NaN   \n",
       "685                 0.022907                 0.011767            NaN   \n",
       "688                 0.039423                 0.011686            NaN   \n",
       "689                      NaN                      NaN   (20480, 512)   \n",
       "690                      NaN                      NaN  (7168, 12288)   \n",
       "692                 0.025397                 0.011801            NaN   \n",
       "693                      NaN                      NaN  (12288, 1536)   \n",
       "696                 0.062792                 0.011876            NaN   \n",
       "697                 0.011761                 0.022751            NaN   \n",
       "698                 0.021875                 0.011780            NaN   \n",
       "699                 0.022686                 0.011838            NaN   \n",
       "702                 0.041435                 0.011826            NaN   \n",
       "703                      NaN                      NaN   (20480, 512)   \n",
       "704                      NaN                      NaN  (7168, 12288)   \n",
       "706                 0.025662                 0.011741            NaN   \n",
       "707                      NaN                      NaN  (12288, 1536)   \n",
       "710                 0.062268                 0.011705            NaN   \n",
       "711                 0.011728                 0.021523            NaN   \n",
       "712                 0.023938                 0.011771            NaN   \n",
       "713                 0.021531                 0.011832            NaN   \n",
       "716                 0.041276                 0.011811            NaN   \n",
       "717                      NaN                      NaN   (20480, 512)   \n",
       "718                      NaN                      NaN  (7168, 12288)   \n",
       "720                 0.025480                 0.011834            NaN   \n",
       "721                      NaN                      NaN  (12288, 1536)   \n",
       "724                 0.061770                 0.011842            NaN   \n",
       "725                 0.011738                 0.022066            NaN   \n",
       "726                 0.023145                 0.012011            NaN   \n",
       "727                 0.022058                 0.011762            NaN   \n",
       "730                 0.040178                 0.011787            NaN   \n",
       "731                      NaN                      NaN   (20480, 512)   \n",
       "732                      NaN                      NaN  (7168, 12288)   \n",
       "734                 0.025408                 0.011776            NaN   \n",
       "735                      NaN                      NaN  (12288, 1536)   \n",
       "738                 0.062385                 0.011773            NaN   \n",
       "739                 0.011741                 0.022367            NaN   \n",
       "740                 0.022096                 0.011876            NaN   \n",
       "741                 0.022348                 0.011792            NaN   \n",
       "744                 0.040021                 0.011785            NaN   \n",
       "745                      NaN                      NaN   (20480, 512)   \n",
       "746                      NaN                      NaN  (7168, 12288)   \n",
       "748                 0.025608                 0.011729            NaN   \n",
       "749                      NaN                      NaN  (12288, 1536)   \n",
       "752                 0.062886                 0.011905            NaN   \n",
       "753                 0.011797                 0.022399            NaN   \n",
       "754                 0.022301                 0.011794            NaN   \n",
       "755                 0.021914                 0.011851            NaN   \n",
       "758                 0.038368                 0.011807            NaN   \n",
       "759                      NaN                      NaN   (20480, 512)   \n",
       "760                      NaN                      NaN  (7168, 12288)   \n",
       "762                 0.025254                 0.011706            NaN   \n",
       "763                      NaN                      NaN  (12288, 1536)   \n",
       "766                 0.063870                 0.011861            NaN   \n",
       "767                 0.011905                 0.021921            NaN   \n",
       "768                 0.023523                 0.011778            NaN   \n",
       "769                 0.022539                 0.011818            NaN   \n",
       "772                 0.039604                 0.011853            NaN   \n",
       "773                      NaN                      NaN   (20480, 512)   \n",
       "774                      NaN                      NaN  (7168, 12288)   \n",
       "776                 0.025436                 0.011889            NaN   \n",
       "777                      NaN                      NaN  (12288, 1536)   \n",
       "780                 0.063257                 0.011911            NaN   \n",
       "781                 0.011864                 0.022340            NaN   \n",
       "782                 0.022923                 0.011761            NaN   \n",
       "783                 0.021762                 0.011792            NaN   \n",
       "786                 0.041463                 0.011913            NaN   \n",
       "787                      NaN                      NaN   (20480, 512)   \n",
       "788                      NaN                      NaN  (7168, 12288)   \n",
       "790                 0.025454                 0.011833            NaN   \n",
       "791                      NaN                      NaN  (12288, 1536)   \n",
       "794                 0.061735                 0.011763            NaN   \n",
       "795                 0.011805                 0.021849            NaN   \n",
       "796                 0.023475                 0.011813            NaN   \n",
       "797                 0.021717                 0.011800            NaN   \n",
       "800                 0.041435                 0.011742            NaN   \n",
       "801                      NaN                      NaN   (20480, 512)   \n",
       "802                      NaN                      NaN  (7168, 12288)   \n",
       "804                 0.025466                 0.011807            NaN   \n",
       "805                      NaN                      NaN  (12288, 1536)   \n",
       "808                 0.062059                 0.011828            NaN   \n",
       "809                 0.011829                 0.022289            NaN   \n",
       "810                 0.022630                 0.011793            NaN   \n",
       "811                 0.022453                 0.011754            NaN   \n",
       "814                 0.040510                 0.011884            NaN   \n",
       "815                      NaN                      NaN   (20480, 512)   \n",
       "816                      NaN                      NaN  (7168, 12288)   \n",
       "818                 0.025667                 0.011828            NaN   \n",
       "819                      NaN                      NaN  (12288, 1536)   \n",
       "822                 0.061247                 0.011847            NaN   \n",
       "823                 0.011745                 0.021816            NaN   \n",
       "824                 0.023111                 0.011823            NaN   \n",
       "825                 0.022061                 0.011825            NaN   \n",
       "828                 0.042103                 0.011751            NaN   \n",
       "829                      NaN                      NaN   (20480, 512)   \n",
       "830                      NaN                      NaN  (7168, 12288)   \n",
       "832                 0.025616                 0.011772            NaN   \n",
       "833                      NaN                      NaN  (12288, 1536)   \n",
       "836                 0.062994                 0.011920            NaN   \n",
       "837                 0.011763                 0.022365            NaN   \n",
       "838                 0.022847                 0.011725            NaN   \n",
       "839                 0.022036                 0.011843            NaN   \n",
       "842                 0.040544                 0.011873            NaN   \n",
       "843                      NaN                      NaN   (20480, 512)   \n",
       "844                      NaN                      NaN  (7168, 12288)   \n",
       "846                 0.025320                 0.011864            NaN   \n",
       "847                      NaN                      NaN  (12288, 1536)   \n",
       "\n",
       "           shape_b            note  \n",
       "1              NaN             NaN  \n",
       "2              NaN             NaN  \n",
       "3              NaN             NaN  \n",
       "6              NaN             NaN  \n",
       "7     (32768, 512)  shape_mismatch  \n",
       "8    (7168, 16384)  shape_mismatch  \n",
       "10             NaN             NaN  \n",
       "11   (24576, 1536)  shape_mismatch  \n",
       "13             NaN             NaN  \n",
       "14             NaN             NaN  \n",
       "15             NaN             NaN  \n",
       "18             NaN             NaN  \n",
       "19    (32768, 512)  shape_mismatch  \n",
       "20   (7168, 16384)  shape_mismatch  \n",
       "22             NaN             NaN  \n",
       "23   (24576, 1536)  shape_mismatch  \n",
       "25             NaN             NaN  \n",
       "26             NaN             NaN  \n",
       "27             NaN             NaN  \n",
       "30             NaN             NaN  \n",
       "31    (32768, 512)  shape_mismatch  \n",
       "32   (7168, 16384)  shape_mismatch  \n",
       "34             NaN             NaN  \n",
       "35   (24576, 1536)  shape_mismatch  \n",
       "38             NaN             NaN  \n",
       "39             NaN             NaN  \n",
       "40             NaN             NaN  \n",
       "41             NaN             NaN  \n",
       "44             NaN             NaN  \n",
       "45    (32768, 512)  shape_mismatch  \n",
       "46   (7168, 16384)  shape_mismatch  \n",
       "48             NaN             NaN  \n",
       "49   (24576, 1536)  shape_mismatch  \n",
       "52             NaN             NaN  \n",
       "53             NaN             NaN  \n",
       "54             NaN             NaN  \n",
       "55             NaN             NaN  \n",
       "58             NaN             NaN  \n",
       "59    (32768, 512)  shape_mismatch  \n",
       "60   (7168, 16384)  shape_mismatch  \n",
       "62             NaN             NaN  \n",
       "63   (24576, 1536)  shape_mismatch  \n",
       "66             NaN             NaN  \n",
       "67             NaN             NaN  \n",
       "68             NaN             NaN  \n",
       "69             NaN             NaN  \n",
       "72             NaN             NaN  \n",
       "73    (32768, 512)  shape_mismatch  \n",
       "74   (7168, 16384)  shape_mismatch  \n",
       "76             NaN             NaN  \n",
       "77   (24576, 1536)  shape_mismatch  \n",
       "80             NaN             NaN  \n",
       "81             NaN             NaN  \n",
       "82             NaN             NaN  \n",
       "83             NaN             NaN  \n",
       "86             NaN             NaN  \n",
       "87    (32768, 512)  shape_mismatch  \n",
       "88   (7168, 16384)  shape_mismatch  \n",
       "90             NaN             NaN  \n",
       "91   (24576, 1536)  shape_mismatch  \n",
       "94             NaN             NaN  \n",
       "95             NaN             NaN  \n",
       "96             NaN             NaN  \n",
       "97             NaN             NaN  \n",
       "100            NaN             NaN  \n",
       "101   (32768, 512)  shape_mismatch  \n",
       "102  (7168, 16384)  shape_mismatch  \n",
       "104            NaN             NaN  \n",
       "105  (24576, 1536)  shape_mismatch  \n",
       "108            NaN             NaN  \n",
       "109            NaN             NaN  \n",
       "110            NaN             NaN  \n",
       "111            NaN             NaN  \n",
       "114            NaN             NaN  \n",
       "115   (32768, 512)  shape_mismatch  \n",
       "116  (7168, 16384)  shape_mismatch  \n",
       "118            NaN             NaN  \n",
       "119  (24576, 1536)  shape_mismatch  \n",
       "122            NaN             NaN  \n",
       "123            NaN             NaN  \n",
       "124            NaN             NaN  \n",
       "125            NaN             NaN  \n",
       "128            NaN             NaN  \n",
       "129   (32768, 512)  shape_mismatch  \n",
       "130  (7168, 16384)  shape_mismatch  \n",
       "132            NaN             NaN  \n",
       "133  (24576, 1536)  shape_mismatch  \n",
       "136            NaN             NaN  \n",
       "137            NaN             NaN  \n",
       "138            NaN             NaN  \n",
       "139            NaN             NaN  \n",
       "142            NaN             NaN  \n",
       "143   (32768, 512)  shape_mismatch  \n",
       "144  (7168, 16384)  shape_mismatch  \n",
       "146            NaN             NaN  \n",
       "147  (24576, 1536)  shape_mismatch  \n",
       "150            NaN             NaN  \n",
       "151            NaN             NaN  \n",
       "152            NaN             NaN  \n",
       "153            NaN             NaN  \n",
       "156            NaN             NaN  \n",
       "157   (32768, 512)  shape_mismatch  \n",
       "158  (7168, 16384)  shape_mismatch  \n",
       "160            NaN             NaN  \n",
       "161  (24576, 1536)  shape_mismatch  \n",
       "164            NaN             NaN  \n",
       "165            NaN             NaN  \n",
       "166            NaN             NaN  \n",
       "167            NaN             NaN  \n",
       "170            NaN             NaN  \n",
       "171   (32768, 512)  shape_mismatch  \n",
       "172  (7168, 16384)  shape_mismatch  \n",
       "174            NaN             NaN  \n",
       "175  (24576, 1536)  shape_mismatch  \n",
       "178            NaN             NaN  \n",
       "179            NaN             NaN  \n",
       "180            NaN             NaN  \n",
       "181            NaN             NaN  \n",
       "184            NaN             NaN  \n",
       "185   (32768, 512)  shape_mismatch  \n",
       "186  (7168, 16384)  shape_mismatch  \n",
       "188            NaN             NaN  \n",
       "189  (24576, 1536)  shape_mismatch  \n",
       "192            NaN             NaN  \n",
       "193            NaN             NaN  \n",
       "194            NaN             NaN  \n",
       "195            NaN             NaN  \n",
       "198            NaN             NaN  \n",
       "199   (32768, 512)  shape_mismatch  \n",
       "200  (7168, 16384)  shape_mismatch  \n",
       "202            NaN             NaN  \n",
       "203  (24576, 1536)  shape_mismatch  \n",
       "206            NaN             NaN  \n",
       "207            NaN             NaN  \n",
       "208            NaN             NaN  \n",
       "209            NaN             NaN  \n",
       "212            NaN             NaN  \n",
       "213   (32768, 512)  shape_mismatch  \n",
       "214  (7168, 16384)  shape_mismatch  \n",
       "216            NaN             NaN  \n",
       "217  (24576, 1536)  shape_mismatch  \n",
       "220            NaN             NaN  \n",
       "221            NaN             NaN  \n",
       "222            NaN             NaN  \n",
       "223            NaN             NaN  \n",
       "226            NaN             NaN  \n",
       "227   (32768, 512)  shape_mismatch  \n",
       "228  (7168, 16384)  shape_mismatch  \n",
       "230            NaN             NaN  \n",
       "231  (24576, 1536)  shape_mismatch  \n",
       "234            NaN             NaN  \n",
       "235            NaN             NaN  \n",
       "236            NaN             NaN  \n",
       "237            NaN             NaN  \n",
       "240            NaN             NaN  \n",
       "241   (32768, 512)  shape_mismatch  \n",
       "242  (7168, 16384)  shape_mismatch  \n",
       "244            NaN             NaN  \n",
       "245  (24576, 1536)  shape_mismatch  \n",
       "248            NaN             NaN  \n",
       "249            NaN             NaN  \n",
       "250            NaN             NaN  \n",
       "251            NaN             NaN  \n",
       "254            NaN             NaN  \n",
       "255   (32768, 512)  shape_mismatch  \n",
       "256  (7168, 16384)  shape_mismatch  \n",
       "258            NaN             NaN  \n",
       "259  (24576, 1536)  shape_mismatch  \n",
       "262            NaN             NaN  \n",
       "263            NaN             NaN  \n",
       "264            NaN             NaN  \n",
       "265            NaN             NaN  \n",
       "268            NaN             NaN  \n",
       "269   (32768, 512)  shape_mismatch  \n",
       "270  (7168, 16384)  shape_mismatch  \n",
       "272            NaN             NaN  \n",
       "273  (24576, 1536)  shape_mismatch  \n",
       "276            NaN             NaN  \n",
       "277            NaN             NaN  \n",
       "278            NaN             NaN  \n",
       "279            NaN             NaN  \n",
       "282            NaN             NaN  \n",
       "283   (32768, 512)  shape_mismatch  \n",
       "284  (7168, 16384)  shape_mismatch  \n",
       "286            NaN             NaN  \n",
       "287  (24576, 1536)  shape_mismatch  \n",
       "290            NaN             NaN  \n",
       "291            NaN             NaN  \n",
       "292            NaN             NaN  \n",
       "293            NaN             NaN  \n",
       "296            NaN             NaN  \n",
       "297   (32768, 512)  shape_mismatch  \n",
       "298  (7168, 16384)  shape_mismatch  \n",
       "300            NaN             NaN  \n",
       "301  (24576, 1536)  shape_mismatch  \n",
       "304            NaN             NaN  \n",
       "305            NaN             NaN  \n",
       "306            NaN             NaN  \n",
       "307            NaN             NaN  \n",
       "310            NaN             NaN  \n",
       "311   (32768, 512)  shape_mismatch  \n",
       "312  (7168, 16384)  shape_mismatch  \n",
       "314            NaN             NaN  \n",
       "315  (24576, 1536)  shape_mismatch  \n",
       "318            NaN             NaN  \n",
       "319            NaN             NaN  \n",
       "320            NaN             NaN  \n",
       "321            NaN             NaN  \n",
       "324            NaN             NaN  \n",
       "325   (32768, 512)  shape_mismatch  \n",
       "326  (7168, 16384)  shape_mismatch  \n",
       "328            NaN             NaN  \n",
       "329  (24576, 1536)  shape_mismatch  \n",
       "332            NaN             NaN  \n",
       "333            NaN             NaN  \n",
       "334            NaN             NaN  \n",
       "335            NaN             NaN  \n",
       "338            NaN             NaN  \n",
       "339   (32768, 512)  shape_mismatch  \n",
       "340  (7168, 16384)  shape_mismatch  \n",
       "342            NaN             NaN  \n",
       "343  (24576, 1536)  shape_mismatch  \n",
       "346            NaN             NaN  \n",
       "347            NaN             NaN  \n",
       "348            NaN             NaN  \n",
       "349            NaN             NaN  \n",
       "352            NaN             NaN  \n",
       "353   (32768, 512)  shape_mismatch  \n",
       "354  (7168, 16384)  shape_mismatch  \n",
       "356            NaN             NaN  \n",
       "357  (24576, 1536)  shape_mismatch  \n",
       "360            NaN             NaN  \n",
       "361            NaN             NaN  \n",
       "362            NaN             NaN  \n",
       "363            NaN             NaN  \n",
       "366            NaN             NaN  \n",
       "367   (32768, 512)  shape_mismatch  \n",
       "368  (7168, 16384)  shape_mismatch  \n",
       "370            NaN             NaN  \n",
       "371  (24576, 1536)  shape_mismatch  \n",
       "374            NaN             NaN  \n",
       "375            NaN             NaN  \n",
       "376            NaN             NaN  \n",
       "377            NaN             NaN  \n",
       "380            NaN             NaN  \n",
       "381   (32768, 512)  shape_mismatch  \n",
       "382  (7168, 16384)  shape_mismatch  \n",
       "384            NaN             NaN  \n",
       "385  (24576, 1536)  shape_mismatch  \n",
       "388            NaN             NaN  \n",
       "389            NaN             NaN  \n",
       "390            NaN             NaN  \n",
       "391            NaN             NaN  \n",
       "394            NaN             NaN  \n",
       "395   (32768, 512)  shape_mismatch  \n",
       "396  (7168, 16384)  shape_mismatch  \n",
       "398            NaN             NaN  \n",
       "399  (24576, 1536)  shape_mismatch  \n",
       "402            NaN             NaN  \n",
       "403            NaN             NaN  \n",
       "404            NaN             NaN  \n",
       "405            NaN             NaN  \n",
       "408            NaN             NaN  \n",
       "409   (32768, 512)  shape_mismatch  \n",
       "410  (7168, 16384)  shape_mismatch  \n",
       "412            NaN             NaN  \n",
       "413  (24576, 1536)  shape_mismatch  \n",
       "416            NaN             NaN  \n",
       "417            NaN             NaN  \n",
       "418            NaN             NaN  \n",
       "419            NaN             NaN  \n",
       "422            NaN             NaN  \n",
       "423   (32768, 512)  shape_mismatch  \n",
       "424  (7168, 16384)  shape_mismatch  \n",
       "426            NaN             NaN  \n",
       "427  (24576, 1536)  shape_mismatch  \n",
       "430            NaN             NaN  \n",
       "431            NaN             NaN  \n",
       "432            NaN             NaN  \n",
       "433            NaN             NaN  \n",
       "436            NaN             NaN  \n",
       "437   (32768, 512)  shape_mismatch  \n",
       "438  (7168, 16384)  shape_mismatch  \n",
       "440            NaN             NaN  \n",
       "441  (24576, 1536)  shape_mismatch  \n",
       "444            NaN             NaN  \n",
       "445            NaN             NaN  \n",
       "446            NaN             NaN  \n",
       "447            NaN             NaN  \n",
       "450            NaN             NaN  \n",
       "451   (32768, 512)  shape_mismatch  \n",
       "452  (7168, 16384)  shape_mismatch  \n",
       "454            NaN             NaN  \n",
       "455  (24576, 1536)  shape_mismatch  \n",
       "458            NaN             NaN  \n",
       "459            NaN             NaN  \n",
       "460            NaN             NaN  \n",
       "461            NaN             NaN  \n",
       "464            NaN             NaN  \n",
       "465   (32768, 512)  shape_mismatch  \n",
       "466  (7168, 16384)  shape_mismatch  \n",
       "468            NaN             NaN  \n",
       "469  (24576, 1536)  shape_mismatch  \n",
       "472            NaN             NaN  \n",
       "473            NaN             NaN  \n",
       "474            NaN             NaN  \n",
       "475            NaN             NaN  \n",
       "478            NaN             NaN  \n",
       "479   (32768, 512)  shape_mismatch  \n",
       "480  (7168, 16384)  shape_mismatch  \n",
       "482            NaN             NaN  \n",
       "483  (24576, 1536)  shape_mismatch  \n",
       "486            NaN             NaN  \n",
       "487            NaN             NaN  \n",
       "488            NaN             NaN  \n",
       "489            NaN             NaN  \n",
       "492            NaN             NaN  \n",
       "493   (32768, 512)  shape_mismatch  \n",
       "494  (7168, 16384)  shape_mismatch  \n",
       "496            NaN             NaN  \n",
       "497  (24576, 1536)  shape_mismatch  \n",
       "500            NaN             NaN  \n",
       "501            NaN             NaN  \n",
       "502            NaN             NaN  \n",
       "503            NaN             NaN  \n",
       "506            NaN             NaN  \n",
       "507   (32768, 512)  shape_mismatch  \n",
       "508  (7168, 16384)  shape_mismatch  \n",
       "510            NaN             NaN  \n",
       "511  (24576, 1536)  shape_mismatch  \n",
       "514            NaN             NaN  \n",
       "515            NaN             NaN  \n",
       "516            NaN             NaN  \n",
       "517            NaN             NaN  \n",
       "520            NaN             NaN  \n",
       "521   (32768, 512)  shape_mismatch  \n",
       "522  (7168, 16384)  shape_mismatch  \n",
       "524            NaN             NaN  \n",
       "525  (24576, 1536)  shape_mismatch  \n",
       "528            NaN             NaN  \n",
       "529            NaN             NaN  \n",
       "530            NaN             NaN  \n",
       "531            NaN             NaN  \n",
       "534            NaN             NaN  \n",
       "535   (32768, 512)  shape_mismatch  \n",
       "536  (7168, 16384)  shape_mismatch  \n",
       "538            NaN             NaN  \n",
       "539  (24576, 1536)  shape_mismatch  \n",
       "542            NaN             NaN  \n",
       "543            NaN             NaN  \n",
       "544            NaN             NaN  \n",
       "545            NaN             NaN  \n",
       "548            NaN             NaN  \n",
       "549   (32768, 512)  shape_mismatch  \n",
       "550  (7168, 16384)  shape_mismatch  \n",
       "552            NaN             NaN  \n",
       "553  (24576, 1536)  shape_mismatch  \n",
       "556            NaN             NaN  \n",
       "557            NaN             NaN  \n",
       "558            NaN             NaN  \n",
       "559            NaN             NaN  \n",
       "562            NaN             NaN  \n",
       "563   (32768, 512)  shape_mismatch  \n",
       "564  (7168, 16384)  shape_mismatch  \n",
       "566            NaN             NaN  \n",
       "567  (24576, 1536)  shape_mismatch  \n",
       "570            NaN             NaN  \n",
       "571            NaN             NaN  \n",
       "572            NaN             NaN  \n",
       "573            NaN             NaN  \n",
       "576            NaN             NaN  \n",
       "577   (32768, 512)  shape_mismatch  \n",
       "578  (7168, 16384)  shape_mismatch  \n",
       "580            NaN             NaN  \n",
       "581  (24576, 1536)  shape_mismatch  \n",
       "584            NaN             NaN  \n",
       "585            NaN             NaN  \n",
       "586            NaN             NaN  \n",
       "587            NaN             NaN  \n",
       "590            NaN             NaN  \n",
       "591   (32768, 512)  shape_mismatch  \n",
       "592  (7168, 16384)  shape_mismatch  \n",
       "594            NaN             NaN  \n",
       "595  (24576, 1536)  shape_mismatch  \n",
       "598            NaN             NaN  \n",
       "599            NaN             NaN  \n",
       "600            NaN             NaN  \n",
       "601            NaN             NaN  \n",
       "604            NaN             NaN  \n",
       "605   (32768, 512)  shape_mismatch  \n",
       "606  (7168, 16384)  shape_mismatch  \n",
       "608            NaN             NaN  \n",
       "609  (24576, 1536)  shape_mismatch  \n",
       "612            NaN             NaN  \n",
       "613            NaN             NaN  \n",
       "614            NaN             NaN  \n",
       "615            NaN             NaN  \n",
       "618            NaN             NaN  \n",
       "619   (32768, 512)  shape_mismatch  \n",
       "620  (7168, 16384)  shape_mismatch  \n",
       "622            NaN             NaN  \n",
       "623  (24576, 1536)  shape_mismatch  \n",
       "626            NaN             NaN  \n",
       "627            NaN             NaN  \n",
       "628            NaN             NaN  \n",
       "629            NaN             NaN  \n",
       "632            NaN             NaN  \n",
       "633   (32768, 512)  shape_mismatch  \n",
       "634  (7168, 16384)  shape_mismatch  \n",
       "636            NaN             NaN  \n",
       "637  (24576, 1536)  shape_mismatch  \n",
       "640            NaN             NaN  \n",
       "641            NaN             NaN  \n",
       "642            NaN             NaN  \n",
       "643            NaN             NaN  \n",
       "646            NaN             NaN  \n",
       "647   (32768, 512)  shape_mismatch  \n",
       "648  (7168, 16384)  shape_mismatch  \n",
       "650            NaN             NaN  \n",
       "651  (24576, 1536)  shape_mismatch  \n",
       "654            NaN             NaN  \n",
       "655            NaN             NaN  \n",
       "656            NaN             NaN  \n",
       "657            NaN             NaN  \n",
       "660            NaN             NaN  \n",
       "661   (32768, 512)  shape_mismatch  \n",
       "662  (7168, 16384)  shape_mismatch  \n",
       "664            NaN             NaN  \n",
       "665  (24576, 1536)  shape_mismatch  \n",
       "668            NaN             NaN  \n",
       "669            NaN             NaN  \n",
       "670            NaN             NaN  \n",
       "671            NaN             NaN  \n",
       "674            NaN             NaN  \n",
       "675   (32768, 512)  shape_mismatch  \n",
       "676  (7168, 16384)  shape_mismatch  \n",
       "678            NaN             NaN  \n",
       "679  (24576, 1536)  shape_mismatch  \n",
       "682            NaN             NaN  \n",
       "683            NaN             NaN  \n",
       "684            NaN             NaN  \n",
       "685            NaN             NaN  \n",
       "688            NaN             NaN  \n",
       "689   (32768, 512)  shape_mismatch  \n",
       "690  (7168, 16384)  shape_mismatch  \n",
       "692            NaN             NaN  \n",
       "693  (24576, 1536)  shape_mismatch  \n",
       "696            NaN             NaN  \n",
       "697            NaN             NaN  \n",
       "698            NaN             NaN  \n",
       "699            NaN             NaN  \n",
       "702            NaN             NaN  \n",
       "703   (32768, 512)  shape_mismatch  \n",
       "704  (7168, 16384)  shape_mismatch  \n",
       "706            NaN             NaN  \n",
       "707  (24576, 1536)  shape_mismatch  \n",
       "710            NaN             NaN  \n",
       "711            NaN             NaN  \n",
       "712            NaN             NaN  \n",
       "713            NaN             NaN  \n",
       "716            NaN             NaN  \n",
       "717   (32768, 512)  shape_mismatch  \n",
       "718  (7168, 16384)  shape_mismatch  \n",
       "720            NaN             NaN  \n",
       "721  (24576, 1536)  shape_mismatch  \n",
       "724            NaN             NaN  \n",
       "725            NaN             NaN  \n",
       "726            NaN             NaN  \n",
       "727            NaN             NaN  \n",
       "730            NaN             NaN  \n",
       "731   (32768, 512)  shape_mismatch  \n",
       "732  (7168, 16384)  shape_mismatch  \n",
       "734            NaN             NaN  \n",
       "735  (24576, 1536)  shape_mismatch  \n",
       "738            NaN             NaN  \n",
       "739            NaN             NaN  \n",
       "740            NaN             NaN  \n",
       "741            NaN             NaN  \n",
       "744            NaN             NaN  \n",
       "745   (32768, 512)  shape_mismatch  \n",
       "746  (7168, 16384)  shape_mismatch  \n",
       "748            NaN             NaN  \n",
       "749  (24576, 1536)  shape_mismatch  \n",
       "752            NaN             NaN  \n",
       "753            NaN             NaN  \n",
       "754            NaN             NaN  \n",
       "755            NaN             NaN  \n",
       "758            NaN             NaN  \n",
       "759   (32768, 512)  shape_mismatch  \n",
       "760  (7168, 16384)  shape_mismatch  \n",
       "762            NaN             NaN  \n",
       "763  (24576, 1536)  shape_mismatch  \n",
       "766            NaN             NaN  \n",
       "767            NaN             NaN  \n",
       "768            NaN             NaN  \n",
       "769            NaN             NaN  \n",
       "772            NaN             NaN  \n",
       "773   (32768, 512)  shape_mismatch  \n",
       "774  (7168, 16384)  shape_mismatch  \n",
       "776            NaN             NaN  \n",
       "777  (24576, 1536)  shape_mismatch  \n",
       "780            NaN             NaN  \n",
       "781            NaN             NaN  \n",
       "782            NaN             NaN  \n",
       "783            NaN             NaN  \n",
       "786            NaN             NaN  \n",
       "787   (32768, 512)  shape_mismatch  \n",
       "788  (7168, 16384)  shape_mismatch  \n",
       "790            NaN             NaN  \n",
       "791  (24576, 1536)  shape_mismatch  \n",
       "794            NaN             NaN  \n",
       "795            NaN             NaN  \n",
       "796            NaN             NaN  \n",
       "797            NaN             NaN  \n",
       "800            NaN             NaN  \n",
       "801   (32768, 512)  shape_mismatch  \n",
       "802  (7168, 16384)  shape_mismatch  \n",
       "804            NaN             NaN  \n",
       "805  (24576, 1536)  shape_mismatch  \n",
       "808            NaN             NaN  \n",
       "809            NaN             NaN  \n",
       "810            NaN             NaN  \n",
       "811            NaN             NaN  \n",
       "814            NaN             NaN  \n",
       "815   (32768, 512)  shape_mismatch  \n",
       "816  (7168, 16384)  shape_mismatch  \n",
       "818            NaN             NaN  \n",
       "819  (24576, 1536)  shape_mismatch  \n",
       "822            NaN             NaN  \n",
       "823            NaN             NaN  \n",
       "824            NaN             NaN  \n",
       "825            NaN             NaN  \n",
       "828            NaN             NaN  \n",
       "829   (32768, 512)  shape_mismatch  \n",
       "830  (7168, 16384)  shape_mismatch  \n",
       "832            NaN             NaN  \n",
       "833  (24576, 1536)  shape_mismatch  \n",
       "836            NaN             NaN  \n",
       "837            NaN             NaN  \n",
       "838            NaN             NaN  \n",
       "839            NaN             NaN  \n",
       "842            NaN             NaN  \n",
       "843   (32768, 512)  shape_mismatch  \n",
       "844  (7168, 16384)  shape_mismatch  \n",
       "846            NaN             NaN  \n",
       "847  (24576, 1536)  shape_mismatch  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)        # все строки\n",
    "pd.set_option('display.max_columns', None)     # все колонки\n",
    "pd.set_option('display.width', None)           # не ограничивать ширину вывода\n",
    "pd.set_option('display.max_colwidth', None)    # не обрезать содержимое ячеек\n",
    "# df\n",
    "ln_mask = df[\"key\"].str.endswith(LAYERNORM_SUFFIXES, na=False)\n",
    "df_ln = df[ln_mask]\n",
    "df_nonln = df[~ln_mask]\n",
    "df_nonln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "255f623d-ed18-44a1-ae0d-053fd2f303c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>key</th>\n",
       "      <th>shape</th>\n",
       "      <th>numel</th>\n",
       "      <th>norm_a</th>\n",
       "      <th>norm_b</th>\n",
       "      <th>norm_ratio</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_a</th>\n",
       "      <th>std_b</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>zero_frac_a</th>\n",
       "      <th>zero_frac_b</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>rel_l2_err</th>\n",
       "      <th>mean_rel_diff</th>\n",
       "      <th>max_rel_diff</th>\n",
       "      <th>pearson</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "      <th>spearman</th>\n",
       "      <th>q01_abs_diff</th>\n",
       "      <th>q05_abs_diff</th>\n",
       "      <th>q50_abs_diff</th>\n",
       "      <th>q95_abs_diff</th>\n",
       "      <th>q99_abs_diff</th>\n",
       "      <th>spec_rel_l2_err</th>\n",
       "      <th>spec_a_max</th>\n",
       "      <th>spec_a_min</th>\n",
       "      <th>spec_b_max</th>\n",
       "      <th>spec_b_min</th>\n",
       "      <th>spec_topk_u_cos_mean</th>\n",
       "      <th>spec_topk_u_cos_min</th>\n",
       "      <th>spec_topk_v_cos_mean</th>\n",
       "      <th>spec_topk_v_cos_min</th>\n",
       "      <th>spec_subspace_overlap_u</th>\n",
       "      <th>spec_subspace_overlap_v</th>\n",
       "      <th>shape_a</th>\n",
       "      <th>shape_b</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>5.333566</td>\n",
       "      <td>3.708255</td>\n",
       "      <td>1.438295</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>0.041479</td>\n",
       "      <td>1.415882</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>1.620160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>0.505120</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>5.045249</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.272217</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>-0.007118</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>0.127278</td>\n",
       "      <td>0.304732</td>\n",
       "      <td>tensor(5.3336, device='cuda:0')</td>\n",
       "      <td>tensor(5.3336, device='cuda:0')</td>\n",
       "      <td>tensor(3.7083, device='cuda:0')</td>\n",
       "      <td>tensor(3.7083, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>1.600154</td>\n",
       "      <td>1.976582</td>\n",
       "      <td>0.809556</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.548183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>0.964386</td>\n",
       "      <td>1.760695</td>\n",
       "      <td>4720.670898</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.676208</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.235245</td>\n",
       "      <td>tensor(1.6002, device='cuda:0')</td>\n",
       "      <td>tensor(1.6002, device='cuda:0')</td>\n",
       "      <td>tensor(1.9766, device='cuda:0')</td>\n",
       "      <td>tensor(1.9766, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.152460</td>\n",
       "      <td>0.231502</td>\n",
       "      <td>0.658569</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.506165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>1.277797</td>\n",
       "      <td>2.887821</td>\n",
       "      <td>84.512604</td>\n",
       "      <td>-0.015007</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.518445</td>\n",
       "      <td>tensor(0.1525, device='cuda:0')</td>\n",
       "      <td>tensor(0.1525, device='cuda:0')</td>\n",
       "      <td>tensor(0.2315, device='cuda:0')</td>\n",
       "      <td>tensor(0.2315, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>model.layers.0.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.237963</td>\n",
       "      <td>17.689760</td>\n",
       "      <td>0.465691</td>\n",
       "      <td>0.193372</td>\n",
       "      <td>0.443633</td>\n",
       "      <td>0.435884</td>\n",
       "      <td>0.082398</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905126</td>\n",
       "      <td>1.312957</td>\n",
       "      <td>1.929219</td>\n",
       "      <td>23.032129</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>1.400146</td>\n",
       "      <td>0.252936</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>0.419006</td>\n",
       "      <td>0.477258</td>\n",
       "      <td>1.147347</td>\n",
       "      <td>tensor(8.2380, device='cuda:0')</td>\n",
       "      <td>tensor(8.2380, device='cuda:0')</td>\n",
       "      <td>tensor(17.6898, device='cuda:0')</td>\n",
       "      <td>tensor(17.6898, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905127</td>\n",
       "      <td>0.905127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>4.966424</td>\n",
       "      <td>4.025096</td>\n",
       "      <td>1.233865</td>\n",
       "      <td>0.053581</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>1.205580</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>1.414466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.437025</td>\n",
       "      <td>12.734513</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.189538</td>\n",
       "      <td>tensor(4.9664, device='cuda:0')</td>\n",
       "      <td>tensor(4.9664, device='cuda:0')</td>\n",
       "      <td>tensor(4.0251, device='cuda:0')</td>\n",
       "      <td>tensor(4.0251, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>4.805261</td>\n",
       "      <td>5.418404</td>\n",
       "      <td>0.886841</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.048390</td>\n",
       "      <td>0.947874</td>\n",
       "      <td>0.033429</td>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.798134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607914</td>\n",
       "      <td>0.948953</td>\n",
       "      <td>1.461620</td>\n",
       "      <td>755.537292</td>\n",
       "      <td>-0.008112</td>\n",
       "      <td>0.530029</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>0.259021</td>\n",
       "      <td>0.127598</td>\n",
       "      <td>tensor(4.8053, device='cuda:0')</td>\n",
       "      <td>tensor(4.8053, device='cuda:0')</td>\n",
       "      <td>tensor(5.4184, device='cuda:0')</td>\n",
       "      <td>tensor(5.4184, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.607914</td>\n",
       "      <td>0.607914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.607914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.091417</td>\n",
       "      <td>0.262622</td>\n",
       "      <td>0.348093</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.348004</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.348181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>2.528081</td>\n",
       "      <td>19.070650</td>\n",
       "      <td>1066.807495</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>1.872793</td>\n",
       "      <td>tensor(0.0914, device='cuda:0')</td>\n",
       "      <td>tensor(0.0914, device='cuda:0')</td>\n",
       "      <td>tensor(0.2626, device='cuda:0')</td>\n",
       "      <td>tensor(0.2626, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>model.layers.1.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>5.265309</td>\n",
       "      <td>17.526243</td>\n",
       "      <td>0.300424</td>\n",
       "      <td>0.116436</td>\n",
       "      <td>0.419999</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.153560</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813170</td>\n",
       "      <td>2.581912</td>\n",
       "      <td>5.037098</td>\n",
       "      <td>172.381821</td>\n",
       "      <td>-0.004717</td>\n",
       "      <td>0.845947</td>\n",
       "      <td>0.306409</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.704395</td>\n",
       "      <td>2.328625</td>\n",
       "      <td>tensor(5.2653, device='cuda:0')</td>\n",
       "      <td>tensor(5.2653, device='cuda:0')</td>\n",
       "      <td>tensor(17.5262, device='cuda:0')</td>\n",
       "      <td>tensor(17.5262, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813170</td>\n",
       "      <td>0.813170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.698238</td>\n",
       "      <td>5.042212</td>\n",
       "      <td>1.328432</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.056358</td>\n",
       "      <td>1.324173</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>1.364385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.468261</td>\n",
       "      <td>0.384318</td>\n",
       "      <td>10.901235</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.073160</td>\n",
       "      <td>0.113362</td>\n",
       "      <td>0.247233</td>\n",
       "      <td>tensor(6.6982, device='cuda:0')</td>\n",
       "      <td>tensor(6.6982, device='cuda:0')</td>\n",
       "      <td>tensor(5.0422, device='cuda:0')</td>\n",
       "      <td>tensor(5.0422, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>5.107561</td>\n",
       "      <td>3.691749</td>\n",
       "      <td>1.383507</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>1.372092</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>1.428917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>0.607275</td>\n",
       "      <td>0.457887</td>\n",
       "      <td>44.881279</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>0.277199</td>\n",
       "      <td>tensor(5.1076, device='cuda:0')</td>\n",
       "      <td>tensor(5.1076, device='cuda:0')</td>\n",
       "      <td>tensor(3.6917, device='cuda:0')</td>\n",
       "      <td>tensor(3.6917, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>0.277005</td>\n",
       "      <td>0.276632</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.260855</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556629</td>\n",
       "      <td>3.169114</td>\n",
       "      <td>14.854513</td>\n",
       "      <td>1442.955078</td>\n",
       "      <td>-0.007952</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>2.614917</td>\n",
       "      <td>tensor(0.0766, device='cuda:0')</td>\n",
       "      <td>tensor(0.0766, device='cuda:0')</td>\n",
       "      <td>tensor(0.2770, device='cuda:0')</td>\n",
       "      <td>tensor(0.2770, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556629</td>\n",
       "      <td>0.556629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>model.layers.2.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>6.045459</td>\n",
       "      <td>18.126390</td>\n",
       "      <td>0.333517</td>\n",
       "      <td>0.147995</td>\n",
       "      <td>0.432889</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>0.267065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897100</td>\n",
       "      <td>2.147197</td>\n",
       "      <td>2.239266</td>\n",
       "      <td>25.785185</td>\n",
       "      <td>-0.009041</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.285435</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.591309</td>\n",
       "      <td>0.731934</td>\n",
       "      <td>1.998348</td>\n",
       "      <td>tensor(6.0455, device='cuda:0')</td>\n",
       "      <td>tensor(6.0455, device='cuda:0')</td>\n",
       "      <td>tensor(18.1264, device='cuda:0')</td>\n",
       "      <td>tensor(18.1264, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897100</td>\n",
       "      <td>0.897100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.191147</td>\n",
       "      <td>4.541937</td>\n",
       "      <td>1.803448</td>\n",
       "      <td>0.092289</td>\n",
       "      <td>0.052340</td>\n",
       "      <td>1.763250</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>2.467632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>0.525156</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>3.993939</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>0.041516</td>\n",
       "      <td>-0.007745</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.445507</td>\n",
       "      <td>tensor(8.1911, device='cuda:0')</td>\n",
       "      <td>tensor(8.1911, device='cuda:0')</td>\n",
       "      <td>tensor(4.5419, device='cuda:0')</td>\n",
       "      <td>tensor(4.5419, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>100.150665</td>\n",
       "      <td>79.248253</td>\n",
       "      <td>1.263759</td>\n",
       "      <td>6.259399</td>\n",
       "      <td>4.953015</td>\n",
       "      <td>1.263755</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>6.715944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.208720</td>\n",
       "      <td>0.208703</td>\n",
       "      <td>0.211952</td>\n",
       "      <td>0.077591</td>\n",
       "      <td>1.331326</td>\n",
       "      <td>1.306384</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>1.291267</td>\n",
       "      <td>1.293877</td>\n",
       "      <td>1.298276</td>\n",
       "      <td>1.330326</td>\n",
       "      <td>1.331326</td>\n",
       "      <td>0.208710</td>\n",
       "      <td>tensor(100.1507, device='cuda:0')</td>\n",
       "      <td>tensor(100.1507, device='cuda:0')</td>\n",
       "      <td>tensor(79.2482, device='cuda:0')</td>\n",
       "      <td>tensor(79.2482, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.430301</td>\n",
       "      <td>10.335238</td>\n",
       "      <td>0.718929</td>\n",
       "      <td>0.080654</td>\n",
       "      <td>0.110154</td>\n",
       "      <td>0.732189</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.657652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825780</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>2.027711</td>\n",
       "      <td>500.894745</td>\n",
       "      <td>-0.020555</td>\n",
       "      <td>0.302460</td>\n",
       "      <td>0.056521</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.390958</td>\n",
       "      <td>tensor(7.4303, device='cuda:0')</td>\n",
       "      <td>tensor(7.4303, device='cuda:0')</td>\n",
       "      <td>tensor(10.3352, device='cuda:0')</td>\n",
       "      <td>tensor(10.3352, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825780</td>\n",
       "      <td>0.825780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.416599</td>\n",
       "      <td>0.834195</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.606496</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>1.278002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>1.105839</td>\n",
       "      <td>18.509750</td>\n",
       "      <td>2520.660645</td>\n",
       "      <td>-0.080960</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>-0.080748</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.198760</td>\n",
       "      <td>tensor(0.3475, device='cuda:0')</td>\n",
       "      <td>tensor(0.3475, device='cuda:0')</td>\n",
       "      <td>tensor(0.4166, device='cuda:0')</td>\n",
       "      <td>tensor(0.4166, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>model.layers.3.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>13.885664</td>\n",
       "      <td>19.065044</td>\n",
       "      <td>0.728331</td>\n",
       "      <td>0.345856</td>\n",
       "      <td>0.456453</td>\n",
       "      <td>0.757705</td>\n",
       "      <td>0.076888</td>\n",
       "      <td>0.168193</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>0.607787</td>\n",
       "      <td>0.518893</td>\n",
       "      <td>4.371428</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>0.165950</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.441406</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.373002</td>\n",
       "      <td>tensor(13.8857, device='cuda:0')</td>\n",
       "      <td>tensor(13.8857, device='cuda:0')</td>\n",
       "      <td>tensor(19.0650, device='cuda:0')</td>\n",
       "      <td>tensor(19.0650, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.282731</td>\n",
       "      <td>3.886504</td>\n",
       "      <td>1.616551</td>\n",
       "      <td>0.071074</td>\n",
       "      <td>0.043553</td>\n",
       "      <td>1.631882</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>1.471112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909860</td>\n",
       "      <td>0.506939</td>\n",
       "      <td>0.391246</td>\n",
       "      <td>3.827586</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>0.030028</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>0.103352</td>\n",
       "      <td>0.381399</td>\n",
       "      <td>tensor(6.2827, device='cuda:0')</td>\n",
       "      <td>tensor(6.2827, device='cuda:0')</td>\n",
       "      <td>tensor(3.8865, device='cuda:0')</td>\n",
       "      <td>tensor(3.8865, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909860</td>\n",
       "      <td>0.909860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>94.486427</td>\n",
       "      <td>105.370796</td>\n",
       "      <td>0.896704</td>\n",
       "      <td>5.905396</td>\n",
       "      <td>6.585674</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>4.698055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>0.115199</td>\n",
       "      <td>0.121158</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.711805</td>\n",
       "      <td>0.680279</td>\n",
       "      <td>0.132161</td>\n",
       "      <td>0.648305</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.691467</td>\n",
       "      <td>0.711695</td>\n",
       "      <td>0.115195</td>\n",
       "      <td>tensor(94.4864, device='cuda:0')</td>\n",
       "      <td>tensor(94.4864, device='cuda:0')</td>\n",
       "      <td>tensor(105.3708, device='cuda:0')</td>\n",
       "      <td>tensor(105.3708, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.501461</td>\n",
       "      <td>10.436382</td>\n",
       "      <td>1.006236</td>\n",
       "      <td>0.118008</td>\n",
       "      <td>0.108037</td>\n",
       "      <td>1.092297</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.059355</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>0.915274</td>\n",
       "      <td>263.826660</td>\n",
       "      <td>-0.028770</td>\n",
       "      <td>0.319336</td>\n",
       "      <td>0.058462</td>\n",
       "      <td>-0.025815</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.134967</td>\n",
       "      <td>0.180012</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>tensor(10.5015, device='cuda:0')</td>\n",
       "      <td>tensor(10.5015, device='cuda:0')</td>\n",
       "      <td>tensor(10.4364, device='cuda:0')</td>\n",
       "      <td>tensor(10.4364, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.145010</td>\n",
       "      <td>1.085993</td>\n",
       "      <td>0.133528</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>0.135009</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>6.717411</td>\n",
       "      <td>16.174299</td>\n",
       "      <td>2135.943359</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.120544</td>\n",
       "      <td>0.037131</td>\n",
       "      <td>0.027201</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.069806</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>6.489081</td>\n",
       "      <td>tensor(0.1450, device='cuda:0')</td>\n",
       "      <td>tensor(0.1450, device='cuda:0')</td>\n",
       "      <td>tensor(1.0860, device='cuda:0')</td>\n",
       "      <td>tensor(1.0860, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>model.layers.4.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.648572</td>\n",
       "      <td>38.966732</td>\n",
       "      <td>0.221948</td>\n",
       "      <td>0.213636</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>0.220554</td>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.224259</td>\n",
       "      <td>0.246504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941680</td>\n",
       "      <td>3.579740</td>\n",
       "      <td>3.865564</td>\n",
       "      <td>11.202021</td>\n",
       "      <td>-0.026300</td>\n",
       "      <td>1.583984</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>-0.028483</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>0.369385</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>1.133057</td>\n",
       "      <td>1.293262</td>\n",
       "      <td>3.505569</td>\n",
       "      <td>tensor(8.6486, device='cuda:0')</td>\n",
       "      <td>tensor(8.6486, device='cuda:0')</td>\n",
       "      <td>tensor(38.9667, device='cuda:0')</td>\n",
       "      <td>tensor(38.9667, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941680</td>\n",
       "      <td>0.941680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.362890</td>\n",
       "      <td>5.834433</td>\n",
       "      <td>1.433368</td>\n",
       "      <td>0.095684</td>\n",
       "      <td>0.066838</td>\n",
       "      <td>1.431584</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>1.461375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>0.418997</td>\n",
       "      <td>0.326038</td>\n",
       "      <td>11.643903</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>0.073932</td>\n",
       "      <td>0.113198</td>\n",
       "      <td>0.302342</td>\n",
       "      <td>tensor(8.3629, device='cuda:0')</td>\n",
       "      <td>tensor(8.3629, device='cuda:0')</td>\n",
       "      <td>tensor(5.8344, device='cuda:0')</td>\n",
       "      <td>tensor(5.8344, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>114.025658</td>\n",
       "      <td>120.610062</td>\n",
       "      <td>0.945408</td>\n",
       "      <td>7.126587</td>\n",
       "      <td>7.538128</td>\n",
       "      <td>0.945405</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>8.115402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.057788</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.072176</td>\n",
       "      <td>0.069558</td>\n",
       "      <td>0.507486</td>\n",
       "      <td>0.411542</td>\n",
       "      <td>0.052694</td>\n",
       "      <td>0.379396</td>\n",
       "      <td>0.382086</td>\n",
       "      <td>0.413536</td>\n",
       "      <td>0.418936</td>\n",
       "      <td>0.472687</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>tensor(114.0257, device='cuda:0')</td>\n",
       "      <td>tensor(114.0257, device='cuda:0')</td>\n",
       "      <td>tensor(120.6101, device='cuda:0')</td>\n",
       "      <td>tensor(120.6101, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>11.926690</td>\n",
       "      <td>12.219624</td>\n",
       "      <td>0.976028</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.129416</td>\n",
       "      <td>1.044210</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.063898</td>\n",
       "      <td>0.622563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857210</td>\n",
       "      <td>0.541476</td>\n",
       "      <td>0.719009</td>\n",
       "      <td>83.879433</td>\n",
       "      <td>-0.023657</td>\n",
       "      <td>0.298401</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>-0.020848</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>0.184062</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>tensor(11.9267, device='cuda:0')</td>\n",
       "      <td>tensor(11.9267, device='cuda:0')</td>\n",
       "      <td>tensor(12.2196, device='cuda:0')</td>\n",
       "      <td>tensor(12.2196, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857210</td>\n",
       "      <td>0.857210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.164448</td>\n",
       "      <td>0.613759</td>\n",
       "      <td>0.267936</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.259980</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.482850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942494</td>\n",
       "      <td>2.809685</td>\n",
       "      <td>5.259251</td>\n",
       "      <td>399.822845</td>\n",
       "      <td>-0.069843</td>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.031139</td>\n",
       "      <td>2.732230</td>\n",
       "      <td>tensor(0.1644, device='cuda:0')</td>\n",
       "      <td>tensor(0.1644, device='cuda:0')</td>\n",
       "      <td>tensor(0.6138, device='cuda:0')</td>\n",
       "      <td>tensor(0.6138, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942494</td>\n",
       "      <td>0.942494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>model.layers.5.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>12.083183</td>\n",
       "      <td>29.750238</td>\n",
       "      <td>0.406154</td>\n",
       "      <td>0.297168</td>\n",
       "      <td>0.715038</td>\n",
       "      <td>0.415598</td>\n",
       "      <td>0.082129</td>\n",
       "      <td>0.254837</td>\n",
       "      <td>0.322280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904794</td>\n",
       "      <td>1.614500</td>\n",
       "      <td>1.662392</td>\n",
       "      <td>10.543379</td>\n",
       "      <td>-0.035047</td>\n",
       "      <td>1.167969</td>\n",
       "      <td>0.429652</td>\n",
       "      <td>-0.041957</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.842041</td>\n",
       "      <td>0.963525</td>\n",
       "      <td>1.462119</td>\n",
       "      <td>tensor(12.0832, device='cuda:0')</td>\n",
       "      <td>tensor(12.0832, device='cuda:0')</td>\n",
       "      <td>tensor(29.7502, device='cuda:0')</td>\n",
       "      <td>tensor(29.7502, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904794</td>\n",
       "      <td>0.904794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.117170</td>\n",
       "      <td>5.769558</td>\n",
       "      <td>1.233573</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.067094</td>\n",
       "      <td>1.214450</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>1.732541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>0.331784</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>3.896552</td>\n",
       "      <td>-0.002211</td>\n",
       "      <td>0.307129</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.082681</td>\n",
       "      <td>0.189347</td>\n",
       "      <td>tensor(7.1172, device='cuda:0')</td>\n",
       "      <td>tensor(7.1172, device='cuda:0')</td>\n",
       "      <td>tensor(5.7696, device='cuda:0')</td>\n",
       "      <td>tensor(5.7696, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>118.371513</td>\n",
       "      <td>95.961823</td>\n",
       "      <td>1.233527</td>\n",
       "      <td>7.398193</td>\n",
       "      <td>5.997613</td>\n",
       "      <td>1.233523</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>9.784381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.189332</td>\n",
       "      <td>0.189308</td>\n",
       "      <td>0.193728</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>1.440852</td>\n",
       "      <td>1.400580</td>\n",
       "      <td>0.085245</td>\n",
       "      <td>1.314402</td>\n",
       "      <td>1.347102</td>\n",
       "      <td>1.408402</td>\n",
       "      <td>1.411452</td>\n",
       "      <td>1.415401</td>\n",
       "      <td>0.189317</td>\n",
       "      <td>tensor(118.3715, device='cuda:0')</td>\n",
       "      <td>tensor(118.3715, device='cuda:0')</td>\n",
       "      <td>tensor(95.9618, device='cuda:0')</td>\n",
       "      <td>tensor(95.9618, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>12.566309</td>\n",
       "      <td>13.817199</td>\n",
       "      <td>0.909469</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>0.928440</td>\n",
       "      <td>0.037405</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>0.719793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>0.442103</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>21.127659</td>\n",
       "      <td>-0.021555</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>-0.019529</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.130371</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>tensor(12.5663, device='cuda:0')</td>\n",
       "      <td>tensor(12.5663, device='cuda:0')</td>\n",
       "      <td>tensor(13.8172, device='cuda:0')</td>\n",
       "      <td>tensor(13.8172, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.135344</td>\n",
       "      <td>0.454429</td>\n",
       "      <td>0.297833</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>0.275999</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.985429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>2.480313</td>\n",
       "      <td>4.264627</td>\n",
       "      <td>114.911110</td>\n",
       "      <td>-0.046069</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>2.357590</td>\n",
       "      <td>tensor(0.1353, device='cuda:0')</td>\n",
       "      <td>tensor(0.1353, device='cuda:0')</td>\n",
       "      <td>tensor(0.4544, device='cuda:0')</td>\n",
       "      <td>tensor(0.4544, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6</td>\n",
       "      <td>model.layers.6.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>8.600546</td>\n",
       "      <td>28.650684</td>\n",
       "      <td>0.300186</td>\n",
       "      <td>0.207385</td>\n",
       "      <td>0.687798</td>\n",
       "      <td>0.301520</td>\n",
       "      <td>0.071755</td>\n",
       "      <td>0.247687</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888783</td>\n",
       "      <td>2.485110</td>\n",
       "      <td>2.776003</td>\n",
       "      <td>11.489796</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>1.109375</td>\n",
       "      <td>0.483756</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.487305</td>\n",
       "      <td>0.884766</td>\n",
       "      <td>1.000293</td>\n",
       "      <td>2.331264</td>\n",
       "      <td>tensor(8.6005, device='cuda:0')</td>\n",
       "      <td>tensor(8.6005, device='cuda:0')</td>\n",
       "      <td>tensor(28.6507, device='cuda:0')</td>\n",
       "      <td>tensor(28.6507, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888783</td>\n",
       "      <td>0.888783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.519102</td>\n",
       "      <td>5.417134</td>\n",
       "      <td>1.388022</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>0.062993</td>\n",
       "      <td>1.381284</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>1.585890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>0.358566</td>\n",
       "      <td>0.270462</td>\n",
       "      <td>3.243094</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.479004</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>0.279550</td>\n",
       "      <td>tensor(7.5191, device='cuda:0')</td>\n",
       "      <td>tensor(7.5191, device='cuda:0')</td>\n",
       "      <td>tensor(5.4171, device='cuda:0')</td>\n",
       "      <td>tensor(5.4171, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>106.918343</td>\n",
       "      <td>87.724533</td>\n",
       "      <td>1.218796</td>\n",
       "      <td>6.682373</td>\n",
       "      <td>5.482783</td>\n",
       "      <td>1.218792</td>\n",
       "      <td>0.017590</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>6.487113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.179534</td>\n",
       "      <td>0.179510</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>0.088802</td>\n",
       "      <td>1.239864</td>\n",
       "      <td>1.199590</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>1.140775</td>\n",
       "      <td>1.171515</td>\n",
       "      <td>1.203815</td>\n",
       "      <td>1.212064</td>\n",
       "      <td>1.237065</td>\n",
       "      <td>0.179518</td>\n",
       "      <td>tensor(106.9184, device='cuda:0')</td>\n",
       "      <td>tensor(106.9184, device='cuda:0')</td>\n",
       "      <td>tensor(87.7245, device='cuda:0')</td>\n",
       "      <td>tensor(87.7245, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>14.079303</td>\n",
       "      <td>14.198127</td>\n",
       "      <td>0.991631</td>\n",
       "      <td>0.163313</td>\n",
       "      <td>0.160756</td>\n",
       "      <td>1.015910</td>\n",
       "      <td>0.031355</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.656547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940211</td>\n",
       "      <td>0.347361</td>\n",
       "      <td>0.387639</td>\n",
       "      <td>73.884354</td>\n",
       "      <td>-0.022177</td>\n",
       "      <td>0.218628</td>\n",
       "      <td>0.044104</td>\n",
       "      <td>-0.026056</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.122314</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>tensor(14.0793, device='cuda:0')</td>\n",
       "      <td>tensor(14.0793, device='cuda:0')</td>\n",
       "      <td>tensor(14.1981, device='cuda:0')</td>\n",
       "      <td>tensor(14.1981, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.426888</td>\n",
       "      <td>0.779261</td>\n",
       "      <td>0.547811</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.537793</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>1.174130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.887372</td>\n",
       "      <td>4.830700</td>\n",
       "      <td>1430.934937</td>\n",
       "      <td>-0.045017</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>0.825447</td>\n",
       "      <td>tensor(0.4269, device='cuda:0')</td>\n",
       "      <td>tensor(0.4269, device='cuda:0')</td>\n",
       "      <td>tensor(0.7793, device='cuda:0')</td>\n",
       "      <td>tensor(0.7793, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>model.layers.7.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>13.775208</td>\n",
       "      <td>36.266392</td>\n",
       "      <td>0.379834</td>\n",
       "      <td>0.334484</td>\n",
       "      <td>0.863280</td>\n",
       "      <td>0.387457</td>\n",
       "      <td>0.107981</td>\n",
       "      <td>0.333213</td>\n",
       "      <td>0.324059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892380</td>\n",
       "      <td>1.797909</td>\n",
       "      <td>1.925852</td>\n",
       "      <td>10.154929</td>\n",
       "      <td>0.041392</td>\n",
       "      <td>1.418945</td>\n",
       "      <td>0.543642</td>\n",
       "      <td>0.042698</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>1.052002</td>\n",
       "      <td>1.183545</td>\n",
       "      <td>1.632729</td>\n",
       "      <td>tensor(13.7752, device='cuda:0')</td>\n",
       "      <td>tensor(13.7752, device='cuda:0')</td>\n",
       "      <td>tensor(36.2664, device='cuda:0')</td>\n",
       "      <td>tensor(36.2664, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892380</td>\n",
       "      <td>0.892380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.110951</td>\n",
       "      <td>5.380949</td>\n",
       "      <td>1.693187</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>0.062231</td>\n",
       "      <td>1.703697</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>1.427530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.458113</td>\n",
       "      <td>0.407056</td>\n",
       "      <td>2.447005</td>\n",
       "      <td>-0.012705</td>\n",
       "      <td>0.354492</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>-0.006039</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>0.409398</td>\n",
       "      <td>tensor(9.1110, device='cuda:0')</td>\n",
       "      <td>tensor(9.1110, device='cuda:0')</td>\n",
       "      <td>tensor(5.3809, device='cuda:0')</td>\n",
       "      <td>tensor(5.3809, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>98.215782</td>\n",
       "      <td>86.622200</td>\n",
       "      <td>1.133841</td>\n",
       "      <td>6.138428</td>\n",
       "      <td>5.413887</td>\n",
       "      <td>1.133830</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>11.140157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.118017</td>\n",
       "      <td>0.122048</td>\n",
       "      <td>-0.016731</td>\n",
       "      <td>0.751359</td>\n",
       "      <td>0.724541</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.633897</td>\n",
       "      <td>0.679010</td>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.746760</td>\n",
       "      <td>0.749559</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>tensor(98.2158, device='cuda:0')</td>\n",
       "      <td>tensor(98.2158, device='cuda:0')</td>\n",
       "      <td>tensor(86.6222, device='cuda:0')</td>\n",
       "      <td>tensor(86.6222, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>15.492817</td>\n",
       "      <td>15.785369</td>\n",
       "      <td>0.981467</td>\n",
       "      <td>0.180642</td>\n",
       "      <td>0.181526</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.686859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960529</td>\n",
       "      <td>0.284235</td>\n",
       "      <td>0.283835</td>\n",
       "      <td>35.402115</td>\n",
       "      <td>-0.015849</td>\n",
       "      <td>0.222778</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>-0.019328</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.167114</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>tensor(15.4928, device='cuda:0')</td>\n",
       "      <td>tensor(15.4928, device='cuda:0')</td>\n",
       "      <td>tensor(15.7854, device='cuda:0')</td>\n",
       "      <td>tensor(15.7854, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960529</td>\n",
       "      <td>0.960529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.265736</td>\n",
       "      <td>0.534529</td>\n",
       "      <td>0.497139</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.506322</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965048</td>\n",
       "      <td>1.078778</td>\n",
       "      <td>3.367396</td>\n",
       "      <td>935.087830</td>\n",
       "      <td>-0.049529</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>-0.045209</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>1.011508</td>\n",
       "      <td>tensor(0.2657, device='cuda:0')</td>\n",
       "      <td>tensor(0.2657, device='cuda:0')</td>\n",
       "      <td>tensor(0.5345, device='cuda:0')</td>\n",
       "      <td>tensor(0.5345, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965048</td>\n",
       "      <td>0.965048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>8</td>\n",
       "      <td>model.layers.8.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>15.508194</td>\n",
       "      <td>24.044184</td>\n",
       "      <td>0.644987</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.703098</td>\n",
       "      <td>0.107487</td>\n",
       "      <td>0.288125</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>0.880355</td>\n",
       "      <td>0.853385</td>\n",
       "      <td>6.896774</td>\n",
       "      <td>-0.014892</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>0.282334</td>\n",
       "      <td>-0.012600</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.839795</td>\n",
       "      <td>0.550418</td>\n",
       "      <td>tensor(15.5082, device='cuda:0')</td>\n",
       "      <td>tensor(15.5082, device='cuda:0')</td>\n",
       "      <td>tensor(24.0442, device='cuda:0')</td>\n",
       "      <td>tensor(24.0442, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.394691</td>\n",
       "      <td>3.145885</td>\n",
       "      <td>2.668467</td>\n",
       "      <td>0.097636</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>2.652601</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>3.397628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>0.639980</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.945423</td>\n",
       "      <td>-0.012499</td>\n",
       "      <td>0.524414</td>\n",
       "      <td>0.060864</td>\n",
       "      <td>-0.002786</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.118001</td>\n",
       "      <td>0.625253</td>\n",
       "      <td>tensor(8.3947, device='cuda:0')</td>\n",
       "      <td>tensor(8.3947, device='cuda:0')</td>\n",
       "      <td>tensor(3.1459, device='cuda:0')</td>\n",
       "      <td>tensor(3.1459, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>89.670647</td>\n",
       "      <td>77.074051</td>\n",
       "      <td>1.163435</td>\n",
       "      <td>5.604370</td>\n",
       "      <td>4.817127</td>\n",
       "      <td>1.163426</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>7.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.140528</td>\n",
       "      <td>0.140455</td>\n",
       "      <td>0.146678</td>\n",
       "      <td>-0.078326</td>\n",
       "      <td>0.825065</td>\n",
       "      <td>0.787243</td>\n",
       "      <td>-0.141759</td>\n",
       "      <td>0.713427</td>\n",
       "      <td>0.744767</td>\n",
       "      <td>0.779016</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.817516</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>tensor(89.6706, device='cuda:0')</td>\n",
       "      <td>tensor(89.6706, device='cuda:0')</td>\n",
       "      <td>tensor(77.0741, device='cuda:0')</td>\n",
       "      <td>tensor(77.0741, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>17.782528</td>\n",
       "      <td>16.459641</td>\n",
       "      <td>1.080372</td>\n",
       "      <td>0.208091</td>\n",
       "      <td>0.190776</td>\n",
       "      <td>1.090763</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.762141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>0.239751</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>13.511628</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.112305</td>\n",
       "      <td>0.179524</td>\n",
       "      <td>0.074393</td>\n",
       "      <td>tensor(17.7825, device='cuda:0')</td>\n",
       "      <td>tensor(17.7825, device='cuda:0')</td>\n",
       "      <td>tensor(16.4596, device='cuda:0')</td>\n",
       "      <td>tensor(16.4596, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>2.375535</td>\n",
       "      <td>0.120433</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.104601</td>\n",
       "      <td>0.119603</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.204072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985790</td>\n",
       "      <td>7.319476</td>\n",
       "      <td>12.125095</td>\n",
       "      <td>2353.144287</td>\n",
       "      <td>-0.005494</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.092130</td>\n",
       "      <td>-0.033861</td>\n",
       "      <td>0.048609</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.100098</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>7.303339</td>\n",
       "      <td>tensor(0.2861, device='cuda:0')</td>\n",
       "      <td>tensor(0.2861, device='cuda:0')</td>\n",
       "      <td>tensor(2.3755, device='cuda:0')</td>\n",
       "      <td>tensor(2.3755, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985790</td>\n",
       "      <td>0.985790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9</td>\n",
       "      <td>model.layers.9.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>12.147147</td>\n",
       "      <td>58.573437</td>\n",
       "      <td>0.207383</td>\n",
       "      <td>0.291249</td>\n",
       "      <td>1.428330</td>\n",
       "      <td>0.203909</td>\n",
       "      <td>0.106005</td>\n",
       "      <td>0.439884</td>\n",
       "      <td>0.240985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>3.949352</td>\n",
       "      <td>4.783004</td>\n",
       "      <td>18.106796</td>\n",
       "      <td>-0.006946</td>\n",
       "      <td>1.940430</td>\n",
       "      <td>1.141272</td>\n",
       "      <td>-0.015383</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>1.252441</td>\n",
       "      <td>1.673828</td>\n",
       "      <td>1.804297</td>\n",
       "      <td>3.821991</td>\n",
       "      <td>tensor(12.1471, device='cuda:0')</td>\n",
       "      <td>tensor(12.1471, device='cuda:0')</td>\n",
       "      <td>tensor(58.5734, device='cuda:0')</td>\n",
       "      <td>tensor(58.5734, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.541730</td>\n",
       "      <td>3.601893</td>\n",
       "      <td>2.371456</td>\n",
       "      <td>0.099587</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>2.353147</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>3.718390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.566980</td>\n",
       "      <td>0.921033</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.119707</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>tensor(8.5417, device='cuda:0')</td>\n",
       "      <td>tensor(8.5417, device='cuda:0')</td>\n",
       "      <td>tensor(3.6019, device='cuda:0')</td>\n",
       "      <td>tensor(3.6019, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>78.372345</td>\n",
       "      <td>64.967072</td>\n",
       "      <td>1.206339</td>\n",
       "      <td>4.898193</td>\n",
       "      <td>4.060442</td>\n",
       "      <td>1.206320</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>11.181231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.171006</td>\n",
       "      <td>0.178169</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>0.879712</td>\n",
       "      <td>0.837752</td>\n",
       "      <td>0.052533</td>\n",
       "      <td>0.705659</td>\n",
       "      <td>0.812012</td>\n",
       "      <td>0.845262</td>\n",
       "      <td>0.850311</td>\n",
       "      <td>0.877712</td>\n",
       "      <td>0.171046</td>\n",
       "      <td>tensor(78.3724, device='cuda:0')</td>\n",
       "      <td>tensor(78.3724, device='cuda:0')</td>\n",
       "      <td>tensor(64.9671, device='cuda:0')</td>\n",
       "      <td>tensor(64.9671, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>19.708843</td>\n",
       "      <td>17.559284</td>\n",
       "      <td>1.122417</td>\n",
       "      <td>0.231204</td>\n",
       "      <td>0.204769</td>\n",
       "      <td>1.129095</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.823633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980439</td>\n",
       "      <td>0.216220</td>\n",
       "      <td>0.181954</td>\n",
       "      <td>12.239436</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.035862</td>\n",
       "      <td>-0.018406</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.103516</td>\n",
       "      <td>0.190022</td>\n",
       "      <td>0.109066</td>\n",
       "      <td>tensor(19.7088, device='cuda:0')</td>\n",
       "      <td>tensor(19.7088, device='cuda:0')</td>\n",
       "      <td>tensor(17.5593, device='cuda:0')</td>\n",
       "      <td>tensor(17.5593, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980439</td>\n",
       "      <td>0.980439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.359084</td>\n",
       "      <td>1.876313</td>\n",
       "      <td>0.191378</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.190269</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.343094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>4.238711</td>\n",
       "      <td>4.865345</td>\n",
       "      <td>129.909088</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.067032</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0.076209</td>\n",
       "      <td>4.225269</td>\n",
       "      <td>tensor(0.3591, device='cuda:0')</td>\n",
       "      <td>tensor(0.3591, device='cuda:0')</td>\n",
       "      <td>tensor(1.8763, device='cuda:0')</td>\n",
       "      <td>tensor(1.8763, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>10</td>\n",
       "      <td>model.layers.10.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>14.437043</td>\n",
       "      <td>61.101032</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.350926</td>\n",
       "      <td>1.483577</td>\n",
       "      <td>0.236541</td>\n",
       "      <td>0.112010</td>\n",
       "      <td>0.479122</td>\n",
       "      <td>0.233783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904946</td>\n",
       "      <td>3.354393</td>\n",
       "      <td>3.807660</td>\n",
       "      <td>17.690266</td>\n",
       "      <td>-0.017125</td>\n",
       "      <td>1.956055</td>\n",
       "      <td>1.142103</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>1.288086</td>\n",
       "      <td>1.699219</td>\n",
       "      <td>1.824756</td>\n",
       "      <td>3.232240</td>\n",
       "      <td>tensor(14.4370, device='cuda:0')</td>\n",
       "      <td>tensor(14.4370, device='cuda:0')</td>\n",
       "      <td>tensor(61.1010, device='cuda:0')</td>\n",
       "      <td>tensor(61.1010, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904946</td>\n",
       "      <td>0.904946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.118999</td>\n",
       "      <td>2.988442</td>\n",
       "      <td>3.051423</td>\n",
       "      <td>0.106996</td>\n",
       "      <td>0.034930</td>\n",
       "      <td>3.063137</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>2.433828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>0.680383</td>\n",
       "      <td>0.670312</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.055908</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.089191</td>\n",
       "      <td>0.113770</td>\n",
       "      <td>0.672284</td>\n",
       "      <td>tensor(9.1190, device='cuda:0')</td>\n",
       "      <td>tensor(9.1190, device='cuda:0')</td>\n",
       "      <td>tensor(2.9884, device='cuda:0')</td>\n",
       "      <td>tensor(2.9884, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.608574</td>\n",
       "      <td>60.910301</td>\n",
       "      <td>1.192057</td>\n",
       "      <td>4.537964</td>\n",
       "      <td>3.806892</td>\n",
       "      <td>1.192039</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>7.560077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.161199</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>0.171046</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.785744</td>\n",
       "      <td>0.731071</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.647481</td>\n",
       "      <td>0.691194</td>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.758743</td>\n",
       "      <td>0.766583</td>\n",
       "      <td>0.161114</td>\n",
       "      <td>tensor(72.6086, device='cuda:0')</td>\n",
       "      <td>tensor(72.6086, device='cuda:0')</td>\n",
       "      <td>tensor(60.9103, device='cuda:0')</td>\n",
       "      <td>tensor(60.9103, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>20.472179</td>\n",
       "      <td>18.495205</td>\n",
       "      <td>1.106891</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.216203</td>\n",
       "      <td>1.112866</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>0.031279</td>\n",
       "      <td>0.769164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>0.192343</td>\n",
       "      <td>0.162446</td>\n",
       "      <td>20.810057</td>\n",
       "      <td>-0.006962</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.197263</td>\n",
       "      <td>0.096569</td>\n",
       "      <td>tensor(20.4722, device='cuda:0')</td>\n",
       "      <td>tensor(20.4722, device='cuda:0')</td>\n",
       "      <td>tensor(18.4952, device='cuda:0')</td>\n",
       "      <td>tensor(18.4952, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>2.485416</td>\n",
       "      <td>0.316369</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.109573</td>\n",
       "      <td>0.315769</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.421386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>2.170675</td>\n",
       "      <td>24.702936</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.109955</td>\n",
       "      <td>0.075135</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.066296</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>2.160861</td>\n",
       "      <td>tensor(0.7863, device='cuda:0')</td>\n",
       "      <td>tensor(0.7863, device='cuda:0')</td>\n",
       "      <td>tensor(2.4854, device='cuda:0')</td>\n",
       "      <td>tensor(2.4854, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>11</td>\n",
       "      <td>model.layers.11.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.092937</td>\n",
       "      <td>53.990604</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.538747</td>\n",
       "      <td>1.274603</td>\n",
       "      <td>0.422678</td>\n",
       "      <td>0.165902</td>\n",
       "      <td>0.522651</td>\n",
       "      <td>0.317425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>1.631507</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>9.926829</td>\n",
       "      <td>-0.021215</td>\n",
       "      <td>1.792969</td>\n",
       "      <td>0.816552</td>\n",
       "      <td>-0.028128</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.877930</td>\n",
       "      <td>1.428955</td>\n",
       "      <td>1.593652</td>\n",
       "      <td>1.443795</td>\n",
       "      <td>tensor(22.0929, device='cuda:0')</td>\n",
       "      <td>tensor(22.0929, device='cuda:0')</td>\n",
       "      <td>tensor(53.9906, device='cuda:0')</td>\n",
       "      <td>tensor(53.9906, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.310952</td>\n",
       "      <td>5.036315</td>\n",
       "      <td>1.848763</td>\n",
       "      <td>0.109255</td>\n",
       "      <td>0.059196</td>\n",
       "      <td>1.845658</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>2.141295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>0.472232</td>\n",
       "      <td>0.452887</td>\n",
       "      <td>0.791096</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.050131</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.089436</td>\n",
       "      <td>0.459098</td>\n",
       "      <td>tensor(9.3110, device='cuda:0')</td>\n",
       "      <td>tensor(9.3110, device='cuda:0')</td>\n",
       "      <td>tensor(5.0363, device='cuda:0')</td>\n",
       "      <td>tensor(5.0363, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>68.907265</td>\n",
       "      <td>57.200222</td>\n",
       "      <td>1.204668</td>\n",
       "      <td>4.306641</td>\n",
       "      <td>3.575012</td>\n",
       "      <td>1.204651</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>6.953601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.169968</td>\n",
       "      <td>0.169859</td>\n",
       "      <td>0.178630</td>\n",
       "      <td>0.067644</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>0.060866</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>0.703027</td>\n",
       "      <td>0.736477</td>\n",
       "      <td>0.744476</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.169896</td>\n",
       "      <td>tensor(68.9073, device='cuda:0')</td>\n",
       "      <td>tensor(68.9073, device='cuda:0')</td>\n",
       "      <td>tensor(57.2002, device='cuda:0')</td>\n",
       "      <td>tensor(57.2002, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.192741</td>\n",
       "      <td>19.668037</td>\n",
       "      <td>1.077522</td>\n",
       "      <td>0.249318</td>\n",
       "      <td>0.230472</td>\n",
       "      <td>1.081770</td>\n",
       "      <td>0.022324</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.766179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>28.014925</td>\n",
       "      <td>-0.003010</td>\n",
       "      <td>0.266907</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>-0.011222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.194417</td>\n",
       "      <td>0.071945</td>\n",
       "      <td>tensor(21.1927, device='cuda:0')</td>\n",
       "      <td>tensor(21.1927, device='cuda:0')</td>\n",
       "      <td>tensor(19.6680, device='cuda:0')</td>\n",
       "      <td>tensor(19.6680, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.493276</td>\n",
       "      <td>1.282483</td>\n",
       "      <td>0.384626</td>\n",
       "      <td>0.021726</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>0.383897</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.579381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>1.608467</td>\n",
       "      <td>1.686309</td>\n",
       "      <td>33.133335</td>\n",
       "      <td>-0.090782</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>1.599928</td>\n",
       "      <td>tensor(0.4933, device='cuda:0')</td>\n",
       "      <td>tensor(0.4933, device='cuda:0')</td>\n",
       "      <td>tensor(1.2825, device='cuda:0')</td>\n",
       "      <td>tensor(1.2825, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>12</td>\n",
       "      <td>model.layers.12.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>16.539137</td>\n",
       "      <td>40.300804</td>\n",
       "      <td>0.410392</td>\n",
       "      <td>0.401939</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>0.424202</td>\n",
       "      <td>0.128579</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.321853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878062</td>\n",
       "      <td>1.630441</td>\n",
       "      <td>1.754232</td>\n",
       "      <td>8.842424</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>1.446289</td>\n",
       "      <td>0.589704</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.613770</td>\n",
       "      <td>1.129150</td>\n",
       "      <td>1.292969</td>\n",
       "      <td>1.436693</td>\n",
       "      <td>tensor(16.5391, device='cuda:0')</td>\n",
       "      <td>tensor(16.5391, device='cuda:0')</td>\n",
       "      <td>tensor(40.3008, device='cuda:0')</td>\n",
       "      <td>tensor(40.3008, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878062</td>\n",
       "      <td>0.878062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.637804</td>\n",
       "      <td>4.383891</td>\n",
       "      <td>1.970351</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>1.968792</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>2.156290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.488571</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>-0.013793</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>0.492476</td>\n",
       "      <td>tensor(8.6378, device='cuda:0')</td>\n",
       "      <td>tensor(8.6378, device='cuda:0')</td>\n",
       "      <td>tensor(4.3839, device='cuda:0')</td>\n",
       "      <td>tensor(4.3839, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>60.936588</td>\n",
       "      <td>51.128990</td>\n",
       "      <td>1.191821</td>\n",
       "      <td>3.808472</td>\n",
       "      <td>3.195559</td>\n",
       "      <td>1.191802</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>4.891450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.161045</td>\n",
       "      <td>0.160905</td>\n",
       "      <td>0.173687</td>\n",
       "      <td>-0.077375</td>\n",
       "      <td>0.670324</td>\n",
       "      <td>0.612913</td>\n",
       "      <td>-0.026785</td>\n",
       "      <td>0.513128</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>0.615649</td>\n",
       "      <td>0.637124</td>\n",
       "      <td>0.648905</td>\n",
       "      <td>0.160947</td>\n",
       "      <td>tensor(60.9366, device='cuda:0')</td>\n",
       "      <td>tensor(60.9366, device='cuda:0')</td>\n",
       "      <td>tensor(51.1290, device='cuda:0')</td>\n",
       "      <td>tensor(51.1290, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.127401</td>\n",
       "      <td>20.101664</td>\n",
       "      <td>1.051028</td>\n",
       "      <td>0.248703</td>\n",
       "      <td>0.235769</td>\n",
       "      <td>1.054858</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>0.730448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989647</td>\n",
       "      <td>0.148516</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>32.947826</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.260788</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>-0.015994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.186685</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>tensor(21.1274, device='cuda:0')</td>\n",
       "      <td>tensor(21.1274, device='cuda:0')</td>\n",
       "      <td>tensor(20.1017, device='cuda:0')</td>\n",
       "      <td>tensor(20.1017, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989647</td>\n",
       "      <td>0.989647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.791774</td>\n",
       "      <td>1.809377</td>\n",
       "      <td>0.437595</td>\n",
       "      <td>0.034928</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.437437</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.488275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>1.291228</td>\n",
       "      <td>1.392268</td>\n",
       "      <td>52.439999</td>\n",
       "      <td>-0.029082</td>\n",
       "      <td>0.080017</td>\n",
       "      <td>0.045048</td>\n",
       "      <td>-0.056886</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>1.285219</td>\n",
       "      <td>tensor(0.7918, device='cuda:0')</td>\n",
       "      <td>tensor(0.7918, device='cuda:0')</td>\n",
       "      <td>tensor(1.8094, device='cuda:0')</td>\n",
       "      <td>tensor(1.8094, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>13</td>\n",
       "      <td>model.layers.13.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.933607</td>\n",
       "      <td>53.314022</td>\n",
       "      <td>0.430161</td>\n",
       "      <td>0.557188</td>\n",
       "      <td>1.237014</td>\n",
       "      <td>0.450430</td>\n",
       "      <td>0.178766</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.315864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>1.547568</td>\n",
       "      <td>1.756489</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>-0.027902</td>\n",
       "      <td>1.943359</td>\n",
       "      <td>0.780742</td>\n",
       "      <td>-0.032075</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>1.669580</td>\n",
       "      <td>1.324711</td>\n",
       "      <td>tensor(22.9336, device='cuda:0')</td>\n",
       "      <td>tensor(22.9336, device='cuda:0')</td>\n",
       "      <td>tensor(53.3140, device='cuda:0')</td>\n",
       "      <td>tensor(53.3140, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.447861</td>\n",
       "      <td>4.184812</td>\n",
       "      <td>1.779736</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>0.049242</td>\n",
       "      <td>1.777459</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>2.057549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>0.433584</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.038317</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.438119</td>\n",
       "      <td>tensor(7.4479, device='cuda:0')</td>\n",
       "      <td>tensor(7.4479, device='cuda:0')</td>\n",
       "      <td>tensor(4.1848, device='cuda:0')</td>\n",
       "      <td>tensor(4.1848, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.117859</td>\n",
       "      <td>50.622261</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>3.694763</td>\n",
       "      <td>3.163889</td>\n",
       "      <td>1.167792</td>\n",
       "      <td>0.027581</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>7.246110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.143878</td>\n",
       "      <td>0.143632</td>\n",
       "      <td>0.153526</td>\n",
       "      <td>-0.037131</td>\n",
       "      <td>0.573322</td>\n",
       "      <td>0.530874</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.441612</td>\n",
       "      <td>0.496697</td>\n",
       "      <td>0.537072</td>\n",
       "      <td>0.555897</td>\n",
       "      <td>0.569222</td>\n",
       "      <td>0.143706</td>\n",
       "      <td>tensor(59.1179, device='cuda:0')</td>\n",
       "      <td>tensor(59.1179, device='cuda:0')</td>\n",
       "      <td>tensor(50.6223, device='cuda:0')</td>\n",
       "      <td>tensor(50.6223, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.704342</td>\n",
       "      <td>20.226292</td>\n",
       "      <td>1.073076</td>\n",
       "      <td>0.255670</td>\n",
       "      <td>0.237395</td>\n",
       "      <td>1.076981</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.026780</td>\n",
       "      <td>0.701217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.146101</td>\n",
       "      <td>0.114674</td>\n",
       "      <td>47.490799</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.268997</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>-0.009827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>0.068099</td>\n",
       "      <td>tensor(21.7043, device='cuda:0')</td>\n",
       "      <td>tensor(21.7043, device='cuda:0')</td>\n",
       "      <td>tensor(20.2263, device='cuda:0')</td>\n",
       "      <td>tensor(20.2263, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.311881</td>\n",
       "      <td>2.227962</td>\n",
       "      <td>0.588826</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.098248</td>\n",
       "      <td>0.588375</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.683947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994724</td>\n",
       "      <td>0.711010</td>\n",
       "      <td>0.852622</td>\n",
       "      <td>52.106384</td>\n",
       "      <td>-0.030337</td>\n",
       "      <td>0.097137</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>-0.078225</td>\n",
       "      <td>0.029893</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>0.698295</td>\n",
       "      <td>tensor(1.3119, device='cuda:0')</td>\n",
       "      <td>tensor(1.3119, device='cuda:0')</td>\n",
       "      <td>tensor(2.2280, device='cuda:0')</td>\n",
       "      <td>tensor(2.2280, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994724</td>\n",
       "      <td>0.994724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>14</td>\n",
       "      <td>model.layers.14.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>28.781591</td>\n",
       "      <td>62.755371</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.704034</td>\n",
       "      <td>1.500387</td>\n",
       "      <td>0.469235</td>\n",
       "      <td>0.208918</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.373548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>1.361276</td>\n",
       "      <td>1.660806</td>\n",
       "      <td>12.402597</td>\n",
       "      <td>-0.037486</td>\n",
       "      <td>2.171875</td>\n",
       "      <td>0.898635</td>\n",
       "      <td>-0.035233</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.583984</td>\n",
       "      <td>1.846289</td>\n",
       "      <td>1.180400</td>\n",
       "      <td>tensor(28.7816, device='cuda:0')</td>\n",
       "      <td>tensor(28.7816, device='cuda:0')</td>\n",
       "      <td>tensor(62.7554, device='cuda:0')</td>\n",
       "      <td>tensor(62.7554, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>6.517498</td>\n",
       "      <td>3.358935</td>\n",
       "      <td>1.940346</td>\n",
       "      <td>0.076545</td>\n",
       "      <td>0.039542</td>\n",
       "      <td>1.935784</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>2.533557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.494089</td>\n",
       "      <td>0.478963</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>0.484628</td>\n",
       "      <td>tensor(6.5175, device='cuda:0')</td>\n",
       "      <td>tensor(6.5175, device='cuda:0')</td>\n",
       "      <td>tensor(3.3589, device='cuda:0')</td>\n",
       "      <td>tensor(3.3589, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>57.500515</td>\n",
       "      <td>50.311974</td>\n",
       "      <td>1.142879</td>\n",
       "      <td>3.593689</td>\n",
       "      <td>3.144496</td>\n",
       "      <td>1.142851</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>6.552856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.124949</td>\n",
       "      <td>0.134385</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>0.487145</td>\n",
       "      <td>0.449193</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.326014</td>\n",
       "      <td>0.402821</td>\n",
       "      <td>0.451695</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>0.481145</td>\n",
       "      <td>0.125017</td>\n",
       "      <td>tensor(57.5005, device='cuda:0')</td>\n",
       "      <td>tensor(57.5005, device='cuda:0')</td>\n",
       "      <td>tensor(50.3120, device='cuda:0')</td>\n",
       "      <td>tensor(50.3120, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.481438</td>\n",
       "      <td>20.713083</td>\n",
       "      <td>1.037095</td>\n",
       "      <td>0.253141</td>\n",
       "      <td>0.243359</td>\n",
       "      <td>1.040197</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.025106</td>\n",
       "      <td>0.685666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>87.480873</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>0.035768</td>\n",
       "      <td>tensor(21.4814, device='cuda:0')</td>\n",
       "      <td>tensor(21.4814, device='cuda:0')</td>\n",
       "      <td>tensor(20.7131, device='cuda:0')</td>\n",
       "      <td>tensor(20.7131, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.776436</td>\n",
       "      <td>3.292956</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.122195</td>\n",
       "      <td>0.145305</td>\n",
       "      <td>0.840955</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>1.380246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994207</td>\n",
       "      <td>0.219886</td>\n",
       "      <td>10.727682</td>\n",
       "      <td>5254.940918</td>\n",
       "      <td>-0.025096</td>\n",
       "      <td>0.148466</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.067779</td>\n",
       "      <td>0.186037</td>\n",
       "      <td>tensor(2.7764, device='cuda:0')</td>\n",
       "      <td>tensor(2.7764, device='cuda:0')</td>\n",
       "      <td>tensor(3.2930, device='cuda:0')</td>\n",
       "      <td>tensor(3.2930, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994208</td>\n",
       "      <td>0.994208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>15</td>\n",
       "      <td>model.layers.15.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.155495</td>\n",
       "      <td>73.755165</td>\n",
       "      <td>0.463093</td>\n",
       "      <td>0.837078</td>\n",
       "      <td>1.792213</td>\n",
       "      <td>0.467064</td>\n",
       "      <td>0.242495</td>\n",
       "      <td>0.574041</td>\n",
       "      <td>0.422434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>1.307852</td>\n",
       "      <td>1.871016</td>\n",
       "      <td>19.912281</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>2.329102</td>\n",
       "      <td>1.042509</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.036523</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>1.115234</td>\n",
       "      <td>1.775879</td>\n",
       "      <td>2.092383</td>\n",
       "      <td>1.159394</td>\n",
       "      <td>tensor(34.1555, device='cuda:0')</td>\n",
       "      <td>tensor(34.1555, device='cuda:0')</td>\n",
       "      <td>tensor(73.7552, device='cuda:0')</td>\n",
       "      <td>tensor(73.7552, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.493422</td>\n",
       "      <td>3.122280</td>\n",
       "      <td>2.399984</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>2.405991</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>1.878375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.590640</td>\n",
       "      <td>0.582067</td>\n",
       "      <td>0.862103</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>-0.005634</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>0.039795</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.583330</td>\n",
       "      <td>tensor(7.4934, device='cuda:0')</td>\n",
       "      <td>tensor(7.4934, device='cuda:0')</td>\n",
       "      <td>tensor(3.1223, device='cuda:0')</td>\n",
       "      <td>tensor(3.1223, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>63.492413</td>\n",
       "      <td>47.654469</td>\n",
       "      <td>1.332350</td>\n",
       "      <td>3.968140</td>\n",
       "      <td>2.978401</td>\n",
       "      <td>1.332306</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>7.457530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.249551</td>\n",
       "      <td>0.249369</td>\n",
       "      <td>0.257533</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>1.030133</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>0.862356</td>\n",
       "      <td>0.931333</td>\n",
       "      <td>0.996683</td>\n",
       "      <td>1.019134</td>\n",
       "      <td>1.023662</td>\n",
       "      <td>0.249446</td>\n",
       "      <td>tensor(63.4924, device='cuda:0')</td>\n",
       "      <td>tensor(63.4924, device='cuda:0')</td>\n",
       "      <td>tensor(47.6545, device='cuda:0')</td>\n",
       "      <td>tensor(47.6545, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.855965</td>\n",
       "      <td>21.130243</td>\n",
       "      <td>1.034345</td>\n",
       "      <td>0.257655</td>\n",
       "      <td>0.248375</td>\n",
       "      <td>1.037365</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.652296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>0.118595</td>\n",
       "      <td>0.081640</td>\n",
       "      <td>43.869564</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.266983</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>tensor(21.8560, device='cuda:0')</td>\n",
       "      <td>tensor(21.8560, device='cuda:0')</td>\n",
       "      <td>tensor(21.1302, device='cuda:0')</td>\n",
       "      <td>tensor(21.1302, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.641315</td>\n",
       "      <td>3.123290</td>\n",
       "      <td>0.525508</td>\n",
       "      <td>0.072362</td>\n",
       "      <td>0.137754</td>\n",
       "      <td>0.525302</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.574459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995508</td>\n",
       "      <td>0.912338</td>\n",
       "      <td>0.957306</td>\n",
       "      <td>23.373056</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.137665</td>\n",
       "      <td>0.065671</td>\n",
       "      <td>-0.049760</td>\n",
       "      <td>0.039819</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>tensor(1.6413, device='cuda:0')</td>\n",
       "      <td>tensor(1.6413, device='cuda:0')</td>\n",
       "      <td>tensor(3.1233, device='cuda:0')</td>\n",
       "      <td>tensor(3.1233, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995508</td>\n",
       "      <td>0.995508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>16</td>\n",
       "      <td>model.layers.16.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>31.587980</td>\n",
       "      <td>59.614555</td>\n",
       "      <td>0.529870</td>\n",
       "      <td>0.757899</td>\n",
       "      <td>1.457768</td>\n",
       "      <td>0.519904</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.434334</td>\n",
       "      <td>0.631367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903922</td>\n",
       "      <td>1.072320</td>\n",
       "      <td>1.502367</td>\n",
       "      <td>10.138122</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>1.860352</td>\n",
       "      <td>0.775614</td>\n",
       "      <td>0.026777</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>1.458008</td>\n",
       "      <td>1.629541</td>\n",
       "      <td>0.887254</td>\n",
       "      <td>tensor(31.5880, device='cuda:0')</td>\n",
       "      <td>tensor(31.5880, device='cuda:0')</td>\n",
       "      <td>tensor(59.6146, device='cuda:0')</td>\n",
       "      <td>tensor(59.6146, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903922</td>\n",
       "      <td>0.903922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.470176</td>\n",
       "      <td>2.893547</td>\n",
       "      <td>2.581667</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>2.589619</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>1.817235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.611855</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.053999</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.035076</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.072021</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>tensor(7.4702, device='cuda:0')</td>\n",
       "      <td>tensor(7.4702, device='cuda:0')</td>\n",
       "      <td>tensor(2.8935, device='cuda:0')</td>\n",
       "      <td>tensor(2.8935, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.110390</td>\n",
       "      <td>43.221100</td>\n",
       "      <td>1.483312</td>\n",
       "      <td>4.006653</td>\n",
       "      <td>2.701313</td>\n",
       "      <td>1.483224</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>8.092406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.325965</td>\n",
       "      <td>0.325706</td>\n",
       "      <td>0.337825</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>1.372413</td>\n",
       "      <td>1.305340</td>\n",
       "      <td>-0.025474</td>\n",
       "      <td>1.095804</td>\n",
       "      <td>1.236563</td>\n",
       "      <td>1.323164</td>\n",
       "      <td>1.338463</td>\n",
       "      <td>1.357954</td>\n",
       "      <td>0.325833</td>\n",
       "      <td>tensor(64.1104, device='cuda:0')</td>\n",
       "      <td>tensor(64.1104, device='cuda:0')</td>\n",
       "      <td>tensor(43.2211, device='cuda:0')</td>\n",
       "      <td>tensor(43.2211, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>21.914175</td>\n",
       "      <td>21.914501</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.258373</td>\n",
       "      <td>0.257723</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.644272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993903</td>\n",
       "      <td>0.110431</td>\n",
       "      <td>0.084935</td>\n",
       "      <td>88.872337</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.266068</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.161284</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>tensor(21.9142, device='cuda:0')</td>\n",
       "      <td>tensor(21.9142, device='cuda:0')</td>\n",
       "      <td>tensor(21.9145, device='cuda:0')</td>\n",
       "      <td>tensor(21.9145, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993903</td>\n",
       "      <td>0.993903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.020492</td>\n",
       "      <td>4.783579</td>\n",
       "      <td>0.422381</td>\n",
       "      <td>0.089113</td>\n",
       "      <td>0.210982</td>\n",
       "      <td>0.422375</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.423756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>1.374585</td>\n",
       "      <td>1.434541</td>\n",
       "      <td>30.716814</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>0.211853</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>-0.065574</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.122559</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>0.141548</td>\n",
       "      <td>1.367532</td>\n",
       "      <td>tensor(2.0205, device='cuda:0')</td>\n",
       "      <td>tensor(2.0205, device='cuda:0')</td>\n",
       "      <td>tensor(4.7836, device='cuda:0')</td>\n",
       "      <td>tensor(4.7836, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>17</td>\n",
       "      <td>model.layers.17.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.808437</td>\n",
       "      <td>71.422585</td>\n",
       "      <td>0.487359</td>\n",
       "      <td>0.841668</td>\n",
       "      <td>1.722112</td>\n",
       "      <td>0.488742</td>\n",
       "      <td>0.283576</td>\n",
       "      <td>0.596166</td>\n",
       "      <td>0.475666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>1.226518</td>\n",
       "      <td>1.678248</td>\n",
       "      <td>12.224490</td>\n",
       "      <td>0.072027</td>\n",
       "      <td>2.339844</td>\n",
       "      <td>0.991634</td>\n",
       "      <td>0.047350</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.771729</td>\n",
       "      <td>1.987158</td>\n",
       "      <td>1.051876</td>\n",
       "      <td>tensor(34.8084, device='cuda:0')</td>\n",
       "      <td>tensor(34.8084, device='cuda:0')</td>\n",
       "      <td>tensor(71.4226, device='cuda:0')</td>\n",
       "      <td>tensor(71.4226, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.183807</td>\n",
       "      <td>3.338204</td>\n",
       "      <td>2.451560</td>\n",
       "      <td>0.096202</td>\n",
       "      <td>0.039203</td>\n",
       "      <td>2.453969</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>2.233580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>0.599349</td>\n",
       "      <td>0.589859</td>\n",
       "      <td>0.857021</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>-0.023784</td>\n",
       "      <td>0.037517</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.069092</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.592096</td>\n",
       "      <td>tensor(8.1838, device='cuda:0')</td>\n",
       "      <td>tensor(8.1838, device='cuda:0')</td>\n",
       "      <td>tensor(3.3382, device='cuda:0')</td>\n",
       "      <td>tensor(3.3382, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>61.606770</td>\n",
       "      <td>41.250099</td>\n",
       "      <td>1.493494</td>\n",
       "      <td>3.850281</td>\n",
       "      <td>2.578124</td>\n",
       "      <td>1.493443</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>5.364066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.330511</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>0.339464</td>\n",
       "      <td>-0.022923</td>\n",
       "      <td>1.320729</td>\n",
       "      <td>1.272157</td>\n",
       "      <td>-0.058165</td>\n",
       "      <td>1.106757</td>\n",
       "      <td>1.217929</td>\n",
       "      <td>1.279280</td>\n",
       "      <td>1.304197</td>\n",
       "      <td>1.314295</td>\n",
       "      <td>0.330429</td>\n",
       "      <td>tensor(61.6068, device='cuda:0')</td>\n",
       "      <td>tensor(61.6068, device='cuda:0')</td>\n",
       "      <td>tensor(41.2501, device='cuda:0')</td>\n",
       "      <td>tensor(41.2501, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>22.301815</td>\n",
       "      <td>22.705572</td>\n",
       "      <td>0.982218</td>\n",
       "      <td>0.262995</td>\n",
       "      <td>0.267114</td>\n",
       "      <td>0.984580</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.621356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>0.108024</td>\n",
       "      <td>0.080463</td>\n",
       "      <td>60.730495</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.266006</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.156084</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>tensor(22.3018, device='cuda:0')</td>\n",
       "      <td>tensor(22.3018, device='cuda:0')</td>\n",
       "      <td>tensor(22.7056, device='cuda:0')</td>\n",
       "      <td>tensor(22.7056, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.790116</td>\n",
       "      <td>3.660754</td>\n",
       "      <td>0.489002</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.161438</td>\n",
       "      <td>0.488288</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.633824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>1.055969</td>\n",
       "      <td>9.782271</td>\n",
       "      <td>4412.109863</td>\n",
       "      <td>0.014655</td>\n",
       "      <td>0.163049</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>1.044981</td>\n",
       "      <td>tensor(1.7901, device='cuda:0')</td>\n",
       "      <td>tensor(1.7901, device='cuda:0')</td>\n",
       "      <td>tensor(3.6608, device='cuda:0')</td>\n",
       "      <td>tensor(3.6608, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>18</td>\n",
       "      <td>model.layers.18.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>22.928190</td>\n",
       "      <td>56.085789</td>\n",
       "      <td>0.408806</td>\n",
       "      <td>0.555045</td>\n",
       "      <td>1.375809</td>\n",
       "      <td>0.403432</td>\n",
       "      <td>0.184876</td>\n",
       "      <td>0.393799</td>\n",
       "      <td>0.469468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911530</td>\n",
       "      <td>1.588764</td>\n",
       "      <td>1.934185</td>\n",
       "      <td>8.409327</td>\n",
       "      <td>-0.006847</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.859472</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.497022</td>\n",
       "      <td>1.446150</td>\n",
       "      <td>tensor(22.9282, device='cuda:0')</td>\n",
       "      <td>tensor(22.9282, device='cuda:0')</td>\n",
       "      <td>tensor(56.0858, device='cuda:0')</td>\n",
       "      <td>tensor(56.0858, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911530</td>\n",
       "      <td>0.911530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.698030</td>\n",
       "      <td>3.559573</td>\n",
       "      <td>2.162627</td>\n",
       "      <td>0.090643</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>2.164872</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>1.872844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>0.543855</td>\n",
       "      <td>0.536279</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>-0.014924</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.048805</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.537599</td>\n",
       "      <td>tensor(7.6980, device='cuda:0')</td>\n",
       "      <td>tensor(7.6980, device='cuda:0')</td>\n",
       "      <td>tensor(3.5596, device='cuda:0')</td>\n",
       "      <td>tensor(3.5596, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.838367</td>\n",
       "      <td>42.235420</td>\n",
       "      <td>1.156337</td>\n",
       "      <td>3.052063</td>\n",
       "      <td>2.639706</td>\n",
       "      <td>1.156213</td>\n",
       "      <td>0.045226</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>7.089037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.135924</td>\n",
       "      <td>0.135136</td>\n",
       "      <td>0.157368</td>\n",
       "      <td>-0.021378</td>\n",
       "      <td>0.486856</td>\n",
       "      <td>0.412969</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>0.279165</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.420409</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>0.459749</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>tensor(48.8384, device='cuda:0')</td>\n",
       "      <td>tensor(48.8384, device='cuda:0')</td>\n",
       "      <td>tensor(42.2354, device='cuda:0')</td>\n",
       "      <td>tensor(42.2354, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>22.808533</td>\n",
       "      <td>24.000456</td>\n",
       "      <td>0.950337</td>\n",
       "      <td>0.269003</td>\n",
       "      <td>0.282359</td>\n",
       "      <td>0.952699</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.118641</td>\n",
       "      <td>0.105258</td>\n",
       "      <td>90.151512</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.272369</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>tensor(22.8085, device='cuda:0')</td>\n",
       "      <td>tensor(22.8085, device='cuda:0')</td>\n",
       "      <td>tensor(24.0005, device='cuda:0')</td>\n",
       "      <td>tensor(24.0005, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.007612</td>\n",
       "      <td>6.082238</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>0.268124</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.302330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>2.036408</td>\n",
       "      <td>2.119742</td>\n",
       "      <td>31.705883</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>0.179885</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>0.139214</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.235523</td>\n",
       "      <td>2.029589</td>\n",
       "      <td>tensor(2.0076, device='cuda:0')</td>\n",
       "      <td>tensor(2.0076, device='cuda:0')</td>\n",
       "      <td>tensor(6.0822, device='cuda:0')</td>\n",
       "      <td>tensor(6.0822, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>19</td>\n",
       "      <td>model.layers.19.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.754414</td>\n",
       "      <td>62.438587</td>\n",
       "      <td>0.572633</td>\n",
       "      <td>0.869946</td>\n",
       "      <td>1.537322</td>\n",
       "      <td>0.565884</td>\n",
       "      <td>0.274722</td>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.657131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>0.920567</td>\n",
       "      <td>1.348303</td>\n",
       "      <td>12.226666</td>\n",
       "      <td>-0.042092</td>\n",
       "      <td>1.803711</td>\n",
       "      <td>0.762092</td>\n",
       "      <td>-0.032200</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>1.430420</td>\n",
       "      <td>1.642481</td>\n",
       "      <td>0.746318</td>\n",
       "      <td>tensor(35.7544, device='cuda:0')</td>\n",
       "      <td>tensor(35.7544, device='cuda:0')</td>\n",
       "      <td>tensor(62.4386, device='cuda:0')</td>\n",
       "      <td>tensor(62.4386, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.941700</td>\n",
       "      <td>3.825140</td>\n",
       "      <td>2.337614</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.045020</td>\n",
       "      <td>2.338668</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>2.184911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993408</td>\n",
       "      <td>0.577120</td>\n",
       "      <td>0.570422</td>\n",
       "      <td>0.843960</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.245605</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.071533</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.572213</td>\n",
       "      <td>tensor(8.9417, device='cuda:0')</td>\n",
       "      <td>tensor(8.9417, device='cuda:0')</td>\n",
       "      <td>tensor(3.8251, device='cuda:0')</td>\n",
       "      <td>tensor(3.8251, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993408</td>\n",
       "      <td>0.993408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>51.349850</td>\n",
       "      <td>41.333645</td>\n",
       "      <td>1.242326</td>\n",
       "      <td>3.208984</td>\n",
       "      <td>2.583346</td>\n",
       "      <td>1.242181</td>\n",
       "      <td>0.049468</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>8.288301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.195568</td>\n",
       "      <td>0.194755</td>\n",
       "      <td>0.211148</td>\n",
       "      <td>-0.064095</td>\n",
       "      <td>0.689529</td>\n",
       "      <td>0.625638</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>0.424509</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.634255</td>\n",
       "      <td>0.669435</td>\n",
       "      <td>0.683344</td>\n",
       "      <td>0.195058</td>\n",
       "      <td>tensor(51.3498, device='cuda:0')</td>\n",
       "      <td>tensor(51.3498, device='cuda:0')</td>\n",
       "      <td>tensor(41.3336, device='cuda:0')</td>\n",
       "      <td>tensor(41.3336, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>23.311581</td>\n",
       "      <td>25.515226</td>\n",
       "      <td>0.913634</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.300217</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.026338</td>\n",
       "      <td>0.544243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.142140</td>\n",
       "      <td>0.135760</td>\n",
       "      <td>75.487808</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>tensor(23.3116, device='cuda:0')</td>\n",
       "      <td>tensor(23.3116, device='cuda:0')</td>\n",
       "      <td>tensor(25.5152, device='cuda:0')</td>\n",
       "      <td>tensor(25.5152, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>0.994853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.465116</td>\n",
       "      <td>6.631782</td>\n",
       "      <td>0.220923</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.292640</td>\n",
       "      <td>0.220905</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.226973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>3.530484</td>\n",
       "      <td>3.609409</td>\n",
       "      <td>44.886791</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>0.290405</td>\n",
       "      <td>0.228209</td>\n",
       "      <td>-0.057530</td>\n",
       "      <td>0.174678</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>3.526457</td>\n",
       "      <td>tensor(1.4651, device='cuda:0')</td>\n",
       "      <td>tensor(1.4651, device='cuda:0')</td>\n",
       "      <td>tensor(6.6318, device='cuda:0')</td>\n",
       "      <td>tensor(6.6318, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>20</td>\n",
       "      <td>model.layers.20.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>28.253962</td>\n",
       "      <td>73.820541</td>\n",
       "      <td>0.382738</td>\n",
       "      <td>0.678922</td>\n",
       "      <td>1.846360</td>\n",
       "      <td>0.367708</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>0.372544</td>\n",
       "      <td>0.650799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>1.734461</td>\n",
       "      <td>2.477821</td>\n",
       "      <td>15.124031</td>\n",
       "      <td>-0.016673</td>\n",
       "      <td>2.003906</td>\n",
       "      <td>1.197476</td>\n",
       "      <td>-0.025932</td>\n",
       "      <td>0.092773</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.779297</td>\n",
       "      <td>1.899707</td>\n",
       "      <td>1.612750</td>\n",
       "      <td>tensor(28.2540, device='cuda:0')</td>\n",
       "      <td>tensor(28.2540, device='cuda:0')</td>\n",
       "      <td>tensor(73.8205, device='cuda:0')</td>\n",
       "      <td>tensor(73.8205, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.068832</td>\n",
       "      <td>3.979035</td>\n",
       "      <td>2.027836</td>\n",
       "      <td>0.094841</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>2.023835</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>2.626806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992202</td>\n",
       "      <td>0.514395</td>\n",
       "      <td>0.502658</td>\n",
       "      <td>0.851724</td>\n",
       "      <td>-0.007349</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>-0.025707</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.506864</td>\n",
       "      <td>tensor(8.0688, device='cuda:0')</td>\n",
       "      <td>tensor(8.0688, device='cuda:0')</td>\n",
       "      <td>tensor(3.9790, device='cuda:0')</td>\n",
       "      <td>tensor(3.9790, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992202</td>\n",
       "      <td>0.992202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.062431</td>\n",
       "      <td>39.149841</td>\n",
       "      <td>1.253196</td>\n",
       "      <td>3.066101</td>\n",
       "      <td>2.446855</td>\n",
       "      <td>1.253078</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>6.122201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.202439</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>0.214921</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.668270</td>\n",
       "      <td>0.619246</td>\n",
       "      <td>0.080404</td>\n",
       "      <td>0.433062</td>\n",
       "      <td>0.543789</td>\n",
       "      <td>0.629020</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.662936</td>\n",
       "      <td>0.202040</td>\n",
       "      <td>tensor(49.0624, device='cuda:0')</td>\n",
       "      <td>tensor(49.0624, device='cuda:0')</td>\n",
       "      <td>tensor(39.1498, device='cuda:0')</td>\n",
       "      <td>tensor(39.1498, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>23.813595</td>\n",
       "      <td>26.737455</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.280909</td>\n",
       "      <td>0.314663</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.026851</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.155446</td>\n",
       "      <td>54.636364</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.293457</td>\n",
       "      <td>0.038960</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.153643</td>\n",
       "      <td>0.122781</td>\n",
       "      <td>tensor(23.8136, device='cuda:0')</td>\n",
       "      <td>tensor(23.8136, device='cuda:0')</td>\n",
       "      <td>tensor(26.7375, device='cuda:0')</td>\n",
       "      <td>tensor(26.7375, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.968177</td>\n",
       "      <td>8.135511</td>\n",
       "      <td>0.241924</td>\n",
       "      <td>0.086753</td>\n",
       "      <td>0.358591</td>\n",
       "      <td>0.241927</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.241362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>3.140450</td>\n",
       "      <td>3.317812</td>\n",
       "      <td>50.929825</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.354370</td>\n",
       "      <td>0.272445</td>\n",
       "      <td>-0.053811</td>\n",
       "      <td>0.212280</td>\n",
       "      <td>0.257104</td>\n",
       "      <td>0.273926</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>0.293838</td>\n",
       "      <td>3.133527</td>\n",
       "      <td>tensor(1.9682, device='cuda:0')</td>\n",
       "      <td>tensor(1.9682, device='cuda:0')</td>\n",
       "      <td>tensor(8.1355, device='cuda:0')</td>\n",
       "      <td>tensor(8.1355, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>21</td>\n",
       "      <td>model.layers.21.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>20.671974</td>\n",
       "      <td>69.679062</td>\n",
       "      <td>0.296674</td>\n",
       "      <td>0.504494</td>\n",
       "      <td>1.735003</td>\n",
       "      <td>0.290774</td>\n",
       "      <td>0.153935</td>\n",
       "      <td>0.388182</td>\n",
       "      <td>0.396555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933343</td>\n",
       "      <td>2.463653</td>\n",
       "      <td>2.931830</td>\n",
       "      <td>14.496063</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>1.884766</td>\n",
       "      <td>1.246964</td>\n",
       "      <td>-0.002507</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>0.274902</td>\n",
       "      <td>1.320312</td>\n",
       "      <td>1.662598</td>\n",
       "      <td>1.762647</td>\n",
       "      <td>2.370702</td>\n",
       "      <td>tensor(20.6720, device='cuda:0')</td>\n",
       "      <td>tensor(20.6720, device='cuda:0')</td>\n",
       "      <td>tensor(69.6791, device='cuda:0')</td>\n",
       "      <td>tensor(69.6791, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933343</td>\n",
       "      <td>0.933343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.130106</td>\n",
       "      <td>4.244864</td>\n",
       "      <td>1.915281</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>1.916806</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>1.724252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.486104</td>\n",
       "      <td>0.476649</td>\n",
       "      <td>0.833942</td>\n",
       "      <td>-0.005453</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.045858</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>0.055908</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.477883</td>\n",
       "      <td>tensor(8.1301, device='cuda:0')</td>\n",
       "      <td>tensor(8.1301, device='cuda:0')</td>\n",
       "      <td>tensor(4.2449, device='cuda:0')</td>\n",
       "      <td>tensor(4.2449, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>45.628685</td>\n",
       "      <td>45.220245</td>\n",
       "      <td>1.009032</td>\n",
       "      <td>2.851501</td>\n",
       "      <td>2.826259</td>\n",
       "      <td>1.008931</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>6.639153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.028532</td>\n",
       "      <td>0.187452</td>\n",
       "      <td>0.040812</td>\n",
       "      <td>0.076558</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.081703</td>\n",
       "      <td>0.142737</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>tensor(45.6287, device='cuda:0')</td>\n",
       "      <td>tensor(45.6287, device='cuda:0')</td>\n",
       "      <td>tensor(45.2202, device='cuda:0')</td>\n",
       "      <td>tensor(45.2202, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>24.354338</td>\n",
       "      <td>27.943714</td>\n",
       "      <td>0.871550</td>\n",
       "      <td>0.287277</td>\n",
       "      <td>0.328794</td>\n",
       "      <td>0.873730</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.514052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>0.182811</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>84.157028</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.311035</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.155918</td>\n",
       "      <td>0.147381</td>\n",
       "      <td>tensor(24.3543, device='cuda:0')</td>\n",
       "      <td>tensor(24.3543, device='cuda:0')</td>\n",
       "      <td>tensor(27.9437, device='cuda:0')</td>\n",
       "      <td>tensor(27.9437, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.095639</td>\n",
       "      <td>6.838748</td>\n",
       "      <td>0.306436</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.301488</td>\n",
       "      <td>0.306796</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>0.221986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>2.268730</td>\n",
       "      <td>2.301948</td>\n",
       "      <td>23.118227</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.314453</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.144580</td>\n",
       "      <td>0.195361</td>\n",
       "      <td>0.209229</td>\n",
       "      <td>0.228247</td>\n",
       "      <td>0.241592</td>\n",
       "      <td>2.263324</td>\n",
       "      <td>tensor(2.0956, device='cuda:0')</td>\n",
       "      <td>tensor(2.0956, device='cuda:0')</td>\n",
       "      <td>tensor(6.8387, device='cuda:0')</td>\n",
       "      <td>tensor(6.8387, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>22</td>\n",
       "      <td>model.layers.22.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>30.609915</td>\n",
       "      <td>63.275879</td>\n",
       "      <td>0.483753</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>1.583948</td>\n",
       "      <td>0.467217</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.312690</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929085</td>\n",
       "      <td>1.196678</td>\n",
       "      <td>1.743547</td>\n",
       "      <td>10.973154</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.876101</td>\n",
       "      <td>-0.007202</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.299805</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.470703</td>\n",
       "      <td>1.602832</td>\n",
       "      <td>1.067170</td>\n",
       "      <td>tensor(30.6099, device='cuda:0')</td>\n",
       "      <td>tensor(30.6099, device='cuda:0')</td>\n",
       "      <td>tensor(63.2759, device='cuda:0')</td>\n",
       "      <td>tensor(63.2759, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929085</td>\n",
       "      <td>0.929085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.086284</td>\n",
       "      <td>4.431251</td>\n",
       "      <td>1.599161</td>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>1.599199</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>1.593569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>0.385940</td>\n",
       "      <td>0.372567</td>\n",
       "      <td>0.801948</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>-0.005840</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.041260</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.374672</td>\n",
       "      <td>tensor(7.0863, device='cuda:0')</td>\n",
       "      <td>tensor(7.0863, device='cuda:0')</td>\n",
       "      <td>tensor(4.4313, device='cuda:0')</td>\n",
       "      <td>tensor(4.4313, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993148</td>\n",
       "      <td>0.993148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.856133</td>\n",
       "      <td>45.227196</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>3.053284</td>\n",
       "      <td>2.826689</td>\n",
       "      <td>1.080163</td>\n",
       "      <td>0.037031</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>4.804199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.226649</td>\n",
       "      <td>0.066821</td>\n",
       "      <td>0.072231</td>\n",
       "      <td>0.160291</td>\n",
       "      <td>0.233623</td>\n",
       "      <td>0.266916</td>\n",
       "      <td>0.272682</td>\n",
       "      <td>0.074278</td>\n",
       "      <td>tensor(48.8561, device='cuda:0')</td>\n",
       "      <td>tensor(48.8561, device='cuda:0')</td>\n",
       "      <td>tensor(45.2272, device='cuda:0')</td>\n",
       "      <td>tensor(45.2272, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>24.984646</td>\n",
       "      <td>29.704109</td>\n",
       "      <td>0.841118</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.349499</td>\n",
       "      <td>0.843272</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.487557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>0.218581</td>\n",
       "      <td>0.218047</td>\n",
       "      <td>55.412373</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.328064</td>\n",
       "      <td>0.059284</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.188895</td>\n",
       "      <td>tensor(24.9846, device='cuda:0')</td>\n",
       "      <td>tensor(24.9846, device='cuda:0')</td>\n",
       "      <td>tensor(29.7041, device='cuda:0')</td>\n",
       "      <td>tensor(29.7041, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.102937</td>\n",
       "      <td>8.542912</td>\n",
       "      <td>0.363218</td>\n",
       "      <td>0.136737</td>\n",
       "      <td>0.376948</td>\n",
       "      <td>0.362748</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.489043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995580</td>\n",
       "      <td>1.760096</td>\n",
       "      <td>1.922224</td>\n",
       "      <td>55.558140</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.364532</td>\n",
       "      <td>0.240680</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.156885</td>\n",
       "      <td>0.225146</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.254614</td>\n",
       "      <td>0.277622</td>\n",
       "      <td>1.753169</td>\n",
       "      <td>tensor(3.1029, device='cuda:0')</td>\n",
       "      <td>tensor(3.1029, device='cuda:0')</td>\n",
       "      <td>tensor(8.5429, device='cuda:0')</td>\n",
       "      <td>tensor(8.5429, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995580</td>\n",
       "      <td>0.995580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>23</td>\n",
       "      <td>model.layers.23.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.525059</td>\n",
       "      <td>69.673721</td>\n",
       "      <td>0.509877</td>\n",
       "      <td>0.861521</td>\n",
       "      <td>1.762080</td>\n",
       "      <td>0.488923</td>\n",
       "      <td>0.281808</td>\n",
       "      <td>0.235603</td>\n",
       "      <td>1.196113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942352</td>\n",
       "      <td>1.072445</td>\n",
       "      <td>1.597363</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>1.742188</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.145898</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.574463</td>\n",
       "      <td>1.685205</td>\n",
       "      <td>0.961255</td>\n",
       "      <td>tensor(35.5251, device='cuda:0')</td>\n",
       "      <td>tensor(35.5251, device='cuda:0')</td>\n",
       "      <td>tensor(69.6737, device='cuda:0')</td>\n",
       "      <td>tensor(69.6737, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942351</td>\n",
       "      <td>0.942351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.211089</td>\n",
       "      <td>4.750062</td>\n",
       "      <td>1.518104</td>\n",
       "      <td>0.084953</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>1.518587</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>1.432913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994543</td>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.339445</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.029088</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.045491</td>\n",
       "      <td>0.341284</td>\n",
       "      <td>tensor(7.2111, device='cuda:0')</td>\n",
       "      <td>tensor(7.2111, device='cuda:0')</td>\n",
       "      <td>tensor(4.7501, device='cuda:0')</td>\n",
       "      <td>tensor(4.7501, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994543</td>\n",
       "      <td>0.994543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.167828</td>\n",
       "      <td>45.486034</td>\n",
       "      <td>1.102928</td>\n",
       "      <td>3.135132</td>\n",
       "      <td>2.842865</td>\n",
       "      <td>1.102807</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>5.814858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.094523</td>\n",
       "      <td>0.093153</td>\n",
       "      <td>0.114329</td>\n",
       "      <td>-0.144866</td>\n",
       "      <td>0.364422</td>\n",
       "      <td>0.292698</td>\n",
       "      <td>-0.082924</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.212374</td>\n",
       "      <td>0.305274</td>\n",
       "      <td>0.336874</td>\n",
       "      <td>0.345619</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>tensor(50.1678, device='cuda:0')</td>\n",
       "      <td>tensor(50.1678, device='cuda:0')</td>\n",
       "      <td>tensor(45.4860, device='cuda:0')</td>\n",
       "      <td>tensor(45.4860, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>25.530970</td>\n",
       "      <td>31.090153</td>\n",
       "      <td>0.821191</td>\n",
       "      <td>0.301155</td>\n",
       "      <td>0.365806</td>\n",
       "      <td>0.823263</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.248719</td>\n",
       "      <td>72.025642</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.342896</td>\n",
       "      <td>0.068901</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.165030</td>\n",
       "      <td>0.217743</td>\n",
       "      <td>tensor(25.5310, device='cuda:0')</td>\n",
       "      <td>tensor(25.5310, device='cuda:0')</td>\n",
       "      <td>tensor(31.0902, device='cuda:0')</td>\n",
       "      <td>tensor(31.0902, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.719140</td>\n",
       "      <td>9.508757</td>\n",
       "      <td>0.496294</td>\n",
       "      <td>0.207878</td>\n",
       "      <td>0.419451</td>\n",
       "      <td>0.495595</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>0.657540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994767</td>\n",
       "      <td>1.025271</td>\n",
       "      <td>1.128071</td>\n",
       "      <td>30.849766</td>\n",
       "      <td>-0.023467</td>\n",
       "      <td>0.402832</td>\n",
       "      <td>0.212310</td>\n",
       "      <td>-0.032187</td>\n",
       "      <td>0.130205</td>\n",
       "      <td>0.185107</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>0.231885</td>\n",
       "      <td>0.258467</td>\n",
       "      <td>1.014934</td>\n",
       "      <td>tensor(4.7191, device='cuda:0')</td>\n",
       "      <td>tensor(4.7191, device='cuda:0')</td>\n",
       "      <td>tensor(9.5088, device='cuda:0')</td>\n",
       "      <td>tensor(9.5088, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994767</td>\n",
       "      <td>0.994767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>24</td>\n",
       "      <td>model.layers.24.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.125446</td>\n",
       "      <td>82.335564</td>\n",
       "      <td>0.548068</td>\n",
       "      <td>1.115506</td>\n",
       "      <td>2.081787</td>\n",
       "      <td>0.535840</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>0.282257</td>\n",
       "      <td>1.010603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960780</td>\n",
       "      <td>0.907235</td>\n",
       "      <td>1.379985</td>\n",
       "      <td>16.192158</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>2.121094</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.112631</td>\n",
       "      <td>0.190234</td>\n",
       "      <td>0.646484</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>1.742676</td>\n",
       "      <td>1.999658</td>\n",
       "      <td>0.824593</td>\n",
       "      <td>tensor(45.1254, device='cuda:0')</td>\n",
       "      <td>tensor(45.1254, device='cuda:0')</td>\n",
       "      <td>tensor(82.3356, device='cuda:0')</td>\n",
       "      <td>tensor(82.3356, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960780</td>\n",
       "      <td>0.960780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.457499</td>\n",
       "      <td>4.945893</td>\n",
       "      <td>1.507816</td>\n",
       "      <td>0.087829</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>1.507902</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>1.493226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.348096</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>0.029705</td>\n",
       "      <td>-0.007906</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>0.336789</td>\n",
       "      <td>tensor(7.4575, device='cuda:0')</td>\n",
       "      <td>tensor(7.4575, device='cuda:0')</td>\n",
       "      <td>tensor(4.9459, device='cuda:0')</td>\n",
       "      <td>tensor(4.9459, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>48.447563</td>\n",
       "      <td>45.497261</td>\n",
       "      <td>1.064846</td>\n",
       "      <td>3.027405</td>\n",
       "      <td>2.843565</td>\n",
       "      <td>1.064651</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>6.738204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.063837</td>\n",
       "      <td>0.062355</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>-0.050876</td>\n",
       "      <td>0.351076</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>0.118424</td>\n",
       "      <td>0.195586</td>\n",
       "      <td>0.234049</td>\n",
       "      <td>0.252879</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>tensor(48.4476, device='cuda:0')</td>\n",
       "      <td>tensor(48.4476, device='cuda:0')</td>\n",
       "      <td>tensor(45.4973, device='cuda:0')</td>\n",
       "      <td>tensor(45.4973, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>25.881824</td>\n",
       "      <td>32.060814</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.305291</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>0.809255</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.480492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994920</td>\n",
       "      <td>0.263784</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>103.675552</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.355942</td>\n",
       "      <td>0.075931</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.162432</td>\n",
       "      <td>0.238739</td>\n",
       "      <td>tensor(25.8818, device='cuda:0')</td>\n",
       "      <td>tensor(25.8818, device='cuda:0')</td>\n",
       "      <td>tensor(32.0608, device='cuda:0')</td>\n",
       "      <td>tensor(32.0608, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994920</td>\n",
       "      <td>0.994920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.022617</td>\n",
       "      <td>9.215854</td>\n",
       "      <td>0.436489</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>0.436201</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.502537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>1.299328</td>\n",
       "      <td>1.383906</td>\n",
       "      <td>28.321587</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>0.392395</td>\n",
       "      <td>0.230217</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.189561</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>0.264658</td>\n",
       "      <td>1.291010</td>\n",
       "      <td>tensor(4.0226, device='cuda:0')</td>\n",
       "      <td>tensor(4.0226, device='cuda:0')</td>\n",
       "      <td>tensor(9.2159, device='cuda:0')</td>\n",
       "      <td>tensor(9.2159, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>25</td>\n",
       "      <td>model.layers.25.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.342270</td>\n",
       "      <td>76.011490</td>\n",
       "      <td>0.543895</td>\n",
       "      <td>1.010875</td>\n",
       "      <td>1.930578</td>\n",
       "      <td>0.523613</td>\n",
       "      <td>0.301465</td>\n",
       "      <td>0.185537</td>\n",
       "      <td>1.624824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954527</td>\n",
       "      <td>0.932976</td>\n",
       "      <td>1.540862</td>\n",
       "      <td>14.085714</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>1.925781</td>\n",
       "      <td>0.929804</td>\n",
       "      <td>-0.013090</td>\n",
       "      <td>0.191602</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.722168</td>\n",
       "      <td>1.834961</td>\n",
       "      <td>0.838590</td>\n",
       "      <td>tensor(41.3423, device='cuda:0')</td>\n",
       "      <td>tensor(41.3423, device='cuda:0')</td>\n",
       "      <td>tensor(76.0115, device='cuda:0')</td>\n",
       "      <td>tensor(76.0115, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954527</td>\n",
       "      <td>0.954527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.811490</td>\n",
       "      <td>5.258142</td>\n",
       "      <td>1.485599</td>\n",
       "      <td>0.092014</td>\n",
       "      <td>0.061970</td>\n",
       "      <td>1.484815</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>1.654349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>0.336839</td>\n",
       "      <td>0.324669</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>-0.003871</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.047444</td>\n",
       "      <td>0.326871</td>\n",
       "      <td>tensor(7.8115, device='cuda:0')</td>\n",
       "      <td>tensor(7.8115, device='cuda:0')</td>\n",
       "      <td>tensor(5.2581, device='cuda:0')</td>\n",
       "      <td>tensor(5.2581, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>46.034271</td>\n",
       "      <td>46.470119</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>2.876648</td>\n",
       "      <td>2.904363</td>\n",
       "      <td>0.990457</td>\n",
       "      <td>0.053311</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>5.029110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.104713</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.274872</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.084456</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>0.116866</td>\n",
       "      <td>0.266807</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>tensor(46.0343, device='cuda:0')</td>\n",
       "      <td>tensor(46.0343, device='cuda:0')</td>\n",
       "      <td>tensor(46.4701, device='cuda:0')</td>\n",
       "      <td>tensor(46.4701, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>26.623869</td>\n",
       "      <td>33.157757</td>\n",
       "      <td>0.802945</td>\n",
       "      <td>0.314048</td>\n",
       "      <td>0.390296</td>\n",
       "      <td>0.804640</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>0.268240</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>75.800003</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.079964</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.245415</td>\n",
       "      <td>tensor(26.6239, device='cuda:0')</td>\n",
       "      <td>tensor(26.6239, device='cuda:0')</td>\n",
       "      <td>tensor(33.1578, device='cuda:0')</td>\n",
       "      <td>tensor(33.1578, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.604096</td>\n",
       "      <td>11.638908</td>\n",
       "      <td>0.395578</td>\n",
       "      <td>0.202725</td>\n",
       "      <td>0.513562</td>\n",
       "      <td>0.394743</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.604701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>1.536790</td>\n",
       "      <td>1.627915</td>\n",
       "      <td>31.738462</td>\n",
       "      <td>-0.022831</td>\n",
       "      <td>0.503662</td>\n",
       "      <td>0.311572</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.242070</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.311523</td>\n",
       "      <td>0.338330</td>\n",
       "      <td>0.399863</td>\n",
       "      <td>1.527947</td>\n",
       "      <td>tensor(4.6041, device='cuda:0')</td>\n",
       "      <td>tensor(4.6041, device='cuda:0')</td>\n",
       "      <td>tensor(11.6389, device='cuda:0')</td>\n",
       "      <td>tensor(11.6389, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26</td>\n",
       "      <td>model.layers.26.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>39.589603</td>\n",
       "      <td>78.118546</td>\n",
       "      <td>0.506789</td>\n",
       "      <td>0.964149</td>\n",
       "      <td>1.983653</td>\n",
       "      <td>0.486047</td>\n",
       "      <td>0.301361</td>\n",
       "      <td>0.195206</td>\n",
       "      <td>1.543809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>1.068205</td>\n",
       "      <td>1.848875</td>\n",
       "      <td>15.578313</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>2.005859</td>\n",
       "      <td>1.029910</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.308691</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>1.829102</td>\n",
       "      <td>1.911426</td>\n",
       "      <td>0.973209</td>\n",
       "      <td>tensor(39.5896, device='cuda:0')</td>\n",
       "      <td>tensor(39.5896, device='cuda:0')</td>\n",
       "      <td>tensor(78.1185, device='cuda:0')</td>\n",
       "      <td>tensor(78.1185, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.708518</td>\n",
       "      <td>5.781740</td>\n",
       "      <td>1.333252</td>\n",
       "      <td>0.090699</td>\n",
       "      <td>0.068131</td>\n",
       "      <td>1.331242</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>1.709746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993821</td>\n",
       "      <td>0.267856</td>\n",
       "      <td>0.246468</td>\n",
       "      <td>0.789384</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>0.225098</td>\n",
       "      <td>0.022701</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.249954</td>\n",
       "      <td>tensor(7.7085, device='cuda:0')</td>\n",
       "      <td>tensor(7.7085, device='cuda:0')</td>\n",
       "      <td>tensor(5.7817, device='cuda:0')</td>\n",
       "      <td>tensor(5.7817, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993821</td>\n",
       "      <td>0.993821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.155056</td>\n",
       "      <td>47.134258</td>\n",
       "      <td>1.064089</td>\n",
       "      <td>3.134216</td>\n",
       "      <td>2.945873</td>\n",
       "      <td>1.063935</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>5.212838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.060893</td>\n",
       "      <td>0.098108</td>\n",
       "      <td>-0.065842</td>\n",
       "      <td>0.314252</td>\n",
       "      <td>0.191410</td>\n",
       "      <td>0.019813</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.107832</td>\n",
       "      <td>0.199382</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>0.260811</td>\n",
       "      <td>0.060229</td>\n",
       "      <td>tensor(50.1551, device='cuda:0')</td>\n",
       "      <td>tensor(50.1551, device='cuda:0')</td>\n",
       "      <td>tensor(47.1343, device='cuda:0')</td>\n",
       "      <td>tensor(47.1343, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.110918</td>\n",
       "      <td>34.026569</td>\n",
       "      <td>0.796757</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.400636</td>\n",
       "      <td>0.798119</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>0.540078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.276547</td>\n",
       "      <td>0.287534</td>\n",
       "      <td>101.193550</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.382935</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>0.166006</td>\n",
       "      <td>0.255088</td>\n",
       "      <td>tensor(27.1109, device='cuda:0')</td>\n",
       "      <td>tensor(27.1109, device='cuda:0')</td>\n",
       "      <td>tensor(34.0266, device='cuda:0')</td>\n",
       "      <td>tensor(34.0266, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.696667</td>\n",
       "      <td>12.212162</td>\n",
       "      <td>0.302704</td>\n",
       "      <td>0.163052</td>\n",
       "      <td>0.538561</td>\n",
       "      <td>0.302754</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.035146</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>2.309118</td>\n",
       "      <td>2.351690</td>\n",
       "      <td>16.982302</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>0.498779</td>\n",
       "      <td>0.376303</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.302285</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.396484</td>\n",
       "      <td>0.410703</td>\n",
       "      <td>2.303561</td>\n",
       "      <td>tensor(3.6967, device='cuda:0')</td>\n",
       "      <td>tensor(3.6967, device='cuda:0')</td>\n",
       "      <td>tensor(12.2122, device='cuda:0')</td>\n",
       "      <td>tensor(12.2122, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>27</td>\n",
       "      <td>model.layers.27.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.217964</td>\n",
       "      <td>79.873123</td>\n",
       "      <td>0.440924</td>\n",
       "      <td>0.859638</td>\n",
       "      <td>2.026072</td>\n",
       "      <td>0.424288</td>\n",
       "      <td>0.261751</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>1.188613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>1.351828</td>\n",
       "      <td>1.987786</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>2.018555</td>\n",
       "      <td>1.176172</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>0.259570</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.829346</td>\n",
       "      <td>1.941699</td>\n",
       "      <td>1.267965</td>\n",
       "      <td>tensor(35.2180, device='cuda:0')</td>\n",
       "      <td>tensor(35.2180, device='cuda:0')</td>\n",
       "      <td>tensor(79.8731, device='cuda:0')</td>\n",
       "      <td>tensor(79.8731, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.035164</td>\n",
       "      <td>5.331933</td>\n",
       "      <td>1.506989</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>1.507417</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>1.428983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994672</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.335391</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>-0.003691</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>0.336425</td>\n",
       "      <td>tensor(8.0352, device='cuda:0')</td>\n",
       "      <td>tensor(8.0352, device='cuda:0')</td>\n",
       "      <td>tensor(5.3319, device='cuda:0')</td>\n",
       "      <td>tensor(5.3319, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>46.787014</td>\n",
       "      <td>50.976673</td>\n",
       "      <td>0.917812</td>\n",
       "      <td>2.923767</td>\n",
       "      <td>3.186023</td>\n",
       "      <td>0.917685</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>4.540858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.091389</td>\n",
       "      <td>0.090030</td>\n",
       "      <td>0.221308</td>\n",
       "      <td>-0.050658</td>\n",
       "      <td>0.577477</td>\n",
       "      <td>0.262256</td>\n",
       "      <td>-0.018378</td>\n",
       "      <td>0.182492</td>\n",
       "      <td>0.201896</td>\n",
       "      <td>0.252864</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.421226</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>tensor(46.7870, device='cuda:0')</td>\n",
       "      <td>tensor(46.7870, device='cuda:0')</td>\n",
       "      <td>tensor(50.9767, device='cuda:0')</td>\n",
       "      <td>tensor(50.9767, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.555099</td>\n",
       "      <td>34.934570</td>\n",
       "      <td>0.788763</td>\n",
       "      <td>0.324967</td>\n",
       "      <td>0.411490</td>\n",
       "      <td>0.789734</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.587316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.295049</td>\n",
       "      <td>68.818184</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.392731</td>\n",
       "      <td>0.089569</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.267808</td>\n",
       "      <td>tensor(27.5551, device='cuda:0')</td>\n",
       "      <td>tensor(27.5551, device='cuda:0')</td>\n",
       "      <td>tensor(34.9346, device='cuda:0')</td>\n",
       "      <td>tensor(34.9346, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.269969</td>\n",
       "      <td>14.672475</td>\n",
       "      <td>0.427329</td>\n",
       "      <td>0.275982</td>\n",
       "      <td>0.647391</td>\n",
       "      <td>0.426299</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.673809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>1.350135</td>\n",
       "      <td>1.509979</td>\n",
       "      <td>59.300579</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>0.626160</td>\n",
       "      <td>0.372419</td>\n",
       "      <td>-0.031893</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.513584</td>\n",
       "      <td>1.340119</td>\n",
       "      <td>tensor(6.2700, device='cuda:0')</td>\n",
       "      <td>tensor(6.2700, device='cuda:0')</td>\n",
       "      <td>tensor(14.6725, device='cuda:0')</td>\n",
       "      <td>tensor(14.6725, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>28</td>\n",
       "      <td>model.layers.28.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.063992</td>\n",
       "      <td>70.867645</td>\n",
       "      <td>0.635890</td>\n",
       "      <td>1.096289</td>\n",
       "      <td>1.792945</td>\n",
       "      <td>0.611446</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.234576</td>\n",
       "      <td>1.478360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.709712</td>\n",
       "      <td>1.434338</td>\n",
       "      <td>15.347826</td>\n",
       "      <td>-0.032695</td>\n",
       "      <td>1.844727</td>\n",
       "      <td>0.731556</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>1.651367</td>\n",
       "      <td>1.756787</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>tensor(45.0640, device='cuda:0')</td>\n",
       "      <td>tensor(45.0640, device='cuda:0')</td>\n",
       "      <td>tensor(70.8676, device='cuda:0')</td>\n",
       "      <td>tensor(70.8676, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.911266</td>\n",
       "      <td>5.675344</td>\n",
       "      <td>1.393971</td>\n",
       "      <td>0.093238</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>1.393914</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>1.407177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.293495</td>\n",
       "      <td>0.282055</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.026530</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>0.282625</td>\n",
       "      <td>tensor(7.9113, device='cuda:0')</td>\n",
       "      <td>tensor(7.9113, device='cuda:0')</td>\n",
       "      <td>tensor(5.6753, device='cuda:0')</td>\n",
       "      <td>tensor(5.6753, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.651878</td>\n",
       "      <td>48.342358</td>\n",
       "      <td>1.027089</td>\n",
       "      <td>3.102722</td>\n",
       "      <td>3.021368</td>\n",
       "      <td>1.026926</td>\n",
       "      <td>0.056814</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>4.282165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.276863</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.142773</td>\n",
       "      <td>0.182142</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>tensor(49.6519, device='cuda:0')</td>\n",
       "      <td>tensor(49.6519, device='cuda:0')</td>\n",
       "      <td>tensor(48.3424, device='cuda:0')</td>\n",
       "      <td>tensor(48.3424, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>27.815681</td>\n",
       "      <td>35.910515</td>\n",
       "      <td>0.774583</td>\n",
       "      <td>0.328044</td>\n",
       "      <td>0.423096</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.604075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.308088</td>\n",
       "      <td>0.321079</td>\n",
       "      <td>89.026665</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.407532</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.172197</td>\n",
       "      <td>0.291017</td>\n",
       "      <td>tensor(27.8157, device='cuda:0')</td>\n",
       "      <td>tensor(27.8157, device='cuda:0')</td>\n",
       "      <td>tensor(35.9105, device='cuda:0')</td>\n",
       "      <td>tensor(35.9105, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5.917262</td>\n",
       "      <td>15.048488</td>\n",
       "      <td>0.393213</td>\n",
       "      <td>0.260768</td>\n",
       "      <td>0.664242</td>\n",
       "      <td>0.392581</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.597711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>1.549931</td>\n",
       "      <td>1.716602</td>\n",
       "      <td>53.303032</td>\n",
       "      <td>-0.019552</td>\n",
       "      <td>0.646118</td>\n",
       "      <td>0.404404</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>0.403809</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.468115</td>\n",
       "      <td>1.543150</td>\n",
       "      <td>tensor(5.9173, device='cuda:0')</td>\n",
       "      <td>tensor(5.9173, device='cuda:0')</td>\n",
       "      <td>tensor(15.0485, device='cuda:0')</td>\n",
       "      <td>tensor(15.0485, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>29</td>\n",
       "      <td>model.layers.29.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>48.664703</td>\n",
       "      <td>70.438400</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>1.224239</td>\n",
       "      <td>1.787476</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>0.207536</td>\n",
       "      <td>0.187394</td>\n",
       "      <td>1.107484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980962</td>\n",
       "      <td>0.505271</td>\n",
       "      <td>0.653128</td>\n",
       "      <td>15.265560</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>1.796387</td>\n",
       "      <td>0.585976</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.166797</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>1.019531</td>\n",
       "      <td>1.628174</td>\n",
       "      <td>0.447423</td>\n",
       "      <td>tensor(48.6647, device='cuda:0')</td>\n",
       "      <td>tensor(48.6647, device='cuda:0')</td>\n",
       "      <td>tensor(70.4384, device='cuda:0')</td>\n",
       "      <td>tensor(70.4384, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980962</td>\n",
       "      <td>0.980962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.062296</td>\n",
       "      <td>5.988408</td>\n",
       "      <td>1.346317</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>0.070541</td>\n",
       "      <td>1.345101</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>1.554713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>0.274706</td>\n",
       "      <td>0.255667</td>\n",
       "      <td>1.021390</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>tensor(8.0623, device='cuda:0')</td>\n",
       "      <td>tensor(8.0623, device='cuda:0')</td>\n",
       "      <td>tensor(5.9884, device='cuda:0')</td>\n",
       "      <td>tensor(5.9884, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>56.364899</td>\n",
       "      <td>50.260181</td>\n",
       "      <td>1.121462</td>\n",
       "      <td>3.522339</td>\n",
       "      <td>3.141231</td>\n",
       "      <td>1.121325</td>\n",
       "      <td>0.057383</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>4.124401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.109506</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>0.132267</td>\n",
       "      <td>-0.054424</td>\n",
       "      <td>0.475520</td>\n",
       "      <td>0.381108</td>\n",
       "      <td>-0.061330</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>0.269465</td>\n",
       "      <td>0.394895</td>\n",
       "      <td>0.445713</td>\n",
       "      <td>0.466214</td>\n",
       "      <td>0.108307</td>\n",
       "      <td>tensor(56.3649, device='cuda:0')</td>\n",
       "      <td>tensor(56.3649, device='cuda:0')</td>\n",
       "      <td>tensor(50.2602, device='cuda:0')</td>\n",
       "      <td>tensor(50.2602, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>28.271057</td>\n",
       "      <td>36.425423</td>\n",
       "      <td>0.776135</td>\n",
       "      <td>0.333436</td>\n",
       "      <td>0.429238</td>\n",
       "      <td>0.776811</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>0.614034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>0.304641</td>\n",
       "      <td>0.316340</td>\n",
       "      <td>83.809814</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.416901</td>\n",
       "      <td>0.098415</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.169268</td>\n",
       "      <td>0.288435</td>\n",
       "      <td>tensor(28.2711, device='cuda:0')</td>\n",
       "      <td>tensor(28.2711, device='cuda:0')</td>\n",
       "      <td>tensor(36.4254, device='cuda:0')</td>\n",
       "      <td>tensor(36.4254, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>5.506713</td>\n",
       "      <td>13.684910</td>\n",
       "      <td>0.402393</td>\n",
       "      <td>0.242844</td>\n",
       "      <td>0.603910</td>\n",
       "      <td>0.402119</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.487159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996577</td>\n",
       "      <td>1.490848</td>\n",
       "      <td>1.523602</td>\n",
       "      <td>12.505377</td>\n",
       "      <td>0.049619</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>0.361906</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.360840</td>\n",
       "      <td>0.391602</td>\n",
       "      <td>0.435137</td>\n",
       "      <td>1.485132</td>\n",
       "      <td>tensor(5.5067, device='cuda:0')</td>\n",
       "      <td>tensor(5.5067, device='cuda:0')</td>\n",
       "      <td>tensor(13.6849, device='cuda:0')</td>\n",
       "      <td>tensor(13.6849, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>30</td>\n",
       "      <td>model.layers.30.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>37.772858</td>\n",
       "      <td>72.382622</td>\n",
       "      <td>0.521850</td>\n",
       "      <td>0.920822</td>\n",
       "      <td>1.830573</td>\n",
       "      <td>0.503024</td>\n",
       "      <td>0.284580</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>1.162086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948715</td>\n",
       "      <td>1.017882</td>\n",
       "      <td>1.578896</td>\n",
       "      <td>12.699347</td>\n",
       "      <td>0.044364</td>\n",
       "      <td>1.897461</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>-0.006347</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.633545</td>\n",
       "      <td>1.762695</td>\n",
       "      <td>0.916260</td>\n",
       "      <td>tensor(37.7729, device='cuda:0')</td>\n",
       "      <td>tensor(37.7729, device='cuda:0')</td>\n",
       "      <td>tensor(72.3826, device='cuda:0')</td>\n",
       "      <td>tensor(72.3826, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948715</td>\n",
       "      <td>0.948715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.897707</td>\n",
       "      <td>6.376474</td>\n",
       "      <td>1.238569</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>1.237419</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>1.476727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994669</td>\n",
       "      <td>0.213796</td>\n",
       "      <td>0.191543</td>\n",
       "      <td>1.158192</td>\n",
       "      <td>-0.003924</td>\n",
       "      <td>0.170410</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.192617</td>\n",
       "      <td>tensor(7.8977, device='cuda:0')</td>\n",
       "      <td>tensor(7.8977, device='cuda:0')</td>\n",
       "      <td>tensor(6.3765, device='cuda:0')</td>\n",
       "      <td>tensor(6.3765, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994670</td>\n",
       "      <td>0.994670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>52.797226</td>\n",
       "      <td>57.852005</td>\n",
       "      <td>0.912626</td>\n",
       "      <td>3.299438</td>\n",
       "      <td>3.615731</td>\n",
       "      <td>0.912523</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>4.224644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.097144</td>\n",
       "      <td>0.096132</td>\n",
       "      <td>0.214323</td>\n",
       "      <td>-0.010071</td>\n",
       "      <td>0.636271</td>\n",
       "      <td>0.316292</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>0.223718</td>\n",
       "      <td>0.260260</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.413445</td>\n",
       "      <td>0.521002</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>tensor(52.7972, device='cuda:0')</td>\n",
       "      <td>tensor(52.7972, device='cuda:0')</td>\n",
       "      <td>tensor(57.8520, device='cuda:0')</td>\n",
       "      <td>tensor(57.8520, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>28.926723</td>\n",
       "      <td>37.828533</td>\n",
       "      <td>0.764680</td>\n",
       "      <td>0.341183</td>\n",
       "      <td>0.445842</td>\n",
       "      <td>0.765255</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.617827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.322378</td>\n",
       "      <td>0.331882</td>\n",
       "      <td>65.666664</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.432861</td>\n",
       "      <td>0.107163</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.175117</td>\n",
       "      <td>0.307736</td>\n",
       "      <td>tensor(28.9267, device='cuda:0')</td>\n",
       "      <td>tensor(28.9267, device='cuda:0')</td>\n",
       "      <td>tensor(37.8285, device='cuda:0')</td>\n",
       "      <td>tensor(37.8285, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.051957</td>\n",
       "      <td>16.307974</td>\n",
       "      <td>0.432424</td>\n",
       "      <td>0.310746</td>\n",
       "      <td>0.719584</td>\n",
       "      <td>0.431842</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>1.320503</td>\n",
       "      <td>1.400346</td>\n",
       "      <td>31.715084</td>\n",
       "      <td>-0.010537</td>\n",
       "      <td>0.692993</td>\n",
       "      <td>0.409939</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.272639</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.446191</td>\n",
       "      <td>0.502393</td>\n",
       "      <td>1.312546</td>\n",
       "      <td>tensor(7.0520, device='cuda:0')</td>\n",
       "      <td>tensor(7.0520, device='cuda:0')</td>\n",
       "      <td>tensor(16.3080, device='cuda:0')</td>\n",
       "      <td>tensor(16.3080, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>31</td>\n",
       "      <td>model.layers.31.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>43.037724</td>\n",
       "      <td>68.926460</td>\n",
       "      <td>0.624401</td>\n",
       "      <td>1.048125</td>\n",
       "      <td>1.746784</td>\n",
       "      <td>0.600031</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>1.603295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.949915</td>\n",
       "      <td>0.722683</td>\n",
       "      <td>1.337174</td>\n",
       "      <td>12.239436</td>\n",
       "      <td>0.055265</td>\n",
       "      <td>1.738281</td>\n",
       "      <td>0.718967</td>\n",
       "      <td>0.057699</td>\n",
       "      <td>0.104297</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>1.570312</td>\n",
       "      <td>1.666650</td>\n",
       "      <td>0.601536</td>\n",
       "      <td>tensor(43.0377, device='cuda:0')</td>\n",
       "      <td>tensor(43.0377, device='cuda:0')</td>\n",
       "      <td>tensor(68.9265, device='cuda:0')</td>\n",
       "      <td>tensor(68.9265, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949915</td>\n",
       "      <td>0.949915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.889240</td>\n",
       "      <td>5.830320</td>\n",
       "      <td>1.524657</td>\n",
       "      <td>0.104726</td>\n",
       "      <td>0.068708</td>\n",
       "      <td>1.524225</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>1.616956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.342881</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.344115</td>\n",
       "      <td>tensor(8.8892, device='cuda:0')</td>\n",
       "      <td>tensor(8.8892, device='cuda:0')</td>\n",
       "      <td>tensor(5.8303, device='cuda:0')</td>\n",
       "      <td>tensor(5.8303, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.152832</td>\n",
       "      <td>49.721458</td>\n",
       "      <td>1.008676</td>\n",
       "      <td>3.134155</td>\n",
       "      <td>3.107569</td>\n",
       "      <td>1.008555</td>\n",
       "      <td>0.049873</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>4.247295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.138051</td>\n",
       "      <td>-0.019193</td>\n",
       "      <td>0.377482</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>0.150838</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>tensor(50.1528, device='cuda:0')</td>\n",
       "      <td>tensor(50.1528, device='cuda:0')</td>\n",
       "      <td>tensor(49.7215, device='cuda:0')</td>\n",
       "      <td>tensor(49.7215, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.162882</td>\n",
       "      <td>38.999523</td>\n",
       "      <td>0.747775</td>\n",
       "      <td>0.343978</td>\n",
       "      <td>0.459724</td>\n",
       "      <td>0.748227</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.624090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.350267</td>\n",
       "      <td>0.363007</td>\n",
       "      <td>79.347824</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.445557</td>\n",
       "      <td>0.118019</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>tensor(29.1629, device='cuda:0')</td>\n",
       "      <td>tensor(29.1629, device='cuda:0')</td>\n",
       "      <td>tensor(38.9995, device='cuda:0')</td>\n",
       "      <td>tensor(38.9995, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.588762</td>\n",
       "      <td>16.664677</td>\n",
       "      <td>0.455380</td>\n",
       "      <td>0.334683</td>\n",
       "      <td>0.735415</td>\n",
       "      <td>0.455094</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.039613</td>\n",
       "      <td>0.545209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>1.202410</td>\n",
       "      <td>1.248351</td>\n",
       "      <td>19.965517</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.706787</td>\n",
       "      <td>0.401917</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.305962</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>0.449004</td>\n",
       "      <td>1.195968</td>\n",
       "      <td>tensor(7.5888, device='cuda:0')</td>\n",
       "      <td>tensor(7.5888, device='cuda:0')</td>\n",
       "      <td>tensor(16.6647, device='cuda:0')</td>\n",
       "      <td>tensor(16.6647, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>32</td>\n",
       "      <td>model.layers.32.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>44.091393</td>\n",
       "      <td>65.182068</td>\n",
       "      <td>0.676434</td>\n",
       "      <td>1.081811</td>\n",
       "      <td>1.647552</td>\n",
       "      <td>0.656617</td>\n",
       "      <td>0.308776</td>\n",
       "      <td>0.227272</td>\n",
       "      <td>1.358615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951048</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>1.199540</td>\n",
       "      <td>15.615385</td>\n",
       "      <td>-0.040758</td>\n",
       "      <td>1.739746</td>\n",
       "      <td>0.604333</td>\n",
       "      <td>-0.052275</td>\n",
       "      <td>0.091211</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1.486328</td>\n",
       "      <td>1.633936</td>\n",
       "      <td>0.478340</td>\n",
       "      <td>tensor(44.0914, device='cuda:0')</td>\n",
       "      <td>tensor(44.0914, device='cuda:0')</td>\n",
       "      <td>tensor(65.1821, device='cuda:0')</td>\n",
       "      <td>tensor(65.1821, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951048</td>\n",
       "      <td>0.951048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.963466</td>\n",
       "      <td>5.802093</td>\n",
       "      <td>1.544868</td>\n",
       "      <td>0.105609</td>\n",
       "      <td>0.068305</td>\n",
       "      <td>1.546131</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>1.340201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994311</td>\n",
       "      <td>0.362987</td>\n",
       "      <td>0.352497</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.190430</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.352695</td>\n",
       "      <td>tensor(8.9635, device='cuda:0')</td>\n",
       "      <td>tensor(8.9635, device='cuda:0')</td>\n",
       "      <td>tensor(5.8021, device='cuda:0')</td>\n",
       "      <td>tensor(5.8021, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994311</td>\n",
       "      <td>0.994311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.935829</td>\n",
       "      <td>58.862942</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>3.120361</td>\n",
       "      <td>3.678916</td>\n",
       "      <td>0.848174</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>5.539257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.180124</td>\n",
       "      <td>0.179510</td>\n",
       "      <td>0.367820</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.558555</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.474553</td>\n",
       "      <td>0.498315</td>\n",
       "      <td>0.545290</td>\n",
       "      <td>0.684265</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.178772</td>\n",
       "      <td>tensor(49.9358, device='cuda:0')</td>\n",
       "      <td>tensor(49.9358, device='cuda:0')</td>\n",
       "      <td>tensor(58.8629, device='cuda:0')</td>\n",
       "      <td>tensor(58.8629, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.481527</td>\n",
       "      <td>39.809658</td>\n",
       "      <td>0.740562</td>\n",
       "      <td>0.347760</td>\n",
       "      <td>0.469333</td>\n",
       "      <td>0.740966</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.622939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>0.362237</td>\n",
       "      <td>0.372869</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.457031</td>\n",
       "      <td>0.123706</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.350326</td>\n",
       "      <td>tensor(29.4815, device='cuda:0')</td>\n",
       "      <td>tensor(29.4815, device='cuda:0')</td>\n",
       "      <td>tensor(39.8097, device='cuda:0')</td>\n",
       "      <td>tensor(39.8097, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.174768</td>\n",
       "      <td>17.283358</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>0.316587</td>\n",
       "      <td>0.762202</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>0.356394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>1.415222</td>\n",
       "      <td>1.472912</td>\n",
       "      <td>31.168421</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>0.722900</td>\n",
       "      <td>0.447776</td>\n",
       "      <td>-0.049150</td>\n",
       "      <td>0.375430</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>1.408908</td>\n",
       "      <td>tensor(7.1748, device='cuda:0')</td>\n",
       "      <td>tensor(7.1748, device='cuda:0')</td>\n",
       "      <td>tensor(17.2834, device='cuda:0')</td>\n",
       "      <td>tensor(17.2834, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>33</td>\n",
       "      <td>model.layers.33.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>47.223068</td>\n",
       "      <td>58.363537</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>1.170833</td>\n",
       "      <td>1.461844</td>\n",
       "      <td>0.800928</td>\n",
       "      <td>0.284580</td>\n",
       "      <td>0.284001</td>\n",
       "      <td>1.002038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>0.411872</td>\n",
       "      <td>0.740873</td>\n",
       "      <td>13.319327</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.638672</td>\n",
       "      <td>0.388416</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>1.461231</td>\n",
       "      <td>0.235912</td>\n",
       "      <td>tensor(47.2231, device='cuda:0')</td>\n",
       "      <td>tensor(47.2231, device='cuda:0')</td>\n",
       "      <td>tensor(58.3635, device='cuda:0')</td>\n",
       "      <td>tensor(58.3635, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.193699</td>\n",
       "      <td>5.759494</td>\n",
       "      <td>1.596268</td>\n",
       "      <td>0.108368</td>\n",
       "      <td>0.067819</td>\n",
       "      <td>1.597897</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>1.305079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.382017</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.040740</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.373539</td>\n",
       "      <td>tensor(9.1937, device='cuda:0')</td>\n",
       "      <td>tensor(9.1937, device='cuda:0')</td>\n",
       "      <td>tensor(5.7595, device='cuda:0')</td>\n",
       "      <td>tensor(5.7595, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>55.477261</td>\n",
       "      <td>60.892586</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>3.466980</td>\n",
       "      <td>3.805771</td>\n",
       "      <td>0.910980</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>4.446198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.098753</td>\n",
       "      <td>0.097948</td>\n",
       "      <td>0.226229</td>\n",
       "      <td>0.068826</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.338791</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>0.273795</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.415631</td>\n",
       "      <td>0.546960</td>\n",
       "      <td>0.097613</td>\n",
       "      <td>tensor(55.4773, device='cuda:0')</td>\n",
       "      <td>tensor(55.4773, device='cuda:0')</td>\n",
       "      <td>tensor(60.8926, device='cuda:0')</td>\n",
       "      <td>tensor(60.8926, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>29.845907</td>\n",
       "      <td>40.668385</td>\n",
       "      <td>0.733885</td>\n",
       "      <td>0.352094</td>\n",
       "      <td>0.479449</td>\n",
       "      <td>0.734372</td>\n",
       "      <td>0.017365</td>\n",
       "      <td>0.029415</td>\n",
       "      <td>0.590349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.373947</td>\n",
       "      <td>0.385385</td>\n",
       "      <td>59.279068</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.466736</td>\n",
       "      <td>0.129530</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.188145</td>\n",
       "      <td>0.362612</td>\n",
       "      <td>tensor(29.8459, device='cuda:0')</td>\n",
       "      <td>tensor(29.8459, device='cuda:0')</td>\n",
       "      <td>tensor(40.6684, device='cuda:0')</td>\n",
       "      <td>tensor(40.6684, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.063729</td>\n",
       "      <td>16.081411</td>\n",
       "      <td>0.439248</td>\n",
       "      <td>0.311392</td>\n",
       "      <td>0.709224</td>\n",
       "      <td>0.439060</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.045857</td>\n",
       "      <td>0.482038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995443</td>\n",
       "      <td>1.284720</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>23.446352</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.666870</td>\n",
       "      <td>0.399222</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.271538</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.491778</td>\n",
       "      <td>1.276618</td>\n",
       "      <td>tensor(7.0637, device='cuda:0')</td>\n",
       "      <td>tensor(7.0637, device='cuda:0')</td>\n",
       "      <td>tensor(16.0814, device='cuda:0')</td>\n",
       "      <td>tensor(16.0814, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>34</td>\n",
       "      <td>model.layers.34.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>47.451469</td>\n",
       "      <td>63.553204</td>\n",
       "      <td>0.746642</td>\n",
       "      <td>1.183826</td>\n",
       "      <td>1.601308</td>\n",
       "      <td>0.739287</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.255691</td>\n",
       "      <td>0.993022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>0.453128</td>\n",
       "      <td>0.693614</td>\n",
       "      <td>14.168000</td>\n",
       "      <td>0.024252</td>\n",
       "      <td>1.729492</td>\n",
       "      <td>0.476263</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>1.531494</td>\n",
       "      <td>0.339331</td>\n",
       "      <td>tensor(47.4515, device='cuda:0')</td>\n",
       "      <td>tensor(47.4515, device='cuda:0')</td>\n",
       "      <td>tensor(63.5532, device='cuda:0')</td>\n",
       "      <td>tensor(63.5532, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.893102</td>\n",
       "      <td>6.090456</td>\n",
       "      <td>1.460170</td>\n",
       "      <td>0.104804</td>\n",
       "      <td>0.071727</td>\n",
       "      <td>1.461141</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>1.283483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>0.326091</td>\n",
       "      <td>0.315790</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.315148</td>\n",
       "      <td>tensor(8.8931, device='cuda:0')</td>\n",
       "      <td>tensor(8.8931, device='cuda:0')</td>\n",
       "      <td>tensor(6.0905, device='cuda:0')</td>\n",
       "      <td>tensor(6.0905, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>66.110176</td>\n",
       "      <td>59.661243</td>\n",
       "      <td>1.108093</td>\n",
       "      <td>4.131592</td>\n",
       "      <td>3.728813</td>\n",
       "      <td>1.108018</td>\n",
       "      <td>0.049318</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>4.696288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.097354</td>\n",
       "      <td>0.119041</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.498485</td>\n",
       "      <td>0.402779</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.216217</td>\n",
       "      <td>0.305138</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>0.453938</td>\n",
       "      <td>0.467799</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>tensor(66.1102, device='cuda:0')</td>\n",
       "      <td>tensor(66.1102, device='cuda:0')</td>\n",
       "      <td>tensor(59.6612, device='cuda:0')</td>\n",
       "      <td>tensor(59.6612, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>30.291435</td>\n",
       "      <td>41.269196</td>\n",
       "      <td>0.733996</td>\n",
       "      <td>0.357377</td>\n",
       "      <td>0.486644</td>\n",
       "      <td>0.734371</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.609970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997244</td>\n",
       "      <td>0.372622</td>\n",
       "      <td>0.388470</td>\n",
       "      <td>85.732239</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.362405</td>\n",
       "      <td>tensor(30.2914, device='cuda:0')</td>\n",
       "      <td>tensor(30.2914, device='cuda:0')</td>\n",
       "      <td>tensor(41.2692, device='cuda:0')</td>\n",
       "      <td>tensor(41.2692, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997244</td>\n",
       "      <td>0.997244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.979453</td>\n",
       "      <td>16.766403</td>\n",
       "      <td>0.416276</td>\n",
       "      <td>0.307707</td>\n",
       "      <td>0.739226</td>\n",
       "      <td>0.416256</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>1.410728</td>\n",
       "      <td>1.470606</td>\n",
       "      <td>27.714285</td>\n",
       "      <td>-0.040188</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.432765</td>\n",
       "      <td>-0.020492</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>1.402252</td>\n",
       "      <td>tensor(6.9795, device='cuda:0')</td>\n",
       "      <td>tensor(6.9795, device='cuda:0')</td>\n",
       "      <td>tensor(16.7664, device='cuda:0')</td>\n",
       "      <td>tensor(16.7664, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>35</td>\n",
       "      <td>model.layers.35.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>46.435028</td>\n",
       "      <td>64.891945</td>\n",
       "      <td>0.715575</td>\n",
       "      <td>1.163125</td>\n",
       "      <td>1.639507</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>0.225664</td>\n",
       "      <td>0.231369</td>\n",
       "      <td>0.975343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>0.486420</td>\n",
       "      <td>0.654955</td>\n",
       "      <td>14.658119</td>\n",
       "      <td>-0.007150</td>\n",
       "      <td>1.674805</td>\n",
       "      <td>0.520839</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>1.047852</td>\n",
       "      <td>1.522217</td>\n",
       "      <td>0.397478</td>\n",
       "      <td>tensor(46.4350, device='cuda:0')</td>\n",
       "      <td>tensor(46.4350, device='cuda:0')</td>\n",
       "      <td>tensor(64.8919, device='cuda:0')</td>\n",
       "      <td>tensor(64.8919, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.348124</td>\n",
       "      <td>6.535086</td>\n",
       "      <td>1.277431</td>\n",
       "      <td>0.098228</td>\n",
       "      <td>0.076935</td>\n",
       "      <td>1.276759</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>1.375659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993009</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>0.217831</td>\n",
       "      <td>1.269430</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.187012</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.217179</td>\n",
       "      <td>tensor(8.3481, device='cuda:0')</td>\n",
       "      <td>tensor(8.3481, device='cuda:0')</td>\n",
       "      <td>tensor(6.5351, device='cuda:0')</td>\n",
       "      <td>tensor(6.5351, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993008</td>\n",
       "      <td>0.993008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>62.670074</td>\n",
       "      <td>57.402885</td>\n",
       "      <td>1.091758</td>\n",
       "      <td>3.916321</td>\n",
       "      <td>3.587661</td>\n",
       "      <td>1.091608</td>\n",
       "      <td>0.066166</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>5.568248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.116691</td>\n",
       "      <td>-0.048167</td>\n",
       "      <td>0.459470</td>\n",
       "      <td>0.330236</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.071826</td>\n",
       "      <td>0.192178</td>\n",
       "      <td>0.342865</td>\n",
       "      <td>0.383914</td>\n",
       "      <td>0.411485</td>\n",
       "      <td>0.084046</td>\n",
       "      <td>tensor(62.6701, device='cuda:0')</td>\n",
       "      <td>tensor(62.6701, device='cuda:0')</td>\n",
       "      <td>tensor(57.4029, device='cuda:0')</td>\n",
       "      <td>tensor(57.4029, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>30.874731</td>\n",
       "      <td>42.265732</td>\n",
       "      <td>0.730491</td>\n",
       "      <td>0.364285</td>\n",
       "      <td>0.498457</td>\n",
       "      <td>0.730824</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.611524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>0.378366</td>\n",
       "      <td>0.395466</td>\n",
       "      <td>100.199997</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.489258</td>\n",
       "      <td>0.136063</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.189775</td>\n",
       "      <td>0.368942</td>\n",
       "      <td>tensor(30.8747, device='cuda:0')</td>\n",
       "      <td>tensor(30.8747, device='cuda:0')</td>\n",
       "      <td>tensor(42.2657, device='cuda:0')</td>\n",
       "      <td>tensor(42.2657, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.706844</td>\n",
       "      <td>17.553160</td>\n",
       "      <td>0.382088</td>\n",
       "      <td>0.295533</td>\n",
       "      <td>0.774706</td>\n",
       "      <td>0.381478</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.040184</td>\n",
       "      <td>0.564736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>1.624116</td>\n",
       "      <td>1.719836</td>\n",
       "      <td>30.842365</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>0.764282</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.380391</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>1.617201</td>\n",
       "      <td>tensor(6.7068, device='cuda:0')</td>\n",
       "      <td>tensor(6.7068, device='cuda:0')</td>\n",
       "      <td>tensor(17.5532, device='cuda:0')</td>\n",
       "      <td>tensor(17.5532, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>36</td>\n",
       "      <td>model.layers.36.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.136681</td>\n",
       "      <td>64.073906</td>\n",
       "      <td>0.548377</td>\n",
       "      <td>0.831806</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>0.514073</td>\n",
       "      <td>0.334463</td>\n",
       "      <td>0.233835</td>\n",
       "      <td>1.430339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.985710</td>\n",
       "      <td>1.787897</td>\n",
       "      <td>11.353742</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>1.634766</td>\n",
       "      <td>0.808131</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>1.494629</td>\n",
       "      <td>1.576807</td>\n",
       "      <td>0.823562</td>\n",
       "      <td>tensor(35.1367, device='cuda:0')</td>\n",
       "      <td>tensor(35.1367, device='cuda:0')</td>\n",
       "      <td>tensor(64.0739, device='cuda:0')</td>\n",
       "      <td>tensor(64.0739, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.235064</td>\n",
       "      <td>5.547874</td>\n",
       "      <td>1.664613</td>\n",
       "      <td>0.108670</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>1.666564</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>1.454245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>0.411916</td>\n",
       "      <td>0.399183</td>\n",
       "      <td>1.122642</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.067952</td>\n",
       "      <td>0.399260</td>\n",
       "      <td>tensor(9.2351, device='cuda:0')</td>\n",
       "      <td>tensor(9.2351, device='cuda:0')</td>\n",
       "      <td>tensor(5.5479, device='cuda:0')</td>\n",
       "      <td>tensor(5.5479, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.229416</td>\n",
       "      <td>60.786652</td>\n",
       "      <td>0.974382</td>\n",
       "      <td>3.701599</td>\n",
       "      <td>3.799148</td>\n",
       "      <td>0.974324</td>\n",
       "      <td>0.042101</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>3.609935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>0.366507</td>\n",
       "      <td>0.097597</td>\n",
       "      <td>0.039227</td>\n",
       "      <td>0.032939</td>\n",
       "      <td>0.053007</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>0.176707</td>\n",
       "      <td>0.262763</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>tensor(59.2294, device='cuda:0')</td>\n",
       "      <td>tensor(59.2294, device='cuda:0')</td>\n",
       "      <td>tensor(60.7866, device='cuda:0')</td>\n",
       "      <td>tensor(60.7866, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>31.662472</td>\n",
       "      <td>42.784061</td>\n",
       "      <td>0.740053</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.504624</td>\n",
       "      <td>0.740369</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.618512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.360320</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.132880</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.351255</td>\n",
       "      <td>tensor(31.6625, device='cuda:0')</td>\n",
       "      <td>tensor(31.6625, device='cuda:0')</td>\n",
       "      <td>tensor(42.7841, device='cuda:0')</td>\n",
       "      <td>tensor(42.7841, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.105305</td>\n",
       "      <td>20.455339</td>\n",
       "      <td>0.347357</td>\n",
       "      <td>0.313262</td>\n",
       "      <td>0.902194</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>0.379456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>1.885559</td>\n",
       "      <td>1.969272</td>\n",
       "      <td>35.349514</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.888916</td>\n",
       "      <td>0.589781</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.409043</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.645410</td>\n",
       "      <td>0.739805</td>\n",
       "      <td>1.878883</td>\n",
       "      <td>tensor(7.1053, device='cuda:0')</td>\n",
       "      <td>tensor(7.1053, device='cuda:0')</td>\n",
       "      <td>tensor(20.4553, device='cuda:0')</td>\n",
       "      <td>tensor(20.4553, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>37</td>\n",
       "      <td>model.layers.37.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.166149</td>\n",
       "      <td>53.906418</td>\n",
       "      <td>0.763660</td>\n",
       "      <td>1.018266</td>\n",
       "      <td>1.338238</td>\n",
       "      <td>0.760901</td>\n",
       "      <td>0.257726</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.811025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.794528</td>\n",
       "      <td>12.102880</td>\n",
       "      <td>-0.035162</td>\n",
       "      <td>1.506836</td>\n",
       "      <td>0.443871</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.381323</td>\n",
       "      <td>0.309484</td>\n",
       "      <td>tensor(41.1661, device='cuda:0')</td>\n",
       "      <td>tensor(41.1661, device='cuda:0')</td>\n",
       "      <td>tensor(53.9064, device='cuda:0')</td>\n",
       "      <td>tensor(53.9064, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.054070</td>\n",
       "      <td>5.683800</td>\n",
       "      <td>1.592961</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>1.596553</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>1.135575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>0.383590</td>\n",
       "      <td>0.373968</td>\n",
       "      <td>1.067961</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.372238</td>\n",
       "      <td>tensor(9.0541, device='cuda:0')</td>\n",
       "      <td>tensor(9.0541, device='cuda:0')</td>\n",
       "      <td>tensor(5.6838, device='cuda:0')</td>\n",
       "      <td>tensor(5.6838, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>54.623924</td>\n",
       "      <td>64.535614</td>\n",
       "      <td>0.846415</td>\n",
       "      <td>3.413574</td>\n",
       "      <td>4.033462</td>\n",
       "      <td>0.846314</td>\n",
       "      <td>0.053611</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>5.132750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.181908</td>\n",
       "      <td>0.318854</td>\n",
       "      <td>-0.060080</td>\n",
       "      <td>0.976490</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>-0.032483</td>\n",
       "      <td>0.543702</td>\n",
       "      <td>0.568990</td>\n",
       "      <td>0.611015</td>\n",
       "      <td>0.709435</td>\n",
       "      <td>0.882136</td>\n",
       "      <td>0.181453</td>\n",
       "      <td>tensor(54.6239, device='cuda:0')</td>\n",
       "      <td>tensor(54.6239, device='cuda:0')</td>\n",
       "      <td>tensor(64.5356, device='cuda:0')</td>\n",
       "      <td>tensor(64.5356, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.022961</td>\n",
       "      <td>44.180645</td>\n",
       "      <td>0.724819</td>\n",
       "      <td>0.377886</td>\n",
       "      <td>0.521095</td>\n",
       "      <td>0.725176</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.585676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.388015</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>93.391060</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.510162</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.379655</td>\n",
       "      <td>tensor(32.0230, device='cuda:0')</td>\n",
       "      <td>tensor(32.0230, device='cuda:0')</td>\n",
       "      <td>tensor(44.1806, device='cuda:0')</td>\n",
       "      <td>tensor(44.1806, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.750358</td>\n",
       "      <td>26.224215</td>\n",
       "      <td>0.295542</td>\n",
       "      <td>0.341728</td>\n",
       "      <td>1.153692</td>\n",
       "      <td>0.296204</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.211025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>2.392235</td>\n",
       "      <td>2.442798</td>\n",
       "      <td>27.611765</td>\n",
       "      <td>0.117644</td>\n",
       "      <td>1.145996</td>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.023442</td>\n",
       "      <td>0.343477</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.833984</td>\n",
       "      <td>0.886523</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>2.383613</td>\n",
       "      <td>tensor(7.7504, device='cuda:0')</td>\n",
       "      <td>tensor(7.7504, device='cuda:0')</td>\n",
       "      <td>tensor(26.2242, device='cuda:0')</td>\n",
       "      <td>tensor(26.2242, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>38</td>\n",
       "      <td>model.layers.38.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>43.734512</td>\n",
       "      <td>55.419159</td>\n",
       "      <td>0.789159</td>\n",
       "      <td>1.098074</td>\n",
       "      <td>1.376326</td>\n",
       "      <td>0.797830</td>\n",
       "      <td>0.198711</td>\n",
       "      <td>0.324437</td>\n",
       "      <td>0.612478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960291</td>\n",
       "      <td>0.414751</td>\n",
       "      <td>0.516173</td>\n",
       "      <td>12.762712</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>1.478516</td>\n",
       "      <td>0.400002</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>1.256227</td>\n",
       "      <td>0.267172</td>\n",
       "      <td>tensor(43.7345, device='cuda:0')</td>\n",
       "      <td>tensor(43.7345, device='cuda:0')</td>\n",
       "      <td>tensor(55.4192, device='cuda:0')</td>\n",
       "      <td>tensor(55.4192, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960291</td>\n",
       "      <td>0.960291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>7.790635</td>\n",
       "      <td>6.803200</td>\n",
       "      <td>1.145143</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>1.145004</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>1.160577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.177642</td>\n",
       "      <td>0.134306</td>\n",
       "      <td>1.680628</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.156738</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>0.126746</td>\n",
       "      <td>tensor(7.7906, device='cuda:0')</td>\n",
       "      <td>tensor(7.7906, device='cuda:0')</td>\n",
       "      <td>tensor(6.8032, device='cuda:0')</td>\n",
       "      <td>tensor(6.8032, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.221333</td>\n",
       "      <td>65.443092</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>3.138489</td>\n",
       "      <td>4.090182</td>\n",
       "      <td>0.767322</td>\n",
       "      <td>0.046510</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>4.961665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.303575</td>\n",
       "      <td>0.303537</td>\n",
       "      <td>0.462341</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>1.293111</td>\n",
       "      <td>0.951693</td>\n",
       "      <td>-0.031404</td>\n",
       "      <td>0.893487</td>\n",
       "      <td>0.910342</td>\n",
       "      <td>0.938736</td>\n",
       "      <td>1.030736</td>\n",
       "      <td>1.113242</td>\n",
       "      <td>0.303093</td>\n",
       "      <td>tensor(50.2213, device='cuda:0')</td>\n",
       "      <td>tensor(50.2213, device='cuda:0')</td>\n",
       "      <td>tensor(65.4431, device='cuda:0')</td>\n",
       "      <td>tensor(65.4431, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.510365</td>\n",
       "      <td>45.550747</td>\n",
       "      <td>0.713717</td>\n",
       "      <td>0.383658</td>\n",
       "      <td>0.537274</td>\n",
       "      <td>0.714084</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>0.566285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>0.408862</td>\n",
       "      <td>0.426743</td>\n",
       "      <td>113.614380</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.530487</td>\n",
       "      <td>0.155432</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.401115</td>\n",
       "      <td>tensor(32.5104, device='cuda:0')</td>\n",
       "      <td>tensor(32.5104, device='cuda:0')</td>\n",
       "      <td>tensor(45.5507, device='cuda:0')</td>\n",
       "      <td>tensor(45.5507, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.257142</td>\n",
       "      <td>28.256945</td>\n",
       "      <td>0.221437</td>\n",
       "      <td>0.275520</td>\n",
       "      <td>1.245100</td>\n",
       "      <td>0.221284</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.095960</td>\n",
       "      <td>0.245937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993192</td>\n",
       "      <td>3.524684</td>\n",
       "      <td>3.634027</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-0.032550</td>\n",
       "      <td>1.256348</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>-0.022374</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>0.982422</td>\n",
       "      <td>1.053613</td>\n",
       "      <td>1.105703</td>\n",
       "      <td>3.515951</td>\n",
       "      <td>tensor(6.2571, device='cuda:0')</td>\n",
       "      <td>tensor(6.2571, device='cuda:0')</td>\n",
       "      <td>tensor(28.2569, device='cuda:0')</td>\n",
       "      <td>tensor(28.2569, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993192</td>\n",
       "      <td>0.993192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>39</td>\n",
       "      <td>model.layers.39.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>33.187252</td>\n",
       "      <td>53.744801</td>\n",
       "      <td>0.617497</td>\n",
       "      <td>0.774536</td>\n",
       "      <td>1.358157</td>\n",
       "      <td>0.570284</td>\n",
       "      <td>0.342269</td>\n",
       "      <td>0.189595</td>\n",
       "      <td>1.805263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903270</td>\n",
       "      <td>0.834869</td>\n",
       "      <td>1.575434</td>\n",
       "      <td>8.018182</td>\n",
       "      <td>-0.046865</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>0.615146</td>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>1.280908</td>\n",
       "      <td>0.619441</td>\n",
       "      <td>tensor(33.1872, device='cuda:0')</td>\n",
       "      <td>tensor(33.1872, device='cuda:0')</td>\n",
       "      <td>tensor(53.7448, device='cuda:0')</td>\n",
       "      <td>tensor(53.7448, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903269</td>\n",
       "      <td>0.903269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.791056</td>\n",
       "      <td>7.212329</td>\n",
       "      <td>1.218893</td>\n",
       "      <td>0.103553</td>\n",
       "      <td>0.084969</td>\n",
       "      <td>1.218713</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>1.253185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.202120</td>\n",
       "      <td>0.181450</td>\n",
       "      <td>1.237624</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.045083</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>tensor(8.7911, device='cuda:0')</td>\n",
       "      <td>tensor(8.7911, device='cuda:0')</td>\n",
       "      <td>tensor(7.2123, device='cuda:0')</td>\n",
       "      <td>tensor(7.2123, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>52.311253</td>\n",
       "      <td>66.598053</td>\n",
       "      <td>0.785477</td>\n",
       "      <td>3.269043</td>\n",
       "      <td>4.162371</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>6.582301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.273723</td>\n",
       "      <td>0.273614</td>\n",
       "      <td>0.426817</td>\n",
       "      <td>-0.134503</td>\n",
       "      <td>1.247106</td>\n",
       "      <td>0.893328</td>\n",
       "      <td>-0.103301</td>\n",
       "      <td>0.827991</td>\n",
       "      <td>0.852250</td>\n",
       "      <td>0.883531</td>\n",
       "      <td>0.972981</td>\n",
       "      <td>1.158377</td>\n",
       "      <td>0.273111</td>\n",
       "      <td>tensor(52.3113, device='cuda:0')</td>\n",
       "      <td>tensor(52.3113, device='cuda:0')</td>\n",
       "      <td>tensor(66.5981, device='cuda:0')</td>\n",
       "      <td>tensor(66.5981, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>32.877995</td>\n",
       "      <td>46.196896</td>\n",
       "      <td>0.711693</td>\n",
       "      <td>0.388004</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>0.712016</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>0.574693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>0.412462</td>\n",
       "      <td>0.456590</td>\n",
       "      <td>299.286926</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.541161</td>\n",
       "      <td>0.158705</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.158203</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.207676</td>\n",
       "      <td>0.405101</td>\n",
       "      <td>tensor(32.8780, device='cuda:0')</td>\n",
       "      <td>tensor(32.8780, device='cuda:0')</td>\n",
       "      <td>tensor(46.1969, device='cuda:0')</td>\n",
       "      <td>tensor(46.1969, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.163482</td>\n",
       "      <td>20.797432</td>\n",
       "      <td>0.440606</td>\n",
       "      <td>0.404043</td>\n",
       "      <td>0.917130</td>\n",
       "      <td>0.440552</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.060538</td>\n",
       "      <td>0.452929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>1.277488</td>\n",
       "      <td>1.319159</td>\n",
       "      <td>16.657658</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.902832</td>\n",
       "      <td>0.515779</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.583770</td>\n",
       "      <td>1.269600</td>\n",
       "      <td>tensor(9.1635, device='cuda:0')</td>\n",
       "      <td>tensor(9.1635, device='cuda:0')</td>\n",
       "      <td>tensor(20.7974, device='cuda:0')</td>\n",
       "      <td>tensor(20.7974, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>40</td>\n",
       "      <td>model.layers.40.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>45.966934</td>\n",
       "      <td>62.618275</td>\n",
       "      <td>0.734082</td>\n",
       "      <td>1.153931</td>\n",
       "      <td>1.579965</td>\n",
       "      <td>0.730353</td>\n",
       "      <td>0.209921</td>\n",
       "      <td>0.237649</td>\n",
       "      <td>0.883324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>0.450313</td>\n",
       "      <td>0.633921</td>\n",
       "      <td>13.569106</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>1.629883</td>\n",
       "      <td>0.473891</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.881714</td>\n",
       "      <td>1.492285</td>\n",
       "      <td>0.362246</td>\n",
       "      <td>tensor(45.9669, device='cuda:0')</td>\n",
       "      <td>tensor(45.9669, device='cuda:0')</td>\n",
       "      <td>tensor(62.6183, device='cuda:0')</td>\n",
       "      <td>tensor(62.6183, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.376526</td>\n",
       "      <td>5.662682</td>\n",
       "      <td>1.655845</td>\n",
       "      <td>0.110416</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>1.658218</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>1.364716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>0.407270</td>\n",
       "      <td>0.396567</td>\n",
       "      <td>1.221198</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.044075</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.396079</td>\n",
       "      <td>tensor(9.3765, device='cuda:0')</td>\n",
       "      <td>tensor(9.3765, device='cuda:0')</td>\n",
       "      <td>tensor(5.6627, device='cuda:0')</td>\n",
       "      <td>tensor(5.6627, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>49.397831</td>\n",
       "      <td>76.283791</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>3.086609</td>\n",
       "      <td>4.767734</td>\n",
       "      <td>0.647395</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>12.237870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.544967</td>\n",
       "      <td>0.545467</td>\n",
       "      <td>0.848140</td>\n",
       "      <td>0.040224</td>\n",
       "      <td>2.186612</td>\n",
       "      <td>1.681125</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>1.609587</td>\n",
       "      <td>1.625012</td>\n",
       "      <td>1.661775</td>\n",
       "      <td>1.813412</td>\n",
       "      <td>1.953422</td>\n",
       "      <td>0.544274</td>\n",
       "      <td>tensor(49.3978, device='cuda:0')</td>\n",
       "      <td>tensor(49.3978, device='cuda:0')</td>\n",
       "      <td>tensor(76.2838, device='cuda:0')</td>\n",
       "      <td>tensor(76.2838, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>33.596287</td>\n",
       "      <td>47.076504</td>\n",
       "      <td>0.713653</td>\n",
       "      <td>0.396493</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.713970</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>0.574828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.408431</td>\n",
       "      <td>0.450126</td>\n",
       "      <td>287.507935</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.552765</td>\n",
       "      <td>0.160618</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.401241</td>\n",
       "      <td>tensor(33.5963, device='cuda:0')</td>\n",
       "      <td>tensor(33.5963, device='cuda:0')</td>\n",
       "      <td>tensor(47.0765, device='cuda:0')</td>\n",
       "      <td>tensor(47.0765, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.331695</td>\n",
       "      <td>25.284454</td>\n",
       "      <td>0.289968</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>1.113093</td>\n",
       "      <td>0.290108</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.098306</td>\n",
       "      <td>0.271452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>2.458431</td>\n",
       "      <td>2.552430</td>\n",
       "      <td>32.361702</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>1.139160</td>\n",
       "      <td>0.792398</td>\n",
       "      <td>0.071805</td>\n",
       "      <td>0.529727</td>\n",
       "      <td>0.700293</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.978301</td>\n",
       "      <td>2.448651</td>\n",
       "      <td>tensor(7.3317, device='cuda:0')</td>\n",
       "      <td>tensor(7.3317, device='cuda:0')</td>\n",
       "      <td>tensor(25.2845, device='cuda:0')</td>\n",
       "      <td>tensor(25.2845, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>41</td>\n",
       "      <td>model.layers.41.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>39.528179</td>\n",
       "      <td>56.054607</td>\n",
       "      <td>0.705173</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>1.402409</td>\n",
       "      <td>0.693441</td>\n",
       "      <td>0.267403</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.951982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944913</td>\n",
       "      <td>0.575359</td>\n",
       "      <td>1.007315</td>\n",
       "      <td>18.065868</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>1.473145</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>-0.000668</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>1.163086</td>\n",
       "      <td>1.392188</td>\n",
       "      <td>0.418092</td>\n",
       "      <td>tensor(39.5282, device='cuda:0')</td>\n",
       "      <td>tensor(39.5282, device='cuda:0')</td>\n",
       "      <td>tensor(56.0546, device='cuda:0')</td>\n",
       "      <td>tensor(56.0546, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944913</td>\n",
       "      <td>0.944913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.423832</td>\n",
       "      <td>7.284523</td>\n",
       "      <td>1.293679</td>\n",
       "      <td>0.111039</td>\n",
       "      <td>0.085643</td>\n",
       "      <td>1.296527</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.937994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>0.249481</td>\n",
       "      <td>0.232726</td>\n",
       "      <td>1.471111</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.171387</td>\n",
       "      <td>0.026155</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.055337</td>\n",
       "      <td>0.227011</td>\n",
       "      <td>tensor(9.4238, device='cuda:0')</td>\n",
       "      <td>tensor(9.4238, device='cuda:0')</td>\n",
       "      <td>tensor(7.2845, device='cuda:0')</td>\n",
       "      <td>tensor(7.2845, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>56.244713</td>\n",
       "      <td>76.695351</td>\n",
       "      <td>0.733352</td>\n",
       "      <td>3.514893</td>\n",
       "      <td>4.793457</td>\n",
       "      <td>0.733269</td>\n",
       "      <td>0.053162</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>9.397799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.364031</td>\n",
       "      <td>0.364083</td>\n",
       "      <td>0.504607</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>1.608435</td>\n",
       "      <td>1.278564</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>1.217270</td>\n",
       "      <td>1.231292</td>\n",
       "      <td>1.265685</td>\n",
       "      <td>1.393391</td>\n",
       "      <td>1.484325</td>\n",
       "      <td>0.363601</td>\n",
       "      <td>tensor(56.2447, device='cuda:0')</td>\n",
       "      <td>tensor(56.2447, device='cuda:0')</td>\n",
       "      <td>tensor(76.6954, device='cuda:0')</td>\n",
       "      <td>tensor(76.6954, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>34.101860</td>\n",
       "      <td>48.291222</td>\n",
       "      <td>0.706171</td>\n",
       "      <td>0.402491</td>\n",
       "      <td>0.569678</td>\n",
       "      <td>0.706525</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.422745</td>\n",
       "      <td>0.436344</td>\n",
       "      <td>87.150940</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.563843</td>\n",
       "      <td>0.168954</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.142578</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.416088</td>\n",
       "      <td>tensor(34.1019, device='cuda:0')</td>\n",
       "      <td>tensor(34.1019, device='cuda:0')</td>\n",
       "      <td>tensor(48.2912, device='cuda:0')</td>\n",
       "      <td>tensor(48.2912, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.728246</td>\n",
       "      <td>28.171011</td>\n",
       "      <td>0.309831</td>\n",
       "      <td>0.384842</td>\n",
       "      <td>1.242149</td>\n",
       "      <td>0.309820</td>\n",
       "      <td>0.026264</td>\n",
       "      <td>0.084122</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>2.234395</td>\n",
       "      <td>2.295405</td>\n",
       "      <td>25.639593</td>\n",
       "      <td>-0.025646</td>\n",
       "      <td>1.233154</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>-0.067910</td>\n",
       "      <td>0.651250</td>\n",
       "      <td>0.802734</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.912988</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>2.227569</td>\n",
       "      <td>tensor(8.7282, device='cuda:0')</td>\n",
       "      <td>tensor(8.7282, device='cuda:0')</td>\n",
       "      <td>tensor(28.1710, device='cuda:0')</td>\n",
       "      <td>tensor(28.1710, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>42</td>\n",
       "      <td>model.layers.42.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>41.792419</td>\n",
       "      <td>46.897865</td>\n",
       "      <td>0.891137</td>\n",
       "      <td>1.032644</td>\n",
       "      <td>1.182349</td>\n",
       "      <td>0.873383</td>\n",
       "      <td>0.266009</td>\n",
       "      <td>0.184280</td>\n",
       "      <td>1.443500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960473</td>\n",
       "      <td>0.321923</td>\n",
       "      <td>0.506649</td>\n",
       "      <td>11.435643</td>\n",
       "      <td>0.094728</td>\n",
       "      <td>1.172852</td>\n",
       "      <td>0.221990</td>\n",
       "      <td>0.050873</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.905029</td>\n",
       "      <td>1.104297</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>tensor(41.7924, device='cuda:0')</td>\n",
       "      <td>tensor(41.7924, device='cuda:0')</td>\n",
       "      <td>tensor(46.8979, device='cuda:0')</td>\n",
       "      <td>tensor(46.8979, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960473</td>\n",
       "      <td>0.960473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.488783</td>\n",
       "      <td>7.310069</td>\n",
       "      <td>1.298043</td>\n",
       "      <td>0.111691</td>\n",
       "      <td>0.086062</td>\n",
       "      <td>1.297794</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>1.335782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>0.250837</td>\n",
       "      <td>0.229963</td>\n",
       "      <td>1.378378</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.229609</td>\n",
       "      <td>tensor(9.4888, device='cuda:0')</td>\n",
       "      <td>tensor(9.4888, device='cuda:0')</td>\n",
       "      <td>tensor(7.3101, device='cuda:0')</td>\n",
       "      <td>tensor(7.3101, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50.673882</td>\n",
       "      <td>76.044945</td>\n",
       "      <td>0.666368</td>\n",
       "      <td>3.166626</td>\n",
       "      <td>4.752805</td>\n",
       "      <td>0.666265</td>\n",
       "      <td>0.055802</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>8.428227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.501129</td>\n",
       "      <td>0.501398</td>\n",
       "      <td>0.690929</td>\n",
       "      <td>0.172116</td>\n",
       "      <td>1.943238</td>\n",
       "      <td>1.586179</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>1.530317</td>\n",
       "      <td>1.539507</td>\n",
       "      <td>1.570651</td>\n",
       "      <td>1.661738</td>\n",
       "      <td>1.829590</td>\n",
       "      <td>0.500673</td>\n",
       "      <td>tensor(50.6739, device='cuda:0')</td>\n",
       "      <td>tensor(50.6739, device='cuda:0')</td>\n",
       "      <td>tensor(76.0449, device='cuda:0')</td>\n",
       "      <td>tensor(76.0449, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>34.838112</td>\n",
       "      <td>49.710381</td>\n",
       "      <td>0.700822</td>\n",
       "      <td>0.411179</td>\n",
       "      <td>0.586426</td>\n",
       "      <td>0.701161</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.546113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.433432</td>\n",
       "      <td>0.458498</td>\n",
       "      <td>161.025314</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.177046</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.426896</td>\n",
       "      <td>tensor(34.8381, device='cuda:0')</td>\n",
       "      <td>tensor(34.8381, device='cuda:0')</td>\n",
       "      <td>tensor(49.7104, device='cuda:0')</td>\n",
       "      <td>tensor(49.7104, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>10.621462</td>\n",
       "      <td>32.936115</td>\n",
       "      <td>0.322487</td>\n",
       "      <td>0.467369</td>\n",
       "      <td>1.450579</td>\n",
       "      <td>0.322195</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.120613</td>\n",
       "      <td>0.362235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993350</td>\n",
       "      <td>2.110694</td>\n",
       "      <td>2.210378</td>\n",
       "      <td>34.619049</td>\n",
       "      <td>0.144624</td>\n",
       "      <td>1.419922</td>\n",
       "      <td>0.984217</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.551191</td>\n",
       "      <td>0.830273</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>1.225508</td>\n",
       "      <td>2.100902</td>\n",
       "      <td>tensor(10.6215, device='cuda:0')</td>\n",
       "      <td>tensor(10.6215, device='cuda:0')</td>\n",
       "      <td>tensor(32.9361, device='cuda:0')</td>\n",
       "      <td>tensor(32.9361, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>43</td>\n",
       "      <td>model.layers.43.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>38.403057</td>\n",
       "      <td>47.869350</td>\n",
       "      <td>0.802247</td>\n",
       "      <td>0.946365</td>\n",
       "      <td>1.209708</td>\n",
       "      <td>0.782309</td>\n",
       "      <td>0.254058</td>\n",
       "      <td>0.168674</td>\n",
       "      <td>1.506205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956671</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.711866</td>\n",
       "      <td>14.907515</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>1.306641</td>\n",
       "      <td>0.303770</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.959473</td>\n",
       "      <td>1.155273</td>\n",
       "      <td>0.246498</td>\n",
       "      <td>tensor(38.4031, device='cuda:0')</td>\n",
       "      <td>tensor(38.4031, device='cuda:0')</td>\n",
       "      <td>tensor(47.8693, device='cuda:0')</td>\n",
       "      <td>tensor(47.8693, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956671</td>\n",
       "      <td>0.956671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.154673</td>\n",
       "      <td>5.561210</td>\n",
       "      <td>1.825983</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>1.838875</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.898730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988647</td>\n",
       "      <td>0.465892</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>1.109705</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>0.054975</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>0.083821</td>\n",
       "      <td>0.452350</td>\n",
       "      <td>tensor(10.1547, device='cuda:0')</td>\n",
       "      <td>tensor(10.1547, device='cuda:0')</td>\n",
       "      <td>tensor(5.5612, device='cuda:0')</td>\n",
       "      <td>tensor(5.5612, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988646</td>\n",
       "      <td>0.988646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.402397</td>\n",
       "      <td>82.002777</td>\n",
       "      <td>0.724395</td>\n",
       "      <td>3.712219</td>\n",
       "      <td>5.125168</td>\n",
       "      <td>0.724312</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>7.696503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.380882</td>\n",
       "      <td>0.380960</td>\n",
       "      <td>0.534119</td>\n",
       "      <td>0.055318</td>\n",
       "      <td>1.785961</td>\n",
       "      <td>1.412949</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>1.361008</td>\n",
       "      <td>1.369412</td>\n",
       "      <td>1.399062</td>\n",
       "      <td>1.494398</td>\n",
       "      <td>1.687996</td>\n",
       "      <td>0.380462</td>\n",
       "      <td>tensor(59.4024, device='cuda:0')</td>\n",
       "      <td>tensor(59.4024, device='cuda:0')</td>\n",
       "      <td>tensor(82.0028, device='cuda:0')</td>\n",
       "      <td>tensor(82.0028, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>35.161789</td>\n",
       "      <td>50.851376</td>\n",
       "      <td>0.691462</td>\n",
       "      <td>0.415019</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>66.506851</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.592651</td>\n",
       "      <td>0.186632</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>0.446211</td>\n",
       "      <td>tensor(35.1618, device='cuda:0')</td>\n",
       "      <td>tensor(35.1618, device='cuda:0')</td>\n",
       "      <td>tensor(50.8514, device='cuda:0')</td>\n",
       "      <td>tensor(50.8514, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.954658</td>\n",
       "      <td>25.348925</td>\n",
       "      <td>0.353256</td>\n",
       "      <td>0.394367</td>\n",
       "      <td>1.116485</td>\n",
       "      <td>0.353222</td>\n",
       "      <td>0.032978</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.358190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993002</td>\n",
       "      <td>1.841598</td>\n",
       "      <td>1.952139</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>-0.021749</td>\n",
       "      <td>1.116699</td>\n",
       "      <td>0.724484</td>\n",
       "      <td>-0.010258</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.635840</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.916524</td>\n",
       "      <td>1.830809</td>\n",
       "      <td>tensor(8.9547, device='cuda:0')</td>\n",
       "      <td>tensor(8.9547, device='cuda:0')</td>\n",
       "      <td>tensor(25.3489, device='cuda:0')</td>\n",
       "      <td>tensor(25.3489, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993002</td>\n",
       "      <td>0.993002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>44</td>\n",
       "      <td>model.layers.44.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>42.673195</td>\n",
       "      <td>41.494488</td>\n",
       "      <td>1.028406</td>\n",
       "      <td>1.042407</td>\n",
       "      <td>1.007337</td>\n",
       "      <td>1.034815</td>\n",
       "      <td>0.314540</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>0.965049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913275</td>\n",
       "      <td>0.411610</td>\n",
       "      <td>0.694963</td>\n",
       "      <td>12.960784</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>1.291016</td>\n",
       "      <td>0.322702</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>1.157642</td>\n",
       "      <td>0.027622</td>\n",
       "      <td>tensor(42.6732, device='cuda:0')</td>\n",
       "      <td>tensor(42.6732, device='cuda:0')</td>\n",
       "      <td>tensor(41.4945, device='cuda:0')</td>\n",
       "      <td>tensor(41.4945, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913275</td>\n",
       "      <td>0.913275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.007144</td>\n",
       "      <td>7.582341</td>\n",
       "      <td>1.187911</td>\n",
       "      <td>0.106024</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>1.189146</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>1.040899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>0.195245</td>\n",
       "      <td>0.164367</td>\n",
       "      <td>1.584906</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.053384</td>\n",
       "      <td>0.158186</td>\n",
       "      <td>tensor(9.0071, device='cuda:0')</td>\n",
       "      <td>tensor(9.0071, device='cuda:0')</td>\n",
       "      <td>tensor(7.5823, device='cuda:0')</td>\n",
       "      <td>tensor(7.5823, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>62.607937</td>\n",
       "      <td>69.010757</td>\n",
       "      <td>0.907220</td>\n",
       "      <td>3.912598</td>\n",
       "      <td>4.313168</td>\n",
       "      <td>0.907129</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>9.018509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.102617</td>\n",
       "      <td>0.202301</td>\n",
       "      <td>-0.019303</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.400570</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.344884</td>\n",
       "      <td>0.353395</td>\n",
       "      <td>0.390495</td>\n",
       "      <td>0.494427</td>\n",
       "      <td>0.701405</td>\n",
       "      <td>0.102268</td>\n",
       "      <td>tensor(62.6079, device='cuda:0')</td>\n",
       "      <td>tensor(62.6079, device='cuda:0')</td>\n",
       "      <td>tensor(69.0107, device='cuda:0')</td>\n",
       "      <td>tensor(69.0107, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>35.825687</td>\n",
       "      <td>51.863037</td>\n",
       "      <td>0.690775</td>\n",
       "      <td>0.422876</td>\n",
       "      <td>0.611889</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>0.526981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>0.453319</td>\n",
       "      <td>0.466282</td>\n",
       "      <td>73.429626</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.190662</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.447649</td>\n",
       "      <td>tensor(35.8257, device='cuda:0')</td>\n",
       "      <td>tensor(35.8257, device='cuda:0')</td>\n",
       "      <td>tensor(51.8630, device='cuda:0')</td>\n",
       "      <td>tensor(51.8630, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.489024</td>\n",
       "      <td>28.782682</td>\n",
       "      <td>0.399164</td>\n",
       "      <td>0.504027</td>\n",
       "      <td>1.268909</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.061354</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>0.689369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>1.521227</td>\n",
       "      <td>1.655462</td>\n",
       "      <td>26.803278</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>1.263916</td>\n",
       "      <td>0.767697</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>0.548945</td>\n",
       "      <td>0.681836</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.911035</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>1.505234</td>\n",
       "      <td>tensor(11.4890, device='cuda:0')</td>\n",
       "      <td>tensor(11.4890, device='cuda:0')</td>\n",
       "      <td>tensor(28.7827, device='cuda:0')</td>\n",
       "      <td>tensor(28.7827, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>0.990339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>45</td>\n",
       "      <td>model.layers.45.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>36.703445</td>\n",
       "      <td>51.659477</td>\n",
       "      <td>0.710488</td>\n",
       "      <td>0.911217</td>\n",
       "      <td>1.291001</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.265993</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951792</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.852011</td>\n",
       "      <td>13.660098</td>\n",
       "      <td>-0.025472</td>\n",
       "      <td>1.396973</td>\n",
       "      <td>0.450266</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>1.048462</td>\n",
       "      <td>1.261548</td>\n",
       "      <td>0.407483</td>\n",
       "      <td>tensor(36.7034, device='cuda:0')</td>\n",
       "      <td>tensor(36.7034, device='cuda:0')</td>\n",
       "      <td>tensor(51.6595, device='cuda:0')</td>\n",
       "      <td>tensor(51.6595, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951792</td>\n",
       "      <td>0.951792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.939654</td>\n",
       "      <td>7.779192</td>\n",
       "      <td>1.277723</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.091431</td>\n",
       "      <td>1.280159</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>1.002010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992180</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>0.221777</td>\n",
       "      <td>1.910638</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.026394</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>0.217358</td>\n",
       "      <td>tensor(9.9397, device='cuda:0')</td>\n",
       "      <td>tensor(9.9397, device='cuda:0')</td>\n",
       "      <td>tensor(7.7792, device='cuda:0')</td>\n",
       "      <td>tensor(7.7792, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992180</td>\n",
       "      <td>0.992180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>78.499130</td>\n",
       "      <td>92.225677</td>\n",
       "      <td>0.851164</td>\n",
       "      <td>4.906006</td>\n",
       "      <td>5.764103</td>\n",
       "      <td>0.851131</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>10.242859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.175124</td>\n",
       "      <td>0.175002</td>\n",
       "      <td>0.263926</td>\n",
       "      <td>-0.010291</td>\n",
       "      <td>1.204165</td>\n",
       "      <td>0.858097</td>\n",
       "      <td>0.058356</td>\n",
       "      <td>0.815276</td>\n",
       "      <td>0.824965</td>\n",
       "      <td>0.856015</td>\n",
       "      <td>0.922965</td>\n",
       "      <td>1.029727</td>\n",
       "      <td>0.174862</td>\n",
       "      <td>tensor(78.4991, device='cuda:0')</td>\n",
       "      <td>tensor(78.4991, device='cuda:0')</td>\n",
       "      <td>tensor(92.2257, device='cuda:0')</td>\n",
       "      <td>tensor(92.2257, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>36.447720</td>\n",
       "      <td>53.549477</td>\n",
       "      <td>0.680636</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.631791</td>\n",
       "      <td>0.680974</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.506673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>0.474578</td>\n",
       "      <td>0.487265</td>\n",
       "      <td>73.057144</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.624268</td>\n",
       "      <td>0.203237</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.469214</td>\n",
       "      <td>tensor(36.4477, device='cuda:0')</td>\n",
       "      <td>tensor(36.4477, device='cuda:0')</td>\n",
       "      <td>tensor(53.5495, device='cuda:0')</td>\n",
       "      <td>tensor(53.5495, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.718669</td>\n",
       "      <td>36.422890</td>\n",
       "      <td>0.239373</td>\n",
       "      <td>0.382303</td>\n",
       "      <td>1.600676</td>\n",
       "      <td>0.238838</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>0.170018</td>\n",
       "      <td>0.282798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>3.193933</td>\n",
       "      <td>3.426511</td>\n",
       "      <td>34.117950</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>1.697754</td>\n",
       "      <td>1.219758</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>0.674629</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>1.237305</td>\n",
       "      <td>1.426660</td>\n",
       "      <td>1.528652</td>\n",
       "      <td>3.177576</td>\n",
       "      <td>tensor(8.7187, device='cuda:0')</td>\n",
       "      <td>tensor(8.7187, device='cuda:0')</td>\n",
       "      <td>tensor(36.4229, device='cuda:0')</td>\n",
       "      <td>tensor(36.4229, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>46</td>\n",
       "      <td>model.layers.46.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>32.507000</td>\n",
       "      <td>36.828556</td>\n",
       "      <td>0.882657</td>\n",
       "      <td>0.769394</td>\n",
       "      <td>0.919811</td>\n",
       "      <td>0.836469</td>\n",
       "      <td>0.309826</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1.611090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.903930</td>\n",
       "      <td>14.661972</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>1.124329</td>\n",
       "      <td>0.298984</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.849976</td>\n",
       "      <td>0.985815</td>\n",
       "      <td>0.132942</td>\n",
       "      <td>tensor(32.5070, device='cuda:0')</td>\n",
       "      <td>tensor(32.5070, device='cuda:0')</td>\n",
       "      <td>tensor(36.8286, device='cuda:0')</td>\n",
       "      <td>tensor(36.8286, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.800538</td>\n",
       "      <td>6.867566</td>\n",
       "      <td>1.281464</td>\n",
       "      <td>0.103454</td>\n",
       "      <td>0.080651</td>\n",
       "      <td>1.282742</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>1.165501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.253847</td>\n",
       "      <td>0.223860</td>\n",
       "      <td>1.354680</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.219642</td>\n",
       "      <td>tensor(8.8005, device='cuda:0')</td>\n",
       "      <td>tensor(8.8005, device='cuda:0')</td>\n",
       "      <td>tensor(6.8676, device='cuda:0')</td>\n",
       "      <td>tensor(6.8676, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.554260</td>\n",
       "      <td>98.685097</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>4.534424</td>\n",
       "      <td>6.167814</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.044425</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>6.170753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.360342</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>0.463428</td>\n",
       "      <td>-0.063909</td>\n",
       "      <td>1.955085</td>\n",
       "      <td>1.633391</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>1.583734</td>\n",
       "      <td>1.598286</td>\n",
       "      <td>1.633986</td>\n",
       "      <td>1.699435</td>\n",
       "      <td>1.870858</td>\n",
       "      <td>0.360156</td>\n",
       "      <td>tensor(72.5543, device='cuda:0')</td>\n",
       "      <td>tensor(72.5543, device='cuda:0')</td>\n",
       "      <td>tensor(98.6851, device='cuda:0')</td>\n",
       "      <td>tensor(98.6851, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>37.153988</td>\n",
       "      <td>55.376076</td>\n",
       "      <td>0.670939</td>\n",
       "      <td>0.438575</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>0.671269</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.030606</td>\n",
       "      <td>0.498673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.495571</td>\n",
       "      <td>0.511253</td>\n",
       "      <td>90.350426</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.645203</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.165371</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.490448</td>\n",
       "      <td>tensor(37.1540, device='cuda:0')</td>\n",
       "      <td>tensor(37.1540, device='cuda:0')</td>\n",
       "      <td>tensor(55.3761, device='cuda:0')</td>\n",
       "      <td>tensor(55.3761, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.115090</td>\n",
       "      <td>47.734306</td>\n",
       "      <td>0.149056</td>\n",
       "      <td>0.313553</td>\n",
       "      <td>2.088741</td>\n",
       "      <td>0.150116</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.295770</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>5.724276</td>\n",
       "      <td>5.825323</td>\n",
       "      <td>51.901733</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>2.265869</td>\n",
       "      <td>1.776920</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.399062</td>\n",
       "      <td>1.301172</td>\n",
       "      <td>1.837891</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.140860</td>\n",
       "      <td>5.708883</td>\n",
       "      <td>tensor(7.1151, device='cuda:0')</td>\n",
       "      <td>tensor(7.1151, device='cuda:0')</td>\n",
       "      <td>tensor(47.7343, device='cuda:0')</td>\n",
       "      <td>tensor(47.7343, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>47</td>\n",
       "      <td>model.layers.47.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>35.043316</td>\n",
       "      <td>43.275734</td>\n",
       "      <td>0.809768</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>1.084227</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.300994</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>1.439601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>0.483167</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>9.847458</td>\n",
       "      <td>0.050526</td>\n",
       "      <td>1.134766</td>\n",
       "      <td>0.327145</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>1.044531</td>\n",
       "      <td>0.234921</td>\n",
       "      <td>tensor(35.0433, device='cuda:0')</td>\n",
       "      <td>tensor(35.0433, device='cuda:0')</td>\n",
       "      <td>tensor(43.2757, device='cuda:0')</td>\n",
       "      <td>tensor(43.2757, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.160581</td>\n",
       "      <td>6.904369</td>\n",
       "      <td>1.326780</td>\n",
       "      <td>0.107597</td>\n",
       "      <td>0.081167</td>\n",
       "      <td>1.325630</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>1.443225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>0.245112</td>\n",
       "      <td>1.621359</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.073892</td>\n",
       "      <td>0.246296</td>\n",
       "      <td>tensor(9.1606, device='cuda:0')</td>\n",
       "      <td>tensor(9.1606, device='cuda:0')</td>\n",
       "      <td>tensor(6.9044, device='cuda:0')</td>\n",
       "      <td>tensor(6.9044, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>75.652328</td>\n",
       "      <td>128.706833</td>\n",
       "      <td>0.587788</td>\n",
       "      <td>4.728149</td>\n",
       "      <td>8.044176</td>\n",
       "      <td>0.587773</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>7.792107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.701356</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>0.038708</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>3.316026</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>3.274062</td>\n",
       "      <td>3.288668</td>\n",
       "      <td>3.298522</td>\n",
       "      <td>3.387670</td>\n",
       "      <td>3.451971</td>\n",
       "      <td>0.701294</td>\n",
       "      <td>tensor(75.6523, device='cuda:0')</td>\n",
       "      <td>tensor(75.6523, device='cuda:0')</td>\n",
       "      <td>tensor(128.7068, device='cuda:0')</td>\n",
       "      <td>tensor(128.7068, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>37.708935</td>\n",
       "      <td>56.685688</td>\n",
       "      <td>0.665228</td>\n",
       "      <td>0.445136</td>\n",
       "      <td>0.668839</td>\n",
       "      <td>0.665535</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>0.497328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.508047</td>\n",
       "      <td>0.518542</td>\n",
       "      <td>54.316582</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.659729</td>\n",
       "      <td>0.225288</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.175137</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.248047</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.503243</td>\n",
       "      <td>tensor(37.7089, device='cuda:0')</td>\n",
       "      <td>tensor(37.7089, device='cuda:0')</td>\n",
       "      <td>tensor(56.6857, device='cuda:0')</td>\n",
       "      <td>tensor(56.6857, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.742046</td>\n",
       "      <td>32.763737</td>\n",
       "      <td>0.205778</td>\n",
       "      <td>0.295794</td>\n",
       "      <td>1.444372</td>\n",
       "      <td>0.204791</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.101958</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>3.871047</td>\n",
       "      <td>4.226618</td>\n",
       "      <td>60.015545</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.149841</td>\n",
       "      <td>0.099979</td>\n",
       "      <td>0.883418</td>\n",
       "      <td>1.064648</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>1.237744</td>\n",
       "      <td>1.301016</td>\n",
       "      <td>3.859613</td>\n",
       "      <td>tensor(6.7420, device='cuda:0')</td>\n",
       "      <td>tensor(6.7420, device='cuda:0')</td>\n",
       "      <td>tensor(32.7637, device='cuda:0')</td>\n",
       "      <td>tensor(32.7637, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>48</td>\n",
       "      <td>model.layers.48.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>29.981049</td>\n",
       "      <td>38.430950</td>\n",
       "      <td>0.780128</td>\n",
       "      <td>0.686651</td>\n",
       "      <td>0.953880</td>\n",
       "      <td>0.719851</td>\n",
       "      <td>0.337205</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>1.483593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873983</td>\n",
       "      <td>0.634430</td>\n",
       "      <td>1.520104</td>\n",
       "      <td>12.202186</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>1.160309</td>\n",
       "      <td>0.381107</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>1.048486</td>\n",
       "      <td>0.281841</td>\n",
       "      <td>tensor(29.9810, device='cuda:0')</td>\n",
       "      <td>tensor(29.9810, device='cuda:0')</td>\n",
       "      <td>tensor(38.4310, device='cuda:0')</td>\n",
       "      <td>tensor(38.4310, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873983</td>\n",
       "      <td>0.873983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.295721</td>\n",
       "      <td>7.969981</td>\n",
       "      <td>1.040871</td>\n",
       "      <td>0.097570</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>1.041584</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.965903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990946</td>\n",
       "      <td>0.137616</td>\n",
       "      <td>0.079553</td>\n",
       "      <td>1.872340</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.176270</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.019136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>tensor(8.2957, device='cuda:0')</td>\n",
       "      <td>tensor(8.2957, device='cuda:0')</td>\n",
       "      <td>tensor(7.9700, device='cuda:0')</td>\n",
       "      <td>tensor(7.9700, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990946</td>\n",
       "      <td>0.990946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>61.280964</td>\n",
       "      <td>102.592842</td>\n",
       "      <td>0.597322</td>\n",
       "      <td>3.829773</td>\n",
       "      <td>6.412050</td>\n",
       "      <td>0.597277</td>\n",
       "      <td>0.046917</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>8.273088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.674525</td>\n",
       "      <td>0.823806</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>2.896193</td>\n",
       "      <td>2.582277</td>\n",
       "      <td>0.136936</td>\n",
       "      <td>2.538258</td>\n",
       "      <td>2.541200</td>\n",
       "      <td>2.570968</td>\n",
       "      <td>2.644493</td>\n",
       "      <td>2.804333</td>\n",
       "      <td>0.674139</td>\n",
       "      <td>tensor(61.2810, device='cuda:0')</td>\n",
       "      <td>tensor(61.2810, device='cuda:0')</td>\n",
       "      <td>tensor(102.5928, device='cuda:0')</td>\n",
       "      <td>tensor(102.5928, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>38.697121</td>\n",
       "      <td>58.836311</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>0.456815</td>\n",
       "      <td>0.694219</td>\n",
       "      <td>0.658027</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.479692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.525038</td>\n",
       "      <td>0.543178</td>\n",
       "      <td>115.244896</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.689331</td>\n",
       "      <td>0.238976</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.240234</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>0.520431</td>\n",
       "      <td>tensor(38.6971, device='cuda:0')</td>\n",
       "      <td>tensor(38.6971, device='cuda:0')</td>\n",
       "      <td>tensor(58.8363, device='cuda:0')</td>\n",
       "      <td>tensor(58.8363, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.011235</td>\n",
       "      <td>35.228909</td>\n",
       "      <td>0.227405</td>\n",
       "      <td>0.351188</td>\n",
       "      <td>1.553320</td>\n",
       "      <td>0.226089</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>0.105702</td>\n",
       "      <td>0.425028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>3.410647</td>\n",
       "      <td>3.729453</td>\n",
       "      <td>60.825241</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>1.529541</td>\n",
       "      <td>1.203486</td>\n",
       "      <td>0.076847</td>\n",
       "      <td>0.725801</td>\n",
       "      <td>1.131934</td>\n",
       "      <td>1.205078</td>\n",
       "      <td>1.305566</td>\n",
       "      <td>1.431875</td>\n",
       "      <td>3.397438</td>\n",
       "      <td>tensor(8.0112, device='cuda:0')</td>\n",
       "      <td>tensor(8.0112, device='cuda:0')</td>\n",
       "      <td>tensor(35.2289, device='cuda:0')</td>\n",
       "      <td>tensor(35.2289, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>49</td>\n",
       "      <td>model.layers.49.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>23.515059</td>\n",
       "      <td>45.900337</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>0.551928</td>\n",
       "      <td>1.145307</td>\n",
       "      <td>0.481904</td>\n",
       "      <td>0.235317</td>\n",
       "      <td>0.244770</td>\n",
       "      <td>0.961379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>1.135430</td>\n",
       "      <td>1.877399</td>\n",
       "      <td>9.376812</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>0.624642</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>0.198242</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>1.089844</td>\n",
       "      <td>1.163526</td>\n",
       "      <td>0.951956</td>\n",
       "      <td>tensor(23.5151, device='cuda:0')</td>\n",
       "      <td>tensor(23.5151, device='cuda:0')</td>\n",
       "      <td>tensor(45.9003, device='cuda:0')</td>\n",
       "      <td>tensor(45.9003, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.215260</td>\n",
       "      <td>7.529285</td>\n",
       "      <td>1.356737</td>\n",
       "      <td>0.120324</td>\n",
       "      <td>0.088465</td>\n",
       "      <td>1.360138</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.983629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992116</td>\n",
       "      <td>0.284181</td>\n",
       "      <td>0.267275</td>\n",
       "      <td>1.380567</td>\n",
       "      <td>0.013946</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.017096</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.068032</td>\n",
       "      <td>0.262937</td>\n",
       "      <td>tensor(10.2153, device='cuda:0')</td>\n",
       "      <td>tensor(10.2153, device='cuda:0')</td>\n",
       "      <td>tensor(7.5293, device='cuda:0')</td>\n",
       "      <td>tensor(7.5293, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>81.724022</td>\n",
       "      <td>115.252037</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>5.107544</td>\n",
       "      <td>7.203250</td>\n",
       "      <td>0.709061</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>8.805516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.410436</td>\n",
       "      <td>0.545141</td>\n",
       "      <td>-0.023420</td>\n",
       "      <td>2.538311</td>\n",
       "      <td>2.095706</td>\n",
       "      <td>-0.060634</td>\n",
       "      <td>2.046421</td>\n",
       "      <td>2.061811</td>\n",
       "      <td>2.081560</td>\n",
       "      <td>2.150823</td>\n",
       "      <td>2.299760</td>\n",
       "      <td>0.410259</td>\n",
       "      <td>tensor(81.7240, device='cuda:0')</td>\n",
       "      <td>tensor(81.7240, device='cuda:0')</td>\n",
       "      <td>tensor(115.2520, device='cuda:0')</td>\n",
       "      <td>tensor(115.2520, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>39.805771</td>\n",
       "      <td>60.309048</td>\n",
       "      <td>0.660030</td>\n",
       "      <td>0.469902</td>\n",
       "      <td>0.711620</td>\n",
       "      <td>0.660327</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.490270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.519624</td>\n",
       "      <td>0.539169</td>\n",
       "      <td>122.284210</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.709045</td>\n",
       "      <td>0.243286</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>0.515083</td>\n",
       "      <td>tensor(39.8058, device='cuda:0')</td>\n",
       "      <td>tensor(39.8058, device='cuda:0')</td>\n",
       "      <td>tensor(60.3090, device='cuda:0')</td>\n",
       "      <td>tensor(60.3090, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>12.517245</td>\n",
       "      <td>37.646488</td>\n",
       "      <td>0.332494</td>\n",
       "      <td>0.549931</td>\n",
       "      <td>1.656654</td>\n",
       "      <td>0.331953</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>0.153553</td>\n",
       "      <td>0.390433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988923</td>\n",
       "      <td>2.024096</td>\n",
       "      <td>2.214938</td>\n",
       "      <td>39.608189</td>\n",
       "      <td>-0.094381</td>\n",
       "      <td>1.756836</td>\n",
       "      <td>1.110065</td>\n",
       "      <td>-0.098317</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.879297</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.300781</td>\n",
       "      <td>1.476856</td>\n",
       "      <td>2.007570</td>\n",
       "      <td>tensor(12.5172, device='cuda:0')</td>\n",
       "      <td>tensor(12.5172, device='cuda:0')</td>\n",
       "      <td>tensor(37.6465, device='cuda:0')</td>\n",
       "      <td>tensor(37.6465, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988923</td>\n",
       "      <td>0.988923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>50</td>\n",
       "      <td>model.layers.50.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>32.272610</td>\n",
       "      <td>35.608696</td>\n",
       "      <td>0.906313</td>\n",
       "      <td>0.802544</td>\n",
       "      <td>0.886374</td>\n",
       "      <td>0.905423</td>\n",
       "      <td>0.184383</td>\n",
       "      <td>0.199620</td>\n",
       "      <td>0.923668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948857</td>\n",
       "      <td>0.351490</td>\n",
       "      <td>0.522235</td>\n",
       "      <td>14.879700</td>\n",
       "      <td>-0.039399</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>0.206102</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>0.922681</td>\n",
       "      <td>0.103372</td>\n",
       "      <td>tensor(32.2726, device='cuda:0')</td>\n",
       "      <td>tensor(32.2726, device='cuda:0')</td>\n",
       "      <td>tensor(35.6087, device='cuda:0')</td>\n",
       "      <td>tensor(35.6087, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948857</td>\n",
       "      <td>0.948857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.227710</td>\n",
       "      <td>6.190627</td>\n",
       "      <td>1.652128</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>0.072577</td>\n",
       "      <td>1.660446</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.945764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.399131</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.394720</td>\n",
       "      <td>tensor(10.2277, device='cuda:0')</td>\n",
       "      <td>tensor(10.2277, device='cuda:0')</td>\n",
       "      <td>tensor(6.1906, device='cuda:0')</td>\n",
       "      <td>tensor(6.1906, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>65.781540</td>\n",
       "      <td>103.148209</td>\n",
       "      <td>0.637738</td>\n",
       "      <td>4.111206</td>\n",
       "      <td>6.446762</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>6.987781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.568137</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>2.572815</td>\n",
       "      <td>2.335556</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>2.289006</td>\n",
       "      <td>2.307166</td>\n",
       "      <td>2.324615</td>\n",
       "      <td>2.386315</td>\n",
       "      <td>2.463500</td>\n",
       "      <td>0.568042</td>\n",
       "      <td>tensor(65.7815, device='cuda:0')</td>\n",
       "      <td>tensor(65.7815, device='cuda:0')</td>\n",
       "      <td>tensor(103.1482, device='cuda:0')</td>\n",
       "      <td>tensor(103.1482, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>40.384220</td>\n",
       "      <td>61.571194</td>\n",
       "      <td>0.655895</td>\n",
       "      <td>0.476740</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.656223</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.471176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.529138</td>\n",
       "      <td>0.563514</td>\n",
       "      <td>230.145630</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.723419</td>\n",
       "      <td>0.251372</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.200527</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.524635</td>\n",
       "      <td>tensor(40.3842, device='cuda:0')</td>\n",
       "      <td>tensor(40.3842, device='cuda:0')</td>\n",
       "      <td>tensor(61.5712, device='cuda:0')</td>\n",
       "      <td>tensor(61.5712, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.126939</td>\n",
       "      <td>33.346466</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>0.358415</td>\n",
       "      <td>1.467971</td>\n",
       "      <td>0.244156</td>\n",
       "      <td>0.023179</td>\n",
       "      <td>0.130038</td>\n",
       "      <td>0.178247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>3.111147</td>\n",
       "      <td>3.176197</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>1.428711</td>\n",
       "      <td>1.111480</td>\n",
       "      <td>-0.017341</td>\n",
       "      <td>0.601738</td>\n",
       "      <td>1.010840</td>\n",
       "      <td>1.130859</td>\n",
       "      <td>1.190332</td>\n",
       "      <td>1.247637</td>\n",
       "      <td>3.103201</td>\n",
       "      <td>tensor(8.1269, device='cuda:0')</td>\n",
       "      <td>tensor(8.1269, device='cuda:0')</td>\n",
       "      <td>tensor(33.3465, device='cuda:0')</td>\n",
       "      <td>tensor(33.3465, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>51</td>\n",
       "      <td>model.layers.51.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>37.580723</td>\n",
       "      <td>48.322044</td>\n",
       "      <td>0.777714</td>\n",
       "      <td>0.902179</td>\n",
       "      <td>1.196343</td>\n",
       "      <td>0.754114</td>\n",
       "      <td>0.324878</td>\n",
       "      <td>0.298259</td>\n",
       "      <td>1.089246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>0.560993</td>\n",
       "      <td>1.080937</td>\n",
       "      <td>11.131147</td>\n",
       "      <td>-0.043005</td>\n",
       "      <td>1.376953</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>1.131348</td>\n",
       "      <td>1.276367</td>\n",
       "      <td>0.285820</td>\n",
       "      <td>tensor(37.5807, device='cuda:0')</td>\n",
       "      <td>tensor(37.5807, device='cuda:0')</td>\n",
       "      <td>tensor(48.3220, device='cuda:0')</td>\n",
       "      <td>tensor(48.3220, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.311213</td>\n",
       "      <td>7.520018</td>\n",
       "      <td>1.238190</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>1.241025</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.948531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>0.225452</td>\n",
       "      <td>0.199711</td>\n",
       "      <td>1.403756</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.060220</td>\n",
       "      <td>0.192370</td>\n",
       "      <td>tensor(9.3112, device='cuda:0')</td>\n",
       "      <td>tensor(9.3112, device='cuda:0')</td>\n",
       "      <td>tensor(7.5200, device='cuda:0')</td>\n",
       "      <td>tensor(7.5200, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>72.959496</td>\n",
       "      <td>101.678253</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>4.559570</td>\n",
       "      <td>6.354887</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>9.178478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.394006</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>2.233622</td>\n",
       "      <td>1.795317</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>1.739064</td>\n",
       "      <td>1.757422</td>\n",
       "      <td>1.790122</td>\n",
       "      <td>1.888172</td>\n",
       "      <td>2.087419</td>\n",
       "      <td>0.393626</td>\n",
       "      <td>tensor(72.9595, device='cuda:0')</td>\n",
       "      <td>tensor(72.9595, device='cuda:0')</td>\n",
       "      <td>tensor(101.6782, device='cuda:0')</td>\n",
       "      <td>tensor(101.6782, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>41.616852</td>\n",
       "      <td>63.846737</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>0.491295</td>\n",
       "      <td>0.753357</td>\n",
       "      <td>0.652141</td>\n",
       "      <td>0.015909</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.469553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.538533</td>\n",
       "      <td>0.558187</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.751892</td>\n",
       "      <td>0.263675</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>0.210293</td>\n",
       "      <td>0.237012</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.534156</td>\n",
       "      <td>tensor(41.6169, device='cuda:0')</td>\n",
       "      <td>tensor(41.6169, device='cuda:0')</td>\n",
       "      <td>tensor(63.8467, device='cuda:0')</td>\n",
       "      <td>tensor(63.8467, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.611343</td>\n",
       "      <td>37.183098</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.422691</td>\n",
       "      <td>1.638337</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.127317</td>\n",
       "      <td>0.329312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>2.878687</td>\n",
       "      <td>3.178475</td>\n",
       "      <td>87.582779</td>\n",
       "      <td>0.056576</td>\n",
       "      <td>1.655762</td>\n",
       "      <td>1.217247</td>\n",
       "      <td>-0.030813</td>\n",
       "      <td>0.726074</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.225586</td>\n",
       "      <td>1.322949</td>\n",
       "      <td>1.399531</td>\n",
       "      <td>2.868668</td>\n",
       "      <td>tensor(9.6113, device='cuda:0')</td>\n",
       "      <td>tensor(9.6113, device='cuda:0')</td>\n",
       "      <td>tensor(37.1831, device='cuda:0')</td>\n",
       "      <td>tensor(37.1831, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>52</td>\n",
       "      <td>model.layers.52.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>34.930744</td>\n",
       "      <td>36.876457</td>\n",
       "      <td>0.947237</td>\n",
       "      <td>0.849323</td>\n",
       "      <td>0.912941</td>\n",
       "      <td>0.930315</td>\n",
       "      <td>0.270228</td>\n",
       "      <td>0.227754</td>\n",
       "      <td>1.186487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.625477</td>\n",
       "      <td>6.520000</td>\n",
       "      <td>-0.042133</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>-0.040038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.822510</td>\n",
       "      <td>0.978174</td>\n",
       "      <td>0.055702</td>\n",
       "      <td>tensor(34.9307, device='cuda:0')</td>\n",
       "      <td>tensor(34.9307, device='cuda:0')</td>\n",
       "      <td>tensor(36.8765, device='cuda:0')</td>\n",
       "      <td>tensor(36.8765, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>10.748524</td>\n",
       "      <td>7.695841</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>0.126456</td>\n",
       "      <td>0.090483</td>\n",
       "      <td>1.397565</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>1.295368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.304481</td>\n",
       "      <td>0.283303</td>\n",
       "      <td>1.029851</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.227539</td>\n",
       "      <td>0.036414</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.284010</td>\n",
       "      <td>tensor(10.7485, device='cuda:0')</td>\n",
       "      <td>tensor(10.7485, device='cuda:0')</td>\n",
       "      <td>tensor(7.6958, device='cuda:0')</td>\n",
       "      <td>tensor(7.6958, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.888145</td>\n",
       "      <td>100.560814</td>\n",
       "      <td>0.595542</td>\n",
       "      <td>3.742798</td>\n",
       "      <td>6.285046</td>\n",
       "      <td>0.595508</td>\n",
       "      <td>0.039760</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>5.273404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.679432</td>\n",
       "      <td>0.804865</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>2.804452</td>\n",
       "      <td>2.542248</td>\n",
       "      <td>0.111989</td>\n",
       "      <td>2.490165</td>\n",
       "      <td>2.503577</td>\n",
       "      <td>2.535627</td>\n",
       "      <td>2.618715</td>\n",
       "      <td>2.694504</td>\n",
       "      <td>0.679144</td>\n",
       "      <td>tensor(59.8881, device='cuda:0')</td>\n",
       "      <td>tensor(59.8881, device='cuda:0')</td>\n",
       "      <td>tensor(100.5608, device='cuda:0')</td>\n",
       "      <td>tensor(100.5608, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>42.831245</td>\n",
       "      <td>66.664520</td>\n",
       "      <td>0.642489</td>\n",
       "      <td>0.505628</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>0.642805</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.035570</td>\n",
       "      <td>0.463301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.560759</td>\n",
       "      <td>0.578697</td>\n",
       "      <td>114.484444</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.786102</td>\n",
       "      <td>0.282584</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0.556446</td>\n",
       "      <td>tensor(42.8312, device='cuda:0')</td>\n",
       "      <td>tensor(42.8312, device='cuda:0')</td>\n",
       "      <td>tensor(66.6645, device='cuda:0')</td>\n",
       "      <td>tensor(66.6645, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.470158</td>\n",
       "      <td>32.872959</td>\n",
       "      <td>0.288084</td>\n",
       "      <td>0.416720</td>\n",
       "      <td>1.447085</td>\n",
       "      <td>0.287972</td>\n",
       "      <td>0.038838</td>\n",
       "      <td>0.128654</td>\n",
       "      <td>0.301876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>2.483415</td>\n",
       "      <td>2.579660</td>\n",
       "      <td>34.108570</td>\n",
       "      <td>-0.058378</td>\n",
       "      <td>1.628906</td>\n",
       "      <td>1.032031</td>\n",
       "      <td>-0.062585</td>\n",
       "      <td>0.580879</td>\n",
       "      <td>0.903613</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>1.219629</td>\n",
       "      <td>1.363066</td>\n",
       "      <td>2.471215</td>\n",
       "      <td>tensor(9.4702, device='cuda:0')</td>\n",
       "      <td>tensor(9.4702, device='cuda:0')</td>\n",
       "      <td>tensor(32.8730, device='cuda:0')</td>\n",
       "      <td>tensor(32.8730, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>53</td>\n",
       "      <td>model.layers.53.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>24.918390</td>\n",
       "      <td>34.973537</td>\n",
       "      <td>0.712493</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.869858</td>\n",
       "      <td>0.705106</td>\n",
       "      <td>0.167512</td>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.841066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.575936</td>\n",
       "      <td>0.804069</td>\n",
       "      <td>19.296297</td>\n",
       "      <td>-0.008424</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.313290</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.671143</td>\n",
       "      <td>0.873755</td>\n",
       "      <td>0.403523</td>\n",
       "      <td>tensor(24.9184, device='cuda:0')</td>\n",
       "      <td>tensor(24.9184, device='cuda:0')</td>\n",
       "      <td>tensor(34.9735, device='cuda:0')</td>\n",
       "      <td>tensor(34.9735, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.168660</td>\n",
       "      <td>7.409281</td>\n",
       "      <td>1.237456</td>\n",
       "      <td>0.107799</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>1.237447</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>1.238439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990979</td>\n",
       "      <td>0.226719</td>\n",
       "      <td>0.192571</td>\n",
       "      <td>1.757282</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.065591</td>\n",
       "      <td>0.191890</td>\n",
       "      <td>tensor(9.1687, device='cuda:0')</td>\n",
       "      <td>tensor(9.1687, device='cuda:0')</td>\n",
       "      <td>tensor(7.4093, device='cuda:0')</td>\n",
       "      <td>tensor(7.4093, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990979</td>\n",
       "      <td>0.990979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>100.741928</td>\n",
       "      <td>98.467979</td>\n",
       "      <td>1.023093</td>\n",
       "      <td>6.296143</td>\n",
       "      <td>6.154246</td>\n",
       "      <td>1.023057</td>\n",
       "      <td>0.053555</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>9.993901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.024093</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.076570</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>0.437886</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>-0.060572</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.092114</td>\n",
       "      <td>0.154864</td>\n",
       "      <td>0.187614</td>\n",
       "      <td>0.195273</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>tensor(100.7419, device='cuda:0')</td>\n",
       "      <td>tensor(100.7419, device='cuda:0')</td>\n",
       "      <td>tensor(98.4680, device='cuda:0')</td>\n",
       "      <td>tensor(98.4680, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>43.947289</td>\n",
       "      <td>67.934235</td>\n",
       "      <td>0.646909</td>\n",
       "      <td>0.518812</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.647256</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>0.452475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.550202</td>\n",
       "      <td>0.566499</td>\n",
       "      <td>106.707314</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.801086</td>\n",
       "      <td>0.284464</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.217461</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.545812</td>\n",
       "      <td>tensor(43.9473, device='cuda:0')</td>\n",
       "      <td>tensor(43.9473, device='cuda:0')</td>\n",
       "      <td>tensor(67.9342, device='cuda:0')</td>\n",
       "      <td>tensor(67.9342, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.110057</td>\n",
       "      <td>40.890011</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.353097</td>\n",
       "      <td>1.802124</td>\n",
       "      <td>0.195934</td>\n",
       "      <td>0.061525</td>\n",
       "      <td>0.134016</td>\n",
       "      <td>0.459085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>4.062770</td>\n",
       "      <td>4.565912</td>\n",
       "      <td>93.967743</td>\n",
       "      <td>0.060758</td>\n",
       "      <td>1.824951</td>\n",
       "      <td>1.449965</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>0.870840</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>1.455078</td>\n",
       "      <td>1.614013</td>\n",
       "      <td>1.735469</td>\n",
       "      <td>4.041889</td>\n",
       "      <td>tensor(8.1101, device='cuda:0')</td>\n",
       "      <td>tensor(8.1101, device='cuda:0')</td>\n",
       "      <td>tensor(40.8900, device='cuda:0')</td>\n",
       "      <td>tensor(40.8900, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>54</td>\n",
       "      <td>model.layers.54.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>25.249483</td>\n",
       "      <td>32.930283</td>\n",
       "      <td>0.766756</td>\n",
       "      <td>0.596802</td>\n",
       "      <td>0.801044</td>\n",
       "      <td>0.745031</td>\n",
       "      <td>0.242672</td>\n",
       "      <td>0.253614</td>\n",
       "      <td>0.956855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>0.635460</td>\n",
       "      <td>0.966599</td>\n",
       "      <td>8.742222</td>\n",
       "      <td>-0.021787</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.333666</td>\n",
       "      <td>-0.004649</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.758789</td>\n",
       "      <td>0.898676</td>\n",
       "      <td>0.304196</td>\n",
       "      <td>tensor(25.2495, device='cuda:0')</td>\n",
       "      <td>tensor(25.2495, device='cuda:0')</td>\n",
       "      <td>tensor(32.9303, device='cuda:0')</td>\n",
       "      <td>tensor(32.9303, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.544826</td>\n",
       "      <td>7.688483</td>\n",
       "      <td>1.241445</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.090386</td>\n",
       "      <td>1.240623</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>1.325586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0.232005</td>\n",
       "      <td>0.194837</td>\n",
       "      <td>1.655462</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>0.068521</td>\n",
       "      <td>0.194487</td>\n",
       "      <td>tensor(9.5448, device='cuda:0')</td>\n",
       "      <td>tensor(9.5448, device='cuda:0')</td>\n",
       "      <td>tensor(7.6885, device='cuda:0')</td>\n",
       "      <td>tensor(7.6885, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990067</td>\n",
       "      <td>0.990067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>71.458214</td>\n",
       "      <td>49.634304</td>\n",
       "      <td>1.439694</td>\n",
       "      <td>4.465942</td>\n",
       "      <td>3.102138</td>\n",
       "      <td>1.439634</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>6.876036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.305513</td>\n",
       "      <td>0.305316</td>\n",
       "      <td>0.320475</td>\n",
       "      <td>-0.010523</td>\n",
       "      <td>1.442139</td>\n",
       "      <td>1.363804</td>\n",
       "      <td>-0.018369</td>\n",
       "      <td>1.222820</td>\n",
       "      <td>1.278892</td>\n",
       "      <td>1.366892</td>\n",
       "      <td>1.402942</td>\n",
       "      <td>1.410501</td>\n",
       "      <td>0.305408</td>\n",
       "      <td>tensor(71.4582, device='cuda:0')</td>\n",
       "      <td>tensor(71.4582, device='cuda:0')</td>\n",
       "      <td>tensor(49.6343, device='cuda:0')</td>\n",
       "      <td>tensor(49.6343, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>45.374569</td>\n",
       "      <td>70.578873</td>\n",
       "      <td>0.642892</td>\n",
       "      <td>0.535663</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>0.643331</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.040710</td>\n",
       "      <td>0.420680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.560207</td>\n",
       "      <td>0.592579</td>\n",
       "      <td>223.780487</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.839996</td>\n",
       "      <td>0.298991</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.555472</td>\n",
       "      <td>tensor(45.3746, device='cuda:0')</td>\n",
       "      <td>tensor(45.3746, device='cuda:0')</td>\n",
       "      <td>tensor(70.5789, device='cuda:0')</td>\n",
       "      <td>tensor(70.5789, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.315055</td>\n",
       "      <td>43.304157</td>\n",
       "      <td>0.168923</td>\n",
       "      <td>0.315494</td>\n",
       "      <td>1.907967</td>\n",
       "      <td>0.165356</td>\n",
       "      <td>0.070538</td>\n",
       "      <td>0.149193</td>\n",
       "      <td>0.472793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972362</td>\n",
       "      <td>4.953011</td>\n",
       "      <td>5.731565</td>\n",
       "      <td>52.698631</td>\n",
       "      <td>-0.033712</td>\n",
       "      <td>1.899414</td>\n",
       "      <td>1.594395</td>\n",
       "      <td>-0.061291</td>\n",
       "      <td>1.176152</td>\n",
       "      <td>1.445312</td>\n",
       "      <td>1.597656</td>\n",
       "      <td>1.803174</td>\n",
       "      <td>1.869033</td>\n",
       "      <td>4.919867</td>\n",
       "      <td>tensor(7.3151, device='cuda:0')</td>\n",
       "      <td>tensor(7.3151, device='cuda:0')</td>\n",
       "      <td>tensor(43.3042, device='cuda:0')</td>\n",
       "      <td>tensor(43.3042, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972363</td>\n",
       "      <td>0.972363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>55</td>\n",
       "      <td>model.layers.55.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>20.395445</td>\n",
       "      <td>38.993725</td>\n",
       "      <td>0.523044</td>\n",
       "      <td>0.461432</td>\n",
       "      <td>0.971314</td>\n",
       "      <td>0.475060</td>\n",
       "      <td>0.240618</td>\n",
       "      <td>0.215558</td>\n",
       "      <td>1.116256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861877</td>\n",
       "      <td>1.166055</td>\n",
       "      <td>2.159798</td>\n",
       "      <td>10.807487</td>\n",
       "      <td>-0.037435</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>0.543181</td>\n",
       "      <td>-0.057100</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.944092</td>\n",
       "      <td>1.021484</td>\n",
       "      <td>0.911884</td>\n",
       "      <td>tensor(20.3954, device='cuda:0')</td>\n",
       "      <td>tensor(20.3954, device='cuda:0')</td>\n",
       "      <td>tensor(38.9937, device='cuda:0')</td>\n",
       "      <td>tensor(38.9937, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861877</td>\n",
       "      <td>0.861877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.346161</td>\n",
       "      <td>8.306944</td>\n",
       "      <td>1.125102</td>\n",
       "      <td>0.109936</td>\n",
       "      <td>0.097532</td>\n",
       "      <td>1.127175</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.936658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990058</td>\n",
       "      <td>0.173313</td>\n",
       "      <td>0.131827</td>\n",
       "      <td>1.423645</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>0.111192</td>\n",
       "      <td>tensor(9.3462, device='cuda:0')</td>\n",
       "      <td>tensor(9.3462, device='cuda:0')</td>\n",
       "      <td>tensor(8.3069, device='cuda:0')</td>\n",
       "      <td>tensor(8.3069, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990058</td>\n",
       "      <td>0.990058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>75.489738</td>\n",
       "      <td>43.398766</td>\n",
       "      <td>1.739444</td>\n",
       "      <td>4.717896</td>\n",
       "      <td>2.712412</td>\n",
       "      <td>1.739372</td>\n",
       "      <td>0.044829</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>5.947058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.425168</td>\n",
       "      <td>0.425027</td>\n",
       "      <td>0.437876</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>2.079911</td>\n",
       "      <td>2.005483</td>\n",
       "      <td>0.069906</td>\n",
       "      <td>1.745152</td>\n",
       "      <td>1.944964</td>\n",
       "      <td>2.005864</td>\n",
       "      <td>2.042114</td>\n",
       "      <td>2.055563</td>\n",
       "      <td>0.425104</td>\n",
       "      <td>tensor(75.4897, device='cuda:0')</td>\n",
       "      <td>tensor(75.4897, device='cuda:0')</td>\n",
       "      <td>tensor(43.3988, device='cuda:0')</td>\n",
       "      <td>tensor(43.3988, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>46.954895</td>\n",
       "      <td>72.460052</td>\n",
       "      <td>0.648011</td>\n",
       "      <td>0.554308</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.648659</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.047314</td>\n",
       "      <td>0.381947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.548982</td>\n",
       "      <td>0.589416</td>\n",
       "      <td>286.030304</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.864166</td>\n",
       "      <td>0.302922</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.205742</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>0.543184</td>\n",
       "      <td>tensor(46.9549, device='cuda:0')</td>\n",
       "      <td>tensor(46.9549, device='cuda:0')</td>\n",
       "      <td>tensor(72.4600, device='cuda:0')</td>\n",
       "      <td>tensor(72.4600, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.712090</td>\n",
       "      <td>35.579922</td>\n",
       "      <td>0.244860</td>\n",
       "      <td>0.382761</td>\n",
       "      <td>1.567657</td>\n",
       "      <td>0.244161</td>\n",
       "      <td>0.041680</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>3.095836</td>\n",
       "      <td>3.300892</td>\n",
       "      <td>38.135136</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>1.507324</td>\n",
       "      <td>1.185812</td>\n",
       "      <td>-0.011821</td>\n",
       "      <td>0.794922</td>\n",
       "      <td>1.060547</td>\n",
       "      <td>1.181641</td>\n",
       "      <td>1.345508</td>\n",
       "      <td>1.435244</td>\n",
       "      <td>3.083971</td>\n",
       "      <td>tensor(8.7121, device='cuda:0')</td>\n",
       "      <td>tensor(8.7121, device='cuda:0')</td>\n",
       "      <td>tensor(35.5799, device='cuda:0')</td>\n",
       "      <td>tensor(35.5799, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>56</td>\n",
       "      <td>model.layers.56.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>26.489454</td>\n",
       "      <td>33.930782</td>\n",
       "      <td>0.780691</td>\n",
       "      <td>0.623040</td>\n",
       "      <td>0.826527</td>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.262014</td>\n",
       "      <td>0.257674</td>\n",
       "      <td>1.016844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.637991</td>\n",
       "      <td>1.015950</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>-0.070283</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.346962</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.290039</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.952783</td>\n",
       "      <td>0.280916</td>\n",
       "      <td>tensor(26.4895, device='cuda:0')</td>\n",
       "      <td>tensor(26.4895, device='cuda:0')</td>\n",
       "      <td>tensor(33.9308, device='cuda:0')</td>\n",
       "      <td>tensor(33.9308, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.111650</td>\n",
       "      <td>5.735451</td>\n",
       "      <td>1.588655</td>\n",
       "      <td>0.107061</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>1.593023</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>1.287539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>0.392105</td>\n",
       "      <td>0.370166</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.040192</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.370537</td>\n",
       "      <td>tensor(9.1116, device='cuda:0')</td>\n",
       "      <td>tensor(9.1116, device='cuda:0')</td>\n",
       "      <td>tensor(5.7355, device='cuda:0')</td>\n",
       "      <td>tensor(5.7355, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>73.364540</td>\n",
       "      <td>38.575268</td>\n",
       "      <td>1.901854</td>\n",
       "      <td>4.584961</td>\n",
       "      <td>2.410940</td>\n",
       "      <td>1.901732</td>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>6.482912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.474286</td>\n",
       "      <td>0.474084</td>\n",
       "      <td>0.486030</td>\n",
       "      <td>-0.074846</td>\n",
       "      <td>2.247890</td>\n",
       "      <td>2.174021</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>1.922179</td>\n",
       "      <td>2.093942</td>\n",
       "      <td>2.180643</td>\n",
       "      <td>2.223292</td>\n",
       "      <td>2.241890</td>\n",
       "      <td>0.474197</td>\n",
       "      <td>tensor(73.3645, device='cuda:0')</td>\n",
       "      <td>tensor(73.3645, device='cuda:0')</td>\n",
       "      <td>tensor(38.5753, device='cuda:0')</td>\n",
       "      <td>tensor(38.5753, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>48.476753</td>\n",
       "      <td>71.995995</td>\n",
       "      <td>0.673326</td>\n",
       "      <td>0.572268</td>\n",
       "      <td>0.848505</td>\n",
       "      <td>0.674443</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997274</td>\n",
       "      <td>0.493440</td>\n",
       "      <td>0.512047</td>\n",
       "      <td>146.134018</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.865173</td>\n",
       "      <td>0.279695</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.485165</td>\n",
       "      <td>tensor(48.4767, device='cuda:0')</td>\n",
       "      <td>tensor(48.4767, device='cuda:0')</td>\n",
       "      <td>tensor(71.9960, device='cuda:0')</td>\n",
       "      <td>tensor(71.9960, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997274</td>\n",
       "      <td>0.997274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.402333</td>\n",
       "      <td>35.996288</td>\n",
       "      <td>0.261203</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>1.578283</td>\n",
       "      <td>0.251944</td>\n",
       "      <td>0.120610</td>\n",
       "      <td>0.199375</td>\n",
       "      <td>0.604943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948076</td>\n",
       "      <td>2.897871</td>\n",
       "      <td>3.862682</td>\n",
       "      <td>69.468086</td>\n",
       "      <td>-0.036480</td>\n",
       "      <td>1.689453</td>\n",
       "      <td>1.184997</td>\n",
       "      <td>-0.024219</td>\n",
       "      <td>0.420332</td>\n",
       "      <td>0.814160</td>\n",
       "      <td>1.184570</td>\n",
       "      <td>1.494385</td>\n",
       "      <td>1.565547</td>\n",
       "      <td>2.828442</td>\n",
       "      <td>tensor(9.4023, device='cuda:0')</td>\n",
       "      <td>tensor(9.4023, device='cuda:0')</td>\n",
       "      <td>tensor(35.9963, device='cuda:0')</td>\n",
       "      <td>tensor(35.9963, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948076</td>\n",
       "      <td>0.948076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>57</td>\n",
       "      <td>model.layers.57.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>19.423687</td>\n",
       "      <td>41.781937</td>\n",
       "      <td>0.464882</td>\n",
       "      <td>0.452640</td>\n",
       "      <td>1.000939</td>\n",
       "      <td>0.452216</td>\n",
       "      <td>0.201845</td>\n",
       "      <td>0.366966</td>\n",
       "      <td>0.550038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>1.395874</td>\n",
       "      <td>2.364907</td>\n",
       "      <td>14.587629</td>\n",
       "      <td>-0.017237</td>\n",
       "      <td>1.425781</td>\n",
       "      <td>0.614956</td>\n",
       "      <td>-0.027108</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>1.151611</td>\n",
       "      <td>1.248047</td>\n",
       "      <td>1.151081</td>\n",
       "      <td>tensor(19.4237, device='cuda:0')</td>\n",
       "      <td>tensor(19.4237, device='cuda:0')</td>\n",
       "      <td>tensor(41.7819, device='cuda:0')</td>\n",
       "      <td>tensor(41.7819, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8.886652</td>\n",
       "      <td>6.214496</td>\n",
       "      <td>1.429988</td>\n",
       "      <td>0.104353</td>\n",
       "      <td>0.072141</td>\n",
       "      <td>1.446505</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.834777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977215</td>\n",
       "      <td>0.349691</td>\n",
       "      <td>0.315246</td>\n",
       "      <td>1.020100</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.180908</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>0.300693</td>\n",
       "      <td>tensor(8.8867, device='cuda:0')</td>\n",
       "      <td>tensor(8.8867, device='cuda:0')</td>\n",
       "      <td>tensor(6.2145, device='cuda:0')</td>\n",
       "      <td>tensor(6.2145, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977215</td>\n",
       "      <td>0.977215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>63.740585</td>\n",
       "      <td>37.870277</td>\n",
       "      <td>1.683130</td>\n",
       "      <td>3.983276</td>\n",
       "      <td>2.366880</td>\n",
       "      <td>1.682922</td>\n",
       "      <td>0.063759</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>8.493230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.406058</td>\n",
       "      <td>0.405635</td>\n",
       "      <td>0.418068</td>\n",
       "      <td>0.074904</td>\n",
       "      <td>1.685338</td>\n",
       "      <td>1.616396</td>\n",
       "      <td>0.033294</td>\n",
       "      <td>1.339604</td>\n",
       "      <td>1.502433</td>\n",
       "      <td>1.627490</td>\n",
       "      <td>1.669389</td>\n",
       "      <td>1.677698</td>\n",
       "      <td>0.405869</td>\n",
       "      <td>tensor(63.7406, device='cuda:0')</td>\n",
       "      <td>tensor(63.7406, device='cuda:0')</td>\n",
       "      <td>tensor(37.8703, device='cuda:0')</td>\n",
       "      <td>tensor(37.8703, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>50.561478</td>\n",
       "      <td>69.906929</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.596867</td>\n",
       "      <td>0.823406</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.394457</td>\n",
       "      <td>0.402549</td>\n",
       "      <td>81.120483</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.821899</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>tensor(50.5615, device='cuda:0')</td>\n",
       "      <td>tensor(50.5615, device='cuda:0')</td>\n",
       "      <td>tensor(69.9069, device='cuda:0')</td>\n",
       "      <td>tensor(69.9069, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>8.999374</td>\n",
       "      <td>38.314774</td>\n",
       "      <td>0.234880</td>\n",
       "      <td>0.387518</td>\n",
       "      <td>1.659230</td>\n",
       "      <td>0.233553</td>\n",
       "      <td>0.089502</td>\n",
       "      <td>0.337913</td>\n",
       "      <td>0.264867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952422</td>\n",
       "      <td>3.319094</td>\n",
       "      <td>4.482933</td>\n",
       "      <td>220.176468</td>\n",
       "      <td>-0.051873</td>\n",
       "      <td>1.873291</td>\n",
       "      <td>1.287091</td>\n",
       "      <td>-0.025912</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.455567</td>\n",
       "      <td>1.337891</td>\n",
       "      <td>1.613915</td>\n",
       "      <td>1.713438</td>\n",
       "      <td>3.257493</td>\n",
       "      <td>tensor(8.9994, device='cuda:0')</td>\n",
       "      <td>tensor(8.9994, device='cuda:0')</td>\n",
       "      <td>tensor(38.3148, device='cuda:0')</td>\n",
       "      <td>tensor(38.3148, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952422</td>\n",
       "      <td>0.952422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>58</td>\n",
       "      <td>model.layers.58.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>15.078004</td>\n",
       "      <td>29.374578</td>\n",
       "      <td>0.513301</td>\n",
       "      <td>0.340074</td>\n",
       "      <td>0.678578</td>\n",
       "      <td>0.501156</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>0.318267</td>\n",
       "      <td>0.565230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>1.289036</td>\n",
       "      <td>1.963430</td>\n",
       "      <td>16.846153</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>1.390137</td>\n",
       "      <td>0.404566</td>\n",
       "      <td>0.021095</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.358398</td>\n",
       "      <td>0.926270</td>\n",
       "      <td>1.139648</td>\n",
       "      <td>0.948174</td>\n",
       "      <td>tensor(15.0780, device='cuda:0')</td>\n",
       "      <td>tensor(15.0780, device='cuda:0')</td>\n",
       "      <td>tensor(29.3746, device='cuda:0')</td>\n",
       "      <td>tensor(29.3746, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>11.322188</td>\n",
       "      <td>8.784041</td>\n",
       "      <td>1.288950</td>\n",
       "      <td>0.133168</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>1.297055</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.820073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>0.269433</td>\n",
       "      <td>0.238618</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.235840</td>\n",
       "      <td>0.032437</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.224175</td>\n",
       "      <td>tensor(11.3222, device='cuda:0')</td>\n",
       "      <td>tensor(11.3222, device='cuda:0')</td>\n",
       "      <td>tensor(8.7840, device='cuda:0')</td>\n",
       "      <td>tensor(8.7840, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>59.812157</td>\n",
       "      <td>35.747231</td>\n",
       "      <td>1.673197</td>\n",
       "      <td>3.737732</td>\n",
       "      <td>2.234153</td>\n",
       "      <td>1.672998</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>4.231378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.402591</td>\n",
       "      <td>0.402085</td>\n",
       "      <td>0.461674</td>\n",
       "      <td>-0.040055</td>\n",
       "      <td>1.738490</td>\n",
       "      <td>1.503579</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>1.215207</td>\n",
       "      <td>1.413174</td>\n",
       "      <td>1.519079</td>\n",
       "      <td>1.551329</td>\n",
       "      <td>1.562970</td>\n",
       "      <td>0.402342</td>\n",
       "      <td>tensor(59.8122, device='cuda:0')</td>\n",
       "      <td>tensor(59.8122, device='cuda:0')</td>\n",
       "      <td>tensor(35.7472, device='cuda:0')</td>\n",
       "      <td>tensor(35.7472, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>53.454762</td>\n",
       "      <td>59.229683</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.630971</td>\n",
       "      <td>0.695732</td>\n",
       "      <td>0.906917</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.307945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993864</td>\n",
       "      <td>0.158960</td>\n",
       "      <td>0.174163</td>\n",
       "      <td>268.473694</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.700516</td>\n",
       "      <td>0.084888</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>0.108034</td>\n",
       "      <td>tensor(53.4548, device='cuda:0')</td>\n",
       "      <td>tensor(53.4548, device='cuda:0')</td>\n",
       "      <td>tensor(59.2297, device='cuda:0')</td>\n",
       "      <td>tensor(59.2297, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993864</td>\n",
       "      <td>0.993864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.440676</td>\n",
       "      <td>41.729496</td>\n",
       "      <td>0.226235</td>\n",
       "      <td>0.414216</td>\n",
       "      <td>1.828960</td>\n",
       "      <td>0.226476</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.211326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>3.440193</td>\n",
       "      <td>3.584890</td>\n",
       "      <td>34.111111</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>1.966309</td>\n",
       "      <td>1.416369</td>\n",
       "      <td>0.029226</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>1.214746</td>\n",
       "      <td>1.443359</td>\n",
       "      <td>1.631738</td>\n",
       "      <td>1.770410</td>\n",
       "      <td>3.420182</td>\n",
       "      <td>tensor(9.4407, device='cuda:0')</td>\n",
       "      <td>tensor(9.4407, device='cuda:0')</td>\n",
       "      <td>tensor(41.7295, device='cuda:0')</td>\n",
       "      <td>tensor(41.7295, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>59</td>\n",
       "      <td>model.layers.59.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>19.711937</td>\n",
       "      <td>36.543213</td>\n",
       "      <td>0.539414</td>\n",
       "      <td>0.480752</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.147805</td>\n",
       "      <td>0.295889</td>\n",
       "      <td>0.499527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>1.033867</td>\n",
       "      <td>1.288793</td>\n",
       "      <td>16.386667</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>1.200195</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.842529</td>\n",
       "      <td>0.971289</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>tensor(19.7119, device='cuda:0')</td>\n",
       "      <td>tensor(19.7119, device='cuda:0')</td>\n",
       "      <td>tensor(36.5432, device='cuda:0')</td>\n",
       "      <td>tensor(36.5432, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.input_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>9.121619</td>\n",
       "      <td>5.163881</td>\n",
       "      <td>1.766427</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>1.789316</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.856086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.439555</td>\n",
       "      <td>1.000123</td>\n",
       "      <td>-0.006742</td>\n",
       "      <td>0.204346</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.433885</td>\n",
       "      <td>tensor(9.1216, device='cuda:0')</td>\n",
       "      <td>tensor(9.1216, device='cuda:0')</td>\n",
       "      <td>tensor(5.1639, device='cuda:0')</td>\n",
       "      <td>tensor(5.1639, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.mlp.gate.e_score_correction_bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.962166</td>\n",
       "      <td>56.208115</td>\n",
       "      <td>1.155744</td>\n",
       "      <td>4.059692</td>\n",
       "      <td>3.512983</td>\n",
       "      <td>1.155625</td>\n",
       "      <td>0.059959</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>4.628320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.135434</td>\n",
       "      <td>0.134477</td>\n",
       "      <td>0.158780</td>\n",
       "      <td>0.183239</td>\n",
       "      <td>0.654969</td>\n",
       "      <td>0.546709</td>\n",
       "      <td>0.107217</td>\n",
       "      <td>0.306801</td>\n",
       "      <td>0.436898</td>\n",
       "      <td>0.553572</td>\n",
       "      <td>0.606183</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>0.134756</td>\n",
       "      <td>tensor(64.9622, device='cuda:0')</td>\n",
       "      <td>tensor(64.9622, device='cuda:0')</td>\n",
       "      <td>tensor(56.2081, device='cuda:0')</td>\n",
       "      <td>tensor(56.2081, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.post_attention_layernorm.weight</td>\n",
       "      <td>(7168,)</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>55.236790</td>\n",
       "      <td>35.182590</td>\n",
       "      <td>1.570004</td>\n",
       "      <td>0.651910</td>\n",
       "      <td>0.409948</td>\n",
       "      <td>1.590227</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.380428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>49.218979</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.678223</td>\n",
       "      <td>0.242459</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0.363059</td>\n",
       "      <td>tensor(55.2368, device='cuda:0')</td>\n",
       "      <td>tensor(55.2368, device='cuda:0')</td>\n",
       "      <td>tensor(35.1826, device='cuda:0')</td>\n",
       "      <td>tensor(35.1826, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.kv_a_layernorm.weight</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>11.628647</td>\n",
       "      <td>33.892223</td>\n",
       "      <td>0.343107</td>\n",
       "      <td>0.511723</td>\n",
       "      <td>1.465570</td>\n",
       "      <td>0.349163</td>\n",
       "      <td>0.047457</td>\n",
       "      <td>0.309232</td>\n",
       "      <td>0.153468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>1.951129</td>\n",
       "      <td>1.937069</td>\n",
       "      <td>14.300971</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>1.035156</td>\n",
       "      <td>1.196191</td>\n",
       "      <td>1.436006</td>\n",
       "      <td>1.914545</td>\n",
       "      <td>tensor(11.6286, device='cuda:0')</td>\n",
       "      <td>tensor(11.6286, device='cuda:0')</td>\n",
       "      <td>tensor(33.8922, device='cuda:0')</td>\n",
       "      <td>tensor(33.8922, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>60</td>\n",
       "      <td>model.layers.60.self_attn.q_a_layernorm.weight</td>\n",
       "      <td>(1536,)</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>26.197701</td>\n",
       "      <td>28.950804</td>\n",
       "      <td>0.904904</td>\n",
       "      <td>0.617749</td>\n",
       "      <td>0.643727</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>0.255360</td>\n",
       "      <td>0.362334</td>\n",
       "      <td>0.704765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803287</td>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.897578</td>\n",
       "      <td>12.477477</td>\n",
       "      <td>-0.010974</td>\n",
       "      <td>1.550781</td>\n",
       "      <td>0.362517</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.819580</td>\n",
       "      <td>1.065919</td>\n",
       "      <td>0.105089</td>\n",
       "      <td>tensor(26.1977, device='cuda:0')</td>\n",
       "      <td>tensor(26.1977, device='cuda:0')</td>\n",
       "      <td>tensor(28.9508, device='cuda:0')</td>\n",
       "      <td>tensor(28.9508, device='cuda:0')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803287</td>\n",
       "      <td>0.803287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer                                               key    shape   numel  \\\n",
       "0        0             model.layers.0.input_layernorm.weight  (7168,)  7168.0   \n",
       "4        0    model.layers.0.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "5        0    model.layers.0.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "9        0     model.layers.0.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "12       1             model.layers.1.input_layernorm.weight  (7168,)  7168.0   \n",
       "16       1    model.layers.1.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "17       1    model.layers.1.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "21       1     model.layers.1.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "24       2             model.layers.2.input_layernorm.weight  (7168,)  7168.0   \n",
       "28       2    model.layers.2.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "29       2    model.layers.2.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "33       2     model.layers.2.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "36       3             model.layers.3.input_layernorm.weight  (7168,)  7168.0   \n",
       "37       3   model.layers.3.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "42       3    model.layers.3.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "43       3    model.layers.3.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "47       3     model.layers.3.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "50       4             model.layers.4.input_layernorm.weight  (7168,)  7168.0   \n",
       "51       4   model.layers.4.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "56       4    model.layers.4.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "57       4    model.layers.4.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "61       4     model.layers.4.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "64       5             model.layers.5.input_layernorm.weight  (7168,)  7168.0   \n",
       "65       5   model.layers.5.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "70       5    model.layers.5.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "71       5    model.layers.5.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "75       5     model.layers.5.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "78       6             model.layers.6.input_layernorm.weight  (7168,)  7168.0   \n",
       "79       6   model.layers.6.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "84       6    model.layers.6.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "85       6    model.layers.6.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "89       6     model.layers.6.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "92       7             model.layers.7.input_layernorm.weight  (7168,)  7168.0   \n",
       "93       7   model.layers.7.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "98       7    model.layers.7.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "99       7    model.layers.7.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "103      7     model.layers.7.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "106      8             model.layers.8.input_layernorm.weight  (7168,)  7168.0   \n",
       "107      8   model.layers.8.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "112      8    model.layers.8.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "113      8    model.layers.8.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "117      8     model.layers.8.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "120      9             model.layers.9.input_layernorm.weight  (7168,)  7168.0   \n",
       "121      9   model.layers.9.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "126      9    model.layers.9.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "127      9    model.layers.9.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "131      9     model.layers.9.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "134     10            model.layers.10.input_layernorm.weight  (7168,)  7168.0   \n",
       "135     10  model.layers.10.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "140     10   model.layers.10.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "141     10   model.layers.10.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "145     10    model.layers.10.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "148     11            model.layers.11.input_layernorm.weight  (7168,)  7168.0   \n",
       "149     11  model.layers.11.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "154     11   model.layers.11.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "155     11   model.layers.11.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "159     11    model.layers.11.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "162     12            model.layers.12.input_layernorm.weight  (7168,)  7168.0   \n",
       "163     12  model.layers.12.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "168     12   model.layers.12.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "169     12   model.layers.12.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "173     12    model.layers.12.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "176     13            model.layers.13.input_layernorm.weight  (7168,)  7168.0   \n",
       "177     13  model.layers.13.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "182     13   model.layers.13.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "183     13   model.layers.13.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "187     13    model.layers.13.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "190     14            model.layers.14.input_layernorm.weight  (7168,)  7168.0   \n",
       "191     14  model.layers.14.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "196     14   model.layers.14.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "197     14   model.layers.14.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "201     14    model.layers.14.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "204     15            model.layers.15.input_layernorm.weight  (7168,)  7168.0   \n",
       "205     15  model.layers.15.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "210     15   model.layers.15.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "211     15   model.layers.15.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "215     15    model.layers.15.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "218     16            model.layers.16.input_layernorm.weight  (7168,)  7168.0   \n",
       "219     16  model.layers.16.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "224     16   model.layers.16.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "225     16   model.layers.16.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "229     16    model.layers.16.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "232     17            model.layers.17.input_layernorm.weight  (7168,)  7168.0   \n",
       "233     17  model.layers.17.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "238     17   model.layers.17.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "239     17   model.layers.17.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "243     17    model.layers.17.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "246     18            model.layers.18.input_layernorm.weight  (7168,)  7168.0   \n",
       "247     18  model.layers.18.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "252     18   model.layers.18.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "253     18   model.layers.18.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "257     18    model.layers.18.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "260     19            model.layers.19.input_layernorm.weight  (7168,)  7168.0   \n",
       "261     19  model.layers.19.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "266     19   model.layers.19.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "267     19   model.layers.19.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "271     19    model.layers.19.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "274     20            model.layers.20.input_layernorm.weight  (7168,)  7168.0   \n",
       "275     20  model.layers.20.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "280     20   model.layers.20.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "281     20   model.layers.20.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "285     20    model.layers.20.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "288     21            model.layers.21.input_layernorm.weight  (7168,)  7168.0   \n",
       "289     21  model.layers.21.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "294     21   model.layers.21.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "295     21   model.layers.21.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "299     21    model.layers.21.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "302     22            model.layers.22.input_layernorm.weight  (7168,)  7168.0   \n",
       "303     22  model.layers.22.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "308     22   model.layers.22.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "309     22   model.layers.22.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "313     22    model.layers.22.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "316     23            model.layers.23.input_layernorm.weight  (7168,)  7168.0   \n",
       "317     23  model.layers.23.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "322     23   model.layers.23.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "323     23   model.layers.23.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "327     23    model.layers.23.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "330     24            model.layers.24.input_layernorm.weight  (7168,)  7168.0   \n",
       "331     24  model.layers.24.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "336     24   model.layers.24.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "337     24   model.layers.24.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "341     24    model.layers.24.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "344     25            model.layers.25.input_layernorm.weight  (7168,)  7168.0   \n",
       "345     25  model.layers.25.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "350     25   model.layers.25.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "351     25   model.layers.25.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "355     25    model.layers.25.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "358     26            model.layers.26.input_layernorm.weight  (7168,)  7168.0   \n",
       "359     26  model.layers.26.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "364     26   model.layers.26.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "365     26   model.layers.26.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "369     26    model.layers.26.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "372     27            model.layers.27.input_layernorm.weight  (7168,)  7168.0   \n",
       "373     27  model.layers.27.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "378     27   model.layers.27.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "379     27   model.layers.27.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "383     27    model.layers.27.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "386     28            model.layers.28.input_layernorm.weight  (7168,)  7168.0   \n",
       "387     28  model.layers.28.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "392     28   model.layers.28.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "393     28   model.layers.28.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "397     28    model.layers.28.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "400     29            model.layers.29.input_layernorm.weight  (7168,)  7168.0   \n",
       "401     29  model.layers.29.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "406     29   model.layers.29.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "407     29   model.layers.29.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "411     29    model.layers.29.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "414     30            model.layers.30.input_layernorm.weight  (7168,)  7168.0   \n",
       "415     30  model.layers.30.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "420     30   model.layers.30.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "421     30   model.layers.30.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "425     30    model.layers.30.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "428     31            model.layers.31.input_layernorm.weight  (7168,)  7168.0   \n",
       "429     31  model.layers.31.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "434     31   model.layers.31.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "435     31   model.layers.31.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "439     31    model.layers.31.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "442     32            model.layers.32.input_layernorm.weight  (7168,)  7168.0   \n",
       "443     32  model.layers.32.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "448     32   model.layers.32.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "449     32   model.layers.32.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "453     32    model.layers.32.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "456     33            model.layers.33.input_layernorm.weight  (7168,)  7168.0   \n",
       "457     33  model.layers.33.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "462     33   model.layers.33.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "463     33   model.layers.33.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "467     33    model.layers.33.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "470     34            model.layers.34.input_layernorm.weight  (7168,)  7168.0   \n",
       "471     34  model.layers.34.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "476     34   model.layers.34.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "477     34   model.layers.34.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "481     34    model.layers.34.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "484     35            model.layers.35.input_layernorm.weight  (7168,)  7168.0   \n",
       "485     35  model.layers.35.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "490     35   model.layers.35.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "491     35   model.layers.35.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "495     35    model.layers.35.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "498     36            model.layers.36.input_layernorm.weight  (7168,)  7168.0   \n",
       "499     36  model.layers.36.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "504     36   model.layers.36.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "505     36   model.layers.36.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "509     36    model.layers.36.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "512     37            model.layers.37.input_layernorm.weight  (7168,)  7168.0   \n",
       "513     37  model.layers.37.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "518     37   model.layers.37.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "519     37   model.layers.37.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "523     37    model.layers.37.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "526     38            model.layers.38.input_layernorm.weight  (7168,)  7168.0   \n",
       "527     38  model.layers.38.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "532     38   model.layers.38.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "533     38   model.layers.38.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "537     38    model.layers.38.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "540     39            model.layers.39.input_layernorm.weight  (7168,)  7168.0   \n",
       "541     39  model.layers.39.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "546     39   model.layers.39.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "547     39   model.layers.39.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "551     39    model.layers.39.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "554     40            model.layers.40.input_layernorm.weight  (7168,)  7168.0   \n",
       "555     40  model.layers.40.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "560     40   model.layers.40.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "561     40   model.layers.40.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "565     40    model.layers.40.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "568     41            model.layers.41.input_layernorm.weight  (7168,)  7168.0   \n",
       "569     41  model.layers.41.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "574     41   model.layers.41.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "575     41   model.layers.41.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "579     41    model.layers.41.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "582     42            model.layers.42.input_layernorm.weight  (7168,)  7168.0   \n",
       "583     42  model.layers.42.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "588     42   model.layers.42.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "589     42   model.layers.42.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "593     42    model.layers.42.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "596     43            model.layers.43.input_layernorm.weight  (7168,)  7168.0   \n",
       "597     43  model.layers.43.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "602     43   model.layers.43.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "603     43   model.layers.43.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "607     43    model.layers.43.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "610     44            model.layers.44.input_layernorm.weight  (7168,)  7168.0   \n",
       "611     44  model.layers.44.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "616     44   model.layers.44.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "617     44   model.layers.44.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "621     44    model.layers.44.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "624     45            model.layers.45.input_layernorm.weight  (7168,)  7168.0   \n",
       "625     45  model.layers.45.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "630     45   model.layers.45.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "631     45   model.layers.45.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "635     45    model.layers.45.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "638     46            model.layers.46.input_layernorm.weight  (7168,)  7168.0   \n",
       "639     46  model.layers.46.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "644     46   model.layers.46.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "645     46   model.layers.46.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "649     46    model.layers.46.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "652     47            model.layers.47.input_layernorm.weight  (7168,)  7168.0   \n",
       "653     47  model.layers.47.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "658     47   model.layers.47.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "659     47   model.layers.47.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "663     47    model.layers.47.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "666     48            model.layers.48.input_layernorm.weight  (7168,)  7168.0   \n",
       "667     48  model.layers.48.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "672     48   model.layers.48.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "673     48   model.layers.48.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "677     48    model.layers.48.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "680     49            model.layers.49.input_layernorm.weight  (7168,)  7168.0   \n",
       "681     49  model.layers.49.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "686     49   model.layers.49.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "687     49   model.layers.49.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "691     49    model.layers.49.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "694     50            model.layers.50.input_layernorm.weight  (7168,)  7168.0   \n",
       "695     50  model.layers.50.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "700     50   model.layers.50.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "701     50   model.layers.50.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "705     50    model.layers.50.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "708     51            model.layers.51.input_layernorm.weight  (7168,)  7168.0   \n",
       "709     51  model.layers.51.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "714     51   model.layers.51.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "715     51   model.layers.51.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "719     51    model.layers.51.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "722     52            model.layers.52.input_layernorm.weight  (7168,)  7168.0   \n",
       "723     52  model.layers.52.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "728     52   model.layers.52.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "729     52   model.layers.52.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "733     52    model.layers.52.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "736     53            model.layers.53.input_layernorm.weight  (7168,)  7168.0   \n",
       "737     53  model.layers.53.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "742     53   model.layers.53.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "743     53   model.layers.53.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "747     53    model.layers.53.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "750     54            model.layers.54.input_layernorm.weight  (7168,)  7168.0   \n",
       "751     54  model.layers.54.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "756     54   model.layers.54.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "757     54   model.layers.54.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "761     54    model.layers.54.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "764     55            model.layers.55.input_layernorm.weight  (7168,)  7168.0   \n",
       "765     55  model.layers.55.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "770     55   model.layers.55.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "771     55   model.layers.55.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "775     55    model.layers.55.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "778     56            model.layers.56.input_layernorm.weight  (7168,)  7168.0   \n",
       "779     56  model.layers.56.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "784     56   model.layers.56.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "785     56   model.layers.56.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "789     56    model.layers.56.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "792     57            model.layers.57.input_layernorm.weight  (7168,)  7168.0   \n",
       "793     57  model.layers.57.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "798     57   model.layers.57.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "799     57   model.layers.57.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "803     57    model.layers.57.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "806     58            model.layers.58.input_layernorm.weight  (7168,)  7168.0   \n",
       "807     58  model.layers.58.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "812     58   model.layers.58.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "813     58   model.layers.58.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "817     58    model.layers.58.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "820     59            model.layers.59.input_layernorm.weight  (7168,)  7168.0   \n",
       "821     59  model.layers.59.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "826     59   model.layers.59.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "827     59   model.layers.59.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "831     59    model.layers.59.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "834     60            model.layers.60.input_layernorm.weight  (7168,)  7168.0   \n",
       "835     60  model.layers.60.mlp.gate.e_score_correction_bias   (256,)   256.0   \n",
       "840     60   model.layers.60.post_attention_layernorm.weight  (7168,)  7168.0   \n",
       "841     60   model.layers.60.self_attn.kv_a_layernorm.weight   (512,)   512.0   \n",
       "845     60    model.layers.60.self_attn.q_a_layernorm.weight  (1536,)  1536.0   \n",
       "\n",
       "         norm_a      norm_b  norm_ratio    mean_a    mean_b  mean_ratio  \\\n",
       "0      5.333566    3.708255    1.438295  0.058730  0.041479    1.415882   \n",
       "4      1.600154    1.976582    0.809556  0.016732  0.016968    0.986042   \n",
       "5      0.152460    0.231502    0.658569  0.005553  0.006916    0.802899   \n",
       "9      8.237963   17.689760    0.465691  0.193372  0.443633    0.435884   \n",
       "12     4.966424    4.025096    1.233865  0.053581  0.044444    1.205580   \n",
       "16     4.805261    5.418404    0.886841  0.045868  0.048390    0.947874   \n",
       "17     0.091417    0.262622    0.348093  0.002844  0.008173    0.348004   \n",
       "21     5.265309   17.526243    0.300424  0.116436  0.419999    0.277228   \n",
       "24     6.698238    5.042212    1.328432  0.074627  0.056358    1.324173   \n",
       "28     5.107561    3.691749    1.383507  0.053593  0.039059    1.372092   \n",
       "29     0.076628    0.277005    0.276632  0.002461  0.009435    0.260855   \n",
       "33     6.045459   18.126390    0.333517  0.147995  0.432889    0.341879   \n",
       "36     8.191147    4.541937    1.803448  0.092289  0.052340    1.763250   \n",
       "37   100.150665   79.248253    1.263759  6.259399  4.953015    1.263755   \n",
       "42     7.430301   10.335238    0.718929  0.080654  0.110154    0.732189   \n",
       "43     0.347525    0.416599    0.834195  0.009611  0.015846    0.606496   \n",
       "47    13.885664   19.065044    0.728331  0.345856  0.456453    0.757705   \n",
       "50     6.282731    3.886504    1.616551  0.071074  0.043553    1.631882   \n",
       "51    94.486427  105.370796    0.896704  5.905396  6.585674    0.896703   \n",
       "56    10.501461   10.436382    1.006236  0.118008  0.108037    1.092297   \n",
       "57     0.145010    1.085993    0.133528  0.005741  0.042525    0.135009   \n",
       "61     8.648572   38.966732    0.221948  0.213636  0.968635    0.220554   \n",
       "64     8.362890    5.834433    1.433368  0.095684  0.066838    1.431584   \n",
       "65   114.025658  120.610062    0.945408  7.126587  7.538128    0.945405   \n",
       "70    11.926690   12.219624    0.976028  0.135137  0.129416    1.044210   \n",
       "71     0.164448    0.613759    0.267936  0.006962  0.026778    0.259980   \n",
       "75    12.083183   29.750238    0.406154  0.297168  0.715038    0.415598   \n",
       "78     7.117170    5.769558    1.233573  0.081482  0.067094    1.214450   \n",
       "79   118.371513   95.961823    1.233527  7.398193  5.997613    1.233523   \n",
       "84    12.566309   13.817199    0.909469  0.143635  0.154706    0.928440   \n",
       "85     0.135344    0.454429    0.297833  0.005504  0.019942    0.275999   \n",
       "89     8.600546   28.650684    0.300186  0.207385  0.687798    0.301520   \n",
       "92     7.519102    5.417134    1.388022  0.087011  0.062993    1.381284   \n",
       "93   106.918343   87.724533    1.218796  6.682373  5.482783    1.218792   \n",
       "98    14.079303   14.198127    0.991631  0.163313  0.160756    1.015910   \n",
       "99     0.426888    0.779261    0.547811  0.018428  0.034266    0.537793   \n",
       "103   13.775208   36.266392    0.379834  0.334484  0.863280    0.387457   \n",
       "106    9.110951    5.380949    1.693187  0.106022  0.062231    1.703697   \n",
       "107   98.215782   86.622200    1.133841  6.138428  5.413887    1.133830   \n",
       "112   15.492817   15.785369    0.981467  0.180642  0.181526    0.995132   \n",
       "113    0.265736    0.534529    0.497139  0.011651  0.023012    0.506322   \n",
       "117   15.508194   24.044184    0.644987  0.380821  0.541633    0.703098   \n",
       "120    8.394691    3.145885    2.668467  0.097636  0.036808    2.652601   \n",
       "121   89.670647   77.074051    1.163435  5.604370  4.817127    1.163426   \n",
       "126   17.782528   16.459641    1.080372  0.208091  0.190776    1.090763   \n",
       "127    0.286094    2.375535    0.120433  0.012511  0.104601    0.119603   \n",
       "131   12.147147   58.573437    0.207383  0.291249  1.428330    0.203909   \n",
       "134    8.541730    3.601893    2.371456  0.099587  0.042321    2.353147   \n",
       "135   78.372345   64.967072    1.206339  4.898193  4.060442    1.206320   \n",
       "140   19.708843   17.559284    1.122417  0.231204  0.204769    1.129095   \n",
       "141    0.359084    1.876313    0.191378  0.015736  0.082707    0.190269   \n",
       "145   14.437043   61.101032    0.236281  0.350926  1.483577    0.236541   \n",
       "148    9.118999    2.988442    3.051423  0.106996  0.034930    3.063137   \n",
       "149   72.608574   60.910301    1.192057  4.537964  3.806892    1.192039   \n",
       "154   20.472179   18.495205    1.106891  0.240605  0.216203    1.112866   \n",
       "155    0.786310    2.485416    0.316369  0.034600  0.109573    0.315769   \n",
       "159   22.092937   53.990604    0.409200  0.538747  1.274603    0.422678   \n",
       "162    9.310952    5.036315    1.848763  0.109255  0.059196    1.845658   \n",
       "163   68.907265   57.200222    1.204668  4.306641  3.575012    1.204651   \n",
       "168   21.192741   19.668037    1.077522  0.249318  0.230472    1.081770   \n",
       "169    0.493276    1.282483    0.384626  0.021726  0.056594    0.383897   \n",
       "173   16.539137   40.300804    0.410392  0.401939  0.947520    0.424202   \n",
       "176    8.637804    4.383891    1.970351  0.101538  0.051574    1.968792   \n",
       "177   60.936588   51.128990    1.191821  3.808472  3.195559    1.191802   \n",
       "182   21.127401   20.101664    1.051028  0.248703  0.235769    1.054858   \n",
       "183    0.791774    1.809377    0.437595  0.034928  0.079847    0.437437   \n",
       "187   22.933607   53.314022    0.430161  0.557188  1.237014    0.450430   \n",
       "190    7.447861    4.184812    1.779736  0.087525  0.049242    1.777459   \n",
       "191   59.117859   50.622261    1.167823  3.694763  3.163889    1.167792   \n",
       "196   21.704342   20.226292    1.073076  0.255670  0.237395    1.076981   \n",
       "197    1.311881    2.227962    0.588826  0.057807  0.098248    0.588375   \n",
       "201   28.781591   62.755371    0.458632  0.704034  1.500387    0.469235   \n",
       "204    6.517498    3.358935    1.940346  0.076545  0.039542    1.935784   \n",
       "205   57.500515   50.311974    1.142879  3.593689  3.144496    1.142851   \n",
       "210   21.481438   20.713083    1.037095  0.253141  0.243359    1.040197   \n",
       "211    2.776436    3.292956    0.843144  0.122195  0.145305    0.840955   \n",
       "215   34.155495   73.755165    0.463093  0.837078  1.792213    0.467064   \n",
       "218    7.493422    3.122280    2.399984  0.088161  0.036642    2.405991   \n",
       "219   63.492413   47.654469    1.332350  3.968140  2.978401    1.332306   \n",
       "224   21.855965   21.130243    1.034345  0.257655  0.248375    1.037365   \n",
       "225    1.641315    3.123290    0.525508  0.072362  0.137754    0.525302   \n",
       "229   31.587980   59.614555    0.529870  0.757899  1.457768    0.519904   \n",
       "232    7.470176    2.893547    2.581667  0.087969  0.033970    2.589619   \n",
       "233   64.110390   43.221100    1.483312  4.006653  2.701313    1.483224   \n",
       "238   21.914175   21.914501    0.999985  0.258373  0.257723    1.002524   \n",
       "239    2.020492    4.783579    0.422381  0.089113  0.210982    0.422375   \n",
       "243   34.808437   71.422585    0.487359  0.841668  1.722112    0.488742   \n",
       "246    8.183807    3.338204    2.451560  0.096202  0.039203    2.453969   \n",
       "247   61.606770   41.250099    1.493494  3.850281  2.578124    1.493443   \n",
       "252   22.301815   22.705572    0.982218  0.262995  0.267114    0.984580   \n",
       "253    1.790116    3.660754    0.489002  0.078828  0.161438    0.488288   \n",
       "257   22.928190   56.085789    0.408806  0.555045  1.375809    0.403432   \n",
       "260    7.698030    3.559573    2.162627  0.090643  0.041870    2.164872   \n",
       "261   48.838367   42.235420    1.156337  3.052063  2.639706    1.156213   \n",
       "266   22.808533   24.000456    0.950337  0.269003  0.282359    0.952699   \n",
       "267    2.007612    6.082238    0.330078  0.088538  0.268124    0.330212   \n",
       "271   35.754414   62.438587    0.572633  0.869946  1.537322    0.565884   \n",
       "274    8.941700    3.825140    2.337614  0.105286  0.045020    2.338668   \n",
       "275   51.349850   41.333645    1.242326  3.208984  2.583346    1.242181   \n",
       "280   23.311581   25.515226    0.913634  0.274969  0.300217    0.915900   \n",
       "281    1.465116    6.631782    0.220923  0.064646  0.292640    0.220905   \n",
       "285   28.253962   73.820541    0.382738  0.678922  1.846360    0.367708   \n",
       "288    8.068832    3.979035    2.027836  0.094841  0.046862    2.023835   \n",
       "289   49.062431   39.149841    1.253196  3.066101  2.446855    1.253078   \n",
       "294   23.813595   26.737455    0.890646  0.280909  0.314663    0.892731   \n",
       "295    1.968177    8.135511    0.241924  0.086753  0.358591    0.241927   \n",
       "299   20.671974   69.679062    0.296674  0.504494  1.735003    0.290774   \n",
       "302    8.130106    4.244864    1.915281  0.095703  0.049928    1.916806   \n",
       "303   45.628685   45.220245    1.009032  2.851501  2.826259    1.008931   \n",
       "308   24.354338   27.943714    0.871550  0.287277  0.328794    0.873730   \n",
       "309    2.095639    6.838748    0.306436  0.092495  0.301488    0.306796   \n",
       "313   30.609915   63.275879    0.483753  0.740047  1.583948    0.467217   \n",
       "316    7.086284    4.431251    1.599161  0.083416  0.052161    1.599199   \n",
       "317   48.856133   45.227196    1.080238  3.053284  2.826689    1.080163   \n",
       "322   24.984646   29.704109    0.841118  0.294723  0.349499    0.843272   \n",
       "323    3.102937    8.542912    0.363218  0.136737  0.376948    0.362748   \n",
       "327   35.525059   69.673721    0.509877  0.861521  1.762080    0.488923   \n",
       "330    7.211089    4.750062    1.518104  0.084953  0.055942    1.518587   \n",
       "331   50.167828   45.486034    1.102928  3.135132  2.842865    1.102807   \n",
       "336   25.530970   31.090153    0.821191  0.301155  0.365806    0.823263   \n",
       "337    4.719140    9.508757    0.496294  0.207878  0.419451    0.495595   \n",
       "341   45.125446   82.335564    0.548068  1.115506  2.081787    0.535840   \n",
       "344    7.457499    4.945893    1.507816  0.087829  0.058246    1.507902   \n",
       "345   48.447563   45.497261    1.064846  3.027405  2.843565    1.064651   \n",
       "350   25.881824   32.060814    0.807273  0.305291  0.377249    0.809255   \n",
       "351    4.022617    9.215854    0.436489  0.177301  0.406466    0.436201   \n",
       "355   41.342270   76.011490    0.543895  1.010875  1.930578    0.523613   \n",
       "358    7.811490    5.258142    1.485599  0.092014  0.061970    1.484815   \n",
       "359   46.034271   46.470119    0.990621  2.876648  2.904363    0.990457   \n",
       "364   26.623869   33.157757    0.802945  0.314048  0.390296    0.804640   \n",
       "365    4.604096   11.638908    0.395578  0.202725  0.513562    0.394743   \n",
       "369   39.589603   78.118546    0.506789  0.964149  1.983653    0.486047   \n",
       "372    7.708518    5.781740    1.333252  0.090699  0.068131    1.331242   \n",
       "373   50.155056   47.134258    1.064089  3.134216  2.945873    1.063935   \n",
       "378   27.110918   34.026569    0.796757  0.319755  0.400636    0.798119   \n",
       "379    3.696667   12.212162    0.302704  0.163052  0.538561    0.302754   \n",
       "383   35.217964   79.873123    0.440924  0.859638  2.026072    0.424288   \n",
       "386    8.035164    5.331933    1.506989  0.094667  0.062801    1.507417   \n",
       "387   46.787014   50.976673    0.917812  2.923767  3.186023    0.917685   \n",
       "392   27.555099   34.934570    0.788763  0.324967  0.411490    0.789734   \n",
       "393    6.269969   14.672475    0.427329  0.275982  0.647391    0.426299   \n",
       "397   45.063992   70.867645    0.635890  1.096289  1.792945    0.611446   \n",
       "400    7.911266    5.675344    1.393971  0.093238  0.066889    1.393914   \n",
       "401   49.651878   48.342358    1.027089  3.102722  3.021368    1.026926   \n",
       "406   27.815681   35.910515    0.774583  0.328044  0.423096    0.775342   \n",
       "407    5.917262   15.048488    0.393213  0.260768  0.664242    0.392581   \n",
       "411   48.664703   70.438400    0.690883  1.224239  1.787476    0.684898   \n",
       "414    8.062296    5.988408    1.346317  0.094885  0.070541    1.345101   \n",
       "415   56.364899   50.260181    1.121462  3.522339  3.141231    1.121325   \n",
       "420   28.271057   36.425423    0.776135  0.333436  0.429238    0.776811   \n",
       "421    5.506713   13.684910    0.402393  0.242844  0.603910    0.402119   \n",
       "425   37.772858   72.382622    0.521850  0.920822  1.830573    0.503024   \n",
       "428    7.897707    6.376474    1.238569  0.092992  0.075150    1.237419   \n",
       "429   52.797226   57.852005    0.912626  3.299438  3.615731    0.912523   \n",
       "434   28.926723   37.828533    0.764680  0.341183  0.445842    0.765255   \n",
       "435    7.051957   16.307974    0.432424  0.310746  0.719584    0.431842   \n",
       "439   43.037724   68.926460    0.624401  1.048125  1.746784    0.600031   \n",
       "442    8.889240    5.830320    1.524657  0.104726  0.068708    1.524225   \n",
       "443   50.152832   49.721458    1.008676  3.134155  3.107569    1.008555   \n",
       "448   29.162882   38.999523    0.747775  0.343978  0.459724    0.748227   \n",
       "449    7.588762   16.664677    0.455380  0.334683  0.735415    0.455094   \n",
       "453   44.091393   65.182068    0.676434  1.081811  1.647552    0.656617   \n",
       "456    8.963466    5.802093    1.544868  0.105609  0.068305    1.546131   \n",
       "457   49.935829   58.862942    0.848341  3.120361  3.678916    0.848174   \n",
       "462   29.481527   39.809658    0.740562  0.347760  0.469333    0.740966   \n",
       "463    7.174768   17.283358    0.415126  0.316587  0.762202    0.415358   \n",
       "467   47.223068   58.363537    0.809119  1.170833  1.461844    0.800928   \n",
       "470    9.193699    5.759494    1.596268  0.108368  0.067819    1.597897   \n",
       "471   55.477261   60.892586    0.911068  3.466980  3.805771    0.910980   \n",
       "476   29.845907   40.668385    0.733885  0.352094  0.479449    0.734372   \n",
       "477    7.063729   16.081411    0.439248  0.311392  0.709224    0.439060   \n",
       "481   47.451469   63.553204    0.746642  1.183826  1.601308    0.739287   \n",
       "484    8.893102    6.090456    1.460170  0.104804  0.071727    1.461141   \n",
       "485   66.110176   59.661243    1.108093  4.131592  3.728813    1.108018   \n",
       "490   30.291435   41.269196    0.733996  0.357377  0.486644    0.734371   \n",
       "491    6.979453   16.766403    0.416276  0.307707  0.739226    0.416256   \n",
       "495   46.435028   64.891945    0.715575  1.163125  1.639507    0.709436   \n",
       "498    8.348124    6.535086    1.277431  0.098228  0.076935    1.276759   \n",
       "499   62.670074   57.402885    1.091758  3.916321  3.587661    1.091608   \n",
       "504   30.874731   42.265732    0.730491  0.364285  0.498457    0.730824   \n",
       "505    6.706844   17.553160    0.382088  0.295533  0.774706    0.381478   \n",
       "509   35.136681   64.073906    0.548377  0.831806  1.618070    0.514073   \n",
       "512    9.235064    5.547874    1.664613  0.108670  0.065206    1.666564   \n",
       "513   59.229416   60.786652    0.974382  3.701599  3.799148    0.974324   \n",
       "518   31.662472   42.784061    0.740053  0.373608  0.504624    0.740369   \n",
       "519    7.105305   20.455339    0.347357  0.313262  0.902194    0.347222   \n",
       "523   41.166149   53.906418    0.763660  1.018266  1.338238    0.760901   \n",
       "526    9.054070    5.683800    1.592961  0.106694  0.066828    1.596553   \n",
       "527   54.623924   64.535614    0.846415  3.413574  4.033462    0.846314   \n",
       "532   32.022961   44.180645    0.724819  0.377886  0.521095    0.725176   \n",
       "533    7.750358   26.224215    0.295542  0.341728  1.153692    0.296204   \n",
       "537   43.734512   55.419159    0.789159  1.098074  1.376326    0.797830   \n",
       "540    7.790635    6.803200    1.145143  0.091599  0.079999    1.145004   \n",
       "541   50.221333   65.443092    0.767405  3.138489  4.090182    0.767322   \n",
       "546   32.510365   45.550747    0.713717  0.383658  0.537274    0.714084   \n",
       "547    6.257142   28.256945    0.221437  0.275520  1.245100    0.221284   \n",
       "551   33.187252   53.744801    0.617497  0.774536  1.358157    0.570284   \n",
       "554    8.791056    7.212329    1.218893  0.103553  0.084969    1.218713   \n",
       "555   52.311253   66.598053    0.785477  3.269043  4.162371    0.785380   \n",
       "560   32.877995   46.196896    0.711693  0.388004  0.544937    0.712016   \n",
       "561    9.163482   20.797432    0.440606  0.404043  0.917130    0.440552   \n",
       "565   45.966934   62.618275    0.734082  1.153931  1.579965    0.730353   \n",
       "568    9.376526    5.662682    1.655845  0.110416  0.066587    1.658218   \n",
       "569   49.397831   76.283791    0.647553  3.086609  4.767734    0.647395   \n",
       "574   33.596287   47.076504    0.713653  0.396493  0.555336    0.713970   \n",
       "575    7.331695   25.284454    0.289968  0.322917  1.113093    0.290108   \n",
       "579   39.528179   56.054607    0.705173  0.972488  1.402409    0.693441   \n",
       "582    9.423832    7.284523    1.293679  0.111039  0.085643    1.296527   \n",
       "583   56.244713   76.695351    0.733352  3.514893  4.793457    0.733269   \n",
       "588   34.101860   48.291222    0.706171  0.402491  0.569678    0.706525   \n",
       "589    8.728246   28.171011    0.309831  0.384842  1.242149    0.309820   \n",
       "593   41.792419   46.897865    0.891137  1.032644  1.182349    0.873383   \n",
       "596    9.488783    7.310069    1.298043  0.111691  0.086062    1.297794   \n",
       "597   50.673882   76.044945    0.666368  3.166626  4.752805    0.666265   \n",
       "602   34.838112   49.710381    0.700822  0.411179  0.586426    0.701161   \n",
       "603   10.621462   32.936115    0.322487  0.467369  1.450579    0.322195   \n",
       "607   38.403057   47.869350    0.802247  0.946365  1.209708    0.782309   \n",
       "610   10.154673    5.561210    1.825983  0.119674  0.065080    1.838875   \n",
       "611   59.402397   82.002777    0.724395  3.712219  5.125168    0.724312   \n",
       "616   35.161789   50.851376    0.691462  0.415019  0.599913    0.691798   \n",
       "617    8.954658   25.348925    0.353256  0.394367  1.116485    0.353222   \n",
       "621   42.673195   41.494488    1.028406  1.042407  1.007337    1.034815   \n",
       "624    9.007144    7.582341    1.187911  0.106024  0.089159    1.189146   \n",
       "625   62.607937   69.010757    0.907220  3.912598  4.313168    0.907129   \n",
       "630   35.825687   51.863037    0.690775  0.422876  0.611889    0.691099   \n",
       "631   11.489024   28.782682    0.399164  0.504027  1.268909    0.397213   \n",
       "635   36.703445   51.659477    0.710488  0.911217  1.291001    0.705822   \n",
       "638    9.939654    7.779192    1.277723  0.117046  0.091431    1.280159   \n",
       "639   78.499130   92.225677    0.851164  4.906006  5.764103    0.851131   \n",
       "644   36.447720   53.549477    0.680636  0.430233  0.631791    0.680974   \n",
       "645    8.718669   36.422890    0.239373  0.382303  1.600676    0.238838   \n",
       "649   32.507000   36.828556    0.882657  0.769394  0.919811    0.836469   \n",
       "652    8.800538    6.867566    1.281464  0.103454  0.080651    1.282742   \n",
       "653   72.554260   98.685097    0.735210  4.534424  6.167814    0.735175   \n",
       "658   37.153988   55.376076    0.670939  0.438575  0.653352    0.671269   \n",
       "659    7.115090   47.734306    0.149056  0.313553  2.088741    0.150116   \n",
       "663   35.043316   43.275734    0.809768  0.841964  1.084227    0.776557   \n",
       "666    9.160581    6.904369    1.326780  0.107597  0.081167    1.325630   \n",
       "667   75.652328  128.706833    0.587788  4.728149  8.044176    0.587773   \n",
       "672   37.708935   56.685688    0.665228  0.445136  0.668839    0.665535   \n",
       "673    6.742046   32.763737    0.205778  0.295794  1.444372    0.204791   \n",
       "677   29.981049   38.430950    0.780128  0.686651  0.953880    0.719851   \n",
       "680    8.295721    7.969981    1.040871  0.097570  0.093675    1.041584   \n",
       "681   61.280964  102.592842    0.597322  3.829773  6.412050    0.597277   \n",
       "686   38.697121   58.836311    0.657708  0.456815  0.694219    0.658027   \n",
       "687    8.011235   35.228909    0.227405  0.351188  1.553320    0.226089   \n",
       "691   23.515059   45.900337    0.512307  0.551928  1.145307    0.481904   \n",
       "694   10.215260    7.529285    1.356737  0.120324  0.088465    1.360138   \n",
       "695   81.724022  115.252037    0.709090  5.107544  7.203250    0.709061   \n",
       "700   39.805771   60.309048    0.660030  0.469902  0.711620    0.660327   \n",
       "701   12.517245   37.646488    0.332494  0.549931  1.656654    0.331953   \n",
       "705   32.272610   35.608696    0.906313  0.802544  0.886374    0.905423   \n",
       "708   10.227710    6.190627    1.652128  0.120510  0.072577    1.660446   \n",
       "709   65.781540  103.148209    0.637738  4.111206  6.446762    0.637716   \n",
       "714   40.384220   61.571194    0.655895  0.476740  0.726491    0.656223   \n",
       "715    8.126939   33.346466    0.243712  0.358415  1.467971    0.244156   \n",
       "719   37.580723   48.322044    0.777714  0.902179  1.196343    0.754114   \n",
       "722    9.311213    7.520018    1.238190  0.109624  0.088333    1.241025   \n",
       "723   72.959496  101.678253    0.717553  4.559570  6.354887    0.717490   \n",
       "728   41.616852   63.846737    0.651824  0.491295  0.753357    0.652141   \n",
       "729    9.611343   37.183098    0.258487  0.422691  1.638337    0.258000   \n",
       "733   34.930744   36.876457    0.947237  0.849323  0.912941    0.930315   \n",
       "736   10.748524    7.695841    1.396667  0.126456  0.090483    1.397565   \n",
       "737   59.888145  100.560814    0.595542  3.742798  6.285046    0.595508   \n",
       "742   42.831245   66.664520    0.642489  0.505628  0.786597    0.642805   \n",
       "743    9.470158   32.872959    0.288084  0.416720  1.447085    0.287972   \n",
       "747   24.918390   34.973537    0.712493  0.613342  0.869858    0.705106   \n",
       "750    9.168660    7.409281    1.237456  0.107799  0.087114    1.237447   \n",
       "751  100.741928   98.467979    1.023093  6.296143  6.154246    1.023057   \n",
       "756   43.947289   67.934235    0.646909  0.518812  0.801556    0.647256   \n",
       "757    8.110057   40.890011    0.198338  0.353097  1.802124    0.195934   \n",
       "761   25.249483   32.930283    0.766756  0.596802  0.801044    0.745031   \n",
       "764    9.544826    7.688483    1.241445  0.112135  0.090386    1.240623   \n",
       "765   71.458214   49.634304    1.439694  4.465942  3.102138    1.439634   \n",
       "770   45.374569   70.578873    0.642892  0.535663  0.832640    0.643331   \n",
       "771    7.315055   43.304157    0.168923  0.315494  1.907967    0.165356   \n",
       "775   20.395445   38.993725    0.523044  0.461432  0.971314    0.475060   \n",
       "778    9.346161    8.306944    1.125102  0.109936  0.097532    1.127175   \n",
       "779   75.489738   43.398766    1.739444  4.717896  2.712412    1.739372   \n",
       "784   46.954895   72.460052    0.648011  0.554308  0.854545    0.648659   \n",
       "785    8.712090   35.579922    0.244860  0.382761  1.567657    0.244161   \n",
       "789   26.489454   33.930782    0.780691  0.623040  0.826527    0.753805   \n",
       "792    9.111650    5.735451    1.588655  0.107061  0.067206    1.593023   \n",
       "793   73.364540   38.575268    1.901854  4.584961  2.410940    1.901732   \n",
       "798   48.476753   71.995995    0.673326  0.572268  0.848505    0.674443   \n",
       "799    9.402333   35.996288    0.261203  0.397639  1.578283    0.251944   \n",
       "803   19.423687   41.781937    0.464882  0.452640  1.000939    0.452216   \n",
       "806    8.886652    6.214496    1.429988  0.104353  0.072141    1.446505   \n",
       "807   63.740585   37.870277    1.683130  3.983276  2.366880    1.682922   \n",
       "812   50.561478   69.906929    0.723268  0.596867  0.823406    0.724877   \n",
       "813    8.999374   38.314774    0.234880  0.387518  1.659230    0.233553   \n",
       "817   15.078004   29.374578    0.513301  0.340074  0.678578    0.501156   \n",
       "820   11.322188    8.784041    1.288950  0.133168  0.102669    1.297055   \n",
       "821   59.812157   35.747231    1.673197  3.737732  2.234153    1.672998   \n",
       "826   53.454762   59.229683    0.902500  0.630971  0.695732    0.906917   \n",
       "827    9.440676   41.729496    0.226235  0.414216  1.828960    0.226476   \n",
       "831   19.711937   36.543213    0.539414  0.480752  0.884226    0.543699   \n",
       "834    9.121619    5.163881    1.766427  0.107321  0.059979    1.789316   \n",
       "835   64.962166   56.208115    1.155744  4.059692  3.512983    1.155625   \n",
       "840   55.236790   35.182590    1.570004  0.651910  0.409948    1.590227   \n",
       "841   11.628647   33.892223    0.343107  0.511723  1.465570    0.349163   \n",
       "845   26.197701   28.950804    0.904904  0.617749  0.643727    0.959645   \n",
       "\n",
       "        std_a     std_b  std_ratio  zero_frac_a  zero_frac_b   cos_sim  \\\n",
       "0    0.022791  0.014067   1.620160          0.0          0.0  0.883294   \n",
       "4    0.008790  0.016035   0.548183          0.0          0.0  0.645940   \n",
       "5    0.003816  0.007539   0.506165          0.0          0.0  0.550863   \n",
       "9    0.082398  0.083180   0.990599          0.0          0.0  0.905126   \n",
       "12   0.023877  0.016881   1.414466          0.0          0.0  0.853763   \n",
       "16   0.033429  0.041884   0.798134          0.0          0.0  0.607914   \n",
       "17   0.002869  0.008241   0.348181          0.0          0.0  0.498078   \n",
       "21   0.067022  0.153560   0.436454          0.0          0.0  0.813170   \n",
       "24   0.026269  0.019253   1.364385          0.0          0.0  0.894958   \n",
       "28   0.027699  0.019384   1.428917          0.0          0.0  0.798047   \n",
       "29   0.002326  0.007801   0.298212          0.0          0.0  0.556629   \n",
       "33   0.043489  0.162842   0.267065          0.0          0.0  0.897100   \n",
       "36   0.029036  0.011767   2.467632          0.0          0.0  0.930285   \n",
       "37   0.014595  0.002173   6.715944          0.0          0.0  0.999997   \n",
       "42   0.034600  0.052612   0.657652          0.0          0.0  0.825780   \n",
       "43   0.011980  0.009374   1.278002          0.0          0.0  0.506418   \n",
       "47   0.076888  0.168193   0.457143          0.0          0.0  0.916142   \n",
       "50   0.021338  0.014504   1.471112          0.0          0.0  0.909860   \n",
       "51   0.008470  0.001803   4.698055          0.0          0.0  0.999999   \n",
       "56   0.038199  0.059355   0.643564          0.0          0.0  0.829575   \n",
       "57   0.002847  0.022251   0.127971          0.0          0.0  0.798677   \n",
       "61   0.055281  0.224259   0.246504          0.0          0.0  0.941680   \n",
       "64   0.024525  0.016782   1.461375          0.0          0.0  0.939693   \n",
       "65   0.015421  0.001900   8.115402          0.0          0.0  0.999998   \n",
       "70   0.039780  0.063898   0.622563          0.0          0.0  0.857210   \n",
       "71   0.002086  0.004320   0.482850          0.0          0.0  0.942494   \n",
       "75   0.082129  0.254837   0.322280          0.0          0.0  0.904794   \n",
       "78   0.020674  0.011933   1.732541          0.0          0.0  0.954217   \n",
       "79   0.019627  0.002006   9.784381          0.0          0.0  0.999996   \n",
       "84   0.037405  0.051966   0.719793          0.0          0.0  0.915626   \n",
       "85   0.002342  0.002376   0.985429          0.0          0.0  0.911585   \n",
       "89   0.071755  0.247687   0.289699          0.0          0.0  0.888783   \n",
       "92   0.017790  0.011218   1.585890          0.0          0.0  0.965007   \n",
       "93   0.017590  0.002712   6.487113          0.0          0.0  0.999997   \n",
       "98   0.031355  0.047757   0.656547          0.0          0.0  0.940211   \n",
       "99   0.004040  0.003441   1.174130          0.0          0.0  0.970948   \n",
       "103  0.107981  0.333213   0.324059          0.0          0.0  0.892380   \n",
       "106  0.018435  0.012914   1.427530          0.0          0.0  0.964222   \n",
       "107  0.026832  0.002409  11.140157          0.0          0.0  0.999990   \n",
       "112  0.029228  0.042554   0.686859          0.0          0.0  0.960529   \n",
       "113  0.001471  0.005339   0.275604          0.0          0.0  0.965048   \n",
       "117  0.107487  0.288125   0.373056          0.0          0.0  0.847762   \n",
       "120  0.017277  0.005085   3.397628          0.0          0.0  0.975138   \n",
       "121  0.022561  0.002918   7.730451          0.0          0.0  0.999992   \n",
       "126  0.028520  0.037421   0.762141          0.0          0.0  0.971939   \n",
       "127  0.001830  0.008966   0.204072          0.0          0.0  0.985790   \n",
       "131  0.106005  0.439884   0.240985          0.0          0.0  0.897370   \n",
       "134  0.016160  0.004346   3.718390          0.0          0.0  0.981753   \n",
       "135  0.027689  0.002476  11.181231          0.0          0.0  0.999984   \n",
       "140  0.027121  0.032928   0.823633          0.0          0.0  0.980439   \n",
       "141  0.002050  0.005975   0.343094          0.0          0.0  0.989113   \n",
       "145  0.112010  0.479122   0.233783          0.0          0.0  0.904946   \n",
       "148  0.012362  0.005079   2.433828          0.0          0.0  0.983285   \n",
       "149  0.025554  0.003380   7.560077          0.0          0.0  0.999984   \n",
       "154  0.024059  0.031279   0.769164          0.0          0.0  0.984686   \n",
       "155  0.003232  0.007670   0.421386          0.0          0.0  0.993276   \n",
       "159  0.165902  0.522651   0.317425          0.0          0.0  0.881890   \n",
       "162  0.012566  0.005869   2.141295          0.0          0.0  0.988693   \n",
       "163  0.023356  0.003359   6.953601          0.0          0.0  0.999985   \n",
       "168  0.022324  0.029136   0.766179          0.0          0.0  0.988117   \n",
       "169  0.001791  0.003091   0.579381          0.0          0.0  0.994731   \n",
       "173  0.128579  0.399498   0.321853          0.0          0.0  0.878062   \n",
       "176  0.009948  0.004613   2.156290          0.0          0.0  0.991157   \n",
       "177  0.022247  0.004548   4.891450          0.0          0.0  0.999981   \n",
       "182  0.020467  0.028020   0.730448          0.0          0.0  0.989647   \n",
       "183  0.002114  0.004331   0.488275          0.0          0.0  0.996613   \n",
       "187  0.178766  0.565957   0.315864          0.0          0.0  0.862326   \n",
       "190  0.008832  0.004293   2.057549          0.0          0.0  0.991078   \n",
       "191  0.027581  0.003806   7.246110          0.0          0.0  0.999971   \n",
       "196  0.018778  0.026780   0.701217          0.0          0.0  0.991036   \n",
       "197  0.004447  0.006502   0.683947          0.0          0.0  0.994724   \n",
       "201  0.208918  0.559280   0.373548          0.0          0.0  0.894577   \n",
       "204  0.008178  0.003228   2.533557          0.0          0.0  0.991017   \n",
       "205  0.025893  0.003951   6.552856          0.0          0.0  0.999974   \n",
       "210  0.017214  0.025106   0.685666          0.0          0.0  0.992444   \n",
       "211  0.011143  0.008074   1.380246          0.0          0.0  0.994207   \n",
       "215  0.242495  0.574041   0.422434          0.0          0.0  0.915188   \n",
       "218  0.007829  0.004168   1.878375          0.0          0.0  0.989703   \n",
       "219  0.032880  0.004409   7.457530          0.0          0.0  0.999965   \n",
       "224  0.015965  0.024475   0.652296          0.0          0.0  0.993296   \n",
       "225  0.005022  0.008743   0.574459          0.0          0.0  0.995508   \n",
       "229  0.274224  0.434334   0.631367          0.0          0.0  0.903922   \n",
       "232  0.006826  0.003756   1.817235          0.0          0.0  0.991019   \n",
       "233  0.044437  0.005491   8.092406          0.0          0.0  0.999936   \n",
       "238  0.015482  0.024030   0.644272          0.0          0.0  0.993903   \n",
       "239  0.005676  0.013395   0.423756          0.0          0.0  0.995916   \n",
       "243  0.283576  0.596166   0.475666          0.0          0.0  0.903039   \n",
       "246  0.009420  0.004217   2.233580          0.0          0.0  0.989407   \n",
       "247  0.033121  0.006175   5.364066          0.0          0.0  0.999960   \n",
       "252  0.014873  0.023937   0.621356          0.0          0.0  0.994430   \n",
       "253  0.006702  0.010574   0.633824          0.0          0.0  0.994356   \n",
       "257  0.184876  0.393799   0.469468          0.0          0.0  0.911530   \n",
       "260  0.007147  0.003816   1.872844          0.0          0.0  0.992685   \n",
       "261  0.045226  0.006380   7.089037          0.0          0.0  0.999887   \n",
       "266  0.014632  0.025175   0.581225          0.0          0.0  0.994609   \n",
       "267  0.005758  0.019046   0.302330          0.0          0.0  0.995424   \n",
       "271  0.274722  0.418063   0.657131          0.0          0.0  0.916838   \n",
       "274  0.008313  0.003805   2.184911          0.0          0.0  0.993408   \n",
       "275  0.049468  0.005968   8.288301          0.0          0.0  0.999876   \n",
       "280  0.014334  0.026338   0.544243          0.0          0.0  0.994853   \n",
       "281  0.003669  0.016166   0.226973          0.0          0.0  0.996860   \n",
       "285  0.242451  0.372544   0.650799          0.0          0.0  0.922038   \n",
       "288  0.009387  0.003573   2.626806          0.0          0.0  0.992202   \n",
       "289  0.042962  0.007017   6.122201          0.0          0.0  0.999899   \n",
       "294  0.014269  0.026851   0.531409          0.0          0.0  0.995125   \n",
       "295  0.006310  0.026143   0.241362          0.0          0.0  0.994746   \n",
       "299  0.153935  0.388182   0.396555          0.0          0.0  0.933343   \n",
       "302  0.007894  0.004578   1.724252          0.0          0.0  0.992411   \n",
       "303  0.040759  0.006139   6.639153          0.0          0.0  0.999896   \n",
       "308  0.014813  0.028817   0.514052          0.0          0.0  0.994902   \n",
       "309  0.004707  0.021204   0.221986          0.0          0.0  0.996246   \n",
       "313  0.249668  0.312690   0.798453          0.0          0.0  0.929085   \n",
       "316  0.006879  0.004317   1.593569          0.0          0.0  0.993147   \n",
       "317  0.037031  0.007708   4.804199          0.0          0.0  0.999925   \n",
       "322  0.014977  0.030719   0.487557          0.0          0.0  0.994913   \n",
       "323  0.010400  0.021266   0.489043          0.0          0.0  0.995580   \n",
       "327  0.281808  0.235603   1.196113          0.0          0.0  0.942352   \n",
       "330  0.006124  0.004274   1.432913          0.0          0.0  0.994543   \n",
       "331  0.047344  0.008142   5.814858          0.0          0.0  0.999876   \n",
       "336  0.015559  0.032169   0.483660          0.0          0.0  0.994878   \n",
       "337  0.016840  0.025611   0.657540          0.0          0.0  0.994767   \n",
       "341  0.285250  0.282257   1.010603          0.0          0.0  0.960780   \n",
       "344  0.006686  0.004477   1.493226          0.0          0.0  0.994162   \n",
       "345  0.058638  0.008702   6.738204          0.0          0.0  0.999805   \n",
       "350  0.015817  0.032919   0.480492          0.0          0.0  0.994920   \n",
       "351  0.012989  0.025848   0.502537          0.0          0.0  0.995297   \n",
       "355  0.301465  0.185537   1.624824          0.0          0.0  0.954527   \n",
       "358  0.006798  0.004109   1.654349          0.0          0.0  0.995086   \n",
       "359  0.053311  0.010601   5.029110          0.0          0.0  0.999824   \n",
       "364  0.016193  0.032409   0.499652          0.0          0.0  0.995293   \n",
       "365  0.017446  0.028851   0.604701          0.0          0.0  0.994639   \n",
       "369  0.301361  0.195206   1.543809          0.0          0.0  0.950860   \n",
       "372  0.007964  0.004658   1.709746          0.0          0.0  0.993821   \n",
       "373  0.054547  0.010464   5.212838          0.0          0.0  0.999838   \n",
       "378  0.017211  0.031868   0.540078          0.0          0.0  0.995455   \n",
       "379  0.010213  0.035146   0.290581          0.0          0.0  0.996120   \n",
       "383  0.261751  0.220215   1.188613          0.0          0.0  0.951564   \n",
       "386  0.006739  0.004716   1.428983          0.0          0.0  0.994672   \n",
       "387  0.049634  0.010931   4.540858          0.0          0.0  0.999847   \n",
       "392  0.017971  0.030599   0.587316          0.0          0.0  0.995759   \n",
       "393  0.024823  0.036839   0.673809          0.0          0.0  0.994243   \n",
       "397  0.346788  0.234576   1.478360          0.0          0.0  0.944099   \n",
       "400  0.006193  0.004401   1.407177          0.0          0.0  0.995635   \n",
       "401  0.056814  0.013268   4.282165          0.0          0.0  0.999829   \n",
       "406  0.018078  0.029927   0.604075          0.0          0.0  0.996039   \n",
       "407  0.019661  0.032893   0.597711          0.0          0.0  0.995877   \n",
       "411  0.207536  0.187394   1.107484          0.0          0.0  0.980962   \n",
       "414  0.008068  0.005189   1.554713          0.0          0.0  0.993743   \n",
       "415  0.057383  0.013913   4.124401          0.0          0.0  0.999854   \n",
       "420  0.017977  0.029278   0.614034          0.0          0.0  0.996270   \n",
       "421  0.015916  0.032671   0.487159          0.0          0.0  0.996577   \n",
       "425  0.284580  0.244887   1.162086          0.0          0.0  0.948715   \n",
       "428  0.007365  0.004987   1.476727          0.0          0.0  0.994669   \n",
       "429  0.050604  0.011978   4.224644          0.0          0.0  0.999876   \n",
       "434  0.018136  0.029355   0.617827          0.0          0.0  0.996473   \n",
       "435  0.023786  0.040404   0.588696          0.0          0.0  0.995470   \n",
       "439  0.327602  0.204331   1.603295          0.0          0.0  0.949915   \n",
       "442  0.007496  0.004636   1.616956          0.0          0.0  0.995147   \n",
       "443  0.049873  0.011742   4.247295          0.0          0.0  0.999865   \n",
       "448  0.018111  0.029019   0.624090          0.0          0.0  0.996667   \n",
       "449  0.021598  0.039613   0.545209          0.0          0.0  0.996482   \n",
       "453  0.308776  0.227272   1.358615          0.0          0.0  0.951048   \n",
       "456  0.007443  0.005554   1.340201          0.0          0.0  0.994311   \n",
       "457  0.062602  0.011302   5.539257          0.0          0.0  0.999794   \n",
       "462  0.017858  0.028667   0.622939          0.0          0.0  0.996857   \n",
       "463  0.017728  0.049744   0.356394          0.0          0.0  0.996299   \n",
       "467  0.284580  0.284001   1.002038          0.0          0.0  0.953887   \n",
       "470  0.006946  0.005322   1.305079          0.0          0.0  0.994887   \n",
       "471  0.049176  0.011060   4.446198          0.0          0.0  0.999898   \n",
       "476  0.017365  0.029415   0.590349          0.0          0.0  0.996936   \n",
       "477  0.022105  0.045857   0.482038          0.0          0.0  0.995443   \n",
       "481  0.253906  0.255691   0.993022          0.0          0.0  0.966334   \n",
       "484  0.007042  0.005487   1.283483          0.0          0.0  0.994877   \n",
       "485  0.049318  0.010502   4.696288          0.0          0.0  0.999925   \n",
       "490  0.017059  0.027967   0.609970          0.0          0.0  0.997244   \n",
       "491  0.021415  0.050917   0.420588          0.0          0.0  0.995037   \n",
       "495  0.225664  0.231369   0.975343          0.0          0.0  0.971872   \n",
       "498  0.008589  0.006244   1.375659          0.0          0.0  0.993009   \n",
       "499  0.066166  0.011883   5.568248          0.0          0.0  0.999849   \n",
       "504  0.016837  0.027533   0.611524          0.0          0.0  0.997428   \n",
       "505  0.022693  0.040184   0.564736          0.0          0.0  0.995718   \n",
       "509  0.334463  0.233835   1.430339          0.0          0.0  0.919561   \n",
       "512  0.009438  0.006490   1.454245          0.0          0.0  0.991455   \n",
       "513  0.042101  0.011662   3.609935          0.0          0.0  0.999931   \n",
       "518  0.016627  0.026882   0.618512          0.0          0.0  0.997613   \n",
       "519  0.021713  0.057221   0.379456          0.0          0.0  0.995635   \n",
       "523  0.257726  0.317778   0.811025          0.0          0.0  0.941210   \n",
       "526  0.007271  0.006403   1.135575          0.0          0.0  0.993166   \n",
       "527  0.053611  0.010445   5.132750          0.0          0.0  0.999871   \n",
       "532  0.016271  0.027781   0.585676          0.0          0.0  0.997674   \n",
       "533  0.023286  0.110348   0.211025          0.0          0.0  0.993915   \n",
       "537  0.198711  0.324437   0.612478          0.0          0.0  0.960291   \n",
       "540  0.008773  0.007559   1.160577          0.0          0.0  0.991130   \n",
       "541  0.046510  0.009374   4.961665          0.0          0.0  0.999888   \n",
       "546  0.016016  0.028283   0.566285          0.0          0.0  0.997761   \n",
       "547  0.023600  0.095960   0.245937          0.0          0.0  0.993192   \n",
       "551  0.342269  0.189595   1.805263          0.0          0.0  0.903270   \n",
       "554  0.007645  0.006101   1.253185          0.0          0.0  0.994757   \n",
       "555  0.051802  0.007870   6.582301          0.0          0.0  0.999869   \n",
       "560  0.016016  0.027869   0.574693          0.0          0.0  0.997859   \n",
       "561  0.027419  0.060538   0.452929          0.0          0.0  0.995574   \n",
       "565  0.209921  0.237649   0.883324          0.0          0.0  0.973735   \n",
       "568  0.008593  0.006297   1.364716          0.0          0.0  0.992557   \n",
       "569  0.068300  0.005581  12.237870          0.0          0.0  0.999756   \n",
       "574  0.016069  0.027954   0.574828          0.0          0.0  0.997923   \n",
       "575  0.026685  0.098306   0.271452          0.0          0.0  0.993042   \n",
       "579  0.267403  0.280891   0.951982          0.0          0.0  0.944913   \n",
       "582  0.007744  0.008256   0.937994          0.0          0.0  0.993074   \n",
       "583  0.053162  0.005657   9.397799          0.0          0.0  0.999885   \n",
       "588  0.015515  0.028427   0.545773          0.0          0.0  0.998028   \n",
       "589  0.026264  0.084122   0.312219          0.0          0.0  0.995281   \n",
       "593  0.266009  0.184280   1.443500          0.0          0.0  0.960473   \n",
       "596  0.009275  0.006944   1.335782          0.0          0.0  0.993381   \n",
       "597  0.055802  0.006621   8.428227          0.0          0.0  0.999848   \n",
       "602  0.015907  0.029127   0.546113          0.0          0.0  0.998030   \n",
       "603  0.043690  0.120613   0.362235          0.0          0.0  0.993350   \n",
       "607  0.254058  0.168674   1.506205          0.0          0.0  0.956671   \n",
       "610  0.007999  0.008900   0.898730          0.0          0.0  0.988647   \n",
       "611  0.056542  0.007346   7.696503          0.0          0.0  0.999884   \n",
       "616  0.015536  0.029243   0.531268          0.0          0.0  0.998119   \n",
       "617  0.032978  0.092069   0.358190          0.0          0.0  0.993002   \n",
       "621  0.314540  0.325932   0.965049          0.0          0.0  0.913275   \n",
       "624  0.008785  0.008439   1.040899          0.0          0.0  0.992221   \n",
       "625  0.055842  0.006192   9.018509          0.0          0.0  0.999897   \n",
       "630  0.015270  0.028975   0.526981          0.0          0.0  0.998236   \n",
       "631  0.061354  0.089001   0.689369          0.0          0.0  0.990339   \n",
       "635  0.216169  0.265993   0.812687          0.0          0.0  0.951792   \n",
       "638  0.009121  0.009103   1.002010          0.0          0.0  0.992180   \n",
       "639  0.043145  0.004212  10.242859          0.0          0.0  0.999961   \n",
       "644  0.015107  0.029817   0.506673          0.0          0.0  0.998277   \n",
       "645  0.048081  0.170018   0.282798          0.0          0.0  0.987526   \n",
       "649  0.309826  0.192308   1.611090          0.0          0.0  0.909879   \n",
       "652  0.010104  0.008669   1.165501          0.0          0.0  0.989623   \n",
       "653  0.044425  0.007199   6.170753          0.0          0.0  0.999951   \n",
       "658  0.015262  0.030606   0.498673          0.0          0.0  0.998305   \n",
       "659  0.023677  0.295770   0.080051          0.0          0.0  0.986884   \n",
       "663  0.300994  0.209081   1.439601          0.0          0.0  0.927824   \n",
       "666  0.011395  0.007895   1.443225          0.0          0.0  0.989851   \n",
       "667  0.033820  0.004340   7.792107          0.0          0.0  0.999974   \n",
       "672  0.015196  0.030555   0.497328          0.0          0.0  0.998384   \n",
       "673  0.035853  0.101958   0.351643          0.0          0.0  0.990906   \n",
       "677  0.337205  0.227290   1.483593          0.0          0.0  0.873983   \n",
       "680  0.008992  0.009310   0.965903          0.0          0.0  0.990946   \n",
       "681  0.046917  0.005671   8.273088          0.0          0.0  0.999925   \n",
       "686  0.015166  0.031615   0.479692          0.0          0.0  0.998416   \n",
       "687  0.044926  0.105702   0.425028          0.0          0.0  0.989774   \n",
       "691  0.235317  0.244770   0.961379          0.0          0.0  0.901897   \n",
       "694  0.008951  0.009100   0.983629          0.0          0.0  0.992116   \n",
       "695  0.046018  0.005226   8.805516          0.0          0.0  0.999959   \n",
       "700  0.015629  0.031877   0.490270          0.0          0.0  0.998449   \n",
       "701  0.059952  0.153553   0.390433          0.0          0.0  0.988923   \n",
       "705  0.184383  0.199620   0.923668          0.0          0.0  0.948857   \n",
       "708  0.008411  0.008893   0.945764          0.0          0.0  0.990221   \n",
       "709  0.033977  0.004862   6.987781          0.0          0.0  0.999966   \n",
       "714  0.015557  0.033018   0.471176          0.0          0.0  0.998444   \n",
       "715  0.023179  0.130038   0.178247          0.0          0.0  0.993983   \n",
       "719  0.324878  0.298259   1.089246          0.0          0.0  0.909388   \n",
       "722  0.008825  0.009304   0.948531          0.0          0.0  0.991443   \n",
       "723  0.060255  0.006565   9.178478          0.0          0.0  0.999912   \n",
       "728  0.015909  0.033881   0.469553          0.0          0.0  0.998470   \n",
       "729  0.041927  0.127317   0.329312          0.0          0.0  0.992558   \n",
       "733  0.270228  0.227754   1.186487          0.0          0.0  0.921500   \n",
       "736  0.011248  0.008683   1.295368          0.0          0.0  0.991587   \n",
       "737  0.039760  0.007540   5.273404          0.0          0.0  0.999943   \n",
       "742  0.016480  0.035570   0.463301          0.0          0.0  0.998452   \n",
       "743  0.038838  0.128654   0.301876          0.0          0.0  0.991293   \n",
       "747  0.167512  0.199167   0.841066          0.0          0.0  0.939840   \n",
       "750  0.010353  0.008360   1.238439          0.0          0.0  0.990979   \n",
       "751  0.053555  0.005359   9.993901          0.0          0.0  0.999964   \n",
       "756  0.016625  0.036743   0.452475          0.0          0.0  0.998444   \n",
       "757  0.061525  0.134016   0.459085          0.0          0.0  0.983217   \n",
       "761  0.242672  0.253614   0.956855          0.0          0.0  0.880664   \n",
       "764  0.011644  0.008784   1.325586          0.0          0.0  0.990068   \n",
       "765  0.041841  0.006085   6.876036          0.0          0.0  0.999954   \n",
       "770  0.017126  0.040710   0.420680          0.0          0.0  0.998302   \n",
       "771  0.070538  0.149193   0.472793          0.0          0.0  0.972362   \n",
       "775  0.240618  0.215558   1.116256          0.0          0.0  0.861877   \n",
       "778  0.010014  0.010692   0.936658          0.0          0.0  0.990058   \n",
       "779  0.044829  0.007538   5.947058          0.0          0.0  0.999953   \n",
       "784  0.018072  0.047314   0.381947          0.0          0.0  0.997948   \n",
       "785  0.041680  0.122358   0.340643          0.0          0.0  0.991023   \n",
       "789  0.262014  0.257674   1.016844          0.0          0.0  0.871921   \n",
       "792  0.010963  0.008514   1.287539          0.0          0.0  0.986934   \n",
       "793  0.054399  0.008391   6.482912          0.0          0.0  0.999920   \n",
       "798  0.018818  0.056335   0.334038          0.0          0.0  0.997274   \n",
       "799  0.120610  0.199375   0.604943          0.0          0.0  0.948076   \n",
       "803  0.201845  0.366966   0.550038          0.0          0.0  0.855079   \n",
       "806  0.011306  0.013544   0.834777          0.0          0.0  0.977215   \n",
       "807  0.063759  0.007507   8.493230          0.0          0.0  0.999871   \n",
       "812  0.019971  0.061486   0.324797          0.0          0.0  0.996672   \n",
       "813  0.089502  0.337913   0.264867          0.0          0.0  0.952422   \n",
       "817  0.179894  0.318267   0.565230          0.0          0.0  0.804283   \n",
       "820  0.012258  0.014947   0.820073          0.0          0.0  0.985603   \n",
       "821  0.062813  0.014845   4.231378          0.0          0.0  0.999832   \n",
       "826  0.022578  0.073319   0.307945          0.0          0.0  0.993864   \n",
       "827  0.050000  0.236600   0.211326          0.0          0.0  0.984470   \n",
       "831  0.147805  0.295889   0.499527          0.0          0.0  0.908353   \n",
       "834  0.009481  0.011074   0.856086          0.0          0.0  0.979456   \n",
       "835  0.059959  0.012955   4.628320          0.0          0.0  0.999894   \n",
       "840  0.025884  0.068038   0.380428          0.0          0.0  0.985737   \n",
       "841  0.047457  0.309232   0.153468          0.0          0.0  0.975739   \n",
       "845  0.255360  0.362334   0.704765          0.0          0.0  0.803287   \n",
       "\n",
       "     rel_l2_err  mean_rel_diff  max_rel_diff   pearson  max_abs_diff  \\\n",
       "0      0.505120       0.325193      5.045249  0.003609      0.272217   \n",
       "4      0.964386       1.760695   4720.670898  0.007855      0.676208   \n",
       "5      1.277797       2.887821     84.512604 -0.015007      0.068909   \n",
       "9      1.312957       1.929219     23.032129  0.012730      1.400146   \n",
       "12     0.522459       0.437025     12.734513 -0.000896      0.185303   \n",
       "16     0.948953       1.461620    755.537292 -0.008112      0.530029   \n",
       "17     2.528081      19.070650   1066.807495  0.004631      0.041565   \n",
       "21     2.581912       5.037098    172.381821 -0.004717      0.845947   \n",
       "24     0.468261       0.384318     10.901235  0.021790      0.197266   \n",
       "28     0.607275       0.457887     44.881279  0.011214      0.599915   \n",
       "29     3.169114      14.854513   1442.955078 -0.007952      0.031369   \n",
       "33     2.147197       2.239266     25.785185 -0.009041      0.907227   \n",
       "36     0.525156       0.416418      3.993939 -0.005894      0.352295   \n",
       "37     0.208720       0.208703      0.211952  0.077591      1.331326   \n",
       "42     0.798445       2.027711    500.894745 -0.020555      0.302460   \n",
       "43     1.105839      18.509750   2520.660645 -0.080960      0.044434   \n",
       "47     0.607787       0.518893      4.371428  0.002373      0.888672   \n",
       "50     0.506939       0.391246      3.827586  0.012733      0.244629   \n",
       "51     0.115205       0.115199      0.121158  0.032667      0.711805   \n",
       "56     0.582046       0.915274    263.826660 -0.028770      0.319336   \n",
       "57     6.717411      16.174299   2135.943359  0.023826      0.120544   \n",
       "61     3.579740       3.865564     11.202021 -0.026300      1.583984   \n",
       "64     0.418997       0.326038     11.643903  0.002794      0.348633   \n",
       "65     0.057788       0.057752      0.072176  0.069558      0.507486   \n",
       "70     0.541476       0.719009     83.879433 -0.023657      0.298401   \n",
       "71     2.809685       5.259251    399.822845 -0.069843      0.033981   \n",
       "75     1.614500       1.662392     10.543379 -0.035047      1.167969   \n",
       "78     0.331784       0.236818      3.896552 -0.002211      0.307129   \n",
       "79     0.189332       0.189308      0.193728  0.002269      1.440852   \n",
       "84     0.442103       0.496128     21.127659 -0.021555      0.230469   \n",
       "85     2.480313       4.264627    114.911110 -0.046069      0.031281   \n",
       "89     2.485110       2.776003     11.489796 -0.003180      1.109375   \n",
       "92     0.358566       0.270462      3.243094  0.012820      0.479004   \n",
       "93     0.179534       0.179510      0.184538  0.088802      1.239864   \n",
       "98     0.347361       0.387639     73.884354 -0.022177      0.218628   \n",
       "99     0.887372       4.830700   1430.934937 -0.045017      0.041963   \n",
       "103    1.797909       1.925852     10.154929  0.041392      1.418945   \n",
       "106    0.458113       0.407056      2.447005 -0.012705      0.354492   \n",
       "107    0.118114       0.118017      0.122048 -0.016731      0.751359   \n",
       "112    0.284235       0.283835     35.402115 -0.015849      0.222778   \n",
       "113    1.078778       3.367396    935.087830 -0.049529      0.074402   \n",
       "117    0.880355       0.853385      6.896774 -0.014892      1.043945   \n",
       "120    0.639980       0.614214      0.945423 -0.012499      0.524414   \n",
       "121    0.140528       0.140455      0.146678 -0.078326      0.825065   \n",
       "126    0.239751       0.204379     13.511628 -0.010411      0.227295   \n",
       "127    7.319476      12.125095   2353.144287 -0.005494      0.122070   \n",
       "131    3.949352       4.783004     18.106796 -0.006946      1.940430   \n",
       "134    0.591474       0.566980      0.921033 -0.010487      0.308838   \n",
       "135    0.171124       0.171006      0.178169 -0.000522      0.879712   \n",
       "140    0.216220       0.181954     12.239436 -0.008339      0.254173   \n",
       "141    4.238711       4.865345    129.909088  0.007506      0.087219   \n",
       "145    3.354393       3.807660     17.690266 -0.017125      1.956055   \n",
       "148    0.680383       0.670312      0.881579  0.014008      0.269775   \n",
       "149    0.161199       0.161074      0.171046  0.000102      0.785744   \n",
       "154    0.192343       0.162446     20.810057 -0.006962      0.258667   \n",
       "155    2.170675      24.702936  10239.000000  0.006425      0.109955   \n",
       "159    1.631507       1.854414      9.926829 -0.021215      1.792969   \n",
       "162    0.472232       0.452887      0.791096  0.007894      0.225586   \n",
       "163    0.169968       0.169859      0.178630  0.067644      0.775926   \n",
       "168    0.165023       0.129539     28.014925 -0.003010      0.266907   \n",
       "169    1.608467       1.686309     33.133335 -0.090782      0.053085   \n",
       "173    1.630441       1.754232      8.842424  0.003612      1.446289   \n",
       "176    0.501507       0.488571      0.851240 -0.013793      0.218506   \n",
       "177    0.161045       0.160905      0.173687 -0.077375      0.670324   \n",
       "182    0.148516       0.109167     32.947826 -0.001963      0.260788   \n",
       "183    1.291228       1.392268     52.439999 -0.029082      0.080017   \n",
       "187    1.547568       1.756489     12.333333 -0.027902      1.943359   \n",
       "190    0.449416       0.433584      0.809586 -0.012653      0.199707   \n",
       "191    0.143878       0.143632      0.153526 -0.037131      0.573322   \n",
       "196    0.146101       0.114674     47.490799  0.000908      0.268997   \n",
       "197    0.711010       0.852622     52.106384 -0.030337      0.097137   \n",
       "201    1.361276       1.660806     12.402597 -0.037486      2.171875   \n",
       "204    0.494089       0.478963      0.827801 -0.003161      0.194824   \n",
       "205    0.125200       0.124949      0.134385  0.056575      0.487145   \n",
       "210    0.125898       0.096949     87.480873  0.002217      0.264160   \n",
       "211    0.219886      10.727682   5254.940918 -0.025096      0.148466   \n",
       "215    1.307852       1.871016     19.912281  0.005372      2.329102   \n",
       "218    0.590640       0.582067      0.862103  0.000401      0.212158   \n",
       "219    0.249551       0.249369      0.257533  0.044686      1.030133   \n",
       "224    0.118595       0.081640     43.869564  0.003536      0.266983   \n",
       "225    0.912338       0.957306     23.373056 -0.020380      0.137665   \n",
       "229    1.072320       1.502367     10.138122  0.028108      1.860352   \n",
       "232    0.618305       0.611855      0.858696  0.006729      0.197266   \n",
       "233    0.325965       0.325706      0.337825 -0.015730      1.372413   \n",
       "238    0.110431       0.084935     88.872337  0.000697      0.266068   \n",
       "239    1.374585       1.434541     30.716814 -0.014020      0.211853   \n",
       "243    1.226518       1.678248     12.224490  0.072027      2.339844   \n",
       "246    0.599349       0.589859      0.857021 -0.011786      0.244385   \n",
       "247    0.330511       0.330355      0.339464 -0.022923      1.320729   \n",
       "252    0.108024       0.080463     60.730495  0.002052      0.266006   \n",
       "253    1.055969       9.782271   4412.109863  0.014655      0.163049   \n",
       "257    1.588764       1.934185      8.409327 -0.006847      1.609375   \n",
       "260    0.543855       0.536279      0.844444 -0.014924      0.222656   \n",
       "261    0.135924       0.135136      0.157368 -0.021378      0.486856   \n",
       "266    0.118641       0.105258     90.151512  0.006361      0.272369   \n",
       "267    2.036408       2.119742     31.705883  0.008759      0.340820   \n",
       "271    0.920567       1.348303     12.226666 -0.042092      1.803711   \n",
       "274    0.577120       0.570422      0.843960  0.007729      0.245605   \n",
       "275    0.195568       0.194755      0.211148 -0.064095      0.689529   \n",
       "280    0.142140       0.135760     75.487808  0.006562      0.284912   \n",
       "281    3.530484       3.609409     44.886791 -0.004160      0.290405   \n",
       "285    1.734461       2.477821     15.124031 -0.016673      2.003906   \n",
       "288    0.514395       0.502658      0.851724 -0.007349      0.244141   \n",
       "289    0.202439       0.201801      0.214921  0.030802      0.668270   \n",
       "294    0.161315       0.155446     54.636364  0.006748      0.293457   \n",
       "295    3.140450       3.317812     50.929825  0.003966      0.354370   \n",
       "299    2.463653       2.931830     14.496063 -0.000725      1.884766   \n",
       "302    0.486104       0.476649      0.833942 -0.005453      0.238281   \n",
       "303    0.016897       0.014361      0.070988  0.028532      0.187452   \n",
       "308    0.182811       0.183822     84.157028  0.009452      0.311035   \n",
       "309    2.268730       2.301948     23.118227 -0.000173      0.314453   \n",
       "313    1.196678       1.743547     10.973154 -0.008150      1.666016   \n",
       "316    0.385940       0.372567      0.801948 -0.010969      0.185791   \n",
       "317    0.075211       0.074094      0.088847  0.058065      0.274872   \n",
       "322    0.218581       0.218047     55.412373  0.008312      0.328064   \n",
       "323    1.760096       1.922224     55.558140  0.010141      0.364532   \n",
       "327    1.072445       1.597363      9.880000  0.007066      1.742188   \n",
       "330    0.351658       0.339445      0.753247  0.005403      0.169922   \n",
       "331    0.094523       0.093153      0.114329 -0.144866      0.364422   \n",
       "336    0.244720       0.248719     72.025642  0.010766      0.342896   \n",
       "337    1.025271       1.128071     30.849766 -0.023467      0.402832   \n",
       "341    0.907235       1.379985     16.192158  0.022165      2.121094   \n",
       "344    0.348096       0.335123      0.807910 -0.003455      0.185791   \n",
       "345    0.063837       0.062355      0.140430 -0.050876      0.351076   \n",
       "350    0.263784       0.272826    103.675552  0.008870      0.355942   \n",
       "351    1.299328       1.383906     28.321587 -0.004202      0.392395   \n",
       "355    0.932976       1.540862     14.085714  0.022983      1.925781   \n",
       "358    0.336839       0.324669      0.763889 -0.002376      0.174561   \n",
       "359    0.021082       0.012783      0.104713  0.038309      0.274872   \n",
       "364    0.268240       0.273705     75.800003  0.010594      0.370117   \n",
       "365    1.536790       1.627915     31.738462 -0.022831      0.503662   \n",
       "369    1.068205       1.848875     15.578313  0.033766      2.005859   \n",
       "372    0.267856       0.246468      0.789384 -0.004425      0.225098   \n",
       "373    0.062703       0.060893      0.098108 -0.065842      0.314252   \n",
       "378    0.276547       0.287534    101.193550  0.010490      0.382935   \n",
       "379    2.309118       2.351690     16.982302  0.047744      0.498779   \n",
       "383    1.351828       1.987786     14.111111  0.016806      2.018555   \n",
       "386    0.346776       0.335391      0.752809 -0.000667      0.155762   \n",
       "387    0.091389       0.090030      0.221308 -0.050658      0.577477   \n",
       "392    0.287182       0.295049     68.818184  0.008367      0.392731   \n",
       "393    1.350135       1.509979     59.300579 -0.025200      0.626160   \n",
       "397    0.709712       1.434338     15.347826 -0.032695      1.844727   \n",
       "400    0.293495       0.282055      0.849462 -0.003073      0.172363   \n",
       "401    0.032059       0.030071      0.100677  0.082732      0.276863   \n",
       "406    0.308088       0.321079     89.026665  0.010956      0.407532   \n",
       "407    1.549931       1.716602     53.303032 -0.019552      0.646118   \n",
       "411    0.505271       0.653128     15.265560  0.023098      1.796387   \n",
       "414    0.274706       0.255667      1.021390  0.003842      0.197266   \n",
       "415    0.109506       0.107946      0.132267 -0.054424      0.475520   \n",
       "420    0.304641       0.316340     83.809814  0.009613      0.416901   \n",
       "421    1.490848       1.523602     12.505377  0.049619      0.567871   \n",
       "425    1.017882       1.578896     12.699347  0.044364      1.897461   \n",
       "428    0.213796       0.191543      1.158192 -0.003924      0.170410   \n",
       "429    0.097144       0.096132      0.214323 -0.010071      0.636271   \n",
       "434    0.322378       0.331882     65.666664  0.011437      0.432861   \n",
       "435    1.320503       1.400346     31.715084 -0.010537      0.692993   \n",
       "439    0.722683       1.337174     12.239436  0.055265      1.738281   \n",
       "442    0.353244       0.342881      0.887755 -0.008110      0.158691   \n",
       "443    0.018477       0.014545      0.138051 -0.019193      0.377482   \n",
       "448    0.350267       0.363007     79.347824  0.010090      0.445557   \n",
       "449    1.202410       1.248351     19.965517  0.000548      0.706787   \n",
       "453    0.611182       1.199540     15.615385 -0.040758      1.739746   \n",
       "456    0.362987       0.352497      0.722222  0.011641      0.190430   \n",
       "457    0.180124       0.179510      0.367820  0.001369      0.988516   \n",
       "462    0.362237       0.372869     58.500000  0.009848      0.457031   \n",
       "463    1.415222       1.472912     31.168421 -0.004706      0.722900   \n",
       "467    0.411872       0.740873     13.319327  0.000266      1.638672   \n",
       "470    0.382017       0.373733      0.867299 -0.001236      0.161133   \n",
       "471    0.098753       0.097948      0.226229  0.068826      0.703431   \n",
       "476    0.373947       0.385385     59.279068  0.008171      0.466736   \n",
       "477    1.284720       1.352967     23.446352  0.006831      0.666870   \n",
       "481    0.453128       0.693614     14.168000  0.024252      1.729492   \n",
       "484    0.326091       0.315790      0.866029  0.006509      0.170898   \n",
       "485    0.098237       0.097354      0.119041  0.014319      0.498485   \n",
       "490    0.372622       0.388470     85.732239  0.009691      0.478790   \n",
       "491    1.410728       1.470606     27.714285 -0.040188      0.757812   \n",
       "495    0.486420       0.654955     14.658119 -0.007150      1.674805   \n",
       "498    0.241066       0.217831      1.269430  0.010566      0.187012   \n",
       "499    0.085675       0.084091      0.116691 -0.048167      0.459470   \n",
       "504    0.378366       0.395466    100.199997  0.005834      0.489258   \n",
       "505    1.624116       1.719836     30.842365 -0.002109      0.764282   \n",
       "509    0.985710       1.787897     11.353742  0.024264      1.634766   \n",
       "512    0.411916       0.399183      1.122642  0.011990      0.252930   \n",
       "513    0.028846       0.026502      0.106620  0.022289      0.366507   \n",
       "518    0.360320       0.380645    128.000000  0.006866      0.500000   \n",
       "519    1.885559       1.969272     35.349514  0.006627      0.888916   \n",
       "523    0.499750       0.794528     12.102880 -0.035162      1.506836   \n",
       "526    0.383590       0.373968      1.067961  0.004405      0.206055   \n",
       "527    0.182292       0.181908      0.318854 -0.060080      0.976490   \n",
       "532    0.388015       0.404199     93.391060  0.007262      0.510162   \n",
       "533    2.392235       2.442798     27.611765  0.117644      1.145996   \n",
       "537    0.414751       0.516173     12.762712  0.061763      1.478516   \n",
       "540    0.177642       0.134306      1.680628  0.011072      0.156738   \n",
       "541    0.303575       0.303537      0.462341  0.007456      1.293111   \n",
       "546    0.408862       0.426743    113.614380  0.005679      0.530487   \n",
       "547    3.524684       3.634027     31.000000 -0.032550      1.256348   \n",
       "551    0.834869       1.575434      8.018182 -0.046865      1.359375   \n",
       "554    0.202120       0.181450      1.237624  0.006113      0.173828   \n",
       "555    0.273723       0.273614      0.426817 -0.134503      1.247106   \n",
       "560    0.412462       0.456590    299.286926  0.006396      0.541161   \n",
       "561    1.277488       1.319159     16.657658  0.007819      0.902832   \n",
       "565    0.450313       0.633921     13.569106  0.031042      1.629883   \n",
       "568    0.407270       0.396567      1.221198 -0.000108      0.209473   \n",
       "569    0.544967       0.545467      0.848140  0.040224      2.186612   \n",
       "574    0.408431       0.450126    287.507935  0.003183      0.552765   \n",
       "575    2.458431       2.552430     32.361702  0.041823      1.139160   \n",
       "579    0.575359       1.007315     18.065868 -0.010039      1.473145   \n",
       "582    0.249481       0.232726      1.471111  0.015132      0.171387   \n",
       "583    0.364031       0.364083      0.504607  0.017667      1.608435   \n",
       "588    0.422745       0.436344     87.150940  0.006284      0.563843   \n",
       "589    2.234395       2.295405     25.639593 -0.025646      1.233154   \n",
       "593    0.321923       0.506649     11.435643  0.094728      1.172852   \n",
       "596    0.250837       0.229963      1.378378  0.005820      0.169434   \n",
       "597    0.501129       0.501398      0.690929  0.172116      1.943238   \n",
       "602    0.433432       0.458498    161.025314  0.003851      0.582321   \n",
       "603    2.110694       2.210378     34.619049  0.144624      1.419922   \n",
       "607    0.410828       0.711866     14.907515  0.003402      1.306641   \n",
       "610    0.465892       0.457493      1.109705  0.008152      0.188477   \n",
       "611    0.380882       0.380960      0.534119  0.055318      1.785961   \n",
       "616    0.452267       0.464636     66.506851  0.002084      0.592651   \n",
       "617    1.841598       1.952139     24.600000 -0.021749      1.116699   \n",
       "621    0.411610       0.694963     12.960784  0.027011      1.291016   \n",
       "624    0.195245       0.164367      1.584906  0.009037      0.196777   \n",
       "625    0.103375       0.102617      0.202301 -0.019303      0.727019   \n",
       "630    0.453319       0.466282     73.429626  0.003238      0.605042   \n",
       "631    1.521227       1.655462     26.803278  0.011804      1.263916   \n",
       "635    0.549315       0.852011     13.660098 -0.025472      1.396973   \n",
       "638    0.243896       0.221777      1.910638  0.013917      0.219238   \n",
       "639    0.175124       0.175002      0.263926 -0.010291      1.204165   \n",
       "644    0.474578       0.487265     73.057144  0.002472      0.624268   \n",
       "645    3.193933       3.426511     34.117950  0.067643      1.697754   \n",
       "649    0.471038       0.903930     14.661972  0.024819      1.124329   \n",
       "652    0.253847       0.223860      1.354680  0.005577      0.193359   \n",
       "653    0.360342       0.360357      0.463428 -0.063909      1.955085   \n",
       "658    0.495571       0.511253     90.350426  0.003091      0.645203   \n",
       "659    5.724276       5.825323     51.901733 -0.040571      2.265869   \n",
       "663    0.483167       0.852029      9.847458  0.050526      1.134766   \n",
       "666    0.275609       0.245112      1.621359  0.008213      0.203125   \n",
       "667    0.701356       0.701425      0.775342  0.038708      3.513270   \n",
       "672    0.508047       0.518542     54.316582  0.004841      0.659729   \n",
       "673    3.871047       4.226618     60.015545  0.075019      1.437500   \n",
       "677    0.634430       1.520104     12.202186  0.008066      1.160309   \n",
       "680    0.137616       0.079553      1.872340  0.005296      0.176270   \n",
       "681    0.674324       0.674525      0.823806  0.064486      2.896193   \n",
       "686    0.525038       0.543178    115.244896  0.001010      0.689331   \n",
       "687    3.410647       3.729453     60.825241  0.017024      1.529541   \n",
       "691    1.135430       1.877399      9.376812  0.028421      1.280273   \n",
       "694    0.284181       0.267275      1.380567  0.013946      0.177734   \n",
       "695    0.410400       0.410436      0.545141 -0.023420      2.538311   \n",
       "700    0.519624       0.539169    122.284210  0.002202      0.709045   \n",
       "701    2.024096       2.214938     39.608189 -0.094381      1.756836   \n",
       "705    0.351490       0.522235     14.879700 -0.039399      0.988770   \n",
       "708    0.409441       0.399131      0.905172  0.006340      0.255859   \n",
       "709    0.568137       0.568205      0.663952  0.011457      2.572815   \n",
       "714    0.529138       0.563514    230.145630  0.004467      0.723419   \n",
       "715    3.111147       3.176197     29.857143 -0.007052      1.428711   \n",
       "719    0.560993       1.080937     11.131147 -0.043005      1.376953   \n",
       "722    0.225452       0.199711      1.403756  0.018017      0.166992   \n",
       "723    0.393939       0.394006      0.541484 -0.031236      2.233622   \n",
       "728    0.538533       0.558187    127.000000  0.001977      0.751892   \n",
       "729    2.878687       3.178475     87.582779  0.056576      1.655762   \n",
       "733    0.410912       0.625477      6.520000 -0.042133      1.117188   \n",
       "736    0.304481       0.283303      1.029851  0.008745      0.227539   \n",
       "737    0.679284       0.679432      0.804865  0.029237      2.804452   \n",
       "742    0.560759       0.578697    114.484444  0.002156      0.786102   \n",
       "743    2.483415       2.579660     34.108570 -0.058378      1.628906   \n",
       "747    0.575936       0.804069     19.296297 -0.008424      1.125000   \n",
       "750    0.226719       0.192571      1.757282  0.012264      0.176758   \n",
       "751    0.024093       0.023460      0.076570  0.034095      0.437886   \n",
       "756    0.550202       0.566499    106.707314  0.003396      0.801086   \n",
       "757    4.062770       4.565912     93.967743  0.060758      1.824951   \n",
       "761    0.635460       0.966599      8.742222 -0.021787      1.117188   \n",
       "764    0.232005       0.194837      1.655462  0.007968      0.192383   \n",
       "765    0.305513       0.305316      0.320475 -0.010523      1.442139   \n",
       "770    0.560207       0.592579    223.780487  0.003294      0.839996   \n",
       "771    4.953011       5.731565     52.698631 -0.033712      1.899414   \n",
       "775    1.166055       2.159798     10.807487 -0.037435      1.101562   \n",
       "778    0.173313       0.131827      1.423645  0.011275      0.216309   \n",
       "779    0.425168       0.425027      0.437876  0.056959      2.079911   \n",
       "784    0.548982       0.589416    286.030304  0.004287      0.864166   \n",
       "785    3.095836       3.300892     38.135136 -0.010246      1.507324   \n",
       "789    0.637991       1.015950      8.636364 -0.070283      1.142578   \n",
       "792    0.392105       0.370166      0.910448  0.001901      0.187500   \n",
       "793    0.474286       0.474084      0.486030 -0.074846      2.247890   \n",
       "798    0.493440       0.512047    146.134018  0.004379      0.865173   \n",
       "799    2.897871       3.862682     69.468086 -0.036480      1.689453   \n",
       "803    1.395874       2.364907     14.587629 -0.017237      1.425781   \n",
       "806    0.349691       0.315246      1.020100  0.005220      0.180908   \n",
       "807    0.406058       0.405635      0.418068  0.074904      1.685338   \n",
       "812    0.394457       0.402549     81.120483  0.002309      0.821899   \n",
       "813    3.319094       4.482933    220.176468 -0.051873      1.873291   \n",
       "817    1.289036       1.963430     16.846153  0.020104      1.390137   \n",
       "820    0.269433       0.238618      1.045455  0.015175      0.235840   \n",
       "821    0.402591       0.402085      0.461674 -0.040055      1.738490   \n",
       "826    0.158960       0.174163    268.473694  0.002003      0.700516   \n",
       "827    3.440193       3.584890     34.111111 -0.007737      1.966309   \n",
       "831    1.033867       1.288793     16.386667  0.020504      1.200195   \n",
       "834    0.459910       0.439555      1.000123 -0.006742      0.204346   \n",
       "835    0.135434       0.134477      0.158780  0.183239      0.654969   \n",
       "840    0.387273       0.378300     49.218979  0.001302      0.678223   \n",
       "841    1.951129       1.937069     14.300971  0.076730      1.769531   \n",
       "845    0.667694       0.897578     12.477477 -0.010974      1.550781   \n",
       "\n",
       "     mean_abs_diff  spearman  q01_abs_diff  q05_abs_diff  q50_abs_diff  \\\n",
       "0         0.021565 -0.007118      0.000244      0.001709      0.016113   \n",
       "4         0.009883  0.009918      0.000122      0.000732      0.007568   \n",
       "5         0.006171 -0.009046      0.000122      0.000535      0.004852   \n",
       "9         0.252936  0.021972      0.013672      0.058105      0.260742   \n",
       "12        0.022439 -0.002995      0.000244      0.001465      0.016632   \n",
       "16        0.031187 -0.004826      0.000285      0.001953      0.020996   \n",
       "17        0.007834 -0.010430      0.000132      0.000500      0.005886   \n",
       "21        0.306409  0.003983      0.009131      0.055420      0.300781   \n",
       "24        0.028536  0.022656      0.000488      0.002197      0.022949   \n",
       "28        0.024096  0.028088      0.000244      0.001709      0.018066   \n",
       "29        0.008506  0.000496      0.000185      0.000719      0.006996   \n",
       "33        0.285435 -0.010404      0.007178      0.047852      0.257812   \n",
       "36        0.041516 -0.007745      0.000977      0.005127      0.037842   \n",
       "37        1.306384  0.044163      1.291267      1.293877      1.298276   \n",
       "42        0.056521 -0.019346      0.000977      0.004395      0.049072   \n",
       "43        0.014174 -0.080748      0.000271      0.001410      0.012455   \n",
       "47        0.165950  0.018760      0.001953      0.009766      0.128906   \n",
       "50        0.030028  0.015564      0.000488      0.002930      0.025879   \n",
       "51        0.680279  0.132161      0.648305      0.675556      0.679355   \n",
       "56        0.058462 -0.025815      0.000977      0.004883      0.050781   \n",
       "57        0.037131  0.027201      0.000725      0.002431      0.037491   \n",
       "61        0.755728 -0.028483      0.042334      0.369385      0.760742   \n",
       "64        0.032749  0.014042      0.000488      0.002930      0.028809   \n",
       "65        0.411542  0.052694      0.379396      0.382086      0.413536   \n",
       "70        0.061895 -0.020848      0.000977      0.004883      0.053711   \n",
       "71        0.019957  0.002694      0.009033      0.012682      0.020142   \n",
       "75        0.429652 -0.041957      0.009131      0.037109      0.437500   \n",
       "78        0.020602 -0.003152      0.000488      0.001465      0.016113   \n",
       "79        1.400580  0.085245      1.314402      1.347102      1.408402   \n",
       "84        0.052470 -0.019529      0.000977      0.003906      0.043945   \n",
       "85        0.014492 -0.008604      0.006639      0.009416      0.014618   \n",
       "89        0.483756 -0.004213      0.018896      0.073242      0.487305   \n",
       "92        0.024924  0.007116      0.000977      0.003418      0.022461   \n",
       "93        1.199590  0.094040      1.140775      1.171515      1.203815   \n",
       "98        0.044104 -0.026056      0.000977      0.002930      0.034180   \n",
       "99        0.016000  0.007064      0.004896      0.008246      0.015747   \n",
       "103       0.543642  0.042698      0.011719      0.044922      0.550781   \n",
       "106       0.044589 -0.006039      0.004883      0.015137      0.043457   \n",
       "107       0.724541  0.038277      0.633897      0.679010      0.740360   \n",
       "112       0.037543 -0.019328      0.000977      0.001953      0.027344   \n",
       "113       0.011405 -0.045209      0.003181      0.005771      0.011169   \n",
       "117       0.282334 -0.012600      0.003906      0.021484      0.250000   \n",
       "120       0.060864 -0.002786      0.030273      0.038818      0.059082   \n",
       "121       0.787243 -0.141759      0.713427      0.744767      0.779016   \n",
       "126       0.034986 -0.014315      0.000000      0.001953      0.023438   \n",
       "127       0.092130 -0.033861      0.048609      0.082898      0.093323   \n",
       "131       1.141272 -0.015383      0.031250      0.132568      1.252441   \n",
       "134       0.057278 -0.005885      0.030681      0.038086      0.055420   \n",
       "135       0.837752  0.052533      0.705659      0.812012      0.845262   \n",
       "140       0.035862 -0.018406      0.000977      0.002930      0.027344   \n",
       "141       0.067032  0.034911      0.052185      0.059760      0.067444   \n",
       "145       1.142103  0.009171      0.025391      0.119141      1.288086   \n",
       "148       0.072066  0.002092      0.047527      0.055908      0.071289   \n",
       "149       0.731071  0.005372      0.647481      0.691194      0.725244   \n",
       "154       0.031763 -0.018691      0.000977      0.002930      0.023438   \n",
       "155       0.075135  0.027464      0.059243      0.066296      0.075439   \n",
       "159       0.816552 -0.028128      0.020215      0.089600      0.877930   \n",
       "162       0.050131 -0.002101      0.022949      0.031738      0.049561   \n",
       "163       0.731628  0.060866      0.659254      0.703027      0.736477   \n",
       "168       0.026266 -0.011222      0.000000      0.001953      0.018555   \n",
       "169       0.034972  0.001520      0.028956      0.032349      0.035034   \n",
       "173       0.589704 -0.001843      0.009766      0.044678      0.613770   \n",
       "176       0.050000 -0.018795      0.029216      0.036133      0.049561   \n",
       "177       0.612913 -0.026785      0.513128      0.576743      0.615649   \n",
       "182       0.021546 -0.015994      0.000000      0.001953      0.013672   \n",
       "183       0.045048 -0.056886      0.038438      0.041504      0.045166   \n",
       "187       0.780742 -0.032075      0.015625      0.074219      0.800781   \n",
       "190       0.038317  0.000484      0.021729      0.026855      0.037598   \n",
       "191       0.530874 -0.006490      0.441612      0.496697      0.537072   \n",
       "196       0.023547 -0.009827      0.000000      0.001953      0.016602   \n",
       "197       0.040883 -0.078225      0.029893      0.035645      0.040527   \n",
       "201       0.898635 -0.035233      0.031250      0.131836      0.937500   \n",
       "204       0.037017 -0.013470      0.021079      0.026367      0.036377   \n",
       "205       0.449193  0.003710      0.326014      0.402821      0.451695   \n",
       "210       0.017484 -0.003408      0.000000      0.000977      0.010742   \n",
       "211       0.023877  0.011452      0.008896      0.012695      0.022461   \n",
       "215       1.042509  0.010510      0.036523      0.203125      1.115234   \n",
       "218       0.051553 -0.005634      0.033936      0.039795      0.051270   \n",
       "219       0.989739  0.137209      0.862356      0.931333      0.996683   \n",
       "224       0.016438 -0.000843      0.000000      0.000977      0.009766   \n",
       "225       0.065671 -0.049760      0.039819      0.053223      0.066162   \n",
       "229       0.775614  0.026777      0.031250      0.121094      0.769531   \n",
       "232       0.053999  0.000763      0.035076      0.042969      0.053955   \n",
       "233       1.305340 -0.025474      1.095804      1.236563      1.323164   \n",
       "238       0.014603 -0.003193      0.000000      0.000000      0.009766   \n",
       "239       0.122173 -0.065574      0.092500      0.106445      0.122559   \n",
       "243       0.991634  0.047350      0.029980      0.187500      0.992188   \n",
       "246       0.057040 -0.023784      0.037517      0.044678      0.056641   \n",
       "247       1.272157 -0.058165      1.106757      1.217929      1.279280   \n",
       "252       0.015692  0.001305      0.000000      0.001953      0.010742   \n",
       "253       0.083081  0.034519      0.060327      0.073730      0.083496   \n",
       "257       0.859472 -0.024700      0.023438      0.152344      0.898438   \n",
       "260       0.048805 -0.019072      0.032471      0.039062      0.048584   \n",
       "261       0.412969 -0.032225      0.279165      0.346234      0.420409   \n",
       "266       0.021534  0.004546      0.000000      0.001953      0.017578   \n",
       "267       0.179885 -0.008222      0.139214      0.160156      0.179688   \n",
       "271       0.762092 -0.032200      0.023438      0.163086      0.742676   \n",
       "274       0.060274 -0.002326      0.042969      0.049561      0.059814   \n",
       "275       0.625638 -0.029374      0.424509      0.554480      0.634255   \n",
       "280       0.031288  0.008372      0.001953      0.005859      0.029297   \n",
       "281       0.228209 -0.057530      0.174678      0.220215      0.229492   \n",
       "285       1.197476 -0.025932      0.092773      0.464844      1.207031   \n",
       "288       0.047998 -0.025707      0.029785      0.036377      0.047607   \n",
       "289       0.619246  0.080404      0.433062      0.543789      0.629020   \n",
       "294       0.038960  0.007186      0.001953      0.009766      0.037109   \n",
       "295       0.272445 -0.053811      0.212280      0.257104      0.273926   \n",
       "299       1.246964 -0.002507      0.053516      0.274902      1.320312   \n",
       "302       0.045858 -0.007657      0.029785      0.036133      0.045410   \n",
       "303       0.040812  0.076558      0.001915      0.004952      0.037497   \n",
       "308       0.046512  0.011066      0.003906      0.013672      0.044922   \n",
       "309       0.209300  0.005923      0.144580      0.195361      0.209229   \n",
       "313       0.876101 -0.007202      0.050781      0.299805      0.859375   \n",
       "316       0.031354 -0.005840      0.016113      0.021240      0.031250   \n",
       "317       0.226649  0.066821      0.072231      0.160291      0.233623   \n",
       "322       0.059284  0.010663      0.005859      0.023438      0.058594   \n",
       "323       0.240680  0.018023      0.156885      0.225146      0.242188   \n",
       "327       0.918397  0.011998      0.145898      0.492188      0.859375   \n",
       "330       0.029088  0.001793      0.012695      0.018799      0.029053   \n",
       "331       0.292698 -0.082924      0.080933      0.212374      0.305274   \n",
       "336       0.068901  0.011776      0.007812      0.029297      0.068359   \n",
       "337       0.212310 -0.032187      0.130205      0.185107      0.213867   \n",
       "341       0.995629  0.112631      0.190234      0.646484      0.929688   \n",
       "344       0.029705 -0.007906      0.013184      0.019287      0.029541   \n",
       "345       0.189076  0.020717      0.031174      0.118424      0.195586   \n",
       "350       0.075931  0.008284      0.009766      0.035156      0.076172   \n",
       "351       0.230217  0.003202      0.189561      0.211914      0.230469   \n",
       "355       0.929804 -0.013090      0.191602      0.601562      0.843750   \n",
       "358       0.030131 -0.003871      0.015625      0.020996      0.029785   \n",
       "359       0.035849  0.084456      0.000512      0.002011      0.020446   \n",
       "364       0.079964  0.012719      0.013672      0.039062      0.080078   \n",
       "365       0.311572  0.005374      0.242070      0.280273      0.311523   \n",
       "369       1.029910  0.020146      0.308691      0.664062      0.960938   \n",
       "372       0.022701 -0.000960      0.008301      0.012695      0.021973   \n",
       "373       0.191410  0.019813      0.025485      0.107832      0.199382   \n",
       "378       0.084337  0.013384      0.017578      0.044922      0.083984   \n",
       "379       0.376303  0.001637      0.302285      0.355469      0.377930   \n",
       "383       1.176172  0.023768      0.259570      0.823242      1.125000   \n",
       "386       0.032009 -0.003691      0.017578      0.022461      0.031250   \n",
       "387       0.262256 -0.018378      0.182492      0.201896      0.252864   \n",
       "392       0.089569  0.008641      0.021484      0.050781      0.089844   \n",
       "393       0.372419 -0.031893      0.281250      0.339844      0.371094   \n",
       "397       0.731556  0.004577      0.109375      0.296875      0.648438   \n",
       "400       0.026530  0.000234      0.011719      0.017090      0.026367   \n",
       "401       0.093348  0.070377      0.010477      0.032987      0.094937   \n",
       "406       0.097800  0.010594      0.031250      0.060547      0.097656   \n",
       "407       0.404404  0.003923      0.331797      0.376953      0.403809   \n",
       "411       0.585976  0.012139      0.166797      0.351562      0.539062   \n",
       "414       0.024636 -0.004665      0.008301      0.014160      0.024414   \n",
       "415       0.381108 -0.061330      0.150956      0.269465      0.394895   \n",
       "420       0.098415  0.012467      0.033203      0.062500      0.097656   \n",
       "421       0.361906  0.015911      0.328125      0.339844      0.360840   \n",
       "425       0.928839 -0.006347      0.192969      0.531250      0.859375   \n",
       "428       0.018159  0.002101      0.003906      0.008301      0.017578   \n",
       "429       0.316292  0.030103      0.223718      0.260260      0.308420   \n",
       "434       0.107163  0.010866      0.042969      0.072266      0.107422   \n",
       "435       0.409939  0.071475      0.272639      0.375000      0.410156   \n",
       "439       0.718967  0.057699      0.104297      0.375000      0.609375   \n",
       "442       0.036177  0.008528      0.021973      0.027832      0.035156   \n",
       "443       0.045346  0.000217      0.002608      0.006397      0.041293   \n",
       "448       0.118019  0.011936      0.052734      0.084668      0.119141   \n",
       "449       0.401917 -0.012065      0.305962      0.371094      0.402344   \n",
       "453       0.604333 -0.052275      0.091211      0.242188      0.531250   \n",
       "456       0.037489  0.004408      0.016929      0.026855      0.037598   \n",
       "457       0.558555  0.015097      0.474553      0.498315      0.545290   \n",
       "462       0.123706  0.011032      0.060547      0.091797      0.123047   \n",
       "463       0.447776 -0.049150      0.375430      0.410156      0.447266   \n",
       "467       0.388416 -0.002302      0.010547      0.070312      0.304688   \n",
       "470       0.040740  0.001698      0.023276      0.029785      0.041016   \n",
       "471       0.338791  0.035737      0.273795      0.289995      0.327531   \n",
       "476       0.129530  0.008072      0.066406      0.097656      0.130859   \n",
       "477       0.399222 -0.004605      0.271538      0.365234      0.400391   \n",
       "481       0.476263 -0.000888      0.031250      0.164062      0.414062   \n",
       "484       0.033331  0.015238      0.018555      0.024414      0.033203   \n",
       "485       0.402779  0.005717      0.216217      0.305138      0.419812   \n",
       "490       0.131238  0.013318      0.070312      0.101562      0.130859   \n",
       "491       0.432765 -0.020492      0.251296      0.392578      0.435547   \n",
       "495       0.520839 -0.023757      0.078125      0.252930      0.460938   \n",
       "498       0.021796 -0.005020      0.006348      0.011719      0.020996   \n",
       "499       0.330236  0.004953      0.071826      0.192178      0.342865   \n",
       "504       0.136063  0.013454      0.076172      0.109375      0.136719   \n",
       "505       0.480046  0.001031      0.380391      0.451172      0.476562   \n",
       "509       0.808131  0.004440      0.089941      0.333984      0.718750   \n",
       "512       0.043697  0.006489      0.021812      0.032227      0.043457   \n",
       "513       0.097597  0.039227      0.032939      0.053007      0.088256   \n",
       "518       0.132880  0.007947      0.078125      0.107422      0.132812   \n",
       "519       0.589781  0.002880      0.409043      0.542969      0.589844   \n",
       "523       0.443871 -0.003178      0.018359      0.101562      0.382812   \n",
       "526       0.040120 -0.002264      0.020020      0.029785      0.040039   \n",
       "527       0.619888 -0.032483      0.543702      0.568990      0.611015   \n",
       "532       0.145065  0.011075      0.091797      0.119141      0.144531   \n",
       "533       0.813959  0.023442      0.343477      0.679004      0.833984   \n",
       "537       0.400002  0.026639      0.031250      0.105469      0.351562   \n",
       "540       0.012805  0.005889      0.000488      0.002441      0.011230   \n",
       "541       0.951693 -0.031404      0.893487      0.910342      0.938736   \n",
       "546       0.155432  0.006220      0.101562      0.128906      0.156250   \n",
       "547       0.970430 -0.022374      0.543379      0.873047      0.982422   \n",
       "551       0.615146 -0.019253      0.031250      0.148438      0.539062   \n",
       "554       0.019097  0.003274      0.005371      0.009277      0.018555   \n",
       "555       0.893328 -0.103301      0.827991      0.852250      0.883531   \n",
       "560       0.158705  0.012571      0.107422      0.132812      0.158203   \n",
       "561       0.515779  0.072171      0.458984      0.480469      0.513672   \n",
       "565       0.473891  0.012643      0.078125      0.203125      0.437500   \n",
       "568       0.044075  0.007417      0.025879      0.034180      0.043457   \n",
       "569       1.681125 -0.014194      1.609587      1.625012      1.661775   \n",
       "574       0.160618  0.008953      0.111328      0.134766      0.160156   \n",
       "575       0.792398  0.071805      0.529727      0.700293      0.791016   \n",
       "579       0.503260 -0.000668      0.018359      0.117188      0.453125   \n",
       "582       0.026155  0.018294      0.008301      0.015625      0.025391   \n",
       "583       1.278564  0.112266      1.217270      1.231292      1.265685   \n",
       "588       0.168954  0.006902      0.119141      0.142578      0.169922   \n",
       "589       0.859100 -0.067910      0.651250      0.802734      0.863281   \n",
       "593       0.221990  0.050873      0.007812      0.015625      0.117188   \n",
       "596       0.026141  0.013375      0.008789      0.014648      0.024902   \n",
       "597       1.586179  0.018699      1.530317      1.539507      1.570651   \n",
       "602       0.177046  0.008583      0.125000      0.152344      0.177734   \n",
       "603       0.984217  0.006356      0.551191      0.830273      0.999023   \n",
       "607       0.303770  0.028162      0.007812      0.031250      0.226562   \n",
       "610       0.054975  0.012954      0.026855      0.042480      0.054932   \n",
       "611       1.412949  0.031417      1.361008      1.369412      1.399062   \n",
       "616       0.186632  0.002831      0.136719      0.162109      0.187500   \n",
       "617       0.724484 -0.010258      0.415385      0.635840      0.730469   \n",
       "621       0.322702  0.040585      0.000000      0.015625      0.199219   \n",
       "624       0.017853  0.010440      0.001465      0.004883      0.017090   \n",
       "625       0.400570 -0.016101      0.344884      0.353395      0.390495   \n",
       "630       0.190662  0.003574      0.138672      0.166016      0.191406   \n",
       "631       0.767697 -0.001633      0.548945      0.681836      0.761719   \n",
       "635       0.450266 -0.002157      0.039062      0.148438      0.394531   \n",
       "638       0.026394  0.015804      0.003906      0.011890      0.025879   \n",
       "639       0.858097  0.058356      0.815276      0.824965      0.856015   \n",
       "644       0.203237  0.002284      0.154297      0.177734      0.203125   \n",
       "645       1.219758  0.066391      0.674629      0.978027      1.237305   \n",
       "649       0.298984  0.012592      0.007812      0.019531      0.222656   \n",
       "652       0.023712  0.018169      0.003906      0.010254      0.022461   \n",
       "653       1.633391  0.030082      1.583734      1.598286      1.633986   \n",
       "658       0.216439  0.006513      0.165371      0.191406      0.216797   \n",
       "659       1.776920  0.034714      0.399062      1.301172      1.837891   \n",
       "663       0.327145  0.041186      0.000000      0.015625      0.238281   \n",
       "666       0.027048  0.008264      0.005859      0.012695      0.025391   \n",
       "667       3.316026  0.096552      3.274062      3.288668      3.298522   \n",
       "672       0.225288  0.005034      0.175137      0.201172      0.226562   \n",
       "673       1.149841  0.099979      0.883418      1.064648      1.156250   \n",
       "677       0.381107  0.013044      0.001367      0.023438      0.293945   \n",
       "680       0.008143  0.019136      0.000000      0.000488      0.005859   \n",
       "681       2.582277  0.136936      2.538258      2.541200      2.570968   \n",
       "686       0.238976  0.001001      0.187500      0.214844      0.240234   \n",
       "687       1.203486  0.076847      0.725801      1.131934      1.205078   \n",
       "691       0.624642 -0.016700      0.038745      0.198242      0.589844   \n",
       "694       0.032552  0.017096      0.010581      0.019043      0.031738   \n",
       "695       2.095706 -0.060634      2.046421      2.061811      2.081560   \n",
       "700       0.243286  0.005061      0.193359      0.218750      0.244141   \n",
       "701       1.110065 -0.098317      0.535117      0.879297      1.125000   \n",
       "705       0.206102 -0.067031      0.000000      0.011719      0.144531   \n",
       "708       0.048355  0.011620      0.021484      0.034668      0.048340   \n",
       "709       2.335556  0.009163      2.289006      2.307166      2.324615   \n",
       "714       0.251372  0.002493      0.200527      0.224609      0.251953   \n",
       "715       1.111480 -0.017341      0.601738      1.010840      1.130859   \n",
       "719       0.425486 -0.036488      0.007812      0.034180      0.335938   \n",
       "722       0.022345  0.013347      0.002930      0.008301      0.021484   \n",
       "723       1.795317  0.044818      1.739064      1.757422      1.790122   \n",
       "728       0.263675 -0.001037      0.210293      0.237012      0.263672   \n",
       "729       1.217247 -0.030813      0.726074      1.125000      1.225586   \n",
       "733       0.263855 -0.040038      0.000000      0.015625      0.167969   \n",
       "736       0.036414  0.016478      0.007812      0.019043      0.035156   \n",
       "737       2.542248  0.111989      2.490165      2.503577      2.535627   \n",
       "742       0.282584  0.001183      0.218750      0.253906      0.285156   \n",
       "743       1.032031 -0.062585      0.580879      0.903613      1.023438   \n",
       "747       0.313290  0.013763      0.007812      0.046875      0.295898   \n",
       "750       0.021395  0.021453      0.001953      0.006348      0.020020   \n",
       "751       0.147727 -0.060572      0.025366      0.092114      0.154864   \n",
       "756       0.284464  0.002218      0.217461      0.253906      0.285156   \n",
       "757       1.449965  0.051553      0.870840      1.345703      1.455078   \n",
       "761       0.333666 -0.004649      0.007812      0.026367      0.288086   \n",
       "764       0.022602  0.021099      0.001465      0.006348      0.020996   \n",
       "765       1.363804 -0.018369      1.222820      1.278892      1.366892   \n",
       "770       0.298991  0.001966      0.218750      0.265625      0.300781   \n",
       "771       1.594395 -0.061291      1.176152      1.445312      1.597656   \n",
       "775       0.543181 -0.057100      0.032617      0.101562      0.539062   \n",
       "778       0.015029 -0.004281      0.000488      0.001953      0.013184   \n",
       "779       2.005483  0.069906      1.745152      1.944964      2.005864   \n",
       "784       0.302922  0.000005      0.205742      0.261719      0.304688   \n",
       "785       1.185812 -0.011821      0.794922      1.060547      1.181641   \n",
       "789       0.346962 -0.051287      0.007812      0.023438      0.290039   \n",
       "792       0.040192 -0.002031      0.010742      0.021973      0.039062   \n",
       "793       2.174021  0.005330      1.922179      2.093942      2.180643   \n",
       "798       0.279695 -0.006942      0.132812      0.210938      0.285156   \n",
       "799       1.184997 -0.024219      0.420332      0.814160      1.184570   \n",
       "803       0.614956 -0.027108      0.023438      0.089844      0.617188   \n",
       "806       0.033523  0.006793      0.001465      0.008301      0.033325   \n",
       "807       1.616396  0.033294      1.339604      1.502433      1.627490   \n",
       "812       0.232021 -0.007180      0.074219      0.171875      0.238281   \n",
       "813       1.287091 -0.025912      0.199434      0.455567      1.337891   \n",
       "817       0.404566  0.021095      0.006543      0.031250      0.358398   \n",
       "820       0.032437  0.005523      0.001953      0.007812      0.031738   \n",
       "821       1.503579 -0.005725      1.215207      1.413174      1.519079   \n",
       "826       0.084888 -0.002407      0.003906      0.023438      0.082031   \n",
       "827       1.416369  0.029226      0.235859      1.214746      1.443359   \n",
       "831       0.472467  0.003687      0.015625      0.100586      0.472656   \n",
       "834       0.047568 -0.004929      0.009766      0.024414      0.048096   \n",
       "835       0.546709  0.107217      0.306801      0.436898      0.553572   \n",
       "840       0.242459  0.000591      0.144531      0.175781      0.224609   \n",
       "841       0.963114  0.041732      0.027344      0.182324      1.035156   \n",
       "845       0.362517 -0.009205      0.006543      0.027344      0.322266   \n",
       "\n",
       "     q95_abs_diff  q99_abs_diff  spec_rel_l2_err  \\\n",
       "0        0.060791      0.127278         0.304732   \n",
       "4        0.023434      0.040568         0.235245   \n",
       "5        0.015239      0.021301         0.518445   \n",
       "9        0.419006      0.477258         1.147347   \n",
       "12       0.064941      0.096353         0.189538   \n",
       "16       0.080315      0.259021         0.127598   \n",
       "17       0.020419      0.025437         1.872793   \n",
       "21       0.593750      0.704395         2.328625   \n",
       "24       0.073160      0.113362         0.247233   \n",
       "28       0.063089      0.121575         0.277199   \n",
       "29       0.021604      0.027104         2.614917   \n",
       "33       0.591309      0.731934         1.998348   \n",
       "36       0.089111      0.139402         0.445507   \n",
       "37       1.330326      1.331326         0.208710   \n",
       "42       0.134277      0.176633         0.390958   \n",
       "43       0.030662      0.038589         0.198760   \n",
       "47       0.441406      0.577344         0.373002   \n",
       "50       0.071045      0.103352         0.381399   \n",
       "51       0.691467      0.711695         0.115195   \n",
       "56       0.134967      0.180012         0.006197   \n",
       "57       0.069806      0.081073         6.489081   \n",
       "61       1.133057      1.293262         3.505569   \n",
       "64       0.073932      0.113198         0.302342   \n",
       "65       0.418936      0.472687         0.057745   \n",
       "70       0.144775      0.184062         0.024561   \n",
       "71       0.026879      0.031139         2.732230   \n",
       "75       0.842041      0.963525         1.462119   \n",
       "78       0.053955      0.082681         0.189347   \n",
       "79       1.411452      1.415401         0.189317   \n",
       "84       0.130371      0.166016         0.099543   \n",
       "85       0.019324      0.021444         2.357590   \n",
       "89       0.884766      1.000293         2.331264   \n",
       "92       0.050537      0.076248         0.279550   \n",
       "93       1.212064      1.237065         0.179518   \n",
       "98       0.122314      0.161133         0.008440   \n",
       "99       0.023676      0.028769         0.825447   \n",
       "103      1.052002      1.183545         1.632729   \n",
       "106      0.074463      0.099202         0.409398   \n",
       "107      0.746760      0.749559         0.118042   \n",
       "112      0.115723      0.167114         0.018883   \n",
       "113      0.015741      0.024855         1.011508   \n",
       "117      0.675781      0.839795         0.550418   \n",
       "120      0.088379      0.118001         0.625253   \n",
       "121      0.811116      0.817516         0.140476   \n",
       "126      0.112305      0.179524         0.074393   \n",
       "127      0.100098      0.102899         7.303339   \n",
       "131      1.673828      1.804297         3.821991   \n",
       "134      0.080078      0.119707         0.578318   \n",
       "135      0.850311      0.877712         0.171046   \n",
       "140      0.103516      0.190022         0.109066   \n",
       "141      0.073203      0.076209         4.225269   \n",
       "145      1.699219      1.824756         3.232240   \n",
       "148      0.089191      0.113770         0.672284   \n",
       "149      0.758743      0.766583         0.161114   \n",
       "154      0.090820      0.197263         0.096569   \n",
       "155      0.082764      0.087783         2.160861   \n",
       "159      1.428955      1.593652         1.443795   \n",
       "162      0.069092      0.089436         0.459098   \n",
       "163      0.744476      0.767717         0.169896   \n",
       "168      0.074219      0.194417         0.071945   \n",
       "169      0.037964      0.040745         1.599928   \n",
       "173      1.129150      1.292969         1.436693   \n",
       "176      0.063721      0.077717         0.492476   \n",
       "177      0.637124      0.648905         0.160947   \n",
       "182      0.064453      0.186685         0.048550   \n",
       "183      0.048340      0.050022         1.285219   \n",
       "187      1.523438      1.669580         1.324711   \n",
       "190      0.050293      0.065510         0.438119   \n",
       "191      0.555897      0.569222         0.143706   \n",
       "196      0.063477      0.185215         0.068099   \n",
       "197      0.046631      0.055884         0.698295   \n",
       "201      1.583984      1.846289         1.180400   \n",
       "204      0.048584      0.065183         0.484628   \n",
       "205      0.476476      0.481145         0.125017   \n",
       "210      0.050781      0.172524         0.035768   \n",
       "211      0.035156      0.067779         0.186037   \n",
       "215      1.775879      2.092383         1.159394   \n",
       "218      0.062988      0.073242         0.583330   \n",
       "219      1.019134      1.023662         0.249446   \n",
       "224      0.046875      0.170083         0.033205   \n",
       "225      0.074707      0.078125         0.902919   \n",
       "229      1.458008      1.629541         0.887254   \n",
       "232      0.064209      0.072021         0.612653   \n",
       "233      1.338463      1.357954         0.325833   \n",
       "238      0.039062      0.161284         0.000015   \n",
       "239      0.135742      0.141548         1.367532   \n",
       "243      1.771729      1.987158         1.051876   \n",
       "246      0.069092      0.084795         0.592096   \n",
       "247      1.304197      1.314295         0.330429   \n",
       "252      0.038086      0.156084         0.018104   \n",
       "253      0.090820      0.095649         1.044981   \n",
       "257      1.378906      1.497022         1.446150   \n",
       "260      0.058105      0.066243         0.537599   \n",
       "261      0.451003      0.459749         0.135200   \n",
       "266      0.043945      0.156250         0.052258   \n",
       "267      0.199707      0.235523         2.029589   \n",
       "271      1.430420      1.642481         0.746318   \n",
       "274      0.071533      0.083496         0.572213   \n",
       "275      0.669435      0.683344         0.195058   \n",
       "280      0.052734      0.156899         0.094530   \n",
       "281      0.236816      0.238770         3.526457   \n",
       "285      1.779297      1.899707         1.612750   \n",
       "288      0.059082      0.072100         0.506864   \n",
       "289      0.655271      0.662936         0.202040   \n",
       "294      0.062500      0.153643         0.122781   \n",
       "295      0.287109      0.293838         3.133527   \n",
       "299      1.662598      1.762647         2.370702   \n",
       "302      0.055908      0.066243         0.477883   \n",
       "303      0.081703      0.142737         0.008951   \n",
       "308      0.072266      0.155918         0.147381   \n",
       "309      0.228247      0.241592         2.263324   \n",
       "313      1.470703      1.602832         1.067170   \n",
       "316      0.041260      0.049153         0.374672   \n",
       "317      0.266916      0.272682         0.074278   \n",
       "322      0.087891      0.160156         0.188895   \n",
       "323      0.254614      0.277622         1.753169   \n",
       "327      1.574463      1.685205         0.961255   \n",
       "330      0.039062      0.045491         0.341284   \n",
       "331      0.336874      0.345619         0.093323   \n",
       "336      0.099609      0.165030         0.217743   \n",
       "337      0.231885      0.258467         1.014934   \n",
       "341      1.742676      1.999658         0.824593   \n",
       "344      0.039307      0.045410         0.336789   \n",
       "345      0.234049      0.252879         0.060897   \n",
       "350      0.107422      0.162432         0.238739   \n",
       "351      0.245117      0.264658         1.291010   \n",
       "355      1.722168      1.834961         0.838590   \n",
       "358      0.040039      0.047444         0.326871   \n",
       "359      0.116866      0.266807         0.009468   \n",
       "364      0.111328      0.162100         0.245415   \n",
       "365      0.338330      0.399863         1.527947   \n",
       "369      1.829102      1.911426         0.973209   \n",
       "372      0.033691      0.042480         0.249954   \n",
       "373      0.246731      0.260811         0.060229   \n",
       "378      0.115234      0.166006         0.255088   \n",
       "379      0.396484      0.410703         2.303561   \n",
       "383      1.829346      1.941699         1.267965   \n",
       "386      0.042480      0.055989         0.336425   \n",
       "387      0.363133      0.421226         0.089547   \n",
       "392      0.121094      0.167969         0.267808   \n",
       "393      0.410156      0.513584         1.340119   \n",
       "397      1.651367      1.756787         0.572600   \n",
       "400      0.034668      0.040120         0.282625   \n",
       "401      0.142773      0.182142         0.026374   \n",
       "406      0.128906      0.172197         0.291017   \n",
       "407      0.435547      0.468115         1.543150   \n",
       "411      1.019531      1.628174         0.447423   \n",
       "414      0.034668      0.047688         0.257233   \n",
       "415      0.445713      0.466214         0.108307   \n",
       "420      0.128906      0.169268         0.288435   \n",
       "421      0.391602      0.435137         1.485132   \n",
       "425      1.633545      1.762695         0.916260   \n",
       "428      0.028320      0.038574         0.192617   \n",
       "429      0.413445      0.521002         0.095739   \n",
       "434      0.136719      0.175117         0.307736   \n",
       "435      0.446191      0.502393         1.312546   \n",
       "439      1.570312      1.666650         0.601536   \n",
       "442      0.045898      0.064941         0.344115   \n",
       "443      0.094535      0.150838         0.008601   \n",
       "448      0.146484      0.181641         0.337300   \n",
       "449      0.431641      0.449004         1.195968   \n",
       "453      1.486328      1.633936         0.478340   \n",
       "456      0.046875      0.058594         0.352695   \n",
       "457      0.684265      0.818746         0.178772   \n",
       "462      0.152344      0.183594         0.350326   \n",
       "463      0.484375      0.511289         1.408908   \n",
       "467      1.127930      1.461231         0.235912   \n",
       "470      0.050537      0.055664         0.373539   \n",
       "471      0.415631      0.546960         0.097613   \n",
       "476      0.156250      0.188145         0.362612   \n",
       "477      0.433594      0.491778         1.276618   \n",
       "481      1.071289      1.531494         0.339331   \n",
       "484      0.042480      0.053711         0.315148   \n",
       "485      0.453938      0.467799         0.097548   \n",
       "490      0.156250      0.185547         0.362405   \n",
       "491      0.468750      0.525303         1.402252   \n",
       "495      1.047852      1.522217         0.397478   \n",
       "498      0.031738      0.053223         0.217179   \n",
       "499      0.383914      0.411485         0.084046   \n",
       "504      0.160156      0.189775         0.368942   \n",
       "505      0.521484      0.589414         1.617201   \n",
       "509      1.494629      1.576807         0.823562   \n",
       "512      0.054443      0.067952         0.399260   \n",
       "513      0.176707      0.262763         0.026292   \n",
       "518      0.156250      0.183594         0.351255   \n",
       "519      0.645410      0.739805         1.878883   \n",
       "523      1.062500      1.381323         0.309484   \n",
       "526      0.049316      0.057617         0.372238   \n",
       "527      0.709435      0.882136         0.181453   \n",
       "532      0.167969      0.193359         0.379655   \n",
       "533      0.886523      0.921875         2.383613   \n",
       "537      0.898438      1.256227         0.267172   \n",
       "540      0.025879      0.049478         0.126746   \n",
       "541      1.030736      1.113242         0.303093   \n",
       "546      0.179688      0.203125         0.401115   \n",
       "547      1.053613      1.105703         3.515951   \n",
       "551      1.216064      1.280908         0.619441   \n",
       "554      0.028320      0.045083         0.179583   \n",
       "555      0.972981      1.158377         0.273111   \n",
       "560      0.181641      0.207676         0.405101   \n",
       "561      0.554688      0.583770         1.269600   \n",
       "565      0.881714      1.492285         0.362246   \n",
       "568      0.055664      0.072266         0.396079   \n",
       "569      1.813412      1.953422         0.544274   \n",
       "574      0.185547      0.210938         0.401241   \n",
       "575      0.901269      0.978301         2.448651   \n",
       "579      1.163086      1.392188         0.418092   \n",
       "582      0.037598      0.055337         0.227011   \n",
       "583      1.393391      1.484325         0.363601   \n",
       "588      0.191406      0.216797         0.416088   \n",
       "589      0.912988      0.982891         2.227569   \n",
       "593      0.905029      1.104297         0.122162   \n",
       "596      0.040527      0.065264         0.229609   \n",
       "597      1.661738      1.829590         0.500673   \n",
       "602      0.201172      0.224609         0.426896   \n",
       "603      1.093750      1.225508         2.100902   \n",
       "607      0.959473      1.155273         0.246498   \n",
       "610      0.067139      0.083821         0.452350   \n",
       "611      1.494398      1.687996         0.380462   \n",
       "616      0.208984      0.232422         0.446211   \n",
       "617      0.791016      0.916524         1.830809   \n",
       "621      0.980957      1.157642         0.027622   \n",
       "624      0.032227      0.053384         0.158186   \n",
       "625      0.494427      0.701405         0.102268   \n",
       "630      0.212891      0.234375         0.447649   \n",
       "631      0.911035      0.994141         1.505234   \n",
       "635      1.048462      1.261548         0.407483   \n",
       "638      0.041504      0.065918         0.217358   \n",
       "639      0.922965      1.029727         0.174862   \n",
       "644      0.226562      0.246094         0.469214   \n",
       "645      1.426660      1.528652         3.177576   \n",
       "649      0.849976      0.985815         0.132942   \n",
       "652      0.039551      0.062988         0.219642   \n",
       "653      1.699435      1.870858         0.360156   \n",
       "658      0.240234      0.257812         0.490448   \n",
       "659      2.062500      2.140860         5.708883   \n",
       "663      0.945801      1.044531         0.234921   \n",
       "666      0.046875      0.073892         0.246296   \n",
       "667      3.387670      3.451971         0.701294   \n",
       "672      0.248047      0.265625         0.503243   \n",
       "673      1.237744      1.301016         3.859613   \n",
       "677      0.948853      1.048486         0.281841   \n",
       "680      0.021973      0.054199         0.039266   \n",
       "681      2.644493      2.804333         0.674139   \n",
       "686      0.261719      0.279297         0.520431   \n",
       "687      1.305566      1.431875         3.397438   \n",
       "691      1.089844      1.163526         0.951956   \n",
       "694      0.048340      0.068032         0.262937   \n",
       "695      2.150823      2.299760         0.410259   \n",
       "700      0.267578      0.283203         0.515083   \n",
       "701      1.300781      1.476856         2.007570   \n",
       "705      0.673096      0.922681         0.103372   \n",
       "708      0.062012      0.073242         0.394720   \n",
       "709      2.386315      2.463500         0.568042   \n",
       "714      0.275391      0.291016         0.524635   \n",
       "715      1.190332      1.247637         3.103201   \n",
       "719      1.131348      1.276367         0.285820   \n",
       "722      0.037598      0.060220         0.192370   \n",
       "723      1.888172      2.087419         0.393626   \n",
       "728      0.289062      0.304688         0.534156   \n",
       "729      1.322949      1.399531         2.868668   \n",
       "733      0.822510      0.978174         0.055702   \n",
       "736      0.057617      0.075195         0.284010   \n",
       "737      2.618715      2.694504         0.679144   \n",
       "742      0.308594      0.326172         0.556446   \n",
       "743      1.219629      1.363066         2.471215   \n",
       "747      0.671143      0.873755         0.403523   \n",
       "750      0.040527      0.065591         0.191890   \n",
       "751      0.187614      0.195273         0.022572   \n",
       "756      0.312500      0.328125         0.545812   \n",
       "757      1.614013      1.735469         4.041889   \n",
       "761      0.758789      0.898676         0.304196   \n",
       "764      0.043774      0.068521         0.194487   \n",
       "765      1.402942      1.410501         0.305408   \n",
       "770      0.328125      0.343750         0.555472   \n",
       "771      1.803174      1.869033         4.919867   \n",
       "775      0.944092      1.021484         0.911884   \n",
       "778      0.032715      0.055010         0.111192   \n",
       "779      2.042114      2.055563         0.425104   \n",
       "784      0.335938      0.353516         0.543184   \n",
       "785      1.345508      1.435244         3.083971   \n",
       "789      0.809082      0.952783         0.280916   \n",
       "792      0.061035      0.083008         0.370537   \n",
       "793      2.223292      2.241890         0.474197   \n",
       "798      0.320312      0.339844         0.485165   \n",
       "799      1.494385      1.565547         2.828442   \n",
       "803      1.151611      1.248047         1.151081   \n",
       "806      0.057532      0.076660         0.300693   \n",
       "807      1.669389      1.677698         0.405869   \n",
       "812      0.273438      0.304688         0.382612   \n",
       "813      1.613915      1.713438         3.257493   \n",
       "817      0.926270      1.139648         0.948174   \n",
       "820      0.058105      0.080078         0.224175   \n",
       "821      1.551329      1.562970         0.402342   \n",
       "826      0.132812      0.363281         0.108034   \n",
       "827      1.631738      1.770410         3.420182   \n",
       "831      0.842529      0.971289         0.853862   \n",
       "834      0.067627      0.083496         0.433885   \n",
       "835      0.606183      0.620658         0.134756   \n",
       "840      0.394531      0.530435         0.363059   \n",
       "841      1.196191      1.436006         1.914545   \n",
       "845      0.819580      1.065919         0.105089   \n",
       "\n",
       "                            spec_a_max                         spec_a_min  \\\n",
       "0      tensor(5.3336, device='cuda:0')    tensor(5.3336, device='cuda:0')   \n",
       "4      tensor(1.6002, device='cuda:0')    tensor(1.6002, device='cuda:0')   \n",
       "5      tensor(0.1525, device='cuda:0')    tensor(0.1525, device='cuda:0')   \n",
       "9      tensor(8.2380, device='cuda:0')    tensor(8.2380, device='cuda:0')   \n",
       "12     tensor(4.9664, device='cuda:0')    tensor(4.9664, device='cuda:0')   \n",
       "16     tensor(4.8053, device='cuda:0')    tensor(4.8053, device='cuda:0')   \n",
       "17     tensor(0.0914, device='cuda:0')    tensor(0.0914, device='cuda:0')   \n",
       "21     tensor(5.2653, device='cuda:0')    tensor(5.2653, device='cuda:0')   \n",
       "24     tensor(6.6982, device='cuda:0')    tensor(6.6982, device='cuda:0')   \n",
       "28     tensor(5.1076, device='cuda:0')    tensor(5.1076, device='cuda:0')   \n",
       "29     tensor(0.0766, device='cuda:0')    tensor(0.0766, device='cuda:0')   \n",
       "33     tensor(6.0455, device='cuda:0')    tensor(6.0455, device='cuda:0')   \n",
       "36     tensor(8.1911, device='cuda:0')    tensor(8.1911, device='cuda:0')   \n",
       "37   tensor(100.1507, device='cuda:0')  tensor(100.1507, device='cuda:0')   \n",
       "42     tensor(7.4303, device='cuda:0')    tensor(7.4303, device='cuda:0')   \n",
       "43     tensor(0.3475, device='cuda:0')    tensor(0.3475, device='cuda:0')   \n",
       "47    tensor(13.8857, device='cuda:0')   tensor(13.8857, device='cuda:0')   \n",
       "50     tensor(6.2827, device='cuda:0')    tensor(6.2827, device='cuda:0')   \n",
       "51    tensor(94.4864, device='cuda:0')   tensor(94.4864, device='cuda:0')   \n",
       "56    tensor(10.5015, device='cuda:0')   tensor(10.5015, device='cuda:0')   \n",
       "57     tensor(0.1450, device='cuda:0')    tensor(0.1450, device='cuda:0')   \n",
       "61     tensor(8.6486, device='cuda:0')    tensor(8.6486, device='cuda:0')   \n",
       "64     tensor(8.3629, device='cuda:0')    tensor(8.3629, device='cuda:0')   \n",
       "65   tensor(114.0257, device='cuda:0')  tensor(114.0257, device='cuda:0')   \n",
       "70    tensor(11.9267, device='cuda:0')   tensor(11.9267, device='cuda:0')   \n",
       "71     tensor(0.1644, device='cuda:0')    tensor(0.1644, device='cuda:0')   \n",
       "75    tensor(12.0832, device='cuda:0')   tensor(12.0832, device='cuda:0')   \n",
       "78     tensor(7.1172, device='cuda:0')    tensor(7.1172, device='cuda:0')   \n",
       "79   tensor(118.3715, device='cuda:0')  tensor(118.3715, device='cuda:0')   \n",
       "84    tensor(12.5663, device='cuda:0')   tensor(12.5663, device='cuda:0')   \n",
       "85     tensor(0.1353, device='cuda:0')    tensor(0.1353, device='cuda:0')   \n",
       "89     tensor(8.6005, device='cuda:0')    tensor(8.6005, device='cuda:0')   \n",
       "92     tensor(7.5191, device='cuda:0')    tensor(7.5191, device='cuda:0')   \n",
       "93   tensor(106.9184, device='cuda:0')  tensor(106.9184, device='cuda:0')   \n",
       "98    tensor(14.0793, device='cuda:0')   tensor(14.0793, device='cuda:0')   \n",
       "99     tensor(0.4269, device='cuda:0')    tensor(0.4269, device='cuda:0')   \n",
       "103   tensor(13.7752, device='cuda:0')   tensor(13.7752, device='cuda:0')   \n",
       "106    tensor(9.1110, device='cuda:0')    tensor(9.1110, device='cuda:0')   \n",
       "107   tensor(98.2158, device='cuda:0')   tensor(98.2158, device='cuda:0')   \n",
       "112   tensor(15.4928, device='cuda:0')   tensor(15.4928, device='cuda:0')   \n",
       "113    tensor(0.2657, device='cuda:0')    tensor(0.2657, device='cuda:0')   \n",
       "117   tensor(15.5082, device='cuda:0')   tensor(15.5082, device='cuda:0')   \n",
       "120    tensor(8.3947, device='cuda:0')    tensor(8.3947, device='cuda:0')   \n",
       "121   tensor(89.6706, device='cuda:0')   tensor(89.6706, device='cuda:0')   \n",
       "126   tensor(17.7825, device='cuda:0')   tensor(17.7825, device='cuda:0')   \n",
       "127    tensor(0.2861, device='cuda:0')    tensor(0.2861, device='cuda:0')   \n",
       "131   tensor(12.1471, device='cuda:0')   tensor(12.1471, device='cuda:0')   \n",
       "134    tensor(8.5417, device='cuda:0')    tensor(8.5417, device='cuda:0')   \n",
       "135   tensor(78.3724, device='cuda:0')   tensor(78.3724, device='cuda:0')   \n",
       "140   tensor(19.7088, device='cuda:0')   tensor(19.7088, device='cuda:0')   \n",
       "141    tensor(0.3591, device='cuda:0')    tensor(0.3591, device='cuda:0')   \n",
       "145   tensor(14.4370, device='cuda:0')   tensor(14.4370, device='cuda:0')   \n",
       "148    tensor(9.1190, device='cuda:0')    tensor(9.1190, device='cuda:0')   \n",
       "149   tensor(72.6086, device='cuda:0')   tensor(72.6086, device='cuda:0')   \n",
       "154   tensor(20.4722, device='cuda:0')   tensor(20.4722, device='cuda:0')   \n",
       "155    tensor(0.7863, device='cuda:0')    tensor(0.7863, device='cuda:0')   \n",
       "159   tensor(22.0929, device='cuda:0')   tensor(22.0929, device='cuda:0')   \n",
       "162    tensor(9.3110, device='cuda:0')    tensor(9.3110, device='cuda:0')   \n",
       "163   tensor(68.9073, device='cuda:0')   tensor(68.9073, device='cuda:0')   \n",
       "168   tensor(21.1927, device='cuda:0')   tensor(21.1927, device='cuda:0')   \n",
       "169    tensor(0.4933, device='cuda:0')    tensor(0.4933, device='cuda:0')   \n",
       "173   tensor(16.5391, device='cuda:0')   tensor(16.5391, device='cuda:0')   \n",
       "176    tensor(8.6378, device='cuda:0')    tensor(8.6378, device='cuda:0')   \n",
       "177   tensor(60.9366, device='cuda:0')   tensor(60.9366, device='cuda:0')   \n",
       "182   tensor(21.1274, device='cuda:0')   tensor(21.1274, device='cuda:0')   \n",
       "183    tensor(0.7918, device='cuda:0')    tensor(0.7918, device='cuda:0')   \n",
       "187   tensor(22.9336, device='cuda:0')   tensor(22.9336, device='cuda:0')   \n",
       "190    tensor(7.4479, device='cuda:0')    tensor(7.4479, device='cuda:0')   \n",
       "191   tensor(59.1179, device='cuda:0')   tensor(59.1179, device='cuda:0')   \n",
       "196   tensor(21.7043, device='cuda:0')   tensor(21.7043, device='cuda:0')   \n",
       "197    tensor(1.3119, device='cuda:0')    tensor(1.3119, device='cuda:0')   \n",
       "201   tensor(28.7816, device='cuda:0')   tensor(28.7816, device='cuda:0')   \n",
       "204    tensor(6.5175, device='cuda:0')    tensor(6.5175, device='cuda:0')   \n",
       "205   tensor(57.5005, device='cuda:0')   tensor(57.5005, device='cuda:0')   \n",
       "210   tensor(21.4814, device='cuda:0')   tensor(21.4814, device='cuda:0')   \n",
       "211    tensor(2.7764, device='cuda:0')    tensor(2.7764, device='cuda:0')   \n",
       "215   tensor(34.1555, device='cuda:0')   tensor(34.1555, device='cuda:0')   \n",
       "218    tensor(7.4934, device='cuda:0')    tensor(7.4934, device='cuda:0')   \n",
       "219   tensor(63.4924, device='cuda:0')   tensor(63.4924, device='cuda:0')   \n",
       "224   tensor(21.8560, device='cuda:0')   tensor(21.8560, device='cuda:0')   \n",
       "225    tensor(1.6413, device='cuda:0')    tensor(1.6413, device='cuda:0')   \n",
       "229   tensor(31.5880, device='cuda:0')   tensor(31.5880, device='cuda:0')   \n",
       "232    tensor(7.4702, device='cuda:0')    tensor(7.4702, device='cuda:0')   \n",
       "233   tensor(64.1104, device='cuda:0')   tensor(64.1104, device='cuda:0')   \n",
       "238   tensor(21.9142, device='cuda:0')   tensor(21.9142, device='cuda:0')   \n",
       "239    tensor(2.0205, device='cuda:0')    tensor(2.0205, device='cuda:0')   \n",
       "243   tensor(34.8084, device='cuda:0')   tensor(34.8084, device='cuda:0')   \n",
       "246    tensor(8.1838, device='cuda:0')    tensor(8.1838, device='cuda:0')   \n",
       "247   tensor(61.6068, device='cuda:0')   tensor(61.6068, device='cuda:0')   \n",
       "252   tensor(22.3018, device='cuda:0')   tensor(22.3018, device='cuda:0')   \n",
       "253    tensor(1.7901, device='cuda:0')    tensor(1.7901, device='cuda:0')   \n",
       "257   tensor(22.9282, device='cuda:0')   tensor(22.9282, device='cuda:0')   \n",
       "260    tensor(7.6980, device='cuda:0')    tensor(7.6980, device='cuda:0')   \n",
       "261   tensor(48.8384, device='cuda:0')   tensor(48.8384, device='cuda:0')   \n",
       "266   tensor(22.8085, device='cuda:0')   tensor(22.8085, device='cuda:0')   \n",
       "267    tensor(2.0076, device='cuda:0')    tensor(2.0076, device='cuda:0')   \n",
       "271   tensor(35.7544, device='cuda:0')   tensor(35.7544, device='cuda:0')   \n",
       "274    tensor(8.9417, device='cuda:0')    tensor(8.9417, device='cuda:0')   \n",
       "275   tensor(51.3498, device='cuda:0')   tensor(51.3498, device='cuda:0')   \n",
       "280   tensor(23.3116, device='cuda:0')   tensor(23.3116, device='cuda:0')   \n",
       "281    tensor(1.4651, device='cuda:0')    tensor(1.4651, device='cuda:0')   \n",
       "285   tensor(28.2540, device='cuda:0')   tensor(28.2540, device='cuda:0')   \n",
       "288    tensor(8.0688, device='cuda:0')    tensor(8.0688, device='cuda:0')   \n",
       "289   tensor(49.0624, device='cuda:0')   tensor(49.0624, device='cuda:0')   \n",
       "294   tensor(23.8136, device='cuda:0')   tensor(23.8136, device='cuda:0')   \n",
       "295    tensor(1.9682, device='cuda:0')    tensor(1.9682, device='cuda:0')   \n",
       "299   tensor(20.6720, device='cuda:0')   tensor(20.6720, device='cuda:0')   \n",
       "302    tensor(8.1301, device='cuda:0')    tensor(8.1301, device='cuda:0')   \n",
       "303   tensor(45.6287, device='cuda:0')   tensor(45.6287, device='cuda:0')   \n",
       "308   tensor(24.3543, device='cuda:0')   tensor(24.3543, device='cuda:0')   \n",
       "309    tensor(2.0956, device='cuda:0')    tensor(2.0956, device='cuda:0')   \n",
       "313   tensor(30.6099, device='cuda:0')   tensor(30.6099, device='cuda:0')   \n",
       "316    tensor(7.0863, device='cuda:0')    tensor(7.0863, device='cuda:0')   \n",
       "317   tensor(48.8561, device='cuda:0')   tensor(48.8561, device='cuda:0')   \n",
       "322   tensor(24.9846, device='cuda:0')   tensor(24.9846, device='cuda:0')   \n",
       "323    tensor(3.1029, device='cuda:0')    tensor(3.1029, device='cuda:0')   \n",
       "327   tensor(35.5251, device='cuda:0')   tensor(35.5251, device='cuda:0')   \n",
       "330    tensor(7.2111, device='cuda:0')    tensor(7.2111, device='cuda:0')   \n",
       "331   tensor(50.1678, device='cuda:0')   tensor(50.1678, device='cuda:0')   \n",
       "336   tensor(25.5310, device='cuda:0')   tensor(25.5310, device='cuda:0')   \n",
       "337    tensor(4.7191, device='cuda:0')    tensor(4.7191, device='cuda:0')   \n",
       "341   tensor(45.1254, device='cuda:0')   tensor(45.1254, device='cuda:0')   \n",
       "344    tensor(7.4575, device='cuda:0')    tensor(7.4575, device='cuda:0')   \n",
       "345   tensor(48.4476, device='cuda:0')   tensor(48.4476, device='cuda:0')   \n",
       "350   tensor(25.8818, device='cuda:0')   tensor(25.8818, device='cuda:0')   \n",
       "351    tensor(4.0226, device='cuda:0')    tensor(4.0226, device='cuda:0')   \n",
       "355   tensor(41.3423, device='cuda:0')   tensor(41.3423, device='cuda:0')   \n",
       "358    tensor(7.8115, device='cuda:0')    tensor(7.8115, device='cuda:0')   \n",
       "359   tensor(46.0343, device='cuda:0')   tensor(46.0343, device='cuda:0')   \n",
       "364   tensor(26.6239, device='cuda:0')   tensor(26.6239, device='cuda:0')   \n",
       "365    tensor(4.6041, device='cuda:0')    tensor(4.6041, device='cuda:0')   \n",
       "369   tensor(39.5896, device='cuda:0')   tensor(39.5896, device='cuda:0')   \n",
       "372    tensor(7.7085, device='cuda:0')    tensor(7.7085, device='cuda:0')   \n",
       "373   tensor(50.1551, device='cuda:0')   tensor(50.1551, device='cuda:0')   \n",
       "378   tensor(27.1109, device='cuda:0')   tensor(27.1109, device='cuda:0')   \n",
       "379    tensor(3.6967, device='cuda:0')    tensor(3.6967, device='cuda:0')   \n",
       "383   tensor(35.2180, device='cuda:0')   tensor(35.2180, device='cuda:0')   \n",
       "386    tensor(8.0352, device='cuda:0')    tensor(8.0352, device='cuda:0')   \n",
       "387   tensor(46.7870, device='cuda:0')   tensor(46.7870, device='cuda:0')   \n",
       "392   tensor(27.5551, device='cuda:0')   tensor(27.5551, device='cuda:0')   \n",
       "393    tensor(6.2700, device='cuda:0')    tensor(6.2700, device='cuda:0')   \n",
       "397   tensor(45.0640, device='cuda:0')   tensor(45.0640, device='cuda:0')   \n",
       "400    tensor(7.9113, device='cuda:0')    tensor(7.9113, device='cuda:0')   \n",
       "401   tensor(49.6519, device='cuda:0')   tensor(49.6519, device='cuda:0')   \n",
       "406   tensor(27.8157, device='cuda:0')   tensor(27.8157, device='cuda:0')   \n",
       "407    tensor(5.9173, device='cuda:0')    tensor(5.9173, device='cuda:0')   \n",
       "411   tensor(48.6647, device='cuda:0')   tensor(48.6647, device='cuda:0')   \n",
       "414    tensor(8.0623, device='cuda:0')    tensor(8.0623, device='cuda:0')   \n",
       "415   tensor(56.3649, device='cuda:0')   tensor(56.3649, device='cuda:0')   \n",
       "420   tensor(28.2711, device='cuda:0')   tensor(28.2711, device='cuda:0')   \n",
       "421    tensor(5.5067, device='cuda:0')    tensor(5.5067, device='cuda:0')   \n",
       "425   tensor(37.7729, device='cuda:0')   tensor(37.7729, device='cuda:0')   \n",
       "428    tensor(7.8977, device='cuda:0')    tensor(7.8977, device='cuda:0')   \n",
       "429   tensor(52.7972, device='cuda:0')   tensor(52.7972, device='cuda:0')   \n",
       "434   tensor(28.9267, device='cuda:0')   tensor(28.9267, device='cuda:0')   \n",
       "435    tensor(7.0520, device='cuda:0')    tensor(7.0520, device='cuda:0')   \n",
       "439   tensor(43.0377, device='cuda:0')   tensor(43.0377, device='cuda:0')   \n",
       "442    tensor(8.8892, device='cuda:0')    tensor(8.8892, device='cuda:0')   \n",
       "443   tensor(50.1528, device='cuda:0')   tensor(50.1528, device='cuda:0')   \n",
       "448   tensor(29.1629, device='cuda:0')   tensor(29.1629, device='cuda:0')   \n",
       "449    tensor(7.5888, device='cuda:0')    tensor(7.5888, device='cuda:0')   \n",
       "453   tensor(44.0914, device='cuda:0')   tensor(44.0914, device='cuda:0')   \n",
       "456    tensor(8.9635, device='cuda:0')    tensor(8.9635, device='cuda:0')   \n",
       "457   tensor(49.9358, device='cuda:0')   tensor(49.9358, device='cuda:0')   \n",
       "462   tensor(29.4815, device='cuda:0')   tensor(29.4815, device='cuda:0')   \n",
       "463    tensor(7.1748, device='cuda:0')    tensor(7.1748, device='cuda:0')   \n",
       "467   tensor(47.2231, device='cuda:0')   tensor(47.2231, device='cuda:0')   \n",
       "470    tensor(9.1937, device='cuda:0')    tensor(9.1937, device='cuda:0')   \n",
       "471   tensor(55.4773, device='cuda:0')   tensor(55.4773, device='cuda:0')   \n",
       "476   tensor(29.8459, device='cuda:0')   tensor(29.8459, device='cuda:0')   \n",
       "477    tensor(7.0637, device='cuda:0')    tensor(7.0637, device='cuda:0')   \n",
       "481   tensor(47.4515, device='cuda:0')   tensor(47.4515, device='cuda:0')   \n",
       "484    tensor(8.8931, device='cuda:0')    tensor(8.8931, device='cuda:0')   \n",
       "485   tensor(66.1102, device='cuda:0')   tensor(66.1102, device='cuda:0')   \n",
       "490   tensor(30.2914, device='cuda:0')   tensor(30.2914, device='cuda:0')   \n",
       "491    tensor(6.9795, device='cuda:0')    tensor(6.9795, device='cuda:0')   \n",
       "495   tensor(46.4350, device='cuda:0')   tensor(46.4350, device='cuda:0')   \n",
       "498    tensor(8.3481, device='cuda:0')    tensor(8.3481, device='cuda:0')   \n",
       "499   tensor(62.6701, device='cuda:0')   tensor(62.6701, device='cuda:0')   \n",
       "504   tensor(30.8747, device='cuda:0')   tensor(30.8747, device='cuda:0')   \n",
       "505    tensor(6.7068, device='cuda:0')    tensor(6.7068, device='cuda:0')   \n",
       "509   tensor(35.1367, device='cuda:0')   tensor(35.1367, device='cuda:0')   \n",
       "512    tensor(9.2351, device='cuda:0')    tensor(9.2351, device='cuda:0')   \n",
       "513   tensor(59.2294, device='cuda:0')   tensor(59.2294, device='cuda:0')   \n",
       "518   tensor(31.6625, device='cuda:0')   tensor(31.6625, device='cuda:0')   \n",
       "519    tensor(7.1053, device='cuda:0')    tensor(7.1053, device='cuda:0')   \n",
       "523   tensor(41.1661, device='cuda:0')   tensor(41.1661, device='cuda:0')   \n",
       "526    tensor(9.0541, device='cuda:0')    tensor(9.0541, device='cuda:0')   \n",
       "527   tensor(54.6239, device='cuda:0')   tensor(54.6239, device='cuda:0')   \n",
       "532   tensor(32.0230, device='cuda:0')   tensor(32.0230, device='cuda:0')   \n",
       "533    tensor(7.7504, device='cuda:0')    tensor(7.7504, device='cuda:0')   \n",
       "537   tensor(43.7345, device='cuda:0')   tensor(43.7345, device='cuda:0')   \n",
       "540    tensor(7.7906, device='cuda:0')    tensor(7.7906, device='cuda:0')   \n",
       "541   tensor(50.2213, device='cuda:0')   tensor(50.2213, device='cuda:0')   \n",
       "546   tensor(32.5104, device='cuda:0')   tensor(32.5104, device='cuda:0')   \n",
       "547    tensor(6.2571, device='cuda:0')    tensor(6.2571, device='cuda:0')   \n",
       "551   tensor(33.1872, device='cuda:0')   tensor(33.1872, device='cuda:0')   \n",
       "554    tensor(8.7911, device='cuda:0')    tensor(8.7911, device='cuda:0')   \n",
       "555   tensor(52.3113, device='cuda:0')   tensor(52.3113, device='cuda:0')   \n",
       "560   tensor(32.8780, device='cuda:0')   tensor(32.8780, device='cuda:0')   \n",
       "561    tensor(9.1635, device='cuda:0')    tensor(9.1635, device='cuda:0')   \n",
       "565   tensor(45.9669, device='cuda:0')   tensor(45.9669, device='cuda:0')   \n",
       "568    tensor(9.3765, device='cuda:0')    tensor(9.3765, device='cuda:0')   \n",
       "569   tensor(49.3978, device='cuda:0')   tensor(49.3978, device='cuda:0')   \n",
       "574   tensor(33.5963, device='cuda:0')   tensor(33.5963, device='cuda:0')   \n",
       "575    tensor(7.3317, device='cuda:0')    tensor(7.3317, device='cuda:0')   \n",
       "579   tensor(39.5282, device='cuda:0')   tensor(39.5282, device='cuda:0')   \n",
       "582    tensor(9.4238, device='cuda:0')    tensor(9.4238, device='cuda:0')   \n",
       "583   tensor(56.2447, device='cuda:0')   tensor(56.2447, device='cuda:0')   \n",
       "588   tensor(34.1019, device='cuda:0')   tensor(34.1019, device='cuda:0')   \n",
       "589    tensor(8.7282, device='cuda:0')    tensor(8.7282, device='cuda:0')   \n",
       "593   tensor(41.7924, device='cuda:0')   tensor(41.7924, device='cuda:0')   \n",
       "596    tensor(9.4888, device='cuda:0')    tensor(9.4888, device='cuda:0')   \n",
       "597   tensor(50.6739, device='cuda:0')   tensor(50.6739, device='cuda:0')   \n",
       "602   tensor(34.8381, device='cuda:0')   tensor(34.8381, device='cuda:0')   \n",
       "603   tensor(10.6215, device='cuda:0')   tensor(10.6215, device='cuda:0')   \n",
       "607   tensor(38.4031, device='cuda:0')   tensor(38.4031, device='cuda:0')   \n",
       "610   tensor(10.1547, device='cuda:0')   tensor(10.1547, device='cuda:0')   \n",
       "611   tensor(59.4024, device='cuda:0')   tensor(59.4024, device='cuda:0')   \n",
       "616   tensor(35.1618, device='cuda:0')   tensor(35.1618, device='cuda:0')   \n",
       "617    tensor(8.9547, device='cuda:0')    tensor(8.9547, device='cuda:0')   \n",
       "621   tensor(42.6732, device='cuda:0')   tensor(42.6732, device='cuda:0')   \n",
       "624    tensor(9.0071, device='cuda:0')    tensor(9.0071, device='cuda:0')   \n",
       "625   tensor(62.6079, device='cuda:0')   tensor(62.6079, device='cuda:0')   \n",
       "630   tensor(35.8257, device='cuda:0')   tensor(35.8257, device='cuda:0')   \n",
       "631   tensor(11.4890, device='cuda:0')   tensor(11.4890, device='cuda:0')   \n",
       "635   tensor(36.7034, device='cuda:0')   tensor(36.7034, device='cuda:0')   \n",
       "638    tensor(9.9397, device='cuda:0')    tensor(9.9397, device='cuda:0')   \n",
       "639   tensor(78.4991, device='cuda:0')   tensor(78.4991, device='cuda:0')   \n",
       "644   tensor(36.4477, device='cuda:0')   tensor(36.4477, device='cuda:0')   \n",
       "645    tensor(8.7187, device='cuda:0')    tensor(8.7187, device='cuda:0')   \n",
       "649   tensor(32.5070, device='cuda:0')   tensor(32.5070, device='cuda:0')   \n",
       "652    tensor(8.8005, device='cuda:0')    tensor(8.8005, device='cuda:0')   \n",
       "653   tensor(72.5543, device='cuda:0')   tensor(72.5543, device='cuda:0')   \n",
       "658   tensor(37.1540, device='cuda:0')   tensor(37.1540, device='cuda:0')   \n",
       "659    tensor(7.1151, device='cuda:0')    tensor(7.1151, device='cuda:0')   \n",
       "663   tensor(35.0433, device='cuda:0')   tensor(35.0433, device='cuda:0')   \n",
       "666    tensor(9.1606, device='cuda:0')    tensor(9.1606, device='cuda:0')   \n",
       "667   tensor(75.6523, device='cuda:0')   tensor(75.6523, device='cuda:0')   \n",
       "672   tensor(37.7089, device='cuda:0')   tensor(37.7089, device='cuda:0')   \n",
       "673    tensor(6.7420, device='cuda:0')    tensor(6.7420, device='cuda:0')   \n",
       "677   tensor(29.9810, device='cuda:0')   tensor(29.9810, device='cuda:0')   \n",
       "680    tensor(8.2957, device='cuda:0')    tensor(8.2957, device='cuda:0')   \n",
       "681   tensor(61.2810, device='cuda:0')   tensor(61.2810, device='cuda:0')   \n",
       "686   tensor(38.6971, device='cuda:0')   tensor(38.6971, device='cuda:0')   \n",
       "687    tensor(8.0112, device='cuda:0')    tensor(8.0112, device='cuda:0')   \n",
       "691   tensor(23.5151, device='cuda:0')   tensor(23.5151, device='cuda:0')   \n",
       "694   tensor(10.2153, device='cuda:0')   tensor(10.2153, device='cuda:0')   \n",
       "695   tensor(81.7240, device='cuda:0')   tensor(81.7240, device='cuda:0')   \n",
       "700   tensor(39.8058, device='cuda:0')   tensor(39.8058, device='cuda:0')   \n",
       "701   tensor(12.5172, device='cuda:0')   tensor(12.5172, device='cuda:0')   \n",
       "705   tensor(32.2726, device='cuda:0')   tensor(32.2726, device='cuda:0')   \n",
       "708   tensor(10.2277, device='cuda:0')   tensor(10.2277, device='cuda:0')   \n",
       "709   tensor(65.7815, device='cuda:0')   tensor(65.7815, device='cuda:0')   \n",
       "714   tensor(40.3842, device='cuda:0')   tensor(40.3842, device='cuda:0')   \n",
       "715    tensor(8.1269, device='cuda:0')    tensor(8.1269, device='cuda:0')   \n",
       "719   tensor(37.5807, device='cuda:0')   tensor(37.5807, device='cuda:0')   \n",
       "722    tensor(9.3112, device='cuda:0')    tensor(9.3112, device='cuda:0')   \n",
       "723   tensor(72.9595, device='cuda:0')   tensor(72.9595, device='cuda:0')   \n",
       "728   tensor(41.6169, device='cuda:0')   tensor(41.6169, device='cuda:0')   \n",
       "729    tensor(9.6113, device='cuda:0')    tensor(9.6113, device='cuda:0')   \n",
       "733   tensor(34.9307, device='cuda:0')   tensor(34.9307, device='cuda:0')   \n",
       "736   tensor(10.7485, device='cuda:0')   tensor(10.7485, device='cuda:0')   \n",
       "737   tensor(59.8881, device='cuda:0')   tensor(59.8881, device='cuda:0')   \n",
       "742   tensor(42.8312, device='cuda:0')   tensor(42.8312, device='cuda:0')   \n",
       "743    tensor(9.4702, device='cuda:0')    tensor(9.4702, device='cuda:0')   \n",
       "747   tensor(24.9184, device='cuda:0')   tensor(24.9184, device='cuda:0')   \n",
       "750    tensor(9.1687, device='cuda:0')    tensor(9.1687, device='cuda:0')   \n",
       "751  tensor(100.7419, device='cuda:0')  tensor(100.7419, device='cuda:0')   \n",
       "756   tensor(43.9473, device='cuda:0')   tensor(43.9473, device='cuda:0')   \n",
       "757    tensor(8.1101, device='cuda:0')    tensor(8.1101, device='cuda:0')   \n",
       "761   tensor(25.2495, device='cuda:0')   tensor(25.2495, device='cuda:0')   \n",
       "764    tensor(9.5448, device='cuda:0')    tensor(9.5448, device='cuda:0')   \n",
       "765   tensor(71.4582, device='cuda:0')   tensor(71.4582, device='cuda:0')   \n",
       "770   tensor(45.3746, device='cuda:0')   tensor(45.3746, device='cuda:0')   \n",
       "771    tensor(7.3151, device='cuda:0')    tensor(7.3151, device='cuda:0')   \n",
       "775   tensor(20.3954, device='cuda:0')   tensor(20.3954, device='cuda:0')   \n",
       "778    tensor(9.3462, device='cuda:0')    tensor(9.3462, device='cuda:0')   \n",
       "779   tensor(75.4897, device='cuda:0')   tensor(75.4897, device='cuda:0')   \n",
       "784   tensor(46.9549, device='cuda:0')   tensor(46.9549, device='cuda:0')   \n",
       "785    tensor(8.7121, device='cuda:0')    tensor(8.7121, device='cuda:0')   \n",
       "789   tensor(26.4895, device='cuda:0')   tensor(26.4895, device='cuda:0')   \n",
       "792    tensor(9.1116, device='cuda:0')    tensor(9.1116, device='cuda:0')   \n",
       "793   tensor(73.3645, device='cuda:0')   tensor(73.3645, device='cuda:0')   \n",
       "798   tensor(48.4767, device='cuda:0')   tensor(48.4767, device='cuda:0')   \n",
       "799    tensor(9.4023, device='cuda:0')    tensor(9.4023, device='cuda:0')   \n",
       "803   tensor(19.4237, device='cuda:0')   tensor(19.4237, device='cuda:0')   \n",
       "806    tensor(8.8867, device='cuda:0')    tensor(8.8867, device='cuda:0')   \n",
       "807   tensor(63.7406, device='cuda:0')   tensor(63.7406, device='cuda:0')   \n",
       "812   tensor(50.5615, device='cuda:0')   tensor(50.5615, device='cuda:0')   \n",
       "813    tensor(8.9994, device='cuda:0')    tensor(8.9994, device='cuda:0')   \n",
       "817   tensor(15.0780, device='cuda:0')   tensor(15.0780, device='cuda:0')   \n",
       "820   tensor(11.3222, device='cuda:0')   tensor(11.3222, device='cuda:0')   \n",
       "821   tensor(59.8122, device='cuda:0')   tensor(59.8122, device='cuda:0')   \n",
       "826   tensor(53.4548, device='cuda:0')   tensor(53.4548, device='cuda:0')   \n",
       "827    tensor(9.4407, device='cuda:0')    tensor(9.4407, device='cuda:0')   \n",
       "831   tensor(19.7119, device='cuda:0')   tensor(19.7119, device='cuda:0')   \n",
       "834    tensor(9.1216, device='cuda:0')    tensor(9.1216, device='cuda:0')   \n",
       "835   tensor(64.9622, device='cuda:0')   tensor(64.9622, device='cuda:0')   \n",
       "840   tensor(55.2368, device='cuda:0')   tensor(55.2368, device='cuda:0')   \n",
       "841   tensor(11.6286, device='cuda:0')   tensor(11.6286, device='cuda:0')   \n",
       "845   tensor(26.1977, device='cuda:0')   tensor(26.1977, device='cuda:0')   \n",
       "\n",
       "                            spec_b_max                         spec_b_min  \\\n",
       "0      tensor(3.7083, device='cuda:0')    tensor(3.7083, device='cuda:0')   \n",
       "4      tensor(1.9766, device='cuda:0')    tensor(1.9766, device='cuda:0')   \n",
       "5      tensor(0.2315, device='cuda:0')    tensor(0.2315, device='cuda:0')   \n",
       "9     tensor(17.6898, device='cuda:0')   tensor(17.6898, device='cuda:0')   \n",
       "12     tensor(4.0251, device='cuda:0')    tensor(4.0251, device='cuda:0')   \n",
       "16     tensor(5.4184, device='cuda:0')    tensor(5.4184, device='cuda:0')   \n",
       "17     tensor(0.2626, device='cuda:0')    tensor(0.2626, device='cuda:0')   \n",
       "21    tensor(17.5262, device='cuda:0')   tensor(17.5262, device='cuda:0')   \n",
       "24     tensor(5.0422, device='cuda:0')    tensor(5.0422, device='cuda:0')   \n",
       "28     tensor(3.6917, device='cuda:0')    tensor(3.6917, device='cuda:0')   \n",
       "29     tensor(0.2770, device='cuda:0')    tensor(0.2770, device='cuda:0')   \n",
       "33    tensor(18.1264, device='cuda:0')   tensor(18.1264, device='cuda:0')   \n",
       "36     tensor(4.5419, device='cuda:0')    tensor(4.5419, device='cuda:0')   \n",
       "37    tensor(79.2482, device='cuda:0')   tensor(79.2482, device='cuda:0')   \n",
       "42    tensor(10.3352, device='cuda:0')   tensor(10.3352, device='cuda:0')   \n",
       "43     tensor(0.4166, device='cuda:0')    tensor(0.4166, device='cuda:0')   \n",
       "47    tensor(19.0650, device='cuda:0')   tensor(19.0650, device='cuda:0')   \n",
       "50     tensor(3.8865, device='cuda:0')    tensor(3.8865, device='cuda:0')   \n",
       "51   tensor(105.3708, device='cuda:0')  tensor(105.3708, device='cuda:0')   \n",
       "56    tensor(10.4364, device='cuda:0')   tensor(10.4364, device='cuda:0')   \n",
       "57     tensor(1.0860, device='cuda:0')    tensor(1.0860, device='cuda:0')   \n",
       "61    tensor(38.9667, device='cuda:0')   tensor(38.9667, device='cuda:0')   \n",
       "64     tensor(5.8344, device='cuda:0')    tensor(5.8344, device='cuda:0')   \n",
       "65   tensor(120.6101, device='cuda:0')  tensor(120.6101, device='cuda:0')   \n",
       "70    tensor(12.2196, device='cuda:0')   tensor(12.2196, device='cuda:0')   \n",
       "71     tensor(0.6138, device='cuda:0')    tensor(0.6138, device='cuda:0')   \n",
       "75    tensor(29.7502, device='cuda:0')   tensor(29.7502, device='cuda:0')   \n",
       "78     tensor(5.7696, device='cuda:0')    tensor(5.7696, device='cuda:0')   \n",
       "79    tensor(95.9618, device='cuda:0')   tensor(95.9618, device='cuda:0')   \n",
       "84    tensor(13.8172, device='cuda:0')   tensor(13.8172, device='cuda:0')   \n",
       "85     tensor(0.4544, device='cuda:0')    tensor(0.4544, device='cuda:0')   \n",
       "89    tensor(28.6507, device='cuda:0')   tensor(28.6507, device='cuda:0')   \n",
       "92     tensor(5.4171, device='cuda:0')    tensor(5.4171, device='cuda:0')   \n",
       "93    tensor(87.7245, device='cuda:0')   tensor(87.7245, device='cuda:0')   \n",
       "98    tensor(14.1981, device='cuda:0')   tensor(14.1981, device='cuda:0')   \n",
       "99     tensor(0.7793, device='cuda:0')    tensor(0.7793, device='cuda:0')   \n",
       "103   tensor(36.2664, device='cuda:0')   tensor(36.2664, device='cuda:0')   \n",
       "106    tensor(5.3809, device='cuda:0')    tensor(5.3809, device='cuda:0')   \n",
       "107   tensor(86.6222, device='cuda:0')   tensor(86.6222, device='cuda:0')   \n",
       "112   tensor(15.7854, device='cuda:0')   tensor(15.7854, device='cuda:0')   \n",
       "113    tensor(0.5345, device='cuda:0')    tensor(0.5345, device='cuda:0')   \n",
       "117   tensor(24.0442, device='cuda:0')   tensor(24.0442, device='cuda:0')   \n",
       "120    tensor(3.1459, device='cuda:0')    tensor(3.1459, device='cuda:0')   \n",
       "121   tensor(77.0741, device='cuda:0')   tensor(77.0741, device='cuda:0')   \n",
       "126   tensor(16.4596, device='cuda:0')   tensor(16.4596, device='cuda:0')   \n",
       "127    tensor(2.3755, device='cuda:0')    tensor(2.3755, device='cuda:0')   \n",
       "131   tensor(58.5734, device='cuda:0')   tensor(58.5734, device='cuda:0')   \n",
       "134    tensor(3.6019, device='cuda:0')    tensor(3.6019, device='cuda:0')   \n",
       "135   tensor(64.9671, device='cuda:0')   tensor(64.9671, device='cuda:0')   \n",
       "140   tensor(17.5593, device='cuda:0')   tensor(17.5593, device='cuda:0')   \n",
       "141    tensor(1.8763, device='cuda:0')    tensor(1.8763, device='cuda:0')   \n",
       "145   tensor(61.1010, device='cuda:0')   tensor(61.1010, device='cuda:0')   \n",
       "148    tensor(2.9884, device='cuda:0')    tensor(2.9884, device='cuda:0')   \n",
       "149   tensor(60.9103, device='cuda:0')   tensor(60.9103, device='cuda:0')   \n",
       "154   tensor(18.4952, device='cuda:0')   tensor(18.4952, device='cuda:0')   \n",
       "155    tensor(2.4854, device='cuda:0')    tensor(2.4854, device='cuda:0')   \n",
       "159   tensor(53.9906, device='cuda:0')   tensor(53.9906, device='cuda:0')   \n",
       "162    tensor(5.0363, device='cuda:0')    tensor(5.0363, device='cuda:0')   \n",
       "163   tensor(57.2002, device='cuda:0')   tensor(57.2002, device='cuda:0')   \n",
       "168   tensor(19.6680, device='cuda:0')   tensor(19.6680, device='cuda:0')   \n",
       "169    tensor(1.2825, device='cuda:0')    tensor(1.2825, device='cuda:0')   \n",
       "173   tensor(40.3008, device='cuda:0')   tensor(40.3008, device='cuda:0')   \n",
       "176    tensor(4.3839, device='cuda:0')    tensor(4.3839, device='cuda:0')   \n",
       "177   tensor(51.1290, device='cuda:0')   tensor(51.1290, device='cuda:0')   \n",
       "182   tensor(20.1017, device='cuda:0')   tensor(20.1017, device='cuda:0')   \n",
       "183    tensor(1.8094, device='cuda:0')    tensor(1.8094, device='cuda:0')   \n",
       "187   tensor(53.3140, device='cuda:0')   tensor(53.3140, device='cuda:0')   \n",
       "190    tensor(4.1848, device='cuda:0')    tensor(4.1848, device='cuda:0')   \n",
       "191   tensor(50.6223, device='cuda:0')   tensor(50.6223, device='cuda:0')   \n",
       "196   tensor(20.2263, device='cuda:0')   tensor(20.2263, device='cuda:0')   \n",
       "197    tensor(2.2280, device='cuda:0')    tensor(2.2280, device='cuda:0')   \n",
       "201   tensor(62.7554, device='cuda:0')   tensor(62.7554, device='cuda:0')   \n",
       "204    tensor(3.3589, device='cuda:0')    tensor(3.3589, device='cuda:0')   \n",
       "205   tensor(50.3120, device='cuda:0')   tensor(50.3120, device='cuda:0')   \n",
       "210   tensor(20.7131, device='cuda:0')   tensor(20.7131, device='cuda:0')   \n",
       "211    tensor(3.2930, device='cuda:0')    tensor(3.2930, device='cuda:0')   \n",
       "215   tensor(73.7552, device='cuda:0')   tensor(73.7552, device='cuda:0')   \n",
       "218    tensor(3.1223, device='cuda:0')    tensor(3.1223, device='cuda:0')   \n",
       "219   tensor(47.6545, device='cuda:0')   tensor(47.6545, device='cuda:0')   \n",
       "224   tensor(21.1302, device='cuda:0')   tensor(21.1302, device='cuda:0')   \n",
       "225    tensor(3.1233, device='cuda:0')    tensor(3.1233, device='cuda:0')   \n",
       "229   tensor(59.6146, device='cuda:0')   tensor(59.6146, device='cuda:0')   \n",
       "232    tensor(2.8935, device='cuda:0')    tensor(2.8935, device='cuda:0')   \n",
       "233   tensor(43.2211, device='cuda:0')   tensor(43.2211, device='cuda:0')   \n",
       "238   tensor(21.9145, device='cuda:0')   tensor(21.9145, device='cuda:0')   \n",
       "239    tensor(4.7836, device='cuda:0')    tensor(4.7836, device='cuda:0')   \n",
       "243   tensor(71.4226, device='cuda:0')   tensor(71.4226, device='cuda:0')   \n",
       "246    tensor(3.3382, device='cuda:0')    tensor(3.3382, device='cuda:0')   \n",
       "247   tensor(41.2501, device='cuda:0')   tensor(41.2501, device='cuda:0')   \n",
       "252   tensor(22.7056, device='cuda:0')   tensor(22.7056, device='cuda:0')   \n",
       "253    tensor(3.6608, device='cuda:0')    tensor(3.6608, device='cuda:0')   \n",
       "257   tensor(56.0858, device='cuda:0')   tensor(56.0858, device='cuda:0')   \n",
       "260    tensor(3.5596, device='cuda:0')    tensor(3.5596, device='cuda:0')   \n",
       "261   tensor(42.2354, device='cuda:0')   tensor(42.2354, device='cuda:0')   \n",
       "266   tensor(24.0005, device='cuda:0')   tensor(24.0005, device='cuda:0')   \n",
       "267    tensor(6.0822, device='cuda:0')    tensor(6.0822, device='cuda:0')   \n",
       "271   tensor(62.4386, device='cuda:0')   tensor(62.4386, device='cuda:0')   \n",
       "274    tensor(3.8251, device='cuda:0')    tensor(3.8251, device='cuda:0')   \n",
       "275   tensor(41.3336, device='cuda:0')   tensor(41.3336, device='cuda:0')   \n",
       "280   tensor(25.5152, device='cuda:0')   tensor(25.5152, device='cuda:0')   \n",
       "281    tensor(6.6318, device='cuda:0')    tensor(6.6318, device='cuda:0')   \n",
       "285   tensor(73.8205, device='cuda:0')   tensor(73.8205, device='cuda:0')   \n",
       "288    tensor(3.9790, device='cuda:0')    tensor(3.9790, device='cuda:0')   \n",
       "289   tensor(39.1498, device='cuda:0')   tensor(39.1498, device='cuda:0')   \n",
       "294   tensor(26.7375, device='cuda:0')   tensor(26.7375, device='cuda:0')   \n",
       "295    tensor(8.1355, device='cuda:0')    tensor(8.1355, device='cuda:0')   \n",
       "299   tensor(69.6791, device='cuda:0')   tensor(69.6791, device='cuda:0')   \n",
       "302    tensor(4.2449, device='cuda:0')    tensor(4.2449, device='cuda:0')   \n",
       "303   tensor(45.2202, device='cuda:0')   tensor(45.2202, device='cuda:0')   \n",
       "308   tensor(27.9437, device='cuda:0')   tensor(27.9437, device='cuda:0')   \n",
       "309    tensor(6.8387, device='cuda:0')    tensor(6.8387, device='cuda:0')   \n",
       "313   tensor(63.2759, device='cuda:0')   tensor(63.2759, device='cuda:0')   \n",
       "316    tensor(4.4313, device='cuda:0')    tensor(4.4313, device='cuda:0')   \n",
       "317   tensor(45.2272, device='cuda:0')   tensor(45.2272, device='cuda:0')   \n",
       "322   tensor(29.7041, device='cuda:0')   tensor(29.7041, device='cuda:0')   \n",
       "323    tensor(8.5429, device='cuda:0')    tensor(8.5429, device='cuda:0')   \n",
       "327   tensor(69.6737, device='cuda:0')   tensor(69.6737, device='cuda:0')   \n",
       "330    tensor(4.7501, device='cuda:0')    tensor(4.7501, device='cuda:0')   \n",
       "331   tensor(45.4860, device='cuda:0')   tensor(45.4860, device='cuda:0')   \n",
       "336   tensor(31.0902, device='cuda:0')   tensor(31.0902, device='cuda:0')   \n",
       "337    tensor(9.5088, device='cuda:0')    tensor(9.5088, device='cuda:0')   \n",
       "341   tensor(82.3356, device='cuda:0')   tensor(82.3356, device='cuda:0')   \n",
       "344    tensor(4.9459, device='cuda:0')    tensor(4.9459, device='cuda:0')   \n",
       "345   tensor(45.4973, device='cuda:0')   tensor(45.4973, device='cuda:0')   \n",
       "350   tensor(32.0608, device='cuda:0')   tensor(32.0608, device='cuda:0')   \n",
       "351    tensor(9.2159, device='cuda:0')    tensor(9.2159, device='cuda:0')   \n",
       "355   tensor(76.0115, device='cuda:0')   tensor(76.0115, device='cuda:0')   \n",
       "358    tensor(5.2581, device='cuda:0')    tensor(5.2581, device='cuda:0')   \n",
       "359   tensor(46.4701, device='cuda:0')   tensor(46.4701, device='cuda:0')   \n",
       "364   tensor(33.1578, device='cuda:0')   tensor(33.1578, device='cuda:0')   \n",
       "365   tensor(11.6389, device='cuda:0')   tensor(11.6389, device='cuda:0')   \n",
       "369   tensor(78.1185, device='cuda:0')   tensor(78.1185, device='cuda:0')   \n",
       "372    tensor(5.7817, device='cuda:0')    tensor(5.7817, device='cuda:0')   \n",
       "373   tensor(47.1343, device='cuda:0')   tensor(47.1343, device='cuda:0')   \n",
       "378   tensor(34.0266, device='cuda:0')   tensor(34.0266, device='cuda:0')   \n",
       "379   tensor(12.2122, device='cuda:0')   tensor(12.2122, device='cuda:0')   \n",
       "383   tensor(79.8731, device='cuda:0')   tensor(79.8731, device='cuda:0')   \n",
       "386    tensor(5.3319, device='cuda:0')    tensor(5.3319, device='cuda:0')   \n",
       "387   tensor(50.9767, device='cuda:0')   tensor(50.9767, device='cuda:0')   \n",
       "392   tensor(34.9346, device='cuda:0')   tensor(34.9346, device='cuda:0')   \n",
       "393   tensor(14.6725, device='cuda:0')   tensor(14.6725, device='cuda:0')   \n",
       "397   tensor(70.8676, device='cuda:0')   tensor(70.8676, device='cuda:0')   \n",
       "400    tensor(5.6753, device='cuda:0')    tensor(5.6753, device='cuda:0')   \n",
       "401   tensor(48.3424, device='cuda:0')   tensor(48.3424, device='cuda:0')   \n",
       "406   tensor(35.9105, device='cuda:0')   tensor(35.9105, device='cuda:0')   \n",
       "407   tensor(15.0485, device='cuda:0')   tensor(15.0485, device='cuda:0')   \n",
       "411   tensor(70.4384, device='cuda:0')   tensor(70.4384, device='cuda:0')   \n",
       "414    tensor(5.9884, device='cuda:0')    tensor(5.9884, device='cuda:0')   \n",
       "415   tensor(50.2602, device='cuda:0')   tensor(50.2602, device='cuda:0')   \n",
       "420   tensor(36.4254, device='cuda:0')   tensor(36.4254, device='cuda:0')   \n",
       "421   tensor(13.6849, device='cuda:0')   tensor(13.6849, device='cuda:0')   \n",
       "425   tensor(72.3826, device='cuda:0')   tensor(72.3826, device='cuda:0')   \n",
       "428    tensor(6.3765, device='cuda:0')    tensor(6.3765, device='cuda:0')   \n",
       "429   tensor(57.8520, device='cuda:0')   tensor(57.8520, device='cuda:0')   \n",
       "434   tensor(37.8285, device='cuda:0')   tensor(37.8285, device='cuda:0')   \n",
       "435   tensor(16.3080, device='cuda:0')   tensor(16.3080, device='cuda:0')   \n",
       "439   tensor(68.9265, device='cuda:0')   tensor(68.9265, device='cuda:0')   \n",
       "442    tensor(5.8303, device='cuda:0')    tensor(5.8303, device='cuda:0')   \n",
       "443   tensor(49.7215, device='cuda:0')   tensor(49.7215, device='cuda:0')   \n",
       "448   tensor(38.9995, device='cuda:0')   tensor(38.9995, device='cuda:0')   \n",
       "449   tensor(16.6647, device='cuda:0')   tensor(16.6647, device='cuda:0')   \n",
       "453   tensor(65.1821, device='cuda:0')   tensor(65.1821, device='cuda:0')   \n",
       "456    tensor(5.8021, device='cuda:0')    tensor(5.8021, device='cuda:0')   \n",
       "457   tensor(58.8629, device='cuda:0')   tensor(58.8629, device='cuda:0')   \n",
       "462   tensor(39.8097, device='cuda:0')   tensor(39.8097, device='cuda:0')   \n",
       "463   tensor(17.2834, device='cuda:0')   tensor(17.2834, device='cuda:0')   \n",
       "467   tensor(58.3635, device='cuda:0')   tensor(58.3635, device='cuda:0')   \n",
       "470    tensor(5.7595, device='cuda:0')    tensor(5.7595, device='cuda:0')   \n",
       "471   tensor(60.8926, device='cuda:0')   tensor(60.8926, device='cuda:0')   \n",
       "476   tensor(40.6684, device='cuda:0')   tensor(40.6684, device='cuda:0')   \n",
       "477   tensor(16.0814, device='cuda:0')   tensor(16.0814, device='cuda:0')   \n",
       "481   tensor(63.5532, device='cuda:0')   tensor(63.5532, device='cuda:0')   \n",
       "484    tensor(6.0905, device='cuda:0')    tensor(6.0905, device='cuda:0')   \n",
       "485   tensor(59.6612, device='cuda:0')   tensor(59.6612, device='cuda:0')   \n",
       "490   tensor(41.2692, device='cuda:0')   tensor(41.2692, device='cuda:0')   \n",
       "491   tensor(16.7664, device='cuda:0')   tensor(16.7664, device='cuda:0')   \n",
       "495   tensor(64.8919, device='cuda:0')   tensor(64.8919, device='cuda:0')   \n",
       "498    tensor(6.5351, device='cuda:0')    tensor(6.5351, device='cuda:0')   \n",
       "499   tensor(57.4029, device='cuda:0')   tensor(57.4029, device='cuda:0')   \n",
       "504   tensor(42.2657, device='cuda:0')   tensor(42.2657, device='cuda:0')   \n",
       "505   tensor(17.5532, device='cuda:0')   tensor(17.5532, device='cuda:0')   \n",
       "509   tensor(64.0739, device='cuda:0')   tensor(64.0739, device='cuda:0')   \n",
       "512    tensor(5.5479, device='cuda:0')    tensor(5.5479, device='cuda:0')   \n",
       "513   tensor(60.7866, device='cuda:0')   tensor(60.7866, device='cuda:0')   \n",
       "518   tensor(42.7841, device='cuda:0')   tensor(42.7841, device='cuda:0')   \n",
       "519   tensor(20.4553, device='cuda:0')   tensor(20.4553, device='cuda:0')   \n",
       "523   tensor(53.9064, device='cuda:0')   tensor(53.9064, device='cuda:0')   \n",
       "526    tensor(5.6838, device='cuda:0')    tensor(5.6838, device='cuda:0')   \n",
       "527   tensor(64.5356, device='cuda:0')   tensor(64.5356, device='cuda:0')   \n",
       "532   tensor(44.1806, device='cuda:0')   tensor(44.1806, device='cuda:0')   \n",
       "533   tensor(26.2242, device='cuda:0')   tensor(26.2242, device='cuda:0')   \n",
       "537   tensor(55.4192, device='cuda:0')   tensor(55.4192, device='cuda:0')   \n",
       "540    tensor(6.8032, device='cuda:0')    tensor(6.8032, device='cuda:0')   \n",
       "541   tensor(65.4431, device='cuda:0')   tensor(65.4431, device='cuda:0')   \n",
       "546   tensor(45.5507, device='cuda:0')   tensor(45.5507, device='cuda:0')   \n",
       "547   tensor(28.2569, device='cuda:0')   tensor(28.2569, device='cuda:0')   \n",
       "551   tensor(53.7448, device='cuda:0')   tensor(53.7448, device='cuda:0')   \n",
       "554    tensor(7.2123, device='cuda:0')    tensor(7.2123, device='cuda:0')   \n",
       "555   tensor(66.5981, device='cuda:0')   tensor(66.5981, device='cuda:0')   \n",
       "560   tensor(46.1969, device='cuda:0')   tensor(46.1969, device='cuda:0')   \n",
       "561   tensor(20.7974, device='cuda:0')   tensor(20.7974, device='cuda:0')   \n",
       "565   tensor(62.6183, device='cuda:0')   tensor(62.6183, device='cuda:0')   \n",
       "568    tensor(5.6627, device='cuda:0')    tensor(5.6627, device='cuda:0')   \n",
       "569   tensor(76.2838, device='cuda:0')   tensor(76.2838, device='cuda:0')   \n",
       "574   tensor(47.0765, device='cuda:0')   tensor(47.0765, device='cuda:0')   \n",
       "575   tensor(25.2845, device='cuda:0')   tensor(25.2845, device='cuda:0')   \n",
       "579   tensor(56.0546, device='cuda:0')   tensor(56.0546, device='cuda:0')   \n",
       "582    tensor(7.2845, device='cuda:0')    tensor(7.2845, device='cuda:0')   \n",
       "583   tensor(76.6954, device='cuda:0')   tensor(76.6954, device='cuda:0')   \n",
       "588   tensor(48.2912, device='cuda:0')   tensor(48.2912, device='cuda:0')   \n",
       "589   tensor(28.1710, device='cuda:0')   tensor(28.1710, device='cuda:0')   \n",
       "593   tensor(46.8979, device='cuda:0')   tensor(46.8979, device='cuda:0')   \n",
       "596    tensor(7.3101, device='cuda:0')    tensor(7.3101, device='cuda:0')   \n",
       "597   tensor(76.0449, device='cuda:0')   tensor(76.0449, device='cuda:0')   \n",
       "602   tensor(49.7104, device='cuda:0')   tensor(49.7104, device='cuda:0')   \n",
       "603   tensor(32.9361, device='cuda:0')   tensor(32.9361, device='cuda:0')   \n",
       "607   tensor(47.8693, device='cuda:0')   tensor(47.8693, device='cuda:0')   \n",
       "610    tensor(5.5612, device='cuda:0')    tensor(5.5612, device='cuda:0')   \n",
       "611   tensor(82.0028, device='cuda:0')   tensor(82.0028, device='cuda:0')   \n",
       "616   tensor(50.8514, device='cuda:0')   tensor(50.8514, device='cuda:0')   \n",
       "617   tensor(25.3489, device='cuda:0')   tensor(25.3489, device='cuda:0')   \n",
       "621   tensor(41.4945, device='cuda:0')   tensor(41.4945, device='cuda:0')   \n",
       "624    tensor(7.5823, device='cuda:0')    tensor(7.5823, device='cuda:0')   \n",
       "625   tensor(69.0107, device='cuda:0')   tensor(69.0107, device='cuda:0')   \n",
       "630   tensor(51.8630, device='cuda:0')   tensor(51.8630, device='cuda:0')   \n",
       "631   tensor(28.7827, device='cuda:0')   tensor(28.7827, device='cuda:0')   \n",
       "635   tensor(51.6595, device='cuda:0')   tensor(51.6595, device='cuda:0')   \n",
       "638    tensor(7.7792, device='cuda:0')    tensor(7.7792, device='cuda:0')   \n",
       "639   tensor(92.2257, device='cuda:0')   tensor(92.2257, device='cuda:0')   \n",
       "644   tensor(53.5495, device='cuda:0')   tensor(53.5495, device='cuda:0')   \n",
       "645   tensor(36.4229, device='cuda:0')   tensor(36.4229, device='cuda:0')   \n",
       "649   tensor(36.8286, device='cuda:0')   tensor(36.8286, device='cuda:0')   \n",
       "652    tensor(6.8676, device='cuda:0')    tensor(6.8676, device='cuda:0')   \n",
       "653   tensor(98.6851, device='cuda:0')   tensor(98.6851, device='cuda:0')   \n",
       "658   tensor(55.3761, device='cuda:0')   tensor(55.3761, device='cuda:0')   \n",
       "659   tensor(47.7343, device='cuda:0')   tensor(47.7343, device='cuda:0')   \n",
       "663   tensor(43.2757, device='cuda:0')   tensor(43.2757, device='cuda:0')   \n",
       "666    tensor(6.9044, device='cuda:0')    tensor(6.9044, device='cuda:0')   \n",
       "667  tensor(128.7068, device='cuda:0')  tensor(128.7068, device='cuda:0')   \n",
       "672   tensor(56.6857, device='cuda:0')   tensor(56.6857, device='cuda:0')   \n",
       "673   tensor(32.7637, device='cuda:0')   tensor(32.7637, device='cuda:0')   \n",
       "677   tensor(38.4310, device='cuda:0')   tensor(38.4310, device='cuda:0')   \n",
       "680    tensor(7.9700, device='cuda:0')    tensor(7.9700, device='cuda:0')   \n",
       "681  tensor(102.5928, device='cuda:0')  tensor(102.5928, device='cuda:0')   \n",
       "686   tensor(58.8363, device='cuda:0')   tensor(58.8363, device='cuda:0')   \n",
       "687   tensor(35.2289, device='cuda:0')   tensor(35.2289, device='cuda:0')   \n",
       "691   tensor(45.9003, device='cuda:0')   tensor(45.9003, device='cuda:0')   \n",
       "694    tensor(7.5293, device='cuda:0')    tensor(7.5293, device='cuda:0')   \n",
       "695  tensor(115.2520, device='cuda:0')  tensor(115.2520, device='cuda:0')   \n",
       "700   tensor(60.3090, device='cuda:0')   tensor(60.3090, device='cuda:0')   \n",
       "701   tensor(37.6465, device='cuda:0')   tensor(37.6465, device='cuda:0')   \n",
       "705   tensor(35.6087, device='cuda:0')   tensor(35.6087, device='cuda:0')   \n",
       "708    tensor(6.1906, device='cuda:0')    tensor(6.1906, device='cuda:0')   \n",
       "709  tensor(103.1482, device='cuda:0')  tensor(103.1482, device='cuda:0')   \n",
       "714   tensor(61.5712, device='cuda:0')   tensor(61.5712, device='cuda:0')   \n",
       "715   tensor(33.3465, device='cuda:0')   tensor(33.3465, device='cuda:0')   \n",
       "719   tensor(48.3220, device='cuda:0')   tensor(48.3220, device='cuda:0')   \n",
       "722    tensor(7.5200, device='cuda:0')    tensor(7.5200, device='cuda:0')   \n",
       "723  tensor(101.6782, device='cuda:0')  tensor(101.6782, device='cuda:0')   \n",
       "728   tensor(63.8467, device='cuda:0')   tensor(63.8467, device='cuda:0')   \n",
       "729   tensor(37.1831, device='cuda:0')   tensor(37.1831, device='cuda:0')   \n",
       "733   tensor(36.8765, device='cuda:0')   tensor(36.8765, device='cuda:0')   \n",
       "736    tensor(7.6958, device='cuda:0')    tensor(7.6958, device='cuda:0')   \n",
       "737  tensor(100.5608, device='cuda:0')  tensor(100.5608, device='cuda:0')   \n",
       "742   tensor(66.6645, device='cuda:0')   tensor(66.6645, device='cuda:0')   \n",
       "743   tensor(32.8730, device='cuda:0')   tensor(32.8730, device='cuda:0')   \n",
       "747   tensor(34.9735, device='cuda:0')   tensor(34.9735, device='cuda:0')   \n",
       "750    tensor(7.4093, device='cuda:0')    tensor(7.4093, device='cuda:0')   \n",
       "751   tensor(98.4680, device='cuda:0')   tensor(98.4680, device='cuda:0')   \n",
       "756   tensor(67.9342, device='cuda:0')   tensor(67.9342, device='cuda:0')   \n",
       "757   tensor(40.8900, device='cuda:0')   tensor(40.8900, device='cuda:0')   \n",
       "761   tensor(32.9303, device='cuda:0')   tensor(32.9303, device='cuda:0')   \n",
       "764    tensor(7.6885, device='cuda:0')    tensor(7.6885, device='cuda:0')   \n",
       "765   tensor(49.6343, device='cuda:0')   tensor(49.6343, device='cuda:0')   \n",
       "770   tensor(70.5789, device='cuda:0')   tensor(70.5789, device='cuda:0')   \n",
       "771   tensor(43.3042, device='cuda:0')   tensor(43.3042, device='cuda:0')   \n",
       "775   tensor(38.9937, device='cuda:0')   tensor(38.9937, device='cuda:0')   \n",
       "778    tensor(8.3069, device='cuda:0')    tensor(8.3069, device='cuda:0')   \n",
       "779   tensor(43.3988, device='cuda:0')   tensor(43.3988, device='cuda:0')   \n",
       "784   tensor(72.4600, device='cuda:0')   tensor(72.4600, device='cuda:0')   \n",
       "785   tensor(35.5799, device='cuda:0')   tensor(35.5799, device='cuda:0')   \n",
       "789   tensor(33.9308, device='cuda:0')   tensor(33.9308, device='cuda:0')   \n",
       "792    tensor(5.7355, device='cuda:0')    tensor(5.7355, device='cuda:0')   \n",
       "793   tensor(38.5753, device='cuda:0')   tensor(38.5753, device='cuda:0')   \n",
       "798   tensor(71.9960, device='cuda:0')   tensor(71.9960, device='cuda:0')   \n",
       "799   tensor(35.9963, device='cuda:0')   tensor(35.9963, device='cuda:0')   \n",
       "803   tensor(41.7819, device='cuda:0')   tensor(41.7819, device='cuda:0')   \n",
       "806    tensor(6.2145, device='cuda:0')    tensor(6.2145, device='cuda:0')   \n",
       "807   tensor(37.8703, device='cuda:0')   tensor(37.8703, device='cuda:0')   \n",
       "812   tensor(69.9069, device='cuda:0')   tensor(69.9069, device='cuda:0')   \n",
       "813   tensor(38.3148, device='cuda:0')   tensor(38.3148, device='cuda:0')   \n",
       "817   tensor(29.3746, device='cuda:0')   tensor(29.3746, device='cuda:0')   \n",
       "820    tensor(8.7840, device='cuda:0')    tensor(8.7840, device='cuda:0')   \n",
       "821   tensor(35.7472, device='cuda:0')   tensor(35.7472, device='cuda:0')   \n",
       "826   tensor(59.2297, device='cuda:0')   tensor(59.2297, device='cuda:0')   \n",
       "827   tensor(41.7295, device='cuda:0')   tensor(41.7295, device='cuda:0')   \n",
       "831   tensor(36.5432, device='cuda:0')   tensor(36.5432, device='cuda:0')   \n",
       "834    tensor(5.1639, device='cuda:0')    tensor(5.1639, device='cuda:0')   \n",
       "835   tensor(56.2081, device='cuda:0')   tensor(56.2081, device='cuda:0')   \n",
       "840   tensor(35.1826, device='cuda:0')   tensor(35.1826, device='cuda:0')   \n",
       "841   tensor(33.8922, device='cuda:0')   tensor(33.8922, device='cuda:0')   \n",
       "845   tensor(28.9508, device='cuda:0')   tensor(28.9508, device='cuda:0')   \n",
       "\n",
       "     spec_topk_u_cos_mean  spec_topk_u_cos_min  spec_topk_v_cos_mean  \\\n",
       "0                     1.0                  1.0              0.883294   \n",
       "4                     1.0                  1.0              0.645940   \n",
       "5                     1.0                  1.0              0.550863   \n",
       "9                     1.0                  1.0              0.905127   \n",
       "12                    1.0                  1.0              0.853763   \n",
       "16                    1.0                  1.0              0.607914   \n",
       "17                    1.0                  1.0              0.498078   \n",
       "21                    1.0                  1.0              0.813170   \n",
       "24                    1.0                  1.0              0.894958   \n",
       "28                    1.0                  1.0              0.798047   \n",
       "29                    1.0                  1.0              0.556629   \n",
       "33                    1.0                  1.0              0.897100   \n",
       "36                    1.0                  1.0              0.930285   \n",
       "37                    1.0                  1.0              0.999997   \n",
       "42                    1.0                  1.0              0.825780   \n",
       "43                    1.0                  1.0              0.506418   \n",
       "47                    1.0                  1.0              0.916142   \n",
       "50                    1.0                  1.0              0.909860   \n",
       "51                    1.0                  1.0              0.999999   \n",
       "56                    1.0                  1.0              0.829575   \n",
       "57                    1.0                  1.0              0.798677   \n",
       "61                    1.0                  1.0              0.941680   \n",
       "64                    1.0                  1.0              0.939693   \n",
       "65                    1.0                  1.0              0.999998   \n",
       "70                    1.0                  1.0              0.857210   \n",
       "71                    1.0                  1.0              0.942494   \n",
       "75                    1.0                  1.0              0.904794   \n",
       "78                    1.0                  1.0              0.954217   \n",
       "79                    1.0                  1.0              0.999996   \n",
       "84                    1.0                  1.0              0.915626   \n",
       "85                    1.0                  1.0              0.911585   \n",
       "89                    1.0                  1.0              0.888783   \n",
       "92                    1.0                  1.0              0.965007   \n",
       "93                    1.0                  1.0              0.999996   \n",
       "98                    1.0                  1.0              0.940210   \n",
       "99                    1.0                  1.0              0.970948   \n",
       "103                   1.0                  1.0              0.892380   \n",
       "106                   1.0                  1.0              0.964222   \n",
       "107                   1.0                  1.0              0.999990   \n",
       "112                   1.0                  1.0              0.960529   \n",
       "113                   1.0                  1.0              0.965048   \n",
       "117                   1.0                  1.0              0.847762   \n",
       "120                   1.0                  1.0              0.975138   \n",
       "121                   1.0                  1.0              0.999991   \n",
       "126                   1.0                  1.0              0.971939   \n",
       "127                   1.0                  1.0              0.985790   \n",
       "131                   1.0                  1.0              0.897370   \n",
       "134                   1.0                  1.0              0.981753   \n",
       "135                   1.0                  1.0              0.999984   \n",
       "140                   1.0                  1.0              0.980439   \n",
       "141                   1.0                  1.0              0.989113   \n",
       "145                   1.0                  1.0              0.904946   \n",
       "148                   1.0                  1.0              0.983285   \n",
       "149                   1.0                  1.0              0.999984   \n",
       "154                   1.0                  1.0              0.984686   \n",
       "155                   1.0                  1.0              0.993276   \n",
       "159                   1.0                  1.0              0.881890   \n",
       "162                   1.0                  1.0              0.988693   \n",
       "163                   1.0                  1.0              0.999985   \n",
       "168                   1.0                  1.0              0.988117   \n",
       "169                   1.0                  1.0              0.994731   \n",
       "173                   1.0                  1.0              0.878062   \n",
       "176                   1.0                  1.0              0.991157   \n",
       "177                   1.0                  1.0              0.999981   \n",
       "182                   1.0                  1.0              0.989647   \n",
       "183                   1.0                  1.0              0.996613   \n",
       "187                   1.0                  1.0              0.862326   \n",
       "190                   1.0                  1.0              0.991078   \n",
       "191                   1.0                  1.0              0.999971   \n",
       "196                   1.0                  1.0              0.991036   \n",
       "197                   1.0                  1.0              0.994724   \n",
       "201                   1.0                  1.0              0.894577   \n",
       "204                   1.0                  1.0              0.991017   \n",
       "205                   1.0                  1.0              0.999974   \n",
       "210                   1.0                  1.0              0.992444   \n",
       "211                   1.0                  1.0              0.994208   \n",
       "215                   1.0                  1.0              0.915188   \n",
       "218                   1.0                  1.0              0.989703   \n",
       "219                   1.0                  1.0              0.999965   \n",
       "224                   1.0                  1.0              0.993296   \n",
       "225                   1.0                  1.0              0.995508   \n",
       "229                   1.0                  1.0              0.903922   \n",
       "232                   1.0                  1.0              0.991019   \n",
       "233                   1.0                  1.0              0.999936   \n",
       "238                   1.0                  1.0              0.993903   \n",
       "239                   1.0                  1.0              0.995916   \n",
       "243                   1.0                  1.0              0.903039   \n",
       "246                   1.0                  1.0              0.989407   \n",
       "247                   1.0                  1.0              0.999960   \n",
       "252                   1.0                  1.0              0.994430   \n",
       "253                   1.0                  1.0              0.994356   \n",
       "257                   1.0                  1.0              0.911530   \n",
       "260                   1.0                  1.0              0.992685   \n",
       "261                   1.0                  1.0              0.999887   \n",
       "266                   1.0                  1.0              0.994609   \n",
       "267                   1.0                  1.0              0.995424   \n",
       "271                   1.0                  1.0              0.916838   \n",
       "274                   1.0                  1.0              0.993408   \n",
       "275                   1.0                  1.0              0.999876   \n",
       "280                   1.0                  1.0              0.994853   \n",
       "281                   1.0                  1.0              0.996860   \n",
       "285                   1.0                  1.0              0.922038   \n",
       "288                   1.0                  1.0              0.992202   \n",
       "289                   1.0                  1.0              0.999899   \n",
       "294                   1.0                  1.0              0.995125   \n",
       "295                   1.0                  1.0              0.994746   \n",
       "299                   1.0                  1.0              0.933343   \n",
       "302                   1.0                  1.0              0.992411   \n",
       "303                   1.0                  1.0              0.999896   \n",
       "308                   1.0                  1.0              0.994902   \n",
       "309                   1.0                  1.0              0.996246   \n",
       "313                   1.0                  1.0              0.929085   \n",
       "316                   1.0                  1.0              0.993148   \n",
       "317                   1.0                  1.0              0.999925   \n",
       "322                   1.0                  1.0              0.994913   \n",
       "323                   1.0                  1.0              0.995580   \n",
       "327                   1.0                  1.0              0.942351   \n",
       "330                   1.0                  1.0              0.994543   \n",
       "331                   1.0                  1.0              0.999876   \n",
       "336                   1.0                  1.0              0.994877   \n",
       "337                   1.0                  1.0              0.994767   \n",
       "341                   1.0                  1.0              0.960780   \n",
       "344                   1.0                  1.0              0.994162   \n",
       "345                   1.0                  1.0              0.999805   \n",
       "350                   1.0                  1.0              0.994920   \n",
       "351                   1.0                  1.0              0.995297   \n",
       "355                   1.0                  1.0              0.954527   \n",
       "358                   1.0                  1.0              0.995086   \n",
       "359                   1.0                  1.0              0.999824   \n",
       "364                   1.0                  1.0              0.995293   \n",
       "365                   1.0                  1.0              0.994639   \n",
       "369                   1.0                  1.0              0.950860   \n",
       "372                   1.0                  1.0              0.993821   \n",
       "373                   1.0                  1.0              0.999838   \n",
       "378                   1.0                  1.0              0.995455   \n",
       "379                   1.0                  1.0              0.996120   \n",
       "383                   1.0                  1.0              0.951564   \n",
       "386                   1.0                  1.0              0.994671   \n",
       "387                   1.0                  1.0              0.999847   \n",
       "392                   1.0                  1.0              0.995759   \n",
       "393                   1.0                  1.0              0.994243   \n",
       "397                   1.0                  1.0              0.944099   \n",
       "400                   1.0                  1.0              0.995635   \n",
       "401                   1.0                  1.0              0.999829   \n",
       "406                   1.0                  1.0              0.996039   \n",
       "407                   1.0                  1.0              0.995877   \n",
       "411                   1.0                  1.0              0.980962   \n",
       "414                   1.0                  1.0              0.993743   \n",
       "415                   1.0                  1.0              0.999854   \n",
       "420                   1.0                  1.0              0.996270   \n",
       "421                   1.0                  1.0              0.996578   \n",
       "425                   1.0                  1.0              0.948715   \n",
       "428                   1.0                  1.0              0.994670   \n",
       "429                   1.0                  1.0              0.999876   \n",
       "434                   1.0                  1.0              0.996472   \n",
       "435                   1.0                  1.0              0.995470   \n",
       "439                   1.0                  1.0              0.949915   \n",
       "442                   1.0                  1.0              0.995147   \n",
       "443                   1.0                  1.0              0.999865   \n",
       "448                   1.0                  1.0              0.996667   \n",
       "449                   1.0                  1.0              0.996482   \n",
       "453                   1.0                  1.0              0.951048   \n",
       "456                   1.0                  1.0              0.994311   \n",
       "457                   1.0                  1.0              0.999794   \n",
       "462                   1.0                  1.0              0.996857   \n",
       "463                   1.0                  1.0              0.996299   \n",
       "467                   1.0                  1.0              0.953887   \n",
       "470                   1.0                  1.0              0.994887   \n",
       "471                   1.0                  1.0              0.999898   \n",
       "476                   1.0                  1.0              0.996936   \n",
       "477                   1.0                  1.0              0.995442   \n",
       "481                   1.0                  1.0              0.966334   \n",
       "484                   1.0                  1.0              0.994877   \n",
       "485                   1.0                  1.0              0.999925   \n",
       "490                   1.0                  1.0              0.997244   \n",
       "491                   1.0                  1.0              0.995037   \n",
       "495                   1.0                  1.0              0.971872   \n",
       "498                   1.0                  1.0              0.993008   \n",
       "499                   1.0                  1.0              0.999849   \n",
       "504                   1.0                  1.0              0.997428   \n",
       "505                   1.0                  1.0              0.995718   \n",
       "509                   1.0                  1.0              0.919561   \n",
       "512                   1.0                  1.0              0.991455   \n",
       "513                   1.0                  1.0              0.999932   \n",
       "518                   1.0                  1.0              0.997613   \n",
       "519                   1.0                  1.0              0.995635   \n",
       "523                   1.0                  1.0              0.941210   \n",
       "526                   1.0                  1.0              0.993166   \n",
       "527                   1.0                  1.0              0.999871   \n",
       "532                   1.0                  1.0              0.997674   \n",
       "533                   1.0                  1.0              0.993915   \n",
       "537                   1.0                  1.0              0.960291   \n",
       "540                   1.0                  1.0              0.991130   \n",
       "541                   1.0                  1.0              0.999888   \n",
       "546                   1.0                  1.0              0.997761   \n",
       "547                   1.0                  1.0              0.993192   \n",
       "551                   1.0                  1.0              0.903269   \n",
       "554                   1.0                  1.0              0.994757   \n",
       "555                   1.0                  1.0              0.999869   \n",
       "560                   1.0                  1.0              0.997859   \n",
       "561                   1.0                  1.0              0.995574   \n",
       "565                   1.0                  1.0              0.973735   \n",
       "568                   1.0                  1.0              0.992557   \n",
       "569                   1.0                  1.0              0.999756   \n",
       "574                   1.0                  1.0              0.997923   \n",
       "575                   1.0                  1.0              0.993042   \n",
       "579                   1.0                  1.0              0.944913   \n",
       "582                   1.0                  1.0              0.993074   \n",
       "583                   1.0                  1.0              0.999885   \n",
       "588                   1.0                  1.0              0.998028   \n",
       "589                   1.0                  1.0              0.995281   \n",
       "593                   1.0                  1.0              0.960473   \n",
       "596                   1.0                  1.0              0.993381   \n",
       "597                   1.0                  1.0              0.999848   \n",
       "602                   1.0                  1.0              0.998030   \n",
       "603                   1.0                  1.0              0.993351   \n",
       "607                   1.0                  1.0              0.956671   \n",
       "610                   1.0                  1.0              0.988646   \n",
       "611                   1.0                  1.0              0.999884   \n",
       "616                   1.0                  1.0              0.998119   \n",
       "617                   1.0                  1.0              0.993002   \n",
       "621                   1.0                  1.0              0.913275   \n",
       "624                   1.0                  1.0              0.992221   \n",
       "625                   1.0                  1.0              0.999897   \n",
       "630                   1.0                  1.0              0.998236   \n",
       "631                   1.0                  1.0              0.990339   \n",
       "635                   1.0                  1.0              0.951792   \n",
       "638                   1.0                  1.0              0.992180   \n",
       "639                   1.0                  1.0              0.999961   \n",
       "644                   1.0                  1.0              0.998277   \n",
       "645                   1.0                  1.0              0.987526   \n",
       "649                   1.0                  1.0              0.909879   \n",
       "652                   1.0                  1.0              0.989623   \n",
       "653                   1.0                  1.0              0.999951   \n",
       "658                   1.0                  1.0              0.998305   \n",
       "659                   1.0                  1.0              0.986884   \n",
       "663                   1.0                  1.0              0.927824   \n",
       "666                   1.0                  1.0              0.989851   \n",
       "667                   1.0                  1.0              0.999974   \n",
       "672                   1.0                  1.0              0.998384   \n",
       "673                   1.0                  1.0              0.990906   \n",
       "677                   1.0                  1.0              0.873983   \n",
       "680                   1.0                  1.0              0.990946   \n",
       "681                   1.0                  1.0              0.999925   \n",
       "686                   1.0                  1.0              0.998416   \n",
       "687                   1.0                  1.0              0.989774   \n",
       "691                   1.0                  1.0              0.901897   \n",
       "694                   1.0                  1.0              0.992115   \n",
       "695                   1.0                  1.0              0.999959   \n",
       "700                   1.0                  1.0              0.998449   \n",
       "701                   1.0                  1.0              0.988923   \n",
       "705                   1.0                  1.0              0.948857   \n",
       "708                   1.0                  1.0              0.990221   \n",
       "709                   1.0                  1.0              0.999966   \n",
       "714                   1.0                  1.0              0.998444   \n",
       "715                   1.0                  1.0              0.993983   \n",
       "719                   1.0                  1.0              0.909388   \n",
       "722                   1.0                  1.0              0.991443   \n",
       "723                   1.0                  1.0              0.999912   \n",
       "728                   1.0                  1.0              0.998470   \n",
       "729                   1.0                  1.0              0.992558   \n",
       "733                   1.0                  1.0              0.921500   \n",
       "736                   1.0                  1.0              0.991587   \n",
       "737                   1.0                  1.0              0.999943   \n",
       "742                   1.0                  1.0              0.998452   \n",
       "743                   1.0                  1.0              0.991294   \n",
       "747                   1.0                  1.0              0.939840   \n",
       "750                   1.0                  1.0              0.990979   \n",
       "751                   1.0                  1.0              0.999964   \n",
       "756                   1.0                  1.0              0.998443   \n",
       "757                   1.0                  1.0              0.983217   \n",
       "761                   1.0                  1.0              0.880664   \n",
       "764                   1.0                  1.0              0.990067   \n",
       "765                   1.0                  1.0              0.999954   \n",
       "770                   1.0                  1.0              0.998302   \n",
       "771                   1.0                  1.0              0.972363   \n",
       "775                   1.0                  1.0              0.861877   \n",
       "778                   1.0                  1.0              0.990058   \n",
       "779                   1.0                  1.0              0.999952   \n",
       "784                   1.0                  1.0              0.997948   \n",
       "785                   1.0                  1.0              0.991023   \n",
       "789                   1.0                  1.0              0.871921   \n",
       "792                   1.0                  1.0              0.986934   \n",
       "793                   1.0                  1.0              0.999921   \n",
       "798                   1.0                  1.0              0.997274   \n",
       "799                   1.0                  1.0              0.948076   \n",
       "803                   1.0                  1.0              0.855079   \n",
       "806                   1.0                  1.0              0.977215   \n",
       "807                   1.0                  1.0              0.999871   \n",
       "812                   1.0                  1.0              0.996672   \n",
       "813                   1.0                  1.0              0.952422   \n",
       "817                   1.0                  1.0              0.804283   \n",
       "820                   1.0                  1.0              0.985603   \n",
       "821                   1.0                  1.0              0.999832   \n",
       "826                   1.0                  1.0              0.993864   \n",
       "827                   1.0                  1.0              0.984470   \n",
       "831                   1.0                  1.0              0.908353   \n",
       "834                   1.0                  1.0              0.979456   \n",
       "835                   1.0                  1.0              0.999894   \n",
       "840                   1.0                  1.0              0.985737   \n",
       "841                   1.0                  1.0              0.975739   \n",
       "845                   1.0                  1.0              0.803287   \n",
       "\n",
       "     spec_topk_v_cos_min  spec_subspace_overlap_u  spec_subspace_overlap_v  \\\n",
       "0               0.883294                      1.0                 0.883294   \n",
       "4               0.645940                      1.0                 0.645941   \n",
       "5               0.550863                      1.0                 0.550863   \n",
       "9               0.905127                      1.0                 0.905127   \n",
       "12              0.853763                      1.0                 0.853763   \n",
       "16              0.607914                      1.0                 0.607914   \n",
       "17              0.498078                      1.0                 0.498078   \n",
       "21              0.813170                      1.0                 0.813170   \n",
       "24              0.894958                      1.0                 0.894959   \n",
       "28              0.798047                      1.0                 0.798047   \n",
       "29              0.556629                      1.0                 0.556630   \n",
       "33              0.897100                      1.0                 0.897100   \n",
       "36              0.930285                      1.0                 0.930285   \n",
       "37              0.999997                      1.0                 0.999997   \n",
       "42              0.825780                      1.0                 0.825779   \n",
       "43              0.506418                      1.0                 0.506418   \n",
       "47              0.916142                      1.0                 0.916142   \n",
       "50              0.909860                      1.0                 0.909860   \n",
       "51              0.999999                      1.0                 1.000001   \n",
       "56              0.829575                      1.0                 0.829575   \n",
       "57              0.798677                      1.0                 0.798677   \n",
       "61              0.941680                      1.0                 0.941680   \n",
       "64              0.939693                      1.0                 0.939693   \n",
       "65              0.999998                      1.0                 0.999998   \n",
       "70              0.857210                      1.0                 0.857210   \n",
       "71              0.942494                      1.0                 0.942494   \n",
       "75              0.904794                      1.0                 0.904794   \n",
       "78              0.954217                      1.0                 0.954217   \n",
       "79              0.999996                      1.0                 0.999997   \n",
       "84              0.915626                      1.0                 0.915626   \n",
       "85              0.911585                      1.0                 0.911584   \n",
       "89              0.888783                      1.0                 0.888783   \n",
       "92              0.965007                      1.0                 0.965007   \n",
       "93              0.999996                      1.0                 0.999996   \n",
       "98              0.940210                      1.0                 0.940210   \n",
       "99              0.970948                      1.0                 0.970948   \n",
       "103             0.892380                      1.0                 0.892380   \n",
       "106             0.964222                      1.0                 0.964222   \n",
       "107             0.999990                      1.0                 0.999990   \n",
       "112             0.960529                      1.0                 0.960529   \n",
       "113             0.965048                      1.0                 0.965048   \n",
       "117             0.847762                      1.0                 0.847762   \n",
       "120             0.975138                      1.0                 0.975138   \n",
       "121             0.999991                      1.0                 0.999991   \n",
       "126             0.971939                      1.0                 0.971940   \n",
       "127             0.985790                      1.0                 0.985790   \n",
       "131             0.897370                      1.0                 0.897370   \n",
       "134             0.981753                      1.0                 0.981753   \n",
       "135             0.999984                      1.0                 0.999984   \n",
       "140             0.980439                      1.0                 0.980438   \n",
       "141             0.989113                      1.0                 0.989114   \n",
       "145             0.904946                      1.0                 0.904946   \n",
       "148             0.983285                      1.0                 0.983285   \n",
       "149             0.999984                      1.0                 0.999983   \n",
       "154             0.984686                      1.0                 0.984686   \n",
       "155             0.993276                      1.0                 0.993276   \n",
       "159             0.881890                      1.0                 0.881890   \n",
       "162             0.988693                      1.0                 0.988692   \n",
       "163             0.999985                      1.0                 0.999985   \n",
       "168             0.988117                      1.0                 0.988117   \n",
       "169             0.994731                      1.0                 0.994731   \n",
       "173             0.878062                      1.0                 0.878062   \n",
       "176             0.991157                      1.0                 0.991157   \n",
       "177             0.999981                      1.0                 0.999981   \n",
       "182             0.989647                      1.0                 0.989647   \n",
       "183             0.996613                      1.0                 0.996613   \n",
       "187             0.862326                      1.0                 0.862326   \n",
       "190             0.991078                      1.0                 0.991078   \n",
       "191             0.999971                      1.0                 0.999971   \n",
       "196             0.991036                      1.0                 0.991036   \n",
       "197             0.994724                      1.0                 0.994725   \n",
       "201             0.894577                      1.0                 0.894577   \n",
       "204             0.991017                      1.0                 0.991017   \n",
       "205             0.999974                      1.0                 0.999974   \n",
       "210             0.992444                      1.0                 0.992445   \n",
       "211             0.994208                      1.0                 0.994207   \n",
       "215             0.915188                      1.0                 0.915188   \n",
       "218             0.989703                      1.0                 0.989703   \n",
       "219             0.999965                      1.0                 0.999965   \n",
       "224             0.993296                      1.0                 0.993296   \n",
       "225             0.995508                      1.0                 0.995507   \n",
       "229             0.903922                      1.0                 0.903921   \n",
       "232             0.991019                      1.0                 0.991019   \n",
       "233             0.999936                      1.0                 0.999936   \n",
       "238             0.993903                      1.0                 0.993903   \n",
       "239             0.995916                      1.0                 0.995916   \n",
       "243             0.903039                      1.0                 0.903040   \n",
       "246             0.989407                      1.0                 0.989407   \n",
       "247             0.999960                      1.0                 0.999959   \n",
       "252             0.994430                      1.0                 0.994430   \n",
       "253             0.994356                      1.0                 0.994356   \n",
       "257             0.911530                      1.0                 0.911530   \n",
       "260             0.992685                      1.0                 0.992685   \n",
       "261             0.999887                      1.0                 0.999887   \n",
       "266             0.994609                      1.0                 0.994610   \n",
       "267             0.995424                      1.0                 0.995424   \n",
       "271             0.916838                      1.0                 0.916838   \n",
       "274             0.993408                      1.0                 0.993408   \n",
       "275             0.999876                      1.0                 0.999877   \n",
       "280             0.994853                      1.0                 0.994852   \n",
       "281             0.996860                      1.0                 0.996861   \n",
       "285             0.922038                      1.0                 0.922038   \n",
       "288             0.992202                      1.0                 0.992202   \n",
       "289             0.999899                      1.0                 0.999899   \n",
       "294             0.995125                      1.0                 0.995125   \n",
       "295             0.994746                      1.0                 0.994746   \n",
       "299             0.933343                      1.0                 0.933343   \n",
       "302             0.992411                      1.0                 0.992412   \n",
       "303             0.999896                      1.0                 0.999897   \n",
       "308             0.994902                      1.0                 0.994902   \n",
       "309             0.996246                      1.0                 0.996246   \n",
       "313             0.929085                      1.0                 0.929085   \n",
       "316             0.993148                      1.0                 0.993147   \n",
       "317             0.999925                      1.0                 0.999925   \n",
       "322             0.994913                      1.0                 0.994913   \n",
       "323             0.995580                      1.0                 0.995580   \n",
       "327             0.942351                      1.0                 0.942352   \n",
       "330             0.994543                      1.0                 0.994543   \n",
       "331             0.999876                      1.0                 0.999876   \n",
       "336             0.994877                      1.0                 0.994877   \n",
       "337             0.994767                      1.0                 0.994767   \n",
       "341             0.960780                      1.0                 0.960780   \n",
       "344             0.994162                      1.0                 0.994162   \n",
       "345             0.999805                      1.0                 0.999804   \n",
       "350             0.994920                      1.0                 0.994920   \n",
       "351             0.995297                      1.0                 0.995297   \n",
       "355             0.954527                      1.0                 0.954527   \n",
       "358             0.995086                      1.0                 0.995085   \n",
       "359             0.999824                      1.0                 0.999824   \n",
       "364             0.995293                      1.0                 0.995293   \n",
       "365             0.994639                      1.0                 0.994639   \n",
       "369             0.950860                      1.0                 0.950860   \n",
       "372             0.993821                      1.0                 0.993821   \n",
       "373             0.999838                      1.0                 0.999838   \n",
       "378             0.995455                      1.0                 0.995455   \n",
       "379             0.996120                      1.0                 0.996120   \n",
       "383             0.951564                      1.0                 0.951564   \n",
       "386             0.994671                      1.0                 0.994672   \n",
       "387             0.999847                      1.0                 0.999847   \n",
       "392             0.995759                      1.0                 0.995759   \n",
       "393             0.994243                      1.0                 0.994243   \n",
       "397             0.944099                      1.0                 0.944099   \n",
       "400             0.995635                      1.0                 0.995635   \n",
       "401             0.999829                      1.0                 0.999829   \n",
       "406             0.996039                      1.0                 0.996039   \n",
       "407             0.995877                      1.0                 0.995877   \n",
       "411             0.980962                      1.0                 0.980962   \n",
       "414             0.993743                      1.0                 0.993743   \n",
       "415             0.999854                      1.0                 0.999853   \n",
       "420             0.996270                      1.0                 0.996270   \n",
       "421             0.996578                      1.0                 0.996578   \n",
       "425             0.948715                      1.0                 0.948715   \n",
       "428             0.994670                      1.0                 0.994670   \n",
       "429             0.999876                      1.0                 0.999876   \n",
       "434             0.996472                      1.0                 0.996472   \n",
       "435             0.995470                      1.0                 0.995470   \n",
       "439             0.949915                      1.0                 0.949915   \n",
       "442             0.995147                      1.0                 0.995147   \n",
       "443             0.999865                      1.0                 0.999865   \n",
       "448             0.996667                      1.0                 0.996667   \n",
       "449             0.996482                      1.0                 0.996482   \n",
       "453             0.951048                      1.0                 0.951048   \n",
       "456             0.994311                      1.0                 0.994310   \n",
       "457             0.999794                      1.0                 0.999794   \n",
       "462             0.996857                      1.0                 0.996857   \n",
       "463             0.996299                      1.0                 0.996299   \n",
       "467             0.953887                      1.0                 0.953887   \n",
       "470             0.994887                      1.0                 0.994887   \n",
       "471             0.999898                      1.0                 0.999898   \n",
       "476             0.996936                      1.0                 0.996936   \n",
       "477             0.995442                      1.0                 0.995442   \n",
       "481             0.966334                      1.0                 0.966334   \n",
       "484             0.994877                      1.0                 0.994877   \n",
       "485             0.999925                      1.0                 0.999925   \n",
       "490             0.997244                      1.0                 0.997244   \n",
       "491             0.995037                      1.0                 0.995037   \n",
       "495             0.971872                      1.0                 0.971872   \n",
       "498             0.993008                      1.0                 0.993009   \n",
       "499             0.999849                      1.0                 0.999849   \n",
       "504             0.997428                      1.0                 0.997428   \n",
       "505             0.995718                      1.0                 0.995718   \n",
       "509             0.919561                      1.0                 0.919561   \n",
       "512             0.991455                      1.0                 0.991455   \n",
       "513             0.999932                      1.0                 0.999932   \n",
       "518             0.997613                      1.0                 0.997613   \n",
       "519             0.995635                      1.0                 0.995635   \n",
       "523             0.941210                      1.0                 0.941210   \n",
       "526             0.993166                      1.0                 0.993167   \n",
       "527             0.999871                      1.0                 0.999871   \n",
       "532             0.997674                      1.0                 0.997674   \n",
       "533             0.993915                      1.0                 0.993915   \n",
       "537             0.960291                      1.0                 0.960291   \n",
       "540             0.991130                      1.0                 0.991130   \n",
       "541             0.999888                      1.0                 0.999888   \n",
       "546             0.997761                      1.0                 0.997760   \n",
       "547             0.993192                      1.0                 0.993192   \n",
       "551             0.903269                      1.0                 0.903269   \n",
       "554             0.994757                      1.0                 0.994758   \n",
       "555             0.999869                      1.0                 0.999868   \n",
       "560             0.997859                      1.0                 0.997858   \n",
       "561             0.995574                      1.0                 0.995574   \n",
       "565             0.973735                      1.0                 0.973735   \n",
       "568             0.992557                      1.0                 0.992557   \n",
       "569             0.999756                      1.0                 0.999756   \n",
       "574             0.997923                      1.0                 0.997923   \n",
       "575             0.993042                      1.0                 0.993042   \n",
       "579             0.944913                      1.0                 0.944913   \n",
       "582             0.993074                      1.0                 0.993074   \n",
       "583             0.999885                      1.0                 0.999885   \n",
       "588             0.998028                      1.0                 0.998028   \n",
       "589             0.995281                      1.0                 0.995281   \n",
       "593             0.960473                      1.0                 0.960473   \n",
       "596             0.993381                      1.0                 0.993381   \n",
       "597             0.999848                      1.0                 0.999848   \n",
       "602             0.998030                      1.0                 0.998030   \n",
       "603             0.993351                      1.0                 0.993351   \n",
       "607             0.956671                      1.0                 0.956671   \n",
       "610             0.988646                      1.0                 0.988646   \n",
       "611             0.999884                      1.0                 0.999885   \n",
       "616             0.998119                      1.0                 0.998119   \n",
       "617             0.993002                      1.0                 0.993002   \n",
       "621             0.913275                      1.0                 0.913274   \n",
       "624             0.992221                      1.0                 0.992220   \n",
       "625             0.999897                      1.0                 0.999897   \n",
       "630             0.998236                      1.0                 0.998236   \n",
       "631             0.990339                      1.0                 0.990340   \n",
       "635             0.951792                      1.0                 0.951791   \n",
       "638             0.992180                      1.0                 0.992180   \n",
       "639             0.999961                      1.0                 0.999961   \n",
       "644             0.998277                      1.0                 0.998277   \n",
       "645             0.987526                      1.0                 0.987526   \n",
       "649             0.909879                      1.0                 0.909879   \n",
       "652             0.989623                      1.0                 0.989623   \n",
       "653             0.999951                      1.0                 0.999950   \n",
       "658             0.998305                      1.0                 0.998306   \n",
       "659             0.986884                      1.0                 0.986884   \n",
       "663             0.927824                      1.0                 0.927824   \n",
       "666             0.989851                      1.0                 0.989851   \n",
       "667             0.999974                      1.0                 0.999975   \n",
       "672             0.998384                      1.0                 0.998384   \n",
       "673             0.990906                      1.0                 0.990906   \n",
       "677             0.873983                      1.0                 0.873983   \n",
       "680             0.990946                      1.0                 0.990946   \n",
       "681             0.999925                      1.0                 0.999925   \n",
       "686             0.998416                      1.0                 0.998416   \n",
       "687             0.989774                      1.0                 0.989774   \n",
       "691             0.901897                      1.0                 0.901897   \n",
       "694             0.992115                      1.0                 0.992116   \n",
       "695             0.999959                      1.0                 0.999959   \n",
       "700             0.998449                      1.0                 0.998449   \n",
       "701             0.988923                      1.0                 0.988923   \n",
       "705             0.948857                      1.0                 0.948857   \n",
       "708             0.990221                      1.0                 0.990221   \n",
       "709             0.999966                      1.0                 0.999966   \n",
       "714             0.998444                      1.0                 0.998444   \n",
       "715             0.993983                      1.0                 0.993983   \n",
       "719             0.909388                      1.0                 0.909388   \n",
       "722             0.991443                      1.0                 0.991443   \n",
       "723             0.999912                      1.0                 0.999912   \n",
       "728             0.998470                      1.0                 0.998470   \n",
       "729             0.992558                      1.0                 0.992558   \n",
       "733             0.921500                      1.0                 0.921500   \n",
       "736             0.991587                      1.0                 0.991587   \n",
       "737             0.999943                      1.0                 0.999944   \n",
       "742             0.998452                      1.0                 0.998452   \n",
       "743             0.991294                      1.0                 0.991294   \n",
       "747             0.939840                      1.0                 0.939840   \n",
       "750             0.990979                      1.0                 0.990979   \n",
       "751             0.999964                      1.0                 0.999964   \n",
       "756             0.998443                      1.0                 0.998444   \n",
       "757             0.983217                      1.0                 0.983217   \n",
       "761             0.880664                      1.0                 0.880664   \n",
       "764             0.990067                      1.0                 0.990067   \n",
       "765             0.999954                      1.0                 0.999955   \n",
       "770             0.998302                      1.0                 0.998302   \n",
       "771             0.972363                      1.0                 0.972363   \n",
       "775             0.861877                      1.0                 0.861877   \n",
       "778             0.990058                      1.0                 0.990058   \n",
       "779             0.999952                      1.0                 0.999953   \n",
       "784             0.997948                      1.0                 0.997949   \n",
       "785             0.991023                      1.0                 0.991022   \n",
       "789             0.871921                      1.0                 0.871920   \n",
       "792             0.986934                      1.0                 0.986934   \n",
       "793             0.999921                      1.0                 0.999921   \n",
       "798             0.997274                      1.0                 0.997274   \n",
       "799             0.948076                      1.0                 0.948076   \n",
       "803             0.855079                      1.0                 0.855079   \n",
       "806             0.977215                      1.0                 0.977216   \n",
       "807             0.999871                      1.0                 0.999870   \n",
       "812             0.996672                      1.0                 0.996671   \n",
       "813             0.952422                      1.0                 0.952422   \n",
       "817             0.804283                      1.0                 0.804284   \n",
       "820             0.985603                      1.0                 0.985603   \n",
       "821             0.999832                      1.0                 0.999832   \n",
       "826             0.993864                      1.0                 0.993865   \n",
       "827             0.984470                      1.0                 0.984470   \n",
       "831             0.908353                      1.0                 0.908353   \n",
       "834             0.979456                      1.0                 0.979456   \n",
       "835             0.999894                      1.0                 0.999894   \n",
       "840             0.985737                      1.0                 0.985738   \n",
       "841             0.975739                      1.0                 0.975739   \n",
       "845             0.803287                      1.0                 0.803286   \n",
       "\n",
       "    shape_a shape_b note  \n",
       "0       NaN     NaN  NaN  \n",
       "4       NaN     NaN  NaN  \n",
       "5       NaN     NaN  NaN  \n",
       "9       NaN     NaN  NaN  \n",
       "12      NaN     NaN  NaN  \n",
       "16      NaN     NaN  NaN  \n",
       "17      NaN     NaN  NaN  \n",
       "21      NaN     NaN  NaN  \n",
       "24      NaN     NaN  NaN  \n",
       "28      NaN     NaN  NaN  \n",
       "29      NaN     NaN  NaN  \n",
       "33      NaN     NaN  NaN  \n",
       "36      NaN     NaN  NaN  \n",
       "37      NaN     NaN  NaN  \n",
       "42      NaN     NaN  NaN  \n",
       "43      NaN     NaN  NaN  \n",
       "47      NaN     NaN  NaN  \n",
       "50      NaN     NaN  NaN  \n",
       "51      NaN     NaN  NaN  \n",
       "56      NaN     NaN  NaN  \n",
       "57      NaN     NaN  NaN  \n",
       "61      NaN     NaN  NaN  \n",
       "64      NaN     NaN  NaN  \n",
       "65      NaN     NaN  NaN  \n",
       "70      NaN     NaN  NaN  \n",
       "71      NaN     NaN  NaN  \n",
       "75      NaN     NaN  NaN  \n",
       "78      NaN     NaN  NaN  \n",
       "79      NaN     NaN  NaN  \n",
       "84      NaN     NaN  NaN  \n",
       "85      NaN     NaN  NaN  \n",
       "89      NaN     NaN  NaN  \n",
       "92      NaN     NaN  NaN  \n",
       "93      NaN     NaN  NaN  \n",
       "98      NaN     NaN  NaN  \n",
       "99      NaN     NaN  NaN  \n",
       "103     NaN     NaN  NaN  \n",
       "106     NaN     NaN  NaN  \n",
       "107     NaN     NaN  NaN  \n",
       "112     NaN     NaN  NaN  \n",
       "113     NaN     NaN  NaN  \n",
       "117     NaN     NaN  NaN  \n",
       "120     NaN     NaN  NaN  \n",
       "121     NaN     NaN  NaN  \n",
       "126     NaN     NaN  NaN  \n",
       "127     NaN     NaN  NaN  \n",
       "131     NaN     NaN  NaN  \n",
       "134     NaN     NaN  NaN  \n",
       "135     NaN     NaN  NaN  \n",
       "140     NaN     NaN  NaN  \n",
       "141     NaN     NaN  NaN  \n",
       "145     NaN     NaN  NaN  \n",
       "148     NaN     NaN  NaN  \n",
       "149     NaN     NaN  NaN  \n",
       "154     NaN     NaN  NaN  \n",
       "155     NaN     NaN  NaN  \n",
       "159     NaN     NaN  NaN  \n",
       "162     NaN     NaN  NaN  \n",
       "163     NaN     NaN  NaN  \n",
       "168     NaN     NaN  NaN  \n",
       "169     NaN     NaN  NaN  \n",
       "173     NaN     NaN  NaN  \n",
       "176     NaN     NaN  NaN  \n",
       "177     NaN     NaN  NaN  \n",
       "182     NaN     NaN  NaN  \n",
       "183     NaN     NaN  NaN  \n",
       "187     NaN     NaN  NaN  \n",
       "190     NaN     NaN  NaN  \n",
       "191     NaN     NaN  NaN  \n",
       "196     NaN     NaN  NaN  \n",
       "197     NaN     NaN  NaN  \n",
       "201     NaN     NaN  NaN  \n",
       "204     NaN     NaN  NaN  \n",
       "205     NaN     NaN  NaN  \n",
       "210     NaN     NaN  NaN  \n",
       "211     NaN     NaN  NaN  \n",
       "215     NaN     NaN  NaN  \n",
       "218     NaN     NaN  NaN  \n",
       "219     NaN     NaN  NaN  \n",
       "224     NaN     NaN  NaN  \n",
       "225     NaN     NaN  NaN  \n",
       "229     NaN     NaN  NaN  \n",
       "232     NaN     NaN  NaN  \n",
       "233     NaN     NaN  NaN  \n",
       "238     NaN     NaN  NaN  \n",
       "239     NaN     NaN  NaN  \n",
       "243     NaN     NaN  NaN  \n",
       "246     NaN     NaN  NaN  \n",
       "247     NaN     NaN  NaN  \n",
       "252     NaN     NaN  NaN  \n",
       "253     NaN     NaN  NaN  \n",
       "257     NaN     NaN  NaN  \n",
       "260     NaN     NaN  NaN  \n",
       "261     NaN     NaN  NaN  \n",
       "266     NaN     NaN  NaN  \n",
       "267     NaN     NaN  NaN  \n",
       "271     NaN     NaN  NaN  \n",
       "274     NaN     NaN  NaN  \n",
       "275     NaN     NaN  NaN  \n",
       "280     NaN     NaN  NaN  \n",
       "281     NaN     NaN  NaN  \n",
       "285     NaN     NaN  NaN  \n",
       "288     NaN     NaN  NaN  \n",
       "289     NaN     NaN  NaN  \n",
       "294     NaN     NaN  NaN  \n",
       "295     NaN     NaN  NaN  \n",
       "299     NaN     NaN  NaN  \n",
       "302     NaN     NaN  NaN  \n",
       "303     NaN     NaN  NaN  \n",
       "308     NaN     NaN  NaN  \n",
       "309     NaN     NaN  NaN  \n",
       "313     NaN     NaN  NaN  \n",
       "316     NaN     NaN  NaN  \n",
       "317     NaN     NaN  NaN  \n",
       "322     NaN     NaN  NaN  \n",
       "323     NaN     NaN  NaN  \n",
       "327     NaN     NaN  NaN  \n",
       "330     NaN     NaN  NaN  \n",
       "331     NaN     NaN  NaN  \n",
       "336     NaN     NaN  NaN  \n",
       "337     NaN     NaN  NaN  \n",
       "341     NaN     NaN  NaN  \n",
       "344     NaN     NaN  NaN  \n",
       "345     NaN     NaN  NaN  \n",
       "350     NaN     NaN  NaN  \n",
       "351     NaN     NaN  NaN  \n",
       "355     NaN     NaN  NaN  \n",
       "358     NaN     NaN  NaN  \n",
       "359     NaN     NaN  NaN  \n",
       "364     NaN     NaN  NaN  \n",
       "365     NaN     NaN  NaN  \n",
       "369     NaN     NaN  NaN  \n",
       "372     NaN     NaN  NaN  \n",
       "373     NaN     NaN  NaN  \n",
       "378     NaN     NaN  NaN  \n",
       "379     NaN     NaN  NaN  \n",
       "383     NaN     NaN  NaN  \n",
       "386     NaN     NaN  NaN  \n",
       "387     NaN     NaN  NaN  \n",
       "392     NaN     NaN  NaN  \n",
       "393     NaN     NaN  NaN  \n",
       "397     NaN     NaN  NaN  \n",
       "400     NaN     NaN  NaN  \n",
       "401     NaN     NaN  NaN  \n",
       "406     NaN     NaN  NaN  \n",
       "407     NaN     NaN  NaN  \n",
       "411     NaN     NaN  NaN  \n",
       "414     NaN     NaN  NaN  \n",
       "415     NaN     NaN  NaN  \n",
       "420     NaN     NaN  NaN  \n",
       "421     NaN     NaN  NaN  \n",
       "425     NaN     NaN  NaN  \n",
       "428     NaN     NaN  NaN  \n",
       "429     NaN     NaN  NaN  \n",
       "434     NaN     NaN  NaN  \n",
       "435     NaN     NaN  NaN  \n",
       "439     NaN     NaN  NaN  \n",
       "442     NaN     NaN  NaN  \n",
       "443     NaN     NaN  NaN  \n",
       "448     NaN     NaN  NaN  \n",
       "449     NaN     NaN  NaN  \n",
       "453     NaN     NaN  NaN  \n",
       "456     NaN     NaN  NaN  \n",
       "457     NaN     NaN  NaN  \n",
       "462     NaN     NaN  NaN  \n",
       "463     NaN     NaN  NaN  \n",
       "467     NaN     NaN  NaN  \n",
       "470     NaN     NaN  NaN  \n",
       "471     NaN     NaN  NaN  \n",
       "476     NaN     NaN  NaN  \n",
       "477     NaN     NaN  NaN  \n",
       "481     NaN     NaN  NaN  \n",
       "484     NaN     NaN  NaN  \n",
       "485     NaN     NaN  NaN  \n",
       "490     NaN     NaN  NaN  \n",
       "491     NaN     NaN  NaN  \n",
       "495     NaN     NaN  NaN  \n",
       "498     NaN     NaN  NaN  \n",
       "499     NaN     NaN  NaN  \n",
       "504     NaN     NaN  NaN  \n",
       "505     NaN     NaN  NaN  \n",
       "509     NaN     NaN  NaN  \n",
       "512     NaN     NaN  NaN  \n",
       "513     NaN     NaN  NaN  \n",
       "518     NaN     NaN  NaN  \n",
       "519     NaN     NaN  NaN  \n",
       "523     NaN     NaN  NaN  \n",
       "526     NaN     NaN  NaN  \n",
       "527     NaN     NaN  NaN  \n",
       "532     NaN     NaN  NaN  \n",
       "533     NaN     NaN  NaN  \n",
       "537     NaN     NaN  NaN  \n",
       "540     NaN     NaN  NaN  \n",
       "541     NaN     NaN  NaN  \n",
       "546     NaN     NaN  NaN  \n",
       "547     NaN     NaN  NaN  \n",
       "551     NaN     NaN  NaN  \n",
       "554     NaN     NaN  NaN  \n",
       "555     NaN     NaN  NaN  \n",
       "560     NaN     NaN  NaN  \n",
       "561     NaN     NaN  NaN  \n",
       "565     NaN     NaN  NaN  \n",
       "568     NaN     NaN  NaN  \n",
       "569     NaN     NaN  NaN  \n",
       "574     NaN     NaN  NaN  \n",
       "575     NaN     NaN  NaN  \n",
       "579     NaN     NaN  NaN  \n",
       "582     NaN     NaN  NaN  \n",
       "583     NaN     NaN  NaN  \n",
       "588     NaN     NaN  NaN  \n",
       "589     NaN     NaN  NaN  \n",
       "593     NaN     NaN  NaN  \n",
       "596     NaN     NaN  NaN  \n",
       "597     NaN     NaN  NaN  \n",
       "602     NaN     NaN  NaN  \n",
       "603     NaN     NaN  NaN  \n",
       "607     NaN     NaN  NaN  \n",
       "610     NaN     NaN  NaN  \n",
       "611     NaN     NaN  NaN  \n",
       "616     NaN     NaN  NaN  \n",
       "617     NaN     NaN  NaN  \n",
       "621     NaN     NaN  NaN  \n",
       "624     NaN     NaN  NaN  \n",
       "625     NaN     NaN  NaN  \n",
       "630     NaN     NaN  NaN  \n",
       "631     NaN     NaN  NaN  \n",
       "635     NaN     NaN  NaN  \n",
       "638     NaN     NaN  NaN  \n",
       "639     NaN     NaN  NaN  \n",
       "644     NaN     NaN  NaN  \n",
       "645     NaN     NaN  NaN  \n",
       "649     NaN     NaN  NaN  \n",
       "652     NaN     NaN  NaN  \n",
       "653     NaN     NaN  NaN  \n",
       "658     NaN     NaN  NaN  \n",
       "659     NaN     NaN  NaN  \n",
       "663     NaN     NaN  NaN  \n",
       "666     NaN     NaN  NaN  \n",
       "667     NaN     NaN  NaN  \n",
       "672     NaN     NaN  NaN  \n",
       "673     NaN     NaN  NaN  \n",
       "677     NaN     NaN  NaN  \n",
       "680     NaN     NaN  NaN  \n",
       "681     NaN     NaN  NaN  \n",
       "686     NaN     NaN  NaN  \n",
       "687     NaN     NaN  NaN  \n",
       "691     NaN     NaN  NaN  \n",
       "694     NaN     NaN  NaN  \n",
       "695     NaN     NaN  NaN  \n",
       "700     NaN     NaN  NaN  \n",
       "701     NaN     NaN  NaN  \n",
       "705     NaN     NaN  NaN  \n",
       "708     NaN     NaN  NaN  \n",
       "709     NaN     NaN  NaN  \n",
       "714     NaN     NaN  NaN  \n",
       "715     NaN     NaN  NaN  \n",
       "719     NaN     NaN  NaN  \n",
       "722     NaN     NaN  NaN  \n",
       "723     NaN     NaN  NaN  \n",
       "728     NaN     NaN  NaN  \n",
       "729     NaN     NaN  NaN  \n",
       "733     NaN     NaN  NaN  \n",
       "736     NaN     NaN  NaN  \n",
       "737     NaN     NaN  NaN  \n",
       "742     NaN     NaN  NaN  \n",
       "743     NaN     NaN  NaN  \n",
       "747     NaN     NaN  NaN  \n",
       "750     NaN     NaN  NaN  \n",
       "751     NaN     NaN  NaN  \n",
       "756     NaN     NaN  NaN  \n",
       "757     NaN     NaN  NaN  \n",
       "761     NaN     NaN  NaN  \n",
       "764     NaN     NaN  NaN  \n",
       "765     NaN     NaN  NaN  \n",
       "770     NaN     NaN  NaN  \n",
       "771     NaN     NaN  NaN  \n",
       "775     NaN     NaN  NaN  \n",
       "778     NaN     NaN  NaN  \n",
       "779     NaN     NaN  NaN  \n",
       "784     NaN     NaN  NaN  \n",
       "785     NaN     NaN  NaN  \n",
       "789     NaN     NaN  NaN  \n",
       "792     NaN     NaN  NaN  \n",
       "793     NaN     NaN  NaN  \n",
       "798     NaN     NaN  NaN  \n",
       "799     NaN     NaN  NaN  \n",
       "803     NaN     NaN  NaN  \n",
       "806     NaN     NaN  NaN  \n",
       "807     NaN     NaN  NaN  \n",
       "812     NaN     NaN  NaN  \n",
       "813     NaN     NaN  NaN  \n",
       "817     NaN     NaN  NaN  \n",
       "820     NaN     NaN  NaN  \n",
       "821     NaN     NaN  NaN  \n",
       "826     NaN     NaN  NaN  \n",
       "827     NaN     NaN  NaN  \n",
       "831     NaN     NaN  NaN  \n",
       "834     NaN     NaN  NaN  \n",
       "835     NaN     NaN  NaN  \n",
       "840     NaN     NaN  NaN  \n",
       "841     NaN     NaN  NaN  \n",
       "845     NaN     NaN  NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8497a507-d473-4578-a227-3bbf455effdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RESULT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e93a2-b030-4b56-acd7-0dc94ca90462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751e1ea-8f9a-4fd8-8740-887fff124078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80be940-4c1c-46f0-9bae-fc2d9ba44492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739f144-414b-4c26-bfd2-4ce3b1304fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826dcbb-7a52-465a-9019-52cbaa637432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed9e25-9329-4fac-824c-5bf956272547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a31af2-fd52-4614-b10a-8b55da75a30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d5f18-367d-4d66-b89d-a0460cec2ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59d0bf-db74-48c8-99dd-a46b2d3c4e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1199fe6-ece3-456d-9864-382505306f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa165d4-203e-42cd-97d8-816252103c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81369-33c7-4a8e-a482-fd982b864f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-vmamedov-tmp]",
   "language": "python",
   "name": "conda-env-.mlspace-vmamedov-tmp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
